{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-16T18:34:14.011816209Z",
     "start_time": "2024-02-16T18:34:13.994723093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "' \\n2/13/23 - All methods related to decoding substrokes, wuickly made as extentions of dPCA, but not\\nactually using dpca at all.\\n\\nDecodes both shape and motor variables, various methods of conjunction.\\n\\nGoal: testing whether shape is strongly different for PMv.\\nWhereas for M1 the opposite is true (strong motor, conditioned on shape).\\n\\nScript: analyquick_decode_substrokes.py \\n\\n'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\" \n",
    "2/13/23 - All methods related to decoding substrokes, wuickly made as extentions of dPCA, but not\n",
    "actually using dpca at all.\n",
    "\n",
    "Decodes both shape and motor variables, various methods of conjunction.\n",
    "\n",
    "Goal: testing whether shape is strongly different for PMv.\n",
    "Whereas for M1 the opposite is true (strong motor, conditioned on shape).\n",
    "\n",
    "Script: analyquick_decode_substrokes.py \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quickly test decoding of both shape and motor-related params for each substroke.\n",
    "This is all very scratch.\n",
    "\n",
    "Notebook: 240128_snippets_demixed_PCA (althought this has nothing to do with that code).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pythonlib.tools.plottools import savefig\n",
    "from pythonlib.globals import PATH_ANALYSIS_OUTCOMES\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pythonlib.tools.expttools import writeDictToTxt\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "from neuralmonkey.scripts.analyquick_decode_substrokes import plot_summary_decode_results, load_saved_data, check_var_conti_discr\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T18:35:30.205472987Z",
     "start_time": "2024-02-16T18:35:30.181768583Z"
    }
   },
   "id": "3e0fff965e018190"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.3, 0)]\n",
      "Searching using this string:\n",
      "/mnt/Freiwald/ltian/recordings/*Pancho*/*220719*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/mnt/Freiwald/ltian/recordings/Pancho/220719/Pancho-220719-155517\n",
      "session:  0\n",
      "------------------------------\n",
      "Loading this neural session: 0\n",
      "Loading these beh expts: ['priminvar3e', 'priminvar3e']\n",
      "Loading these beh sessions: [1, 2]\n",
      "Using this beh_trial_map_list: [(1, 0), (1, 45)]\n",
      "Searching using this string:\n",
      "/mnt/Freiwald/ltian/recordings/*Pancho*/*220719*/**\n",
      "Found this many paths:\n",
      "1\n",
      "---\n",
      "/mnt/Freiwald/ltian/recordings/Pancho/220719/Pancho-220719-155517\n",
      "{'filename_components_hyphened': ['Pancho', '220719', '155517'], 'basedirs': ['/mnt/Freiwald/ltian/recordings/Pancho', '/mnt/Freiwald/ltian/recordings/Pancho/220719'], 'basedirs_filenames': ['220719', 'Pancho-220719-155517'], 'filename_final_ext': 'Pancho-220719-155517', 'filename_final_noext': 'Pancho-220719-155517'}\n",
      "FOund this path for spikes:  /mnt/Freiwald/ltian/recordings/Pancho/220719/Pancho-220719-155517/spikes_tdt_quick-3.5\n",
      "== PATHS for this expt: \n",
      "raws  --  /mnt/Freiwald/ltian/recordings/Pancho/220719/Pancho-220719-155517\n",
      "tank  --  /mnt/Freiwald/ltian/recordings/Pancho/220719/Pancho-220719-155517/Pancho-220719-155517\n",
      "spikes  --  /mnt/Freiwald/ltian/recordings/Pancho/220719/Pancho-220719-155517/spikes_tdt_quick-3.5\n",
      "final_dir_name  --  Pancho-220719-155517\n",
      "time  --  155517\n",
      "pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220719/Pancho-220719-155517\n",
      "tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220719/Pancho-220719-155517/data_tank.pkl\n",
      "spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220719/Pancho-220719-155517/data_spikes.pkl\n",
      "datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220719/Pancho-220719-155517/data_datall.pkl\n",
      "events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220719/Pancho-220719-155517/events_photodiode.pkl\n",
      "mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220719/Pancho-220719-155517/mapper_st2dat.pkl\n",
      "figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220719/Pancho-220719-155517/figs\n",
      "metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units\n",
      "cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/220719/Pancho-220719-155517/cached\n",
      "Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/220719.yaml\n",
      "updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')\n",
      "[_sitesdirty_update] skipping! since did not find:  sites_error_spikes\n",
      "Printing whether spikes gotten (o) or not (-) because of spike peak to trough\n",
      "== Loading TDT tank\n",
      "** Loading tank data from local (previusly cached)\n",
      "== Done\n",
      "== Trying to load events data\n",
      "Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/220719/Pancho-220719-155517/events_photodiode.pkl\n",
      "== Done\n",
      "** MINIMAL_LOADING, therefore loading previuosly cached data\n",
      "=== CLEANING UP self.Dat (_cleanup_reloading_saved_state) ===== \n",
      "0 _behclass_alignsim_compute\n",
      "200 _behclass_alignsim_compute\n",
      "400 _behclass_alignsim_compute\n",
      "600 _behclass_alignsim_compute\n",
      "Running D._behclass_tokens_extract_datsegs\n",
      "0 _behclass_tokens_extract_datsegs\n",
      "200 _behclass_tokens_extract_datsegs\n",
      "400 _behclass_tokens_extract_datsegs\n",
      "600 _behclass_tokens_extract_datsegs\n",
      "stored in self.Dat[BehClass]\n",
      "- starting/ending len (grouping params):\n",
      "672\n",
      "672\n",
      "- starting/ending len (getting sequence):\n",
      "672\n",
      "672\n",
      "--- Removing nans\n",
      "start len: 672\n",
      "- num names for each col\n",
      "not removing nans, since columns=[]\n",
      "ADded new column: supervision_online\n",
      "Reassigned train/test, using key: probe\n",
      "and values:\n",
      "Train =  [0]\n",
      "Test =  [1]\n",
      " \n",
      "New distribution of train/test:\n",
      "train    672\n",
      "Name: monkey_train_or_test, dtype: int64\n",
      "Appended column: los_info\n",
      "Appended self.Dat[superv_SEQUENCE_SUP]\n",
      "Appended self.Dat[superv_SEQUENCE_ALPHA]\n",
      "Appended self.Dat[superv_COLOR_ON]\n",
      "Appended self.Dat[superv_COLOR_ITEMS_FADE_TO_DEFAULT_BINSTR]\n",
      "Appended self.Dat[superv_COLOR_METHOD]\n",
      "Appended self.Dat[superv_GUIDEDYN_ON]\n",
      "Appended self.Dat[superv_VISUALFB_METH]\n",
      "appended col to self.Dat:\n",
      "supervision_stage_new\n",
      "[taskgroup_reassign_by_mapper], reassigned values in column: taskgroup\n",
      "GROUPING epoch\n",
      "GROUPING_LEVELS ['220719']\n",
      "FEATURE_NAMES ['hdoffline', 'num_strokes_beh', 'num_strokes_task', 'circ', 'dist']\n",
      "SCORE_COL_NAMES []\n",
      "appended col to self.Dat:\n",
      "date_epoch\n",
      "Appended self.Dat[superv_SEQUENCE_SUP]\n",
      "Appended self.Dat[superv_COLOR_ON]\n",
      "Appended self.Dat[superv_COLOR_METHOD]\n",
      "Appended self.Dat[superv_COLOR_ITEMS_FADE_TO_DEFAULT_BINSTR]\n",
      "Appended self.Dat[superv_GUIDEDYN_ON]\n",
      "appended col to self.Dat:\n",
      "supervision_stage_concise\n",
      "Append column to self.Dat:  supervision_stage_semantic\n",
      "Extracted into self.Dat[epoch_orig]\n",
      "... Generated these...\n",
      "self.BehTrialMapList [(1, 0), (1, 45)]\n",
      "self.BehTrialMapListGood {0: (0, 1), 1: (0, 2), 2: (0, 3), 3: (0, 4), 4: (0, 5), 5: (0, 6), 6: (0, 7), 7: (0, 8), 8: (0, 9), 9: (0, 10), 10: (0, 11), 11: (0, 12), 12: (0, 13), 13: (0, 14), 14: (0, 15), 15: (0, 16), 16: (0, 17), 17: (0, 18), 18: (0, 19), 19: (0, 20), 20: (0, 21), 21: (0, 22), 22: (0, 23), 23: (0, 24), 24: (0, 25), 25: (0, 26), 26: (0, 27), 27: (0, 28), 28: (0, 29), 29: (0, 30), 30: (0, 31), 31: (0, 32), 32: (0, 33), 33: (0, 34), 34: (0, 35), 35: (0, 36), 36: (0, 37), 37: (0, 38), 38: (0, 39), 39: (0, 40), 40: (0, 41), 41: (0, 42), 42: (0, 43), 43: (0, 44), 44: (0, 45), 45: (1, 1), 46: (1, 2), 47: (1, 3), 48: (1, 4), 49: (1, 5), 50: (1, 6), 51: (1, 7), 52: (1, 8), 53: (1, 9), 54: (1, 10), 55: (1, 11), 56: (1, 12), 57: (1, 13), 58: (1, 14), 59: (1, 15), 60: (1, 16), 61: (1, 17), 62: (1, 18), 63: (1, 19), 64: (1, 20), 65: (1, 21), 66: (1, 22), 67: (1, 23), 68: (1, 24), 69: (1, 25), 70: (1, 26), 71: (1, 27), 72: (1, 28), 73: (1, 29), 74: (1, 30), 75: (1, 31), 76: (1, 32), 77: (1, 33), 78: (1, 34), 79: (1, 35), 80: (1, 36), 81: (1, 37), 82: (1, 38), 83: (1, 39), 84: (1, 40), 85: (1, 41), 86: (1, 42), 87: (1, 43), 88: (1, 44), 89: (1, 45), 90: (1, 46), 91: (1, 47), 92: (1, 48), 93: (1, 49), 94: (1, 50), 95: (1, 51), 96: (1, 52), 97: (1, 53), 98: (1, 54), 99: (1, 55), 100: (1, 56), 101: (1, 57), 102: (1, 58), 103: (1, 59), 104: (1, 60), 105: (1, 61), 106: (1, 62), 107: (1, 63), 108: (1, 64), 109: (1, 65), 110: (1, 66), 111: (1, 67), 112: (1, 68), 113: (1, 69), 114: (1, 70), 115: (1, 71), 116: (1, 72), 117: (1, 73), 118: (1, 74), 119: (1, 75), 120: (1, 76), 121: (1, 77), 122: (1, 78), 123: (1, 79), 124: (1, 80), 125: (1, 81), 126: (1, 82), 127: (1, 83), 128: (1, 84), 129: (1, 85), 130: (1, 86), 131: (1, 87), 132: (1, 88), 133: (1, 89), 134: (1, 90), 135: (1, 91), 136: (1, 92), 137: (1, 93), 138: (1, 94), 139: (1, 95), 140: (1, 96), 141: (1, 97), 142: (1, 98), 143: (1, 99), 144: (1, 100), 145: (1, 101), 146: (1, 102), 147: (1, 103), 148: (1, 104), 149: (1, 105), 150: (1, 106), 151: (1, 107), 152: (1, 108), 153: (1, 109), 154: (1, 110), 155: (1, 111), 156: (1, 112), 157: (1, 113), 158: (1, 114), 159: (1, 115), 160: (1, 116), 161: (1, 117), 162: (1, 118), 163: (1, 119), 164: (1, 120), 165: (1, 121), 166: (1, 122), 167: (1, 123), 168: (1, 124), 169: (1, 125), 170: (1, 126), 171: (1, 127), 172: (1, 128), 173: (1, 129), 174: (1, 130), 175: (1, 131), 176: (1, 132), 177: (1, 133), 178: (1, 134), 179: (1, 135), 180: (1, 136), 181: (1, 137), 182: (1, 138), 183: (1, 139), 184: (1, 140), 185: (1, 141), 186: (1, 142), 187: (1, 143), 188: (1, 144), 189: (1, 145), 190: (1, 146), 191: (1, 147), 192: (1, 148), 193: (1, 149), 194: (1, 150), 195: (1, 151), 196: (1, 152), 197: (1, 153), 198: (1, 154), 199: (1, 155), 200: (1, 156), 201: (1, 157), 202: (1, 158), 203: (1, 159), 204: (1, 160), 205: (1, 161), 206: (1, 162), 207: (1, 163), 208: (1, 164), 209: (1, 165), 210: (1, 166), 211: (1, 167), 212: (1, 168), 213: (1, 169), 214: (1, 170), 215: (1, 171), 216: (1, 172), 217: (1, 173), 218: (1, 174), 219: (1, 175), 220: (1, 176), 221: (1, 177), 222: (1, 178), 223: (1, 179), 224: (1, 180), 225: (1, 181), 226: (1, 182), 227: (1, 183), 228: (1, 184), 229: (1, 185), 230: (1, 186), 231: (1, 187), 232: (1, 188), 233: (1, 189), 234: (1, 190), 235: (1, 191), 236: (1, 192), 237: (1, 193), 238: (1, 194), 239: (1, 195), 240: (1, 196), 241: (1, 197), 242: (1, 198), 243: (1, 199), 244: (1, 200), 245: (1, 201), 246: (1, 202), 247: (1, 203), 248: (1, 204), 249: (1, 205), 250: (1, 206), 251: (1, 207), 252: (1, 208), 253: (1, 209), 254: (1, 210), 255: (1, 211), 256: (1, 212), 257: (1, 213), 258: (1, 214), 259: (1, 215), 260: (1, 216), 261: (1, 217), 262: (1, 218), 263: (1, 219), 264: (1, 220), 265: (1, 221), 266: (1, 222), 267: (1, 223), 268: (1, 224), 269: (1, 225), 270: (1, 226), 271: (1, 227), 272: (1, 228), 273: (1, 229), 274: (1, 230), 275: (1, 231), 276: (1, 232), 277: (1, 233), 278: (1, 234), 279: (1, 235), 280: (1, 236), 281: (1, 237), 282: (1, 238), 283: (1, 239), 284: (1, 240), 285: (1, 241), 286: (1, 242), 287: (1, 243), 288: (1, 244), 289: (1, 245), 290: (1, 246), 291: (1, 247), 292: (1, 248), 293: (1, 249), 294: (1, 250), 295: (1, 251), 296: (1, 252), 297: (1, 253), 298: (1, 254), 299: (1, 255), 300: (1, 256), 301: (1, 257), 302: (1, 258), 303: (1, 259), 304: (1, 260), 305: (1, 261), 306: (1, 262), 307: (1, 263), 308: (1, 264), 309: (1, 265), 310: (1, 266), 311: (1, 267), 312: (1, 268), 313: (1, 269), 314: (1, 270), 315: (1, 271), 316: (1, 272), 317: (1, 273), 318: (1, 274), 319: (1, 275), 320: (1, 276), 321: (1, 277), 322: (1, 278), 323: (1, 279), 324: (1, 280), 325: (1, 281), 326: (1, 282), 327: (1, 283), 328: (1, 284), 329: (1, 285), 330: (1, 286), 331: (1, 287), 332: (1, 288), 333: (1, 289), 334: (1, 290), 335: (1, 291), 336: (1, 292), 337: (1, 293), 338: (1, 294), 339: (1, 295), 340: (1, 296), 341: (1, 297), 342: (1, 298), 343: (1, 299), 344: (1, 300), 345: (1, 301), 346: (1, 302), 347: (1, 303), 348: (1, 304), 349: (1, 305), 350: (1, 306), 351: (1, 307), 352: (1, 308), 353: (1, 309), 354: (1, 310), 355: (1, 311), 356: (1, 312), 357: (1, 313), 358: (1, 314), 359: (1, 315), 360: (1, 316), 361: (1, 317), 362: (1, 318), 363: (1, 319), 364: (1, 320), 365: (1, 321), 366: (1, 322), 367: (1, 323), 368: (1, 324), 369: (1, 325), 370: (1, 326), 371: (1, 327), 372: (1, 328), 373: (1, 329), 374: (1, 330), 375: (1, 331), 376: (1, 332), 377: (1, 333), 378: (1, 334), 379: (1, 335), 380: (1, 336), 381: (1, 337), 382: (1, 338), 383: (1, 339), 384: (1, 340), 385: (1, 341), 386: (1, 342), 387: (1, 343), 388: (1, 344), 389: (1, 345), 390: (1, 346), 391: (1, 347), 392: (1, 348), 393: (1, 349), 394: (1, 350), 395: (1, 351), 396: (1, 352), 397: (1, 353), 398: (1, 354), 399: (1, 355), 400: (1, 356), 401: (1, 357), 402: (1, 358), 403: (1, 359), 404: (1, 360), 405: (1, 361), 406: (1, 362), 407: (1, 363), 408: (1, 364), 409: (1, 365), 410: (1, 366), 411: (1, 367), 412: (1, 368), 413: (1, 369), 414: (1, 370), 415: (1, 371), 416: (1, 372), 417: (1, 373), 418: (1, 374), 419: (1, 375), 420: (1, 376), 421: (1, 377), 422: (1, 378), 423: (1, 379), 424: (1, 380), 425: (1, 381), 426: (1, 382), 427: (1, 383), 428: (1, 384), 429: (1, 385), 430: (1, 386), 431: (1, 387), 432: (1, 388), 433: (1, 389), 434: (1, 390), 435: (1, 391), 436: (1, 392), 437: (1, 393), 438: (1, 394), 439: (1, 395), 440: (1, 396), 441: (1, 397), 442: (1, 398), 443: (1, 399), 444: (1, 400), 445: (1, 401), 446: (1, 402), 447: (1, 403), 448: (1, 404), 449: (1, 405), 450: (1, 406), 451: (1, 407), 452: (1, 408), 453: (1, 409), 454: (1, 410), 455: (1, 411), 456: (1, 412), 457: (1, 413), 458: (1, 414), 459: (1, 415), 460: (1, 416), 461: (1, 417), 462: (1, 418), 463: (1, 419), 464: (1, 420), 465: (1, 421), 466: (1, 422), 467: (1, 423), 468: (1, 424), 469: (1, 425), 470: (1, 426), 471: (1, 427), 472: (1, 428), 473: (1, 429), 474: (1, 430), 475: (1, 431), 476: (1, 432), 477: (1, 433), 478: (1, 434), 479: (1, 435), 480: (1, 436), 481: (1, 437), 482: (1, 438), 483: (1, 439), 484: (1, 440), 485: (1, 441), 486: (1, 442), 487: (1, 443), 488: (1, 444), 489: (1, 445), 490: (1, 446), 491: (1, 447), 492: (1, 448), 493: (1, 449), 494: (1, 450), 495: (1, 451), 496: (1, 452), 497: (1, 453), 498: (1, 454), 499: (1, 455), 500: (1, 456), 501: (1, 457), 502: (1, 458), 503: (1, 459), 504: (1, 460), 505: (1, 461), 506: (1, 462), 507: (1, 463), 508: (1, 464), 509: (1, 465), 510: (1, 466), 511: (1, 467), 512: (1, 468), 513: (1, 469), 514: (1, 470), 515: (1, 471), 516: (1, 472), 517: (1, 473), 518: (1, 474), 519: (1, 475), 520: (1, 476), 521: (1, 477), 522: (1, 478), 523: (1, 479), 524: (1, 480), 525: (1, 481), 526: (1, 482), 527: (1, 483), 528: (1, 484), 529: (1, 485), 530: (1, 486), 531: (1, 487), 532: (1, 488), 533: (1, 489), 534: (1, 490), 535: (1, 491), 536: (1, 492), 537: (1, 493), 538: (1, 494), 539: (1, 495), 540: (1, 496), 541: (1, 497), 542: (1, 498), 543: (1, 499), 544: (1, 500), 545: (1, 501), 546: (1, 502), 547: (1, 503), 548: (1, 504), 549: (1, 505), 550: (1, 506), 551: (1, 507), 552: (1, 508), 553: (1, 509), 554: (1, 510), 555: (1, 511), 556: (1, 512), 557: (1, 513), 558: (1, 514), 559: (1, 515), 560: (1, 516), 561: (1, 517), 562: (1, 518), 563: (1, 519), 564: (1, 520), 565: (1, 521), 566: (1, 522), 567: (1, 523), 568: (1, 524), 569: (1, 525), 570: (1, 526), 571: (1, 527), 572: (1, 528), 573: (1, 529), 574: (1, 530), 575: (1, 531), 576: (1, 532), 577: (1, 533), 578: (1, 534), 579: (1, 535), 580: (1, 536), 581: (1, 537), 582: (1, 538), 583: (1, 539), 584: (1, 540), 585: (1, 541), 586: (1, 542), 587: (1, 543), 588: (1, 544), 589: (1, 545), 590: (1, 546), 591: (1, 547), 592: (1, 548), 593: (1, 549), 594: (1, 550), 595: (1, 551), 596: (1, 552), 597: (1, 553), 598: (1, 554), 599: (1, 555), 600: (1, 556), 601: (1, 557), 602: (1, 558), 603: (1, 559), 604: (1, 560), 605: (1, 561), 606: (1, 562), 607: (1, 563), 608: (1, 564), 609: (1, 565), 610: (1, 566), 611: (1, 567), 612: (1, 568), 613: (1, 569), 614: (1, 570), 615: (1, 571), 616: (1, 572), 617: (1, 573), 618: (1, 574), 619: (1, 575), 620: (1, 576), 621: (1, 577), 622: (1, 578), 623: (1, 579), 624: (1, 580), 625: (1, 581), 626: (1, 582), 627: (1, 583), 628: (1, 584), 629: (1, 585), 630: (1, 586), 631: (1, 587), 632: (1, 588), 633: (1, 589), 634: (1, 590), 635: (1, 591), 636: (1, 592), 637: (1, 593), 638: (1, 594), 639: (1, 595), 640: (1, 596), 641: (1, 597), 642: (1, 598), 643: (1, 599), 644: (1, 600), 645: (1, 601), 646: (1, 602), 647: (1, 603), 648: (1, 604), 649: (1, 605), 650: (1, 606), 651: (1, 607), 652: (1, 608), 653: (1, 609), 654: (1, 610), 655: (1, 611), 656: (1, 612), 657: (1, 613), 658: (1, 614), 659: (1, 615), 660: (1, 616), 661: (1, 617), 662: (1, 618), 663: (1, 619), 664: (1, 620), 665: (1, 621), 666: (1, 622), 667: (1, 623), 668: (1, 624), 669: (1, 625), 670: (1, 626), 671: (1, 627), 672: (1, 628), 673: (1, 629), 674: (1, 630), 675: (1, 631), 676: (1, 632), 677: (1, 633), 678: (1, 634), 679: (1, 635), 680: (1, 636), 681: (1, 637), 682: (1, 638), 683: (1, 639), 684: (1, 640), 685: (1, 641), 686: (1, 642), 687: (1, 643), 688: (1, 644), 689: (1, 645), 690: (1, 646), 691: (1, 647), 692: (1, 648), 693: (1, 649), 694: (1, 650), 695: (1, 651), 696: (1, 652), 697: (1, 653)}\n",
      "Generated self._MapperTrialcode2TrialToTrial!\n",
      "Extracted into self.Dat[epoch_orig]\n",
      "Extracted successfully for session:  0\n",
      "Generated index mappers!\n",
      "Loading:  /gorilla1/analyses/recordings/main/anova/bysubstroke/Pancho-220719-sess_0/DfScalar.pkl\n",
      "Loading:  /gorilla1/analyses/recordings/main/anova/bysubstroke/Pancho-220719-sess_0/fr_sm_times.pkl\n",
      "Loading:  /gorilla1/analyses/recordings/main/anova/bysubstroke/Pancho-220719-sess_0/DS.pkl\n",
      "Loading:  /gorilla1/analyses/recordings/main/anova/bysubstroke/Pancho-220719-sess_0/Params.pkl\n",
      "Loading:  /gorilla1/analyses/recordings/main/anova/bysubstroke/Pancho-220719-sess_0/ParamsGlobals.pkl\n",
      "Loading:  /gorilla1/analyses/recordings/main/anova/bysubstroke/Pancho-220719-sess_0/Sites.pkl\n",
      "Loading:  /gorilla1/analyses/recordings/main/anova/bysubstroke/Pancho-220719-sess_0/Trials.pkl\n",
      "This many vals across loaded session\n",
      "0 : 621665\n",
      "Done!, new len of dataset 648\n",
      "Assigning to SP.Params this item:\n",
      "{'which_level': 'substroke', '_list_events': ['00_substrk'], 'list_events_uniqnames': ['00_substrk'], 'list_features_extraction': ['shape', 'index_within_stroke', 'circularity_binned', 'distcum_binned', 'angle_binned', 'dist_angle'], 'list_features_get_conjunction': [], 'list_pre_dur': [-0.6], 'list_post_dur': [0.6], 'map_var_to_othervars': None, 'strokes_only_keep_single': None, 'tasks_only_keep_these': None, 'prune_feature_levels_min_n_trials': 1, 'fr_which_version': 'sqrt', 'SPIKES_VERSION': 'tdt', 'map_var_to_levels': None}\n",
      "Assigning to SP.ParamsGlobals this item:\n",
      "{'n_min_trials_per_level': 5, 'lenient_allow_data_if_has_n_levels': 2, 'PRE_DUR_CALC': -0.6, 'POST_DUR_CALC': 0.6, 'list_events': ['00_substrk'], 'list_pre_dur': [-0.6], 'list_post_dur': [0.6]}\n",
      "Keeping this many sites that pass fr thresh:\n",
      "445 / 445\n",
      "Using threshold:  1.5\n",
      "Updated self.Sites\n",
      "Done!, new len of dataset 672\n",
      "Dataset preprocess, these params:\n",
      "{'DO_CHARSEQ_VER': None, 'EXTRACT_EPOCHSETS': False, 'EXTRACT_EPOCHSETS_trial_label': None, 'EXTRACT_EPOCHSETS_n_max_epochs': None, 'EXTRACT_EPOCHSETS_merge_sets': None, 'taskgroup_reassign_simple_neural': False, 'preprocess_steps_append': ['remove_online_abort', 'beh_strokes_at_least_one'], 'remove_aborts': False, 'list_superv_keep': None, 'list_superv_keep_full': None, 'DO_SCORE_SEQUENCE_VER': None, 'list_epoch_merge': [], 'epoch_merge_key': None, 'DO_EXTRACT_EPOCHKIND': False, 'datasetstrokes_extract_to_prune_trial': None, 'datasetstrokes_extract_to_prune_stroke': None, 'substrokes_features_do_extraction': True}\n",
      "Appended columns gridsize!\n",
      "Num nan/total, for angle_overall\n",
      "671 / 672\n",
      "Num nan/total, for num_strokes_beh\n",
      "0 / 672\n",
      "Num nan/total, for num_strokes_task\n",
      "0 / 672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gorilla1/code/pythonlib/pythonlib/drawmodel/features.py:183: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return [1-p/t for p,t in zip(displace,distance)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num nan/total, for circ\n",
      "1 / 672\n",
      "Num nan/total, for dist\n",
      "0 / 672\n",
      "Added these features:\n",
      "['FEAT_angle_overall', 'FEAT_num_strokes_beh', 'FEAT_num_strokes_task', 'FEAT_circ', 'FEAT_dist']\n",
      ".. Appended new column 'char_seq', version: task_matlab\n",
      "Starting length of D.Dat: 672\n",
      "--BEFORE REMOVE; existing supervision_stage_concise:\n",
      "off|0||1111|0    672\n",
      "Name: supervision_stage_concise, dtype: int64\n",
      "############ TAKING ONLY NO SUPERVISION TRIALS\n",
      "*** RUNNING D.preprocessGood using these params:\n",
      "['no_supervision']\n",
      "-- Len of D, before applying this param: no_supervision, ... 672\n",
      "after: 672\n",
      "Dataset final len: 672\n",
      "*** RUNNING D.preprocessGood using these params:\n",
      "['remove_online_abort', 'beh_strokes_at_least_one']\n",
      "-- Len of D, before applying this param: remove_online_abort, ... 672\n",
      "after: 671\n",
      "-- Len of D, before applying this param: beh_strokes_at_least_one, ... 671\n",
      "after: 671\n",
      "clean_preprocess_data...\n",
      "len of DS.Dat = 1397, before running... dataset_missing_stroke_in_context\n",
      "Removing these inds from DS, since missing context:\n",
      "[6, 7, 11, 12, 14, 15, 31, 32, 33, 38, 39, 54, 58, 59, 65, 70, 71, 90, 91, 128, 129, 138, 139, 157, 158, 177, 178, 179, 180, 181, 195, 196, 224, 228, 229, 233, 234, 249, 250, 257, 258, 259, 285, 286, 289, 290, 310, 311, 318, 319, 324, 336, 337, 391, 392, 393, 394, 422, 434, 435, 438, 439, 440, 450, 451, 457, 458, 472, 473, 487, 488, 512, 513, 545, 546, 552, 553, 578, 579, 580, 581, 584, 585, 590, 591, 592, 622, 623, 628, 629, 642, 643, 647, 648, 677, 678, 682, 683, 688, 689, 692, 693, 696, 697, 723, 724, 744, 745, 746, 794, 795, 815, 816, 817, 822, 823, 831, 844, 845, 846, 847, 874, 875, 876, 877, 901, 902, 903, 912, 913, 914, 920, 921, 930, 931, 944, 945, 965, 966, 975, 976, 984, 986, 987, 988, 993, 994, 995, 999, 1000, 1017, 1018, 1031, 1032, 1033, 1051, 1052, 1056, 1059, 1081, 1082, 1089, 1095, 1096, 1111, 1112, 1140, 1141, 1145, 1154, 1155, 1200, 1201, 1202, 1205, 1206, 1209, 1210, 1211, 1212, 1213, 1218, 1219, 1221, 1222, 1235, 1236, 1237, 1253, 1254, 1268, 1269, 1275, 1280, 1281, 1282, 1314, 1315, 1316, 1317, 1324, 1325, 1331, 1336, 1337, 1350, 1366]\n",
      "New len:  1190\n",
      "clean_preprocess_data...\n",
      "len of DS.Dat = 1190, before running... stroke_too_short\n",
      "Doing...: stroke_too_short\n",
      "New len:  1190\n",
      "len of DS.Dat = 1190, before running... stroke_too_quick\n",
      "Doing...: stroke_too_quick\n",
      "New len:  1190\n",
      "Starting len dfscalar:  621665\n",
      "Ending len dfscalar:  620775\n",
      " --- Pruning SP.DfScalar to match DS... start len:  620775\n",
      "... End len:  529550\n",
      "Appending...  aborted\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "aborted\n",
      "Appending...  FEAT_num_strokes_task\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "FEAT_num_strokes_task\n",
      "Appending...  FEAT_num_strokes_beh\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "FEAT_num_strokes_beh\n",
      "Appending...  character\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "character\n",
      "Appending...  probe\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "probe\n",
      "Appending...  supervision_stage_concise\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "supervision_stage_concise\n",
      "Appending...  epoch_orig\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "epoch_orig\n",
      "Appending...  epoch\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "epoch\n",
      "Appending...  taskgroup\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "taskgroup\n",
      "Appending...  origin\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "origin\n",
      "Appending...  donepos\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "donepos\n",
      "Appending...  seqc_0_shape\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "seqc_0_shape\n",
      "Appending...  seqc_0_loc\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "seqc_0_loc\n",
      "Appending...  seqc_1_shape\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "seqc_1_shape\n",
      "Appending...  seqc_1_loc\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "seqc_1_loc\n",
      "Appending...  seqc_nstrokes_beh\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "seqc_nstrokes_beh\n",
      "Appending...  seqc_nstrokes_task\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "seqc_nstrokes_task\n",
      "Appending...  stroke_index_fromlast_tskstks\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "stroke_index_fromlast_tskstks\n",
      "Appending...  stroke_index_semantic_tskstks\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "stroke_index_semantic_tskstks\n",
      "Appending...  CTXT_loc_next\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "CTXT_loc_next\n",
      "Appending...  CTXT_shape_next\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "CTXT_shape_next\n",
      "Appending...  CTXT_loc_prev\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "CTXT_loc_prev\n",
      "Appending...  CTXT_shape_prev\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "CTXT_shape_prev\n",
      "Appending...  gap_from_prev_angle_binned\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "gap_from_prev_angle_binned\n",
      "Appending...  gap_to_next_angle_binned\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "gap_to_next_angle_binned\n",
      "Appending...  gap_from_prev_angle\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "gap_from_prev_angle\n",
      "Appending...  gap_to_next_angle\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "gap_to_next_angle\n",
      "Appending...  circ_signed\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "circ_signed\n",
      "Appending...  velocity\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "velocity\n",
      "Appending...  distcum\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "distcum\n",
      "Appending...  angle\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "angle\n",
      "Appending...  circ_signed_binned\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "circ_signed_binned\n",
      "Appending...  velocity_binned\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "velocity_binned\n",
      "Appending...  di_an_ci_ve_bin\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "di_an_ci_ve_bin\n",
      "Appending...  ss_this_ctxt\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "ss_this_ctxt\n",
      "Appending...  CTXT_prev_next\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "CTXT_prev_next\n",
      "Appending...  CTXT_prev_this_next\n",
      "Updating this column of self.DfScalar with Dataset beh:\n",
      "CTXT_prev_this_next\n",
      "Colected 1190 out of 1190 datapts.\n",
      "NOTE: missed datapts are likely because of removed outliers\n",
      "00_substrk M1 (-0.3, 0)\n",
      "Sites for this bregion  M1\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "00_substrk  --  M1  --  (-0.3, 0)  -- (data shape:) (57, 1190, 30)\n",
      "00_substrk PMv (-0.3, 0)\n",
      "Sites for this bregion  PMv\n",
      "[97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 116, 117, 118, 119, 121, 122, 123, 124, 126, 127]\n",
      "00_substrk  --  PMv  --  (-0.3, 0)  -- (data shape:) (26, 1190, 30)\n",
      "00_substrk PMd (-0.3, 0)\n",
      "Sites for this bregion  PMd\n",
      "[130, 132, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192]\n",
      "00_substrk  --  PMd  --  (-0.3, 0)  -- (data shape:) (56, 1190, 30)\n",
      "00_substrk dlPFC (-0.3, 0)\n",
      "Sites for this bregion  dlPFC\n",
      "[193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 213, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 230, 231, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256]\n",
      "00_substrk  --  dlPFC  --  (-0.3, 0)  -- (data shape:) (55, 1190, 30)\n",
      "00_substrk vlPFC (-0.3, 0)\n",
      "Sites for this bregion  vlPFC\n",
      "[257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320]\n",
      "00_substrk  --  vlPFC  --  (-0.3, 0)  -- (data shape:) (62, 1190, 30)\n",
      "00_substrk FP (-0.3, 0)\n",
      "Sites for this bregion  FP\n",
      "[322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 336, 337, 339, 341, 342, 343, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 358, 360, 361, 362, 364, 366, 367, 368, 369, 370, 371, 373, 374, 375, 376, 377, 380, 381, 383, 384]\n",
      "00_substrk  --  FP  --  (-0.3, 0)  -- (data shape:) (50, 1190, 30)\n",
      "00_substrk SMA (-0.3, 0)\n",
      "Sites for this bregion  SMA\n",
      "[385, 386, 387, 388, 389, 390, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 429, 430, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 445, 447]\n",
      "00_substrk  --  SMA  --  (-0.3, 0)  -- (data shape:) (56, 1190, 30)\n",
      "00_substrk preSMA (-0.3, 0)\n",
      "Sites for this bregion  preSMA\n",
      "[449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512]\n",
      "00_substrk  --  preSMA  --  (-0.3, 0)  -- (data shape:) (59, 1190, 30)\n",
      "(30, 57, 29, 10)\n",
      "('Lcentered-4-2-0',) [2, 34]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-4-3-0',) [19]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-4-4-0',) [3]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-6-3-0',) [16, 30, 65, 95, 97, 123, 171, 183, 219, 230, 248, 254, 266, 275, 296, 347, 365, 383, 400, 408, 411, 432, 464, 507, 512, 521, 538]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-6-4-0',) [25, 60, 62, 77, 106, 130, 160, 168, 239, 262, 330, 379, 434, 497, 520]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-6-5-0',) [26, 35, 43, 54, 110, 114, 120, 170, 184, 206, 237, 238, 259, 308, 312, 324, 352, 370, 394, 407, 444, 447, 451, 457, 498, 508, 533]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-6-6-0',) [18, 42, 67, 87, 93, 121, 157, 161, 165, 197, 207, 228, 260, 278, 294, 301, 326, 333, 335, 369, 375, 409, 420, 460, 484, 503, 535]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-6-8-0',) [22, 47, 58, 82, 98, 119, 159, 169, 201, 214, 216, 241, 249, 279, 280, 314, 316, 349, 374, 386, 393, 426, 439, 443, 467, 504, 523, 527]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lzigzag1-4-5-0',) [15, 44, 79, 111, 132, 149, 270, 306, 341, 367, 371, 412, 445, 456, 470, 471, 528]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lzigzag1-4-5-1',) [27, 37, 63, 91, 113, 126, 144, 147, 166, 185, 186, 222, 250, 255, 295, 315, 319, 338, 351, 385, 389, 414, 446, 454, 455, 501, 502, 509, 534]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lzigzag1-4-6-0',) [9, 48, 64, 78, 107, 129, 150, 164, 173, 174, 212, 225, 226, 273, 277, 286, 290, 291, 350, 360, 395, 421, 435, 436, 437, 438, 488, 529]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('V-2-1-0',) [0, 40, 52, 115, 125, 156, 200, 252, 288, 317, 339, 356, 358, 382, 391, 403, 425, 465, 480, 510, 525]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('V-2-2-0',) [8, 28, 59, 89, 102, 133, 152, 163, 191, 195, 215, 247, 258, 300, 304, 305, 334, 354, 355, 392, 399, 422, 424, 453, 462, 485, 526, 531, 539]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('V-2-4-0',) [29, 31, 36, 68, 80, 99, 124, 158, 181, 196, 203, 235, 256, 274, 287, 311, 318, 331, 362, 376, 387, 428, 430, 448, 452, 474, 475, 514, 518]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('arcdeep-4-1-0',) [73, 180, 199, 284, 416, 461, 524]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('arcdeep-4-2-0',) [6, 7, 11, 41, 75, 94, 105, 134, 145, 154, 155, 182, 194, 236, 253, 283, 298, 310, 321, 364, 377, 396, 431, 440, 441, 466, 495, 532]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('arcdeep-4-4-0',) [5, 13, 38, 66, 81, 84, 108, 135, 138, 172, 187, 209, 240, 242, 263, 268, 309, 329, 361, 366, 380, 384, 398, 419, 429, 468, 479, 481, 500, 530]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('circle-6-1-0',) [20, 51, 70, 72, 90, 140, 142, 167, 208, 276, 344, 406, 483, 493, 494, 496]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-8-1-0',) [33]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-8-2-0',) [4]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-8-3-0',) [10]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-8-4-0',) [32]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-9-1-0',) [12, 53, 56, 83, 117, 131, 141, 162, 204, 244, 264, 265, 313, 343, 359, 378, 413, 477, 506, 517]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-9-2-0',) [17, 49, 71, 85, 116, 128, 136, 137, 179, 221, 223, 224, 233, 234, 282, 289, 293, 327, 363, 404, 433, 459, 537]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-9-3-0',) [21, 45, 74, 96, 112, 139, 146, 177, 189, 192, 210, 213, 227, 229, 269, 292, 302, 336, 337, 348, 381, 418, 449, 458, 473, 491, 515, 516]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-9-4-0',) [23, 24, 55, 88, 101, 118, 127, 148, 175, 190, 220, 231, 243, 267, 285, 297, 328, 340, 346, 368, 401, 405, 415, 469, 476, 478, 489, 505, 513, 536]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('squiggle3-3-1-0',) [1, 39, 61, 76, 100, 103, 104, 153, 176, 178, 198, 217, 246, 257, 272, 307, 322, 323, 342, 388, 397, 402, 410, 450, 472, 490, 511]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('squiggle3-3-2-0',) [14, 46, 109, 122, 188, 202, 211, 245, 271, 281, 299, 320, 332, 357, 372, 417, 442, 482, 492, 499, 519]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('squiggle3-3-2-1',) [50, 57, 69, 86, 92, 143, 151, 193, 205, 218, 232, 251, 261, 303, 325, 345, 353, 373, 390, 423, 427, 463, 486, 487, 522]\n",
      "dict_keys([('Lcentered-4-2-0',), ('Lcentered-4-3-0',), ('Lcentered-4-4-0',), ('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-8-1-0',), ('line-8-2-0',), ('line-8-3-0',), ('line-8-4-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "---- OUTPUT\n",
      "R.shape: (57, 29, 10)\n",
      "trialR: (30, 57, 29, 10)\n",
      "map_var_to_lev: {'shape': ['Lcentered-4-2-0', 'Lcentered-4-3-0', 'Lcentered-4-4-0', 'Lcentered-6-3-0', 'Lcentered-6-4-0', 'Lcentered-6-5-0', 'Lcentered-6-6-0', 'Lcentered-6-8-0', 'Lzigzag1-4-5-0', 'Lzigzag1-4-5-1', 'Lzigzag1-4-6-0', 'V-2-1-0', 'V-2-2-0', 'V-2-4-0', 'arcdeep-4-1-0', 'arcdeep-4-2-0', 'arcdeep-4-4-0', 'circle-6-1-0', 'line-8-1-0', 'line-8-2-0', 'line-8-3-0', 'line-8-4-0', 'line-9-1-0', 'line-9-2-0', 'line-9-3-0', 'line-9-4-0', 'squiggle3-3-1-0', 'squiggle3-3-2-0', 'squiggle3-3-2-1']}\n",
      "map_grp_to_idx: {('Lcentered-4-2-0',): 0, ('Lcentered-4-3-0',): 1, ('Lcentered-4-4-0',): 2, ('Lcentered-6-3-0',): 3, ('Lcentered-6-4-0',): 4, ('Lcentered-6-5-0',): 5, ('Lcentered-6-6-0',): 6, ('Lcentered-6-8-0',): 7, ('Lzigzag1-4-5-0',): 8, ('Lzigzag1-4-5-1',): 9, ('Lzigzag1-4-6-0',): 10, ('V-2-1-0',): 11, ('V-2-2-0',): 12, ('V-2-4-0',): 13, ('arcdeep-4-1-0',): 14, ('arcdeep-4-2-0',): 15, ('arcdeep-4-4-0',): 16, ('circle-6-1-0',): 17, ('line-8-1-0',): 18, ('line-8-2-0',): 19, ('line-8-3-0',): 20, ('line-8-4-0',): 21, ('line-9-1-0',): 22, ('line-9-2-0',): 23, ('line-9-3-0',): 24, ('line-9-4-0',): 25, ('squiggle3-3-1-0',): 26, ('squiggle3-3-2-0',): 27, ('squiggle3-3-2-1',): 28}\n",
      "params_dpca: {'labels': 'st', 'join': {'s': ['s', 'st']}, 'n_components': 8, 'ntimes': 10, 'nchans': 57, 'times': array([-0.27 , -0.245, -0.22 , -0.195, -0.17 , -0.145, -0.12 , -0.095,\n",
      "       -0.07 , -0.045]), 'map_var_to_lev': {'shape': ['Lcentered-4-2-0', 'Lcentered-4-3-0', 'Lcentered-4-4-0', 'Lcentered-6-3-0', 'Lcentered-6-4-0', 'Lcentered-6-5-0', 'Lcentered-6-6-0', 'Lcentered-6-8-0', 'Lzigzag1-4-5-0', 'Lzigzag1-4-5-1', 'Lzigzag1-4-6-0', 'V-2-1-0', 'V-2-2-0', 'V-2-4-0', 'arcdeep-4-1-0', 'arcdeep-4-2-0', 'arcdeep-4-4-0', 'circle-6-1-0', 'line-8-1-0', 'line-8-2-0', 'line-8-3-0', 'line-8-4-0', 'line-9-1-0', 'line-9-2-0', 'line-9-3-0', 'line-9-4-0', 'squiggle3-3-1-0', 'squiggle3-3-2-0', 'squiggle3-3-2-1']}, 'map_grp_to_idx': {('Lcentered-4-2-0',): 0, ('Lcentered-4-3-0',): 1, ('Lcentered-4-4-0',): 2, ('Lcentered-6-3-0',): 3, ('Lcentered-6-4-0',): 4, ('Lcentered-6-5-0',): 5, ('Lcentered-6-6-0',): 6, ('Lcentered-6-8-0',): 7, ('Lzigzag1-4-5-0',): 8, ('Lzigzag1-4-5-1',): 9, ('Lzigzag1-4-6-0',): 10, ('V-2-1-0',): 11, ('V-2-2-0',): 12, ('V-2-4-0',): 13, ('arcdeep-4-1-0',): 14, ('arcdeep-4-2-0',): 15, ('arcdeep-4-4-0',): 16, ('circle-6-1-0',): 17, ('line-8-1-0',): 18, ('line-8-2-0',): 19, ('line-8-3-0',): 20, ('line-8-4-0',): 21, ('line-9-1-0',): 22, ('line-9-2-0',): 23, ('line-9-3-0',): 24, ('line-9-4-0',): 25, ('squiggle3-3-1-0',): 26, ('squiggle3-3-2-0',): 27, ('squiggle3-3-2-1',): 28}}\n",
      "You chose to determine the regularization parameter automatically. This can\n",
      "                    take substantial time and grows linearly with the number of crossvalidation\n",
      "                    folds. The latter can be set by changing self.n_trials (default = 3). Similarly,\n",
      "                    use self.protect to set the list of axes that are not supposed to get to get shuffled\n",
      "                    (e.g. upon splitting the data into test- and training, time-points should always\n",
      "                    be drawn from the same trial, i.e. self.protect = ['t']). This can significantly\n",
      "                    speed up the code.\n",
      "Start optimizing regularization.\n",
      "Starting trial  1 / 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/dPCA/dPCA.py:681: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  trainX = (X*(N_samples/(N_samples-1))[(np.s_[:],)*n_unprotect + (None,)*n_protect] - blindX/(N_samples-1)[(np.s_[:],)*n_unprotect + (None,)*n_protect])\n",
      "/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/dPCA/dPCA.py:681: RuntimeWarning: invalid value encountered in true_divide\n",
      "  trainX = (X*(N_samples/(N_samples-1))[(np.s_[:],)*n_unprotect + (None,)*n_protect] - blindX/(N_samples-1)[(np.s_[:],)*n_unprotect + (None,)*n_protect])\n",
      "/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/dPCA/dPCA.py:681: RuntimeWarning: invalid value encountered in subtract\n",
      "  trainX = (X*(N_samples/(N_samples-1))[(np.s_[:],)*n_unprotect + (None,)*n_protect] - blindX/(N_samples-1)[(np.s_[:],)*n_unprotect + (None,)*n_protect])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 163\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dpca_marginalization \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;66;03m##### Use dPCA projections for decoding\u001B[39;00m\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mneuralmonkey\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01manaly_dpca_script_substrokes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dpca_compute_pa_to_space, transform_from_pa, transform_trial\n\u001B[0;32m--> 163\u001B[0m     dpca, Z, R, trialR, map_var_to_lev, map_grp_to_idx, params_dpca, panorm \u001B[38;5;241m=\u001B[39m \u001B[43mdpca_compute_pa_to_space\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpa\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mdpca_marginalization\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_all_margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dpca_marginalization \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    166\u001B[0m         marginalization \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/gorilla1/code/neuralmonkey/neuralmonkey/scripts/analy_dpca_script_substrokes.py:147\u001B[0m, in \u001B[0;36mdpca_compute_pa_to_space\u001B[0;34m(pa, effect_vars, keep_all_margs)\u001B[0m\n\u001B[1;32m    144\u001B[0m dpca\u001B[38;5;241m.\u001B[39mprotect \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    146\u001B[0m \u001B[38;5;66;03m# Now fit the data (R) using the model we just instatiated. Note that we only need trial-to-trial data when we want to optimize over the regularization parameter.\u001B[39;00m\n\u001B[0;32m--> 147\u001B[0m Z \u001B[38;5;241m=\u001B[39m \u001B[43mdpca\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mR\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrialR\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    149\u001B[0m plothelper_get_variables(Z, effect_vars, params_dpca) \u001B[38;5;66;03m# Add variables to params\u001B[39;00m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dpca, Z, R, trialR, map_var_to_lev, map_grp_to_idx, params_dpca, PAnorm\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/dPCA/dPCA.py:163\u001B[0m, in \u001B[0;36mdPCA.fit_transform\u001B[0;34m(self, X, trialX)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, trialX\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    147\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001B[39;00m\n\u001B[1;32m    148\u001B[0m \n\u001B[1;32m    149\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    161\u001B[0m \n\u001B[1;32m    162\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 163\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrialX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrialX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/dPCA/dPCA.py:556\u001B[0m, in \u001B[0;36mdPCA._fit\u001B[0;34m(self, X, trialX, mXs, center, SVD, optimize)\u001B[0m\n\u001B[1;32m    553\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trialX \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    554\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTo optimize the regularization parameter, the trial-by-trial data trialX needs to be provided.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 556\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimize_regularization\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrialX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    558\u001B[0m \u001B[38;5;66;03m# add regularization\u001B[39;00m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularizer \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/dPCA/dPCA.py:335\u001B[0m, in \u001B[0;36mdPCA._optimize_regularization\u001B[0;34m(self, X, trialX, center, lams)\u001B[0m\n\u001B[1;32m    332\u001B[0m     lams \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlogspace(\u001B[38;5;241m0\u001B[39m,N,num\u001B[38;5;241m=\u001B[39mN, base\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.4\u001B[39m, endpoint\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m1e-7\u001B[39m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;66;03m# compute crossvalidated score over n_trials repetitions\u001B[39;00m\n\u001B[0;32m--> 335\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcrossval_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlams\u001B[49m\u001B[43m,\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrialX\u001B[49m\u001B[43m,\u001B[49m\u001B[43mmean\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;66;03m# take mean over total scores\u001B[39;00m\n\u001B[1;32m    338\u001B[0m totalscore \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39msum(np\u001B[38;5;241m.\u001B[39mdstack([scores[key] \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(scores\u001B[38;5;241m.\u001B[39mkeys())]),\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m),\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/dPCA/dPCA.py:408\u001B[0m, in \u001B[0;36mdPCA.crossval_score\u001B[0;34m(self, lams, X, trialX, mean)\u001B[0m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, lam \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(lams):\n\u001B[1;32m    406\u001B[0m     \u001B[38;5;66;03m# fit dpca model\u001B[39;00m\n\u001B[1;32m    407\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mregularizer \u001B[38;5;241m=\u001B[39m lam\n\u001B[0;32m--> 408\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainX\u001B[49m\u001B[43m,\u001B[49m\u001B[43mmXs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrainmXs\u001B[49m\u001B[43m,\u001B[49m\u001B[43moptimize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    410\u001B[0m     \u001B[38;5;66;03m# compute crossvalidation score\u001B[39;00m\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mean:\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/dPCA/dPCA.py:565\u001B[0m, in \u001B[0;36mdPCA._fit\u001B[0;34m(self, X, trialX, mXs, center, SVD, optimize)\u001B[0m\n\u001B[1;32m    562\u001B[0m     regX, regmXs, pregX \u001B[38;5;241m=\u001B[39m X, mXs, pinv(X\u001B[38;5;241m.\u001B[39mreshape((n_features,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)))\n\u001B[1;32m    564\u001B[0m \u001B[38;5;66;03m# compute closed-form solution\u001B[39;00m\n\u001B[0;32m--> 565\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mP, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mD \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_randomized_dpca\u001B[49m\u001B[43m(\u001B[49m\u001B[43mregX\u001B[49m\u001B[43m,\u001B[49m\u001B[43mregmXs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpinvX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpregX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/dPCA/dPCA.py:467\u001B[0m, in \u001B[0;36mdPCA._randomized_dpca\u001B[0;34m(self, X, mXs, pinvX)\u001B[0m\n\u001B[1;32m    465\u001B[0m     U,s,V \u001B[38;5;241m=\u001B[39m randomized_svd(np\u001B[38;5;241m.\u001B[39mdot(C,rX),n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_components[key],n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter,random_state\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m10e5\u001B[39m))\n\u001B[1;32m    466\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 467\u001B[0m     U,s,V \u001B[38;5;241m=\u001B[39m \u001B[43mrandomized_svd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrX\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mn_components\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_components\u001B[49m\u001B[43m,\u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10e5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    469\u001B[0m P[key] \u001B[38;5;241m=\u001B[39m U\n\u001B[1;32m    470\u001B[0m D[key] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(U\u001B[38;5;241m.\u001B[39mT,C)\u001B[38;5;241m.\u001B[39mT\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/sklearn/utils/extmath.py:396\u001B[0m, in \u001B[0;36mrandomized_svd\u001B[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001B[0m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transpose:\n\u001B[1;32m    393\u001B[0m     \u001B[38;5;66;03m# this implementation is a bit faster with smaller shape[1]\u001B[39;00m\n\u001B[1;32m    394\u001B[0m     M \u001B[38;5;241m=\u001B[39m M\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m--> 396\u001B[0m Q \u001B[38;5;241m=\u001B[39m \u001B[43mrandomized_range_finder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43mM\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m    \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_random\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpower_iteration_normalizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpower_iteration_normalizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;66;03m# project M to the (k + p) dimensional space using the basis vectors\u001B[39;00m\n\u001B[1;32m    405\u001B[0m B \u001B[38;5;241m=\u001B[39m safe_sparse_dot(Q\u001B[38;5;241m.\u001B[39mT, M)\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/sklearn/utils/extmath.py:245\u001B[0m, in \u001B[0;36mrandomized_range_finder\u001B[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001B[0m\n\u001B[1;32m    241\u001B[0m         Q, _ \u001B[38;5;241m=\u001B[39m linalg\u001B[38;5;241m.\u001B[39mqr(safe_sparse_dot(A\u001B[38;5;241m.\u001B[39mT, Q), mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meconomic\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    243\u001B[0m \u001B[38;5;66;03m# Sample the range of A using by linear projection of Q\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;66;03m# Extract an orthonormal basis\u001B[39;00m\n\u001B[0;32m--> 245\u001B[0m Q, _ \u001B[38;5;241m=\u001B[39m \u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mqr\u001B[49m\u001B[43m(\u001B[49m\u001B[43msafe_sparse_dot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mQ\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meconomic\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Q\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/scipy/linalg/decomp_qr.py:127\u001B[0m, in \u001B[0;36mqr\u001B[0;34m(a, overwrite_a, lwork, mode, pivoting, check_finite)\u001B[0m\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMode argument should be one of [\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    124\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meconomic\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_finite:\n\u001B[0;32m--> 127\u001B[0m     a1 \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray_chkfinite\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    129\u001B[0m     a1 \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39masarray(a)\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/numpy/lib/function_base.py:488\u001B[0m, in \u001B[0;36masarray_chkfinite\u001B[0;34m(a, dtype, order)\u001B[0m\n\u001B[1;32m    486\u001B[0m a \u001B[38;5;241m=\u001B[39m asarray(a, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder)\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m a\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mchar \u001B[38;5;129;01min\u001B[39;00m typecodes[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllFloat\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misfinite(a)\u001B[38;5;241m.\u001B[39mall():\n\u001B[0;32m--> 488\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    489\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray must not contain infs or NaNs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    490\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[0;31mValueError\u001B[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Quickly test decoding of both shape and motor-related params for each substroke.\n",
    "This is all very scratch.\n",
    "\n",
    "Notebook: 240128_snippets_demixed_PCA (althought this has nothing to do with that code).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pythonlib.tools.plottools import savefig\n",
    "from pythonlib.globals import PATH_ANALYSIS_OUTCOMES\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pythonlib.tools.expttools import writeDictToTxt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "############### PARAMS\n",
    "animal = \"Pancho\"\n",
    "date = 220719\n",
    "exclude_bad_areas = True\n",
    "SPIKES_VERSION = \"tdt\" # since Snippets not yet extracted for ks\n",
    "bin_by_time_dur = 0.05\n",
    "bin_by_time_slide = 0.025\n",
    "which_level = \"substroke\"\n",
    "\n",
    "# METHOD 1 - Standard, running separately for each PA\n",
    "question = \"SS_shape\"\n",
    "slice_agg_slices = None\n",
    "slice_agg_vars_to_split = None\n",
    "slice_agg_concat_dim = None\n",
    "\n",
    "# list_time_windows = [(-0.3, 0.)]\n",
    "# list_time_windows = [(-0.3, 0), (0., 0.3)]\n",
    "list_time_windows = [(-0.3, 0)]\n",
    "events_keep = [\"00_substrk\"]\n",
    "# list_time_windows = [(-0.3, 0.)]\n",
    "# events_keep = [\"06_on_strokeidx_0\"]\n",
    "print(list_time_windows)\n",
    "\n",
    "ev = \"00_substrk\"\n",
    "thresh_frac_var = 0.85 # PCA, cumvar\n",
    "n_min_across_all_levs_var = 5\n",
    "\n",
    "# Demixed PCA\n",
    "list_dpca_marginalization = [\"shape\", None]\n",
    "\n",
    "########################################## RUN\n",
    "# Load q_params\n",
    "from neuralmonkey.analyses.rsa import rsagood_questions_dict, rsagood_questions_params\n",
    "q_params = rsagood_questions_dict(animal, date, question)[question]\n",
    "# Load data\n",
    "from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper\n",
    "\n",
    "combine_into_larger_areas = True\n",
    "HACK_RENAME_SHAPES = False\n",
    "if DEBUG:\n",
    "    substrokes_plot_preprocess = False\n",
    "else:\n",
    "    substrokes_plot_preprocess = True\n",
    "DFallpa = dfallpa_extraction_load_wrapper(animal, date, question, list_time_windows,\n",
    "                                          which_level=which_level,\n",
    "                                        bin_by_time_dur = bin_by_time_dur,\n",
    "                                        bin_by_time_slide = bin_by_time_slide,\n",
    "                                          combine_into_larger_areas = combine_into_larger_areas,\n",
    "                                          exclude_bad_areas = exclude_bad_areas,\n",
    "                                          SPIKES_VERSION = SPIKES_VERSION,\n",
    "                                          HACK_RENAME_SHAPES = HACK_RENAME_SHAPES, \n",
    "                                          substrokes_plot_preprocess=substrokes_plot_preprocess)\n",
    "\n",
    "\n",
    "\n",
    "SAVEDIR_ANALYSES = f\"{PATH_ANALYSIS_OUTCOMES}/recordings/main/DECODE\"\n",
    "\n",
    "list_br = sorted(DFallpa[\"bregion\"].unique().tolist())\n",
    "if DEBUG:\n",
    "    list_br = [\"M1\"]\n",
    "\n",
    "\n",
    "for prune_to_first_substroke in [True, False]:\n",
    "\n",
    "\n",
    "    if True:\n",
    "        # Continuous\n",
    "        list_var_decode = [\"velocity\", \"angle\", \"distcum\", \"circ_signed\"]\n",
    "        list_vars_others = [[\"shape\"], [\"shape\"], [\"shape\"], [\"shape\"]]\n",
    "        # list_vars_others = [[\"dummy\"], [\"dummy\"], [\"dummy\"], [\"dummy\"]]\n",
    "    else:\n",
    "        # Discrete\n",
    "        list_var_decode = [\"shape\", \"di_an_ci_ve_bin\"]\n",
    "        list_vars_others = [[\"di_an_ci_ve_bin\"], [\"shape\"]]\n",
    "\n",
    "    # Combine all\n",
    "    if DEBUG:\n",
    "        list_var_decode = [\"shape\"] + [\"shape\"] + [\"velocity\"]\n",
    "        list_vars_others = [[\"ss_this_ctxt\"], [\"di_an_ci_ve_bin\"]] + [[\"shape\"]]\n",
    "    else:\n",
    "        # list_var_decode = [\"shape\", \"di_an_ci_ve_bin\"] + [\"velocity\", \"angle\", \"distcum\", \"circ_signed\"]\n",
    "        # list_vars_others = [[\"di_an_ci_ve_bin\"], [\"shape\"]] + [[\"shape\"], [\"shape\"], [\"shape\"], [\"shape\"]]\n",
    "        list_var_decode = [\"shape\", \"shape\", \"di_an_ci_ve_bin\"] + [\"angle\"]\n",
    "        list_vars_others = [[\"ss_this_ctxt\"], [\"di_an_ci_ve_bin\"], [\"shape\"]] + [[\"shape\"]]\n",
    "\n",
    "    if prune_to_first_substroke==False:\n",
    "        # Then append index within stroke\n",
    "        tmp =[]\n",
    "        for x in list_vars_others:\n",
    "            tmp.append(list(x) + [\"index_within_stroke\"])\n",
    "        list_vars_others = tmp\n",
    "\n",
    "    from pythonlib.tools.listtools import tabulate_list\n",
    "    # Count the lowest n data across classes.\n",
    "    from neuralmonkey.analyses.decode_good import decode_categorical_wrapper\n",
    "\n",
    "    if DEBUG:\n",
    "        list_time_windows = [list_time_windows[0]]\n",
    "\n",
    "    for twind in list_time_windows:\n",
    "\n",
    "        for dpca_marginalization in list_dpca_marginalization:\n",
    "            # a = stringify_list(list_time_windows, return_as_str=True)\n",
    "            # b = stringify_list(events_keep, return_as_str=True)\n",
    "            SAVEDIR = f\"{SAVEDIR_ANALYSES}/{animal}-{date}/{question}/firstsubstrk_{prune_to_first_substroke}-twind_{twind}-dpca_marg_{dpca_marginalization}\"\n",
    "            os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "            params_this = {\n",
    "                \"n_min_across_all_levs_var\":n_min_across_all_levs_var,\n",
    "                \"thresh_frac_var\":thresh_frac_var,\n",
    "                \"prune_to_first_substroke\":prune_to_first_substroke,\n",
    "            }\n",
    "            writeDictToTxt(params_this, f\"{SAVEDIR}/params.txt\")\n",
    "\n",
    "            ##### Condition on one variable and test decoding (within that variable)\n",
    "\n",
    "            RES_SINGLE = [] # Single decoder across all data (after pruning to have conjunctions)\n",
    "            RES = [] # Separate decoder for each lev of conj\n",
    "            for br in list_br:\n",
    "                # br = \"PMv\"\n",
    "\n",
    "                savedir_preprocess = f\"{SAVEDIR}/preprocess_plots/{br}\"\n",
    "                os.makedirs(savedir_preprocess, exist_ok=True)\n",
    "\n",
    "                from neuralmonkey.analyses.state_space_good import popanal_preprocess_scalar_normalization\n",
    "                from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "                from neuralmonkey.analyses.rsa import preprocess_rsa_prepare_popanal_wrapper\n",
    "                from neuralmonkey.scripts.analy_dpca_script_quick import plothelper_get_variables\n",
    "\n",
    "                # Extract PA\n",
    "                tmp = DFallpa[(DFallpa[\"bregion\"]==br) & (DFallpa[\"event\"]==ev) & (DFallpa[\"twind\"]==twind)]\n",
    "                assert len(tmp)==1\n",
    "                pa = tmp[\"pa\"].values[0]\n",
    "\n",
    "                # Restrict analysis to just first substroke\n",
    "                if prune_to_first_substroke:\n",
    "                    pa = pa.slice_by_labels(\"trials\", \"index_within_stroke\", [0])\n",
    "                    \n",
    "                \n",
    "                ###### USE PCS OR DEMIXED PCS\n",
    "                if dpca_marginalization is not None:\n",
    "                    \n",
    "                    ##### Use dPCA projections for decoding\n",
    "                    from neuralmonkey.scripts.analy_dpca_script_substrokes import dpca_compute_pa_to_space, transform_from_pa, transform_trial\n",
    "\n",
    "                    dpca, Z, R, trialR, map_var_to_lev, map_grp_to_idx, params_dpca, panorm = dpca_compute_pa_to_space(\n",
    "                        pa, [dpca_marginalization], keep_all_margs=False)\n",
    "                    if dpca_marginalization == \"shape\":\n",
    "                        marginalization = \"s\"\n",
    "                    elif dpca_marginalization == \"dist_angle\":\n",
    "                        marginalization = \"m\" # motor\n",
    "                    else:\n",
    "                        print(dpca_marginalization)\n",
    "                        assert False\n",
    "\n",
    "                    # First, convert to final data using PA (e.g., scalar)\n",
    "                    panorm_scal = panorm.agg_wrapper(\"times\")\n",
    "                    # dflab = panorm_scal.Xlabels[\"trials\"]\n",
    "                    trialX_proj = transform_from_pa(dpca, panorm_scal, marginalization) # (ndims, ntrials, 1)\n",
    "\n",
    "                    # Prune to dims with >0.1% explained variance, or 3, whichever larger\n",
    "                    tmp = np.argwhere(np.array(dpca.explained_variance_ratio_[marginalization])>0.001)\n",
    "                    if len(tmp)==0:\n",
    "                        ndims = 4\n",
    "                    else:\n",
    "                        ndims = max(tmp)+1\n",
    "                        ndims = max([4, ndims]) # take at least 3 dimensions\n",
    "                        ndims = int(ndims)\n",
    "                    trialX_proj = trialX_proj[:ndims, :, :]\n",
    "\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.plot(dpca.explained_variance_ratio_[marginalization])\n",
    "                    ax.axvline(ndims, color=\"r\")\n",
    "                    ax.set_title(\"var exp, dpca, vline=ndims taken\")\n",
    "                    savefig(fig, f\"{savedir_preprocess}/demixed_pca_explainedvar.pdf\")\n",
    "\n",
    "                    assert trialX_proj.shape[2]==1\n",
    "                    trialX_proj = trialX_proj.squeeze()\n",
    "                    X_orig = trialX_proj.T # (ntrials, nchans)\n",
    "\n",
    "                else:\n",
    "                    # PCA.\n",
    "                    # Standard preprocessing\n",
    "                    if False:\n",
    "                        # Dont do this; will do later in context of decoding.\n",
    "                        pa, res_check_tasksets, res_check_effectvars = preprocess_rsa_prepare_popanal_wrapper(pa, **q_params)\n",
    "                    _, panorm_scal, _, _, _, _ = popanal_preprocess_scalar_normalization(pa, None, DO_AGG_TRIALS=False)\n",
    "\n",
    "                    # PCA\n",
    "                    trialX = panorm_scal.X.copy()\n",
    "                    assert trialX.shape[2]==1\n",
    "                    trialX = trialX.squeeze()\n",
    "                    X_orig = trialX.T # (ntrials, nchans)\n",
    "\n",
    "                    # Prune with PCA\n",
    "                    from sklearn.decomposition import PCA\n",
    "                    pca = PCA(n_components=None)\n",
    "                    Xpca = pca.fit_transform(X_orig) # (ntrials, ndims)\n",
    "                    cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "                    npcs_keep = np.argmin(np.abs(cumvar - thresh_frac_var))\n",
    "\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.plot(pca.explained_variance_ratio_)\n",
    "                    ax.axvline(npcs_keep, color=\"r\")\n",
    "                    X_orig = Xpca[:, :npcs_keep]\n",
    "                    savefig(fig, f\"{savedir_preprocess}/pca_explainedvar.pdf\")\n",
    "\n",
    "\n",
    "                # Get labels\n",
    "                dflab = panorm_scal.Xlabels[\"trials\"].copy()\n",
    "\n",
    "                for var_decode, vars_others in zip(\n",
    "                        list_var_decode,\n",
    "                        list_vars_others):\n",
    "\n",
    "                    map_levother_to_labels = {}\n",
    "\n",
    "                    from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars\n",
    "                    # var_decode = \"shape\"\n",
    "                    # vars_others = [\"di_an_ci_ve_bin\"]\n",
    "\n",
    "                    conti_or_discr = check_var_conti_discr(var_decode)\n",
    "\n",
    "                    if conti_or_discr==\"discr\":\n",
    "                        # var_decode = \"di_an_ci_ve_bin\"\n",
    "                        # vars_others = [\"shape\"]\n",
    "\n",
    "                        Labels_orig = panorm_scal.Xlabels[\"trials\"][var_decode]\n",
    "                        assert len(Labels_orig)==X_orig.shape[0]\n",
    "                        Labels_orig_int, map_int_to_lab = Labels_orig.factorize()\n",
    "                        map_int_to_lab = {i:lab for i, lab in enumerate(map_int_to_lab)}\n",
    "\n",
    "                        writeDictToTxt({\"map_int_to_lab\":map_int_to_lab}, f\"{savedir_preprocess}/map_int_to_lab-var_{var_decode}-var_others_{'|'.join(vars_others)}.txt\")\n",
    "\n",
    "                        # var_decode = \"di_an_ci_ve_bin\"\n",
    "                        # var_decode = \"velocity\"\n",
    "                        path_conj = f\"{savedir_preprocess}/conjunctions-var_{var_decode}-var_others_{'|'.join(vars_others)}.png\"\n",
    "                        dflab_pruned, dict_dfthis = extract_with_levels_of_conjunction_vars(dflab, var_decode,\n",
    "                                                                                vars_others,\n",
    "                                                                                n_min_across_all_levs_var=n_min_across_all_levs_var,\n",
    "                                                                                lenient_allow_data_if_has_n_levels=2,\n",
    "                                                                                prune_levels_with_low_n=True,\n",
    "                                                                                plot_counts_heatmap_savepath=path_conj)\n",
    "\n",
    "                        if len(dflab_pruned)>0:\n",
    "\n",
    "                            ### FIRST, a single decoder over entire data (after pruning to levels of othervar that have some data across var)\n",
    "                            if len(dflab_pruned)==0:\n",
    "                                print(len(dflab))\n",
    "                                print(var_decode)\n",
    "                                print(vars_others)\n",
    "                                print(\"see conjunctions which failed at:\", path_conj)\n",
    "                                assert False\n",
    "\n",
    "                            inds = dflab_pruned[\"_index\"].tolist()\n",
    "                            X = X_orig[inds, :]\n",
    "                            labels = Labels_orig_int[inds]\n",
    "                            plot_resampled_data_path_nosuff = f\"{savedir_preprocess}/var-{var_decode}-ALL_DATA-{br}\"\n",
    "                            res = decode_categorical_wrapper(X, labels, n_min_across_all_levs_var, plot_resampled_data_path_nosuff)\n",
    "                            plt.close(\"all\")\n",
    "\n",
    "                            # avearge over folds\n",
    "                            score_mean = np.mean([r[\"score_xval\"] for r in res])\n",
    "                            score_std = np.std([r[\"score_xval\"] for r in res])\n",
    "                            score_adjusted_mean = np.mean([r[\"score_xval_adjusted\"] for r in res])\n",
    "\n",
    "                            RES_SINGLE.append({\n",
    "                                \"score_xval_mean\":score_mean,\n",
    "                                \"score_adjusted_mean\":score_adjusted_mean,\n",
    "                                \"score_xval_std\":score_std,\n",
    "                                \"nclasses\":len(set(labels)),\n",
    "                                \"n_dat\":len(labels),\n",
    "                                \"n_splits\":res[0][\"n_splits\"],\n",
    "                                \"n_min_across_labs\":res[0][\"n_min_across_labs\"],\n",
    "                                \"n_max_across_labs\":res[0][\"n_max_across_labs\"],\n",
    "                                \"bregion\":br,\n",
    "                                \"var_decode\":var_decode,\n",
    "                                \"vars_others\":tuple(vars_others)\n",
    "                            })\n",
    "                            PLOT_RESAMPLED_DATA = False\n",
    "                            # For each level of \"others\" do decoding\n",
    "\n",
    "                            for levo, dfthis in dict_dfthis.items():\n",
    "\n",
    "                                # Do decode/test\n",
    "                                inds = dfthis[\"_index\"].tolist()\n",
    "                                X = X_orig[inds, :]\n",
    "                                labels = Labels_orig_int[inds]\n",
    "\n",
    "                                # Sanity check, same data across all bregions.\n",
    "                                from pythonlib.tools.checktools import check_objects_identical\n",
    "                                if levo in map_levother_to_labels.items():\n",
    "                                    if not check_objects_identical(map_levother_to_labels[levo], labels):\n",
    "                                        print(map_levother_to_labels[levo])\n",
    "                                        print(labels)\n",
    "                                        assert False\n",
    "                                else:\n",
    "                                    map_levother_to_labels[levo]=labels\n",
    "\n",
    "                                plot_resampled_data_path_nosuff = f\"{savedir_preprocess}/var-{var_decode}-lev_other_{levo}-{br}\"\n",
    "                                res = decode_categorical_wrapper(X, labels, n_min_across_all_levs_var, plot_resampled_data_path_nosuff)\n",
    "                                plt.close(\"all\")\n",
    "\n",
    "                                # avearge over folds\n",
    "                                score_mean = np.mean([r[\"score_xval\"] for r in res])\n",
    "                                score_std = np.std([r[\"score_xval\"] for r in res])\n",
    "                                score_adjusted_mean = np.mean([r[\"score_xval_adjusted\"] for r in res])\n",
    "\n",
    "                                RES.append({\n",
    "                                    \"lev_other\":levo,\n",
    "                                    \"score_xval_mean\":score_mean,\n",
    "                                    \"score_adjusted_mean\":score_adjusted_mean,\n",
    "                                    \"score_xval_std\":score_std,\n",
    "                                    \"nclasses\":len(set(labels)),\n",
    "                                    \"n_dat\":len(labels),\n",
    "                                    \"n_splits\":res[0][\"n_splits\"],\n",
    "                                    \"n_min_across_labs\":res[0][\"n_min_across_labs\"],\n",
    "                                    \"n_max_across_labs\":res[0][\"n_max_across_labs\"],\n",
    "                                    \"bregion\":br,\n",
    "                                    \"var_decode\":var_decode,\n",
    "                                    \"vars_others\":tuple(vars_others)\n",
    "                                })\n",
    "                    elif conti_or_discr==\"conti\":\n",
    "                        # Continuous -- re-bin within each level of othervar...\n",
    "                        PLOT_RESAMPLED_DATA = False\n",
    "                        # For each level of \"others\" do decoding\n",
    "                        n_min_across_all_levs_var = 8 # min n in each class\n",
    "\n",
    "                        # For motor decoding, use bins local to the sahpe (i.e., recalcualte teh bins),\n",
    "                        # and do separately for each feature.\n",
    "\n",
    "                        Labels_orig = dflab[var_decode]\n",
    "                        assert len(Labels_orig)==X_orig.shape[0]\n",
    "\n",
    "                        # SKIP THis, since it resets the indices...\n",
    "                        # from pythonlib.tools.pandastools import extract_with_levels_of_var_good\n",
    "                        # dfthis, inds_keep = extract_with_levels_of_var_good(dflab, vars_others, n_min_across_all_levs_var*2)\n",
    "\n",
    "\n",
    "                        ### FIRST, a single decoder over entire data (after pruning to levels of othervar that have some data across var)\n",
    "                        X = X_orig\n",
    "                        labels = Labels_orig\n",
    "\n",
    "                        # Bin data.\n",
    "                        from pythonlib.tools.nptools import bin_values, bin_values_by_rank\n",
    "                        nbins = int(np.floor(len(labels)/n_min_across_all_levs_var))\n",
    "                        if nbins>6:\n",
    "                            nbins = 6\n",
    "                        labels = bin_values_by_rank(labels, nbins=nbins)\n",
    "\n",
    "                        plot_resampled_data_path_nosuff = f\"{savedir_preprocess}/var-{var_decode}-ALL_DATA-{br}\"\n",
    "                        res = decode_categorical_wrapper(X, labels, n_min_across_all_levs_var, plot_resampled_data_path_nosuff)\n",
    "                        plt.close(\"all\")\n",
    "\n",
    "                        # avearge over folds\n",
    "                        score_mean = np.mean([r[\"score_xval\"] for r in res])\n",
    "                        score_std = np.std([r[\"score_xval\"] for r in res])\n",
    "                        score_adjusted_mean = np.mean([r[\"score_xval_adjusted\"] for r in res])\n",
    "\n",
    "                        RES_SINGLE.append({\n",
    "                            \"score_xval_mean\":score_mean,\n",
    "                            \"score_adjusted_mean\":score_adjusted_mean,\n",
    "                            \"score_xval_std\":score_std,\n",
    "                            \"nclasses\":len(set(labels)),\n",
    "                            \"n_dat\":len(labels),\n",
    "                            \"n_splits\":res[0][\"n_splits\"],\n",
    "                            \"n_min_across_labs\":res[0][\"n_min_across_labs\"],\n",
    "                            \"n_max_across_labs\":res[0][\"n_max_across_labs\"],\n",
    "                            \"bregion\":br,\n",
    "                            \"var_decode\":var_decode,\n",
    "                            \"vars_others\":tuple(vars_others)\n",
    "                        })\n",
    "\n",
    "                        from pythonlib.tools.pandastools import grouping_append_and_return_inner_items\n",
    "                        groupdict = grouping_append_and_return_inner_items(dflab, vars_others)\n",
    "\n",
    "\n",
    "                        for levo, inds in groupdict.items():\n",
    "\n",
    "                            if len(inds)>=n_min_across_all_levs_var*2:\n",
    "                                # Otherwise cant get >1 class for decoding\n",
    "\n",
    "                                # Do decode/test\n",
    "                                X = X_orig[inds, :]\n",
    "                                labels = Labels_orig[inds]\n",
    "\n",
    "                                # Bin data.\n",
    "                                from pythonlib.tools.nptools import bin_values, bin_values_by_rank\n",
    "                                nbins = int(np.floor(len(labels)/n_min_across_all_levs_var))\n",
    "                                if nbins>6:\n",
    "                                    nbins = 6\n",
    "                                labels = bin_values_by_rank(labels, nbins=nbins)\n",
    "\n",
    "                                # Sanity check, same data across all bregions.\n",
    "                                from pythonlib.tools.checktools import check_objects_identical\n",
    "                                if levo in map_levother_to_labels.items():\n",
    "                                    if not check_objects_identical(map_levother_to_labels[levo], labels):\n",
    "                                        print(map_levother_to_labels[levo])\n",
    "                                        print(labels)\n",
    "                                        assert False\n",
    "                                else:\n",
    "                                    map_levother_to_labels[levo]=labels\n",
    "\n",
    "                                from neuralmonkey.analyses.decode_good import decode_categorical_wrapper\n",
    "                                plot_resampled_data_path_nosuff = f\"{savedir_preprocess}/var-{var_decode}-lev_other_{levo}-{br}\"\n",
    "                                res = decode_categorical_wrapper(X, labels, n_min_across_all_levs_var, plot_resampled_data_path_nosuff)\n",
    "                                plt.close(\"all\")\n",
    "\n",
    "                                # avearge over folds\n",
    "                                score_mean = np.mean([r[\"score_xval\"] for r in res])\n",
    "                                score_std = np.std([r[\"score_xval\"] for r in res])\n",
    "                                score_adjusted_mean = np.mean([r[\"score_xval_adjusted\"] for r in res])\n",
    "\n",
    "                                RES.append({\n",
    "                                    \"lev_other\":levo,\n",
    "                                    \"score_xval_mean\":score_mean,\n",
    "                                    \"score_adjusted_mean\":score_adjusted_mean,\n",
    "                                    \"score_xval_std\":score_std,\n",
    "                                    \"nclasses\":len(set(labels)),\n",
    "                                    \"n_dat\":len(labels),\n",
    "                                    \"n_splits\":res[0][\"n_splits\"],\n",
    "                                    \"n_min_across_labs\":res[0][\"n_min_across_labs\"],\n",
    "                                    \"n_max_across_labs\":res[0][\"n_max_across_labs\"],\n",
    "                                    \"bregion\":br,\n",
    "                                    \"var_decode\":var_decode,\n",
    "                                    \"vars_others\":tuple(vars_others)\n",
    "                                })\n",
    "                    else:\n",
    "                        print(conti_or_discr)\n",
    "                        assert False\n",
    "\n",
    "\n",
    "            ##### SAVE DATA\n",
    "            savedir = f\"{SAVEDIR}/summary_plots\"\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            dfres_single = pd.DataFrame(RES_SINGLE)\n",
    "            dfres = pd.DataFrame(RES)\n",
    "\n",
    "            dfres_single.to_csv(f\"{SAVEDIR}/dfres_single.csv\")\n",
    "            dfres.to_csv(f\"{SAVEDIR}/dfres.csv\")\n",
    "\n",
    "            pd.to_pickle(dfres_single, f\"{SAVEDIR}/dfres_single.pkl\")\n",
    "            pd.to_pickle(dfres, f\"{SAVEDIR}/dfres.pkl\")\n",
    "\n",
    "            ####### PLOTS\n",
    "            plot_summary_decode_results(dfres, dfres_single, SAVEDIR)\n",
    "\n",
    "            #\n",
    "            # from pythonlib.tools.snstools import rotateLabel\n",
    "            # import seaborn as sns\n",
    "            # fig = sns.catplot(data=dfres_single, x=\"bregion\", y=\"score_xval_mean\", hue=\"nclasses\", row=\"var_decode\", col=\"vars_others\")\n",
    "            # plt.axhline(0)\n",
    "            # plt.axhline(1)\n",
    "            # rotateLabel(fig)\n",
    "            # savefig(fig, f\"{savedir}/single_decoder_across_all_othervar-1.pdf\")\n",
    "            #\n",
    "            # fig = sns.catplot(data=dfres_single, x=\"bregion\", y=\"score_xval_mean\", hue=\"nclasses\", row=\"var_decode\", col=\"vars_others\", kind=\"bar\", ci=68)\n",
    "            # plt.axhline(0)\n",
    "            # plt.axhline(1)\n",
    "            # rotateLabel(fig)\n",
    "            # savefig(fig, f\"{savedir}/single_decoder_across_all_othervar-2.pdf\")\n",
    "            #\n",
    "            # fig = sns.catplot(data=dfres_single, x=\"bregion\", y=\"score_adjusted_mean\", row=\"var_decode\", col=\"vars_others\", kind=\"bar\", ci=68)\n",
    "            # plt.axhline(0)\n",
    "            # plt.axhline(1)\n",
    "            # rotateLabel(fig)\n",
    "            # savefig(fig, f\"{savedir}/single_decoder_across_all_othervar-score_adjusted-1.pdf\")\n",
    "            #\n",
    "            # ################################\n",
    "            # import seaborn as sns\n",
    "            # fig = sns.catplot(data=dfres, x=\"bregion\", y=\"score_xval_mean\", hue=\"nclasses\", row=\"var_decode\", col=\"vars_others\")\n",
    "            # plt.axhline(0)\n",
    "            # plt.axhline(1)\n",
    "            # rotateLabel(fig)\n",
    "            # savefig(fig, f\"{savedir}/separate_decoder_each_othervar-1.pdf\")\n",
    "            #\n",
    "            # fig = sns.catplot(data=dfres, x=\"bregion\", y=\"score_xval_mean\", hue=\"nclasses\", row=\"var_decode\", col=\"vars_others\", kind=\"bar\", ci=68)\n",
    "            # plt.axhline(0)\n",
    "            # plt.axhline(1)\n",
    "            # rotateLabel(fig)\n",
    "            # savefig(fig, f\"{savedir}/separate_decoder_each_othervar-2.pdf\")\n",
    "            #\n",
    "            # fig = sns.catplot(data=dfres, x=\"bregion\", y=\"score_adjusted_mean\", row=\"var_decode\", col=\"vars_others\", kind=\"bar\", ci=68)\n",
    "            # plt.axhline(0)\n",
    "            # plt.axhline(1)\n",
    "            # rotateLabel(fig)\n",
    "            # savefig(fig, f\"{savedir}/separate_decoder_each_othervar-score_adjusted-1.pdf\")\n",
    "            #\n",
    "            # plt.close(\"all\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T18:43:11.962564370Z",
     "start_time": "2024-02-16T18:40:43.729243936Z"
    }
   },
   "id": "e2f3e1db63771e88"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "'shape'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpca_marginalization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T20:49:32.490703002Z",
     "start_time": "2024-02-16T20:49:32.454367151Z"
    }
   },
   "id": "48ce10fc3028c68"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 540, 10)\n",
      "[CHECK CONJ] NOTHING TO REMOVE!\n",
      "[CHECK CONJ] NOTHING TO REMOVE!\n",
      "(57, 532, 10)\n"
     ]
    }
   ],
   "source": [
    "# Clean up PA\n",
    "print(pa.X.shape)\n",
    "pa_out, res_check_tasksets, res_check_effectvars = preprocess_rsa_prepare_popanal_wrapper(pa, [dpca_marginalization], False, False, None, None, False, None)\n",
    "print(pa_out.X.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T20:50:57.986961220Z",
     "start_time": "2024-02-16T20:50:57.815509200Z"
    }
   },
   "id": "7c6982ca457b5de2"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 57, 22, 10)\n",
      "('Lcentered-6-3-0',) [12, 25, 57, 87, 89, 115, 163, 175, 211, 222, 240, 246, 258, 267, 288, 339, 357, 375, 392, 400, 403, 424, 456, 499, 504, 513, 530]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-6-4-0',) [20, 52, 54, 69, 98, 122, 152, 160, 231, 254, 322, 371, 426, 489, 512]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-6-5-0',) [21, 27, 35, 46, 102, 106, 112, 162, 176, 198, 229, 230, 251, 300, 304, 316, 344, 362, 386, 399, 436, 439, 443, 449, 490, 500, 525]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-6-6-0',) [14, 34, 59, 79, 85, 113, 149, 153, 157, 189, 199, 220, 252, 270, 286, 293, 318, 325, 327, 361, 367, 401, 412, 452, 476, 495, 527]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lcentered-6-8-0',) [17, 39, 50, 74, 90, 111, 151, 161, 193, 206, 208, 233, 241, 271, 272, 306, 308, 341, 366, 378, 385, 418, 431, 435, 459, 496, 515, 519]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lzigzag1-4-5-0',) [11, 36, 71, 103, 124, 141, 262, 298, 333, 359, 363, 404, 437, 448, 462, 463, 520]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lzigzag1-4-5-1',) [22, 29, 55, 83, 105, 118, 136, 139, 158, 177, 178, 214, 242, 247, 287, 307, 311, 330, 343, 377, 381, 406, 438, 446, 447, 493, 494, 501, 526]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('Lzigzag1-4-6-0',) [6, 40, 56, 70, 99, 121, 142, 156, 165, 166, 204, 217, 218, 265, 269, 278, 282, 283, 342, 352, 387, 413, 427, 428, 429, 430, 480, 521]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('V-2-1-0',) [0, 32, 44, 107, 117, 148, 192, 244, 280, 309, 331, 348, 350, 374, 383, 395, 417, 457, 472, 502, 517]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('V-2-2-0',) [5, 23, 51, 81, 94, 125, 144, 155, 183, 187, 207, 239, 250, 292, 296, 297, 326, 346, 347, 384, 391, 414, 416, 445, 454, 477, 518, 523, 531]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('V-2-4-0',) [24, 26, 28, 60, 72, 91, 116, 150, 173, 188, 195, 227, 248, 266, 279, 303, 310, 323, 354, 368, 379, 420, 422, 440, 444, 466, 467, 506, 510]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('arcdeep-4-1-0',) [65, 172, 191, 276, 408, 453, 516]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('arcdeep-4-2-0',) [3, 4, 7, 33, 67, 86, 97, 126, 137, 146, 147, 174, 186, 228, 245, 275, 290, 302, 313, 356, 369, 388, 423, 432, 433, 458, 487, 524]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('arcdeep-4-4-0',) [2, 9, 30, 58, 73, 76, 100, 127, 130, 164, 179, 201, 232, 234, 255, 260, 301, 321, 353, 358, 372, 376, 390, 411, 421, 460, 471, 473, 492, 522]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('circle-6-1-0',) [15, 43, 62, 64, 82, 132, 134, 159, 200, 268, 336, 398, 475, 485, 486, 488]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-9-1-0',) [8, 45, 48, 75, 109, 123, 133, 154, 196, 236, 256, 257, 305, 335, 351, 370, 405, 469, 498, 509]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-9-2-0',) [13, 41, 63, 77, 108, 120, 128, 129, 171, 213, 215, 216, 225, 226, 274, 281, 285, 319, 355, 396, 425, 451, 529]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-9-3-0',) [16, 37, 66, 88, 104, 131, 138, 169, 181, 184, 202, 205, 219, 221, 261, 284, 294, 328, 329, 340, 373, 410, 441, 450, 465, 483, 507, 508]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('line-9-4-0',) [18, 19, 47, 80, 93, 110, 119, 140, 167, 182, 212, 223, 235, 259, 277, 289, 320, 332, 338, 360, 393, 397, 407, 461, 468, 470, 481, 497, 505, 528]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('squiggle3-3-1-0',) [1, 31, 53, 68, 92, 95, 96, 145, 168, 170, 190, 209, 238, 249, 264, 299, 314, 315, 334, 380, 389, 394, 402, 442, 464, 482, 503]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('squiggle3-3-2-0',) [10, 38, 101, 114, 180, 194, 203, 237, 263, 273, 291, 312, 324, 349, 364, 409, 434, 474, 484, 491, 511]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "('squiggle3-3-2-1',) [42, 49, 61, 78, 84, 135, 143, 185, 197, 210, 224, 243, 253, 295, 317, 337, 345, 365, 382, 415, 419, 455, 478, 479, 514]\n",
      "dict_keys([('Lcentered-6-3-0',), ('Lcentered-6-4-0',), ('Lcentered-6-5-0',), ('Lcentered-6-6-0',), ('Lcentered-6-8-0',), ('Lzigzag1-4-5-0',), ('Lzigzag1-4-5-1',), ('Lzigzag1-4-6-0',), ('V-2-1-0',), ('V-2-2-0',), ('V-2-4-0',), ('arcdeep-4-1-0',), ('arcdeep-4-2-0',), ('arcdeep-4-4-0',), ('circle-6-1-0',), ('line-9-1-0',), ('line-9-2-0',), ('line-9-3-0',), ('line-9-4-0',), ('squiggle3-3-1-0',), ('squiggle3-3-2-0',), ('squiggle3-3-2-1',)])\n",
      "You chose to determine the regularization parameter automatically. This can\n",
      "                    take substantial time and grows linearly with the number of crossvalidation\n",
      "                    folds. The latter can be set by changing self.n_trials (default = 3). Similarly,\n",
      "                    use self.protect to set the list of axes that are not supposed to get to get shuffled\n",
      "                    (e.g. upon splitting the data into test- and training, time-points should always\n",
      "                    be drawn from the same trial, i.e. self.protect = ['t']). This can significantly\n",
      "                    speed up the code.\n",
      "Start optimizing regularization.\n",
      "Starting trial  1 / 3\n",
      "Starting trial  2 / 3\n",
      "Starting trial  3 / 3\n",
      "Optimized regularization, optimal lambda =  0.004743480741674971\n",
      "Regularization will be fixed; to compute the optimal                    parameter again on the next fit, please                    set opt_regularizer_flag to True.\n",
      "shape Lcentered-6-3-0 [0.18995 0.07176 0.23217 1.     ]\n",
      "shape Lcentered-6-4-0 [0.23915 0.20833 0.54686 1.     ]\n",
      "shape Lcentered-6-5-0 [0.26816 0.33825 0.7805  1.     ]\n",
      "shape Lcentered-6-6-0 [0.27698 0.46153 0.93309 1.     ]\n",
      "shape Lcentered-6-8-0 [0.25862 0.57958 0.99876 1.     ]\n",
      "shape Lzigzag1-4-5-0 [0.18625 0.69775 0.95498 1.     ]\n",
      "shape Lzigzag1-4-5-1 [0.10738 0.81381 0.83484 1.     ]\n",
      "shape Lzigzag1-4-6-0 [0.10342 0.896   0.715   1.     ]\n",
      "shape V-2-1-0 [0.20877 0.95304 0.58199 1.     ]\n",
      "shape V-2-2-0 [0.38127 0.98909 0.42386 1.     ]\n",
      "shape V-2-4-0 [0.56026 0.99873 0.28623 1.     ]\n",
      "shape arcdeep-4-1-0 [0.70553 0.97255 0.21032 1.     ]\n",
      "shape arcdeep-4-2-0 [0.82333 0.91253 0.20663 1.     ]\n",
      "shape arcdeep-4-4-0 [0.92004 0.82806 0.22456 1.     ]\n",
      "shape circle-6-1-0 [0.98    0.73    0.22161 1.     ]\n",
      "shape line-9-1-0 [0.99672 0.60977 0.17842 1.     ]\n",
      "shape line-9-2-0 [0.97545 0.4574  0.11305 1.     ]\n",
      "shape line-9-3-0 [0.92623 0.32473 0.05837 1.     ]\n",
      "shape line-9-4-0 [0.8538  0.2217  0.02677 1.     ]\n",
      "shape squiggle3-3-1-0 [0.75556 0.13731 0.00942 1.     ]\n",
      "shape squiggle3-3-2-0 [0.63082 0.06868 0.00401 1.     ]\n",
      "shape squiggle3-3-2-1 [0.4796  0.01583 0.01055 1.     ]\n"
     ]
    }
   ],
   "source": [
    "dpca, Z, R, trialR, map_var_to_lev, map_grp_to_idx, params_dpca, panorm = dpca_compute_pa_to_space(\n",
    "    pa_out, [dpca_marginalization], keep_all_margs=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T20:51:05.650223739Z",
     "start_time": "2024-02-16T20:51:05.139133253Z"
    }
   },
   "id": "46280e09ec00b184"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load saved decoding results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b40ca981a5cc820"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analyquick_decode_substrokes import load_saved_data, plot_summary_decode_results\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pythonlib.tools.plottools import savefig\n",
    "from pythonlib.tools.snstools import rotateLabel\n",
    "# import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67a388157b817e3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for animal, date in [\n",
    "    # (\"Diego\", 230615),\n",
    "    # (\"Diego\", 230616),\n",
    "    # (\"Diego\", 230618),\n",
    "    # (\"Diego\", 230619),\n",
    "    # (\"Pancho\", 220715),\n",
    "    # (\"Pancho\", 220719)\n",
    "    # ]:   \n",
    "    (\"Pancho\", 221217)\n",
    "    ]:   \n",
    "    # animal = \"Diego\"  \n",
    "    # date = 230615 \n",
    "    \n",
    "    for prune_to_first_substroke in [False, True]:\n",
    "        for twind in [(-0.3, 0), (0.0, 0.3)]:\n",
    "            # prune_to_first_substroke = False \n",
    "            # twind = (-0.3, 0)\n",
    "            try:\n",
    "                dfres, dfres_single, SAVEDIR = load_saved_data(animal, date, prune_to_first_substroke, twind)\n",
    "                print(\"Loaded data from: \", SAVEDIR)\n",
    "                plot_summary_decode_results(dfres, dfres_single, SAVEDIR)\n",
    "            except Exception as err:\n",
    "                print(\"DID NOT FIND: \", animal, date, prune_to_first_substroke, twind)\n",
    "                pass\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c86a5ac9b6302f47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
