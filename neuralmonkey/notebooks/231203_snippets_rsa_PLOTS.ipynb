{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ma_context_diffimport os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\" Loads data saved in /rsa\n",
    "- TO MAKE PLOTS, which combined all the above, go to 231203_snippets_rsa_PLOTS.ipynb\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from neuralmonkey.classes.session import load_mult_session_helper\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d48dd175d3e9e0"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8a8975d643addef3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MULT RES PLOTS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa1dfb1d5ec391a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples, append_col_with_grp_index\n",
    "from pythonlib.tools.plottools import rotate_x_labels, rotate_y_labels, savefig\n",
    "from pythonlib.tools.snstools import rotateLabel\n",
    "from pythonlib.tools.expttools import writeDictToYaml\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e88b95f92fd902ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # from neuralmonkey.analyses.state_space_good import pipeline_rsa_scalar_population_MULT, load_mult_data_helper, pipeline_rsa_scalar_population_MULT_PLOTS, load_single_data\n",
    "# from neuralmonkey.analyses.rsa import pipeline_rsa_scalar_population_MULT, load_mult_data_helper, pipeline_rsa_scalar_population_MULT_PLOTS, _load_single_data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f894f8e08848b00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "animal = \"Diego\"\n",
    "DATE = 230630\n",
    "version_distance = \"pearson\"\n",
    "RES, SAVEDIR_MULT, params, REGIONS_IN_ORDER = load_mult_data_helper(animal, DATE, version_distance)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec883374c8037c3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a specific bregion and time window\n",
    "\n",
    "res, PA, Clraw, Clsim = load_single_data(RES, \"M1_m\", (-0.5, -0.3), which_level=\"stroke\")\n",
    "from neuralmonkey.analyses.rsa import pipeline_rsa_scalar_population_MULT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfbec83f755821ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MAIN PLOTS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86b638d5600b7746"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if False:\n",
    "    # PIG\n",
    "    list_question = [\"seq_ctxt\"]\n",
    "    # list_question = [\"pig_vs_sp\", \"seq_ctxt\", \"seq_pred\", \"shape_loc\"]\n",
    "    # list_animal_date = [\n",
    "    #         (\"Diego\", \"230628\"),\n",
    "    #         (\"Diego\", \"230630\"),\n",
    "    #         (\"Pancho\", \"230623\"),\n",
    "    #         (\"Pancho\", \"230626\"),\n",
    "    #         ]\n",
    "    list_animal_date = [\n",
    "            (\"Pancho\", \"230623\"),\n",
    "            # (\"Pancho\", \"230623\"),\n",
    "            # (\"Pancho\", \"230626\"),\n",
    "            ]\n",
    "    list_which_level = [\"stroke\", \"stroke_off\"]\n",
    "elif False:\n",
    "    # Char\n",
    "    list_question = [\"CHAR_shape\"]\n",
    "    list_animal_date = [\n",
    "            (\"Pancho\", \"230126\"),\n",
    "            ]\n",
    "    list_which_level = [\"stroke\", \"stroke_off\"]\n",
    "elif False:\n",
    "    list_question = [\"SP_shape_size\"]\n",
    "    list_animal_date = [\n",
    "            (\"Diego\", \"230615\"),\n",
    "        ]\n",
    "    animal = \"Diego\"\n",
    "    # list_question = [\"SP_shape\"]    \n",
    "    # list_animal_date = [\n",
    "    #         (\"Diego\", \"230615\"),\n",
    "    #         ]\n",
    "    \n",
    "    list_which_level = [\"trial\"]\n",
    "else:    \n",
    "    list_question = [\"SP_shape_loc\"]\n",
    "    list_animal_date = [\n",
    "            (\"Diego\", \"230615\"),\n",
    "        ]\n",
    "    list_which_level = [\"trial\"]\n",
    "\n",
    "\n",
    "\n",
    "list_version_distance = [\"pearson\"]\n",
    "list_yvar = [\"cc\"]\n",
    "DO_AGG_TRIALS = True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf10856cb91e04ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.rsa import rsagood_pa_vs_theor_wrapper_loadresults, rsagood_pa_vs_theor_plot_results\n",
    "subtract_mean_each_level_of_var = None\n",
    "yvar = \"cc\"\n",
    "for question in list_question:    \n",
    "    for animal, date in list_animal_date:\n",
    "        for version_distance in list_version_distance:\n",
    "            for yvar in list_yvar:\n",
    "                DFRES_THEOR, DFallpa, Params, savedir = rsagood_pa_vs_theor_wrapper_loadresults(animal, date, question, version_distance, DO_AGG_TRIALS, subtract_mean_each_level_of_var)\n",
    "                    \n",
    "                ### (1) Overview summary plots\n",
    "                print(\"** SAving figures to:\", savedir)\n",
    "                rsagood_pa_vs_theor_plot_results(DFRES_THEOR, savedir, yvar)\n",
    "                \n",
    "                ### (2) PLOT PAIRWISE DIST MATRICES, for hand-selected variables.\n",
    "                # Reload the params for this question.\n",
    "                from neuralmonkey.analyses.rsa import rsagood_questions_params\n",
    "                question_params = rsagood_questions_params(Params[\"question\"])\n",
    "                variables_plot = question_params[\"plot_pairwise_distmats_variables\"]\n",
    "                list_wl_ev_tw_plot = question_params[\"plot_pairwise_distmats_twinds\"]\n",
    "                \n",
    "                rsagood_pa_vs_theor_plot_pairwise_distmats(DFallpa, Params, savedir, variables_plot,\n",
    "                                                           list_wl_ev_tw_plot, DO_AGG_TRIALS_PLOT=True)\n",
    "    \n",
    "                "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bfcd8855457e98d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sumamrizing all results across analyses (combining across questions, taking each var only one time)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10a7b9d7d0522184"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Which vars to extract for each question, for global analysis.\n",
    "import os\n",
    "map_questions_to_vars_take = {\n",
    "    \"shape_loc\":[\"shape_oriented\", \"gridloc\", \"gap_from_prev_angle_binned\"],\n",
    "    \"pig_vs_sp\":[\"task_kind\"],\n",
    "    \"seq_ctxt\":[\"stroke_index_fromlast_tskstks\"],\n",
    "    \"seq_pred\":[\"CTXT_loc_next\", \"CTXT_shape_next\", \"gap_to_next_angle_binned\"],\n",
    "}\n",
    "\n",
    "map_questions_to_vars_take = {\n",
    "    \"SP_shape_size\":[\"seqc_0_shape\", \"gridsize\"]\n",
    "}\n",
    "\n",
    "for animal, DATE in list_animal_date:\n",
    "    for version_distance in list_version_distance:\n",
    "        for yvar in list_yvar:\n",
    "            \n",
    "            # \"sanity that get each var 1x\"\n",
    "            allvars = []\n",
    "            for vars in map_questions_to_vars_take.values():\n",
    "                allvars.extend(vars)\n",
    "            assert len(set(allvars))==len(allvars)\n",
    "            \n",
    "            list_df = []\n",
    "            for question in list_question:\n",
    "                \n",
    "                ########## LOAD ALL DATA\n",
    "                DFRES_THEOR, DFallpa, Params, savedir = rsagood_pa_vs_theor_wrapper_loadresults(animal, date, question, version_distance, DO_AGG_TRIALS, subtract_mean_each_level_of_var)\n",
    "                        \n",
    "                DFRES_THEOR[\"version_distance\"] = version_distance\n",
    "                DFRES_THEOR[\"question\"] = question\n",
    "                vars_keep = map_questions_to_vars_take[question]\n",
    "                DFRES_THEOR = DFRES_THEOR[DFRES_THEOR[\"var\"].isin(vars_keep)]\n",
    "                list_df.append(DFRES_THEOR)    \n",
    "\n",
    "                # ## COLLECT\n",
    "                # # list_which_level = []\n",
    "                # for res in RES:\n",
    "                #     which_level = res[\"which_level\"]\n",
    "                #     version_distance = res[\"version_distance\"]\n",
    "                #     df = res[\"DFRES_THEOR\"]\n",
    "                #     df[\"which_level\"] = which_level\n",
    "                #     df[\"version_distance\"] = version_distance\n",
    "                #     df[\"question\"] = question\n",
    "                #     \n",
    "                #     # Only pull out specific vars, depending on the question\n",
    "                #     \n",
    "                #     vars_keep = map_questions_to_vars_take[question]\n",
    "                #     dfkeep = df[df[\"var\"].isin(vars_keep)]\n",
    "                #     list_df.append(dfkeep)    \n",
    "                # \n",
    "            # list_which_level = sorted(set(list_which_level))\n",
    "            DFMULT_THEOR = pd.concat(list_df).reset_index(drop=True)\n",
    "            DFMULT_THEOR = append_col_with_grp_index(DFMULT_THEOR, [\"question\", \"var\"], \"q-var\", strings_compact=True)\n",
    "            # DFMULT_THEOR[\"var\"] = DFMULT_THEOR[\"q-var\"]\n",
    "            \n",
    "            # CHeck that you got all vars\n",
    "            for var in allvars:\n",
    "                print(var)\n",
    "                assert var in DFMULT_THEOR[\"var\"].unique()\n",
    "            \n",
    "            from neuralmonkey.analyses.rsa import SAVEDIR_ANALYSES\n",
    "            savedir = f\"{SAVEDIR_ANALYSES}/{animal}-{date}/agg_{DO_AGG_TRIALS}-subtr_{subtract_mean_each_level_of_var}-dist_{version_distance}/COMBINED_ACROSS_QUESTIONS_FINAL\"\n",
    "            print(savedir)\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            \n",
    "            DFMULT_THEOR, DictBregionToDf2d, DictVarToDf2d, dfres_kernels_2d, PARAMS = pipeline_rsa_scalar_population_MULT_PLOTS(DFMULT_THEOR, savedir, yvar)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e2ab509d198648"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deeper dive into variable conjucntions and imbalances. [Separately for each question]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29fe220807de35c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.rsa import pipeline_rsa_scalar_population_MULT_PLOT_DETAILED "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d294953c365ce520"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert False, \"NOT READY -- should intergrate this into original steps that do computation, rsagood_pa_vs_theor_wrapper..\"\n",
    "# savedir = f\"{SAVEDIR_MULT}/effects_each_var\"\n",
    "# os.makedirs(savedir, exist_ok=True)\n",
    "# print(savedir)\n",
    "\n",
    "for question in list_question:    \n",
    "    for animal, DATE in list_animal_date:\n",
    "        for version_distance in list_version_distance:\n",
    "            pipeline_rsa_scalar_population_MULT_PLOT_DETAILED(animal, DATE, version_distance, list_which_level, question, DO_AGG_TRIALS=DO_AGG_TRIALS, event=None)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f97a58a018dfb90f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline_rsa_scalar_population_MULT_PLOT_DETAILED"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56b3986469c6c2f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sumamrizing all results across analyses (combining across questions) [conjunction of question-var]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1a7fbf874beace8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert False, \"NOT USEFUL\"\n",
    "# Load all RES, then concatenate them so each variable is actually \"question-varible\"\n",
    "for animal, DATE in list_animal_date:\n",
    "    for version_distance in list_version_distance:\n",
    "        for yvar in list_yvar:\n",
    "\n",
    "            # COLLECT ACROSS QUESTIONS\n",
    "            list_df = []\n",
    "            for question in list_question:\n",
    "                \n",
    "                ########## LOAD ALL DATA\n",
    "                RES, SAVEDIR_MULT, params, REGIONS_IN_ORDER = load_mult_data_helper(animal, DATE, version_distance,\n",
    "                                                                                    list_which_level=list_which_level,\n",
    "                                                                                    question=question, DO_AGG_TRIALS=DO_AGG_TRIALS)\n",
    "                \n",
    "                ## COLLECT\n",
    "                # list_which_level = []\n",
    "                for res in RES:\n",
    "                    which_level = res[\"which_level\"]\n",
    "                    version_distance = res[\"version_distance\"]\n",
    "                    df = res[\"DFRES_THEOR\"]\n",
    "                    df[\"which_level\"] = which_level\n",
    "                    df[\"version_distance\"] = version_distance\n",
    "                    df[\"question\"] = question\n",
    "                    list_df.append(df)\n",
    "                #     list_which_level.append(which_level)\n",
    "                \n",
    "                \n",
    "            # list_which_level = sorted(set(list_which_level))\n",
    "            DFMULT_THEOR = pd.concat(list_df).reset_index(drop=True)\n",
    "            DFMULT_THEOR = append_col_with_grp_index(DFMULT_THEOR, [\"question\", \"var\"], \"q-var\", strings_compact=True)\n",
    "            DFMULT_THEOR[\"var\"] = DFMULT_THEOR[\"q-var\"]\n",
    "            \n",
    "            savedir = f\"{params['SAVEDIR']}/{animal}/SPLIT_BY_QUESTIONS/MULT/{DATE}/{version_distance}/COMBINED_ACROSS_QUESTIONS\"\n",
    "            print(savedir)\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            \n",
    "            pipeline_rsa_scalar_population_MULT_PLOTS(DFMULT_THEOR, savedir, yvar)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa2667121e62a720"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compute decodability of the variable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a69df3f412a8c586"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OLD (all moved above!!)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbde8b703366c775"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Sumamrizing all results across analyses (NOT QUESTIONS-VERSION)\n",
    "from neuralmonkey.analyses.state_space_good import pipeline_rsa_scalar_population_MULT\n",
    "\n",
    "list_animal_date = [\n",
    "        (\"Diego\", \"230628\"),\n",
    "        (\"Diego\", \"230630\"),\n",
    "        (\"Pancho\", \"230623\"),\n",
    "        (\"Pancho\", \"230626\"),\n",
    "        ]\n",
    "# list_version_distance = [\"pearson\", \"euclidian\"]\n",
    "# list_yvar = [\"cc\", \"mr_coeff\"]\n",
    "list_version_distance = [\"pearson\"]\n",
    "list_yvar = [\"cc\"]\n",
    "\n",
    "for animal, DATE in list_animal_date:\n",
    "    for version_distance in list_version_distance:\n",
    "        for yvar in list_yvar:\n",
    "            pipeline_rsa_scalar_population_MULT(animal, DATE, version_distance, yvar)\n",
    "            assert False\n",
    "### Sumamrizing all results, indivudually for each analyses (i.e., question)\n",
    "\n",
    "from neuralmonkey.analyses.rsa import pipeline_rsa_scalar_population_MULT\n",
    "if False:\n",
    "    # PIG\n",
    "    list_question = [\"seq_ctxt\"]\n",
    "    # list_question = [\"pig_vs_sp\", \"seq_ctxt\", \"seq_pred\", \"shape_loc\"]\n",
    "    # list_animal_date = [\n",
    "    #         (\"Diego\", \"230628\"),\n",
    "    #         (\"Diego\", \"230630\"),\n",
    "    #         (\"Pancho\", \"230623\"),\n",
    "    #         (\"Pancho\", \"230626\"),\n",
    "    #         ]\n",
    "    list_animal_date = [\n",
    "            (\"Pancho\", \"230623\"),\n",
    "            # (\"Pancho\", \"230623\"),\n",
    "            # (\"Pancho\", \"230626\"),\n",
    "            ]\n",
    "    list_which_level = [\"stroke\", \"stroke_off\"]\n",
    "elif False:\n",
    "    # Char\n",
    "    list_question = [\"CHAR_shape\"]\n",
    "    list_animal_date = [\n",
    "            (\"Pancho\", \"230126\"),\n",
    "            ]\n",
    "    list_which_level = [\"stroke\", \"stroke_off\"]\n",
    "elif False:\n",
    "    list_question = [\"SP_shape_size\"]\n",
    "    list_animal_date = [\n",
    "            (\"Diego\", \"230615\"),\n",
    "        ]\n",
    "    animal = \"Diego\"\n",
    "    # list_question = [\"SP_shape\"]    \n",
    "    # list_animal_date = [\n",
    "    #         (\"Diego\", \"230615\"),\n",
    "    #         ]\n",
    "    \n",
    "    list_which_level = [\"trial\"]\n",
    "else:    \n",
    "    list_question = [\"SP_shape_size\"]\n",
    "    list_animal_date = [\n",
    "            (\"Pancho\", \"220606\"),\n",
    "        ]\n",
    "    animal = \"Pancho\"    \n",
    "    list_which_level = [\"trial\"]\n",
    "\n",
    "\n",
    "\n",
    "list_version_distance = [\"pearson\"]\n",
    "list_yvar = [\"cc\"]\n",
    "DO_AGG_TRIALS = True\n",
    "for question in list_question:    \n",
    "    for animal, DATE in list_animal_date:\n",
    "        for version_distance in list_version_distance:\n",
    "            for yvar in list_yvar:\n",
    "                pipeline_rsa_scalar_population_MULT(animal, DATE, version_distance, yvar, list_which_level=list_which_level, question=question, DO_AGG_TRIALS=DO_AGG_TRIALS, event=None)\n",
    "### Deeper dive into variable conjucntions and imbalances. [Separately for each question]\n",
    "from neuralmonkey.analyses.rsa import pipeline_rsa_scalar_population_MULT_PLOT_DETAILED \n",
    "# savedir = f\"{SAVEDIR_MULT}/effects_each_var\"\n",
    "# os.makedirs(savedir, exist_ok=True)\n",
    "# print(savedir)\n",
    "\n",
    "for question in list_question:    \n",
    "    for animal, DATE in list_animal_date:\n",
    "        for version_distance in list_version_distance:\n",
    "            pipeline_rsa_scalar_population_MULT_PLOT_DETAILED(animal, DATE, version_distance, list_which_level, question, DO_AGG_TRIALS=DO_AGG_TRIALS, event=None)\n",
    "### Sumamrizing all results across analyses (combining across questions) [conjunction of question-var]\n",
    "# Load all RES, then concatenate them so each variable is actually \"question-varible\"\n",
    "for animal, DATE in list_animal_date:\n",
    "    for version_distance in list_version_distance:\n",
    "        for yvar in list_yvar:\n",
    "\n",
    "            # COLLECT ACROSS QUESTIONS\n",
    "            list_df = []\n",
    "            for question in list_question:\n",
    "                \n",
    "                ########## LOAD ALL DATA\n",
    "                RES, SAVEDIR_MULT, params, REGIONS_IN_ORDER = load_mult_data_helper(animal, DATE, version_distance,\n",
    "                                                                                    list_which_level=list_which_level,\n",
    "                                                                                    question=question, DO_AGG_TRIALS=DO_AGG_TRIALS)\n",
    "                \n",
    "                ## COLLECT\n",
    "                # list_which_level = []\n",
    "                for res in RES:\n",
    "                    which_level = res[\"which_level\"]\n",
    "                    version_distance = res[\"version_distance\"]\n",
    "                    df = res[\"DFRES_THEOR\"]\n",
    "                    df[\"which_level\"] = which_level\n",
    "                    df[\"version_distance\"] = version_distance\n",
    "                    df[\"question\"] = question\n",
    "                    list_df.append(df)\n",
    "                #     list_which_level.append(which_level)\n",
    "                \n",
    "                \n",
    "            # list_which_level = sorted(set(list_which_level))\n",
    "            DFMULT_THEOR = pd.concat(list_df).reset_index(drop=True)\n",
    "            DFMULT_THEOR = append_col_with_grp_index(DFMULT_THEOR, [\"question\", \"var\"], \"q-var\", strings_compact=True)\n",
    "            DFMULT_THEOR[\"var\"] = DFMULT_THEOR[\"q-var\"]\n",
    "            \n",
    "            savedir = f\"{params['SAVEDIR']}/{animal}/SPLIT_BY_QUESTIONS/MULT/{DATE}/{version_distance}/COMBINED_ACROSS_QUESTIONS\"\n",
    "            print(savedir)\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            \n",
    "            pipeline_rsa_scalar_population_MULT_PLOTS(DFMULT_THEOR, savedir, yvar)\n",
    "### Sumamrizing all results across analyses (combining across questions, taking each var only one time)\n",
    "# Which vars to extract for each question, for global analysis.\n",
    "import os\n",
    "map_questions_to_vars_take = {\n",
    "    \"shape_loc\":[\"shape_oriented\", \"gridloc\", \"gap_from_prev_angle_binned\"],\n",
    "    \"pig_vs_sp\":[\"task_kind\"],\n",
    "    \"seq_ctxt\":[\"stroke_index_fromlast_tskstks\"],\n",
    "    \"seq_pred\":[\"CTXT_loc_next\", \"CTXT_shape_next\", \"gap_to_next_angle_binned\"],\n",
    "}\n",
    "\n",
    "\n",
    "for animal, DATE in list_animal_date:\n",
    "    for version_distance in list_version_distance:\n",
    "        for yvar in list_yvar:\n",
    "            \n",
    "            # \"sanity that get each var 1x\"\n",
    "            allvars = []\n",
    "            for vars in map_questions_to_vars_take.values():\n",
    "                allvars.extend(vars)\n",
    "            assert len(set(allvars))==len(allvars)\n",
    "            \n",
    "            list_df = []\n",
    "            for question in list_question:\n",
    "                \n",
    "                ########## LOAD ALL DATA\n",
    "                RES, SAVEDIR_MULT, params, REGIONS_IN_ORDER = load_mult_data_helper(animal, DATE, version_distance,\n",
    "                                                                                    list_which_level=list_which_level,\n",
    "                                                                                    question=question, DO_AGG_TRIALS=DO_AGG_TRIALS)\n",
    "                \n",
    "                ## COLLECT\n",
    "                # list_which_level = []\n",
    "                for res in RES:\n",
    "                    which_level = res[\"which_level\"]\n",
    "                    version_distance = res[\"version_distance\"]\n",
    "                    df = res[\"DFRES_THEOR\"]\n",
    "                    df[\"which_level\"] = which_level\n",
    "                    df[\"version_distance\"] = version_distance\n",
    "                    df[\"question\"] = question\n",
    "                    \n",
    "                    # Only pull out specific vars, depending on the question\n",
    "                    \n",
    "                    vars_keep = map_questions_to_vars_take[question]\n",
    "                    dfkeep = df[df[\"var\"].isin(vars_keep)]\n",
    "                    list_df.append(dfkeep)    \n",
    "                \n",
    "            # list_which_level = sorted(set(list_which_level))\n",
    "            DFMULT_THEOR = pd.concat(list_df).reset_index(drop=True)\n",
    "            DFMULT_THEOR = append_col_with_grp_index(DFMULT_THEOR, [\"question\", \"var\"], \"q-var\", strings_compact=True)\n",
    "            # DFMULT_THEOR[\"var\"] = DFMULT_THEOR[\"q-var\"]\n",
    "            \n",
    "            # CHeck that you got all vars\n",
    "            for var in allvars:\n",
    "                print(var)\n",
    "                assert var in DFMULT_THEOR[\"var\"].unique()\n",
    "            \n",
    "            savedir = f\"{params['SAVEDIR']}/{animal}/SPLIT_BY_QUESTIONS/MULT/{DATE}/{version_distance}/COMBINED_ACROSS_QUESTIONS_FINAL\"\n",
    "            print(savedir)\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            \n",
    "            DFMULT_THEOR, DictBregionToDf2d, DictVarToDf2d, dfres_kernels_2d, PARAMS = pipeline_rsa_scalar_population_MULT_PLOTS(DFMULT_THEOR, savedir, yvar)\n",
    "        \n",
    "### Plotting dist matrices, sorted in various ways\n",
    "from neuralmonkey.analyses.rsa import _pipeline_rsa_score_pa_single\n",
    "import os\n",
    "\n",
    "# twind_keep = (0.1, 0.3)\n",
    "# twind_keep = (0.3, 0.5)\n",
    "twind_keep = (-0.3, -0.1)\n",
    "\n",
    "question = \"SP_shape\"\n",
    "variable_pair = [\"seqc_0_shape\", \"seqc_0_loc\"]\n",
    "\n",
    "# question = \"SP_shape_size\"\n",
    "# variable_pair = [\"seqc_0_shape\", \"gridsize\"]\n",
    "\n",
    "DO_AGG_TRIALS_LOAD = True\n",
    "DO_AGG_TRIALS_PLOT = True\n",
    "version_distance = \"pearson\"\n",
    "list_which_level = [\"trial\"]\n",
    "\n",
    "\n",
    "# \n",
    "# # twind_keep = (0.1, 0.3)\n",
    "# twind_keep = (-0.1, 0.1)\n",
    "# # variable_pair = [\"shape_label\", \"stroke_index\"]\n",
    "# variable_pair = [\"shape_label\", \"velmean_thbin\"]\n",
    "# DO_AGG_TRIALS_LOAD = False\n",
    "# DO_AGG_TRIALS_PLOT = True\n",
    "# # animal = \"Pancho\"\n",
    "# # DATE = 230623\n",
    "# version_distance = \"pearson\"\n",
    "# \n",
    "# # if False:\n",
    "# # list_animal_date = [\n",
    "# #     (\"Pancho\", \"230623\"),\n",
    "# #     (\"Pancho\", \"230626\"),\n",
    "# #     (\"Diego\", \"230628\"),\n",
    "# #     (\"Diego\", \"230630\"),\n",
    "# # ]\n",
    "# question = \"CHAR_shape\"\n",
    "for animal, DATE in list_animal_date:\n",
    "    \n",
    "    RES, SAVEDIR_MULT, params, REGIONS_IN_ORDER = load_mult_data_helper(animal, DATE, version_distance, question=question, DO_AGG_TRIALS=DO_AGG_TRIALS_LOAD,\n",
    "                                                                        list_which_level=list_which_level, event=None)\n",
    "    savedir = f\"{SAVEDIR_MULT}/replotting_pairwise_vars\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    print(savedir)\n",
    "    \n",
    "    # resthis = []\n",
    "    for res in RES:\n",
    "        which_level=res[\"which_level\"]\n",
    "        for bregion in REGIONS_IN_ORDER:\n",
    "            for twind in res[\"list_time_windows\"]:\n",
    "                if twind==twind_keep:\n",
    "                    key = (bregion, twind)\n",
    "                    print(\"Collecting data for:\", res[\"which_level\"], key)\n",
    "                    PA = res[\"DictBregionTwindPA\"][key]\n",
    "                    EFFECT_VARS = res[\"EFFECT_VARS\"]\n",
    "            \n",
    "                    # Norm of activity for each level of the variable. Then average these norms over the levels.    \n",
    "                    for ivar, var1 in enumerate(EFFECT_VARS):\n",
    "                        # condition this on each of the other vars\n",
    "                        for jvar, var2 in enumerate(EFFECT_VARS):\n",
    "                            if jvar>ivar:\n",
    "                                if [var1, var2]==variable_pair:\n",
    "                                    for subtract_mean_each_level_of_var in [None, var1, var2]:\n",
    "                                        sdir = f\"{savedir}/{which_level}-{bregion}{twind}/{var1}--{var2}--subtr_{subtract_mean_each_level_of_var}\"\n",
    "                                        os.makedirs(sdir, exist_ok=True)\n",
    "                                        # Extract raw data\n",
    "                                        \n",
    "                                        _, _, Clraw, _, PAagg, DictVarToClsimtheor = _pipeline_rsa_score_pa_single(PA, [var1, var2], res[\"version_distance\"], \n",
    "                                                                          subtract_mean_each_level_of_var, PLOT = True, sdir=sdir, PLOT_THEORETICAL_SIMMATS=True,\n",
    "                                                                        COMPUTE_SAME_DIFF_DIST = False, COMPUTE_VS_THEOR_MAT = True, DO_AGG_TRIALS=DO_AGG_TRIALS_PLOT)\n",
    "                                        \n",
    "                                        plt.close(\"all\") \n",
    "### Plotting rasters\n",
    "##### Final summary plots (sandbox)\n",
    "DictVarToDf2d[\"shape_oriented\"]\n",
    "dfres_kernels.keys()\n",
    "# Hand-picked ... contrast the temporal structure of small set of variables\n",
    "%matplotlib inline\n",
    "# dfthis = DFMULT_THEOR\n",
    "vars = [\"gridloc\", \"gap_from_prev_angle_binned\", \"gap_to_next_angle_binned\"]\n",
    "dfthis = DFMULT_THEOR[DFMULT_THEOR[\"var\"].isin(vars)]\n",
    "sns.catplot(data=dfthis, x=\"twind_str\", y=yvar, row=\"bregion\", hue=\"var\", col=\"which_level\", kind=\"point\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b319992bee1375c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IN DEVELOPMENT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2db7a5862a9e872"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing out, method for directly pitting two variables against each other"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27c630a5e5bc0339"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) Prune at level of comparisons: keep only comparisons that are opposed across the vars.\n",
    "# -- What is the principle behind this? IT is more about the sign of the effect than the magnitude?\n",
    "# -- More generally, is about getting subset of comparisons which are not correlated across the two vars.\n",
    "# -- This seems weird?\n",
    "# 2) Prune at level of var-levels: keep only levels (of both vars) that have at least 1 case of other var.\n",
    "# -- This would get the \"same beh\" control in epochs.\n",
    "# 3) \"Kernels\" using either the raw results, or the processed ones here (pairwise between variables).\n",
    "\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8754a66b2ea4008f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# - pick specific pair of variables. and plot across (bregion, timewindows). \n",
    "# - Make this saving pipleine"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bfe7d774fb488b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e2e42583baf10f6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6663739efaaccc78"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pull out speciifc dataset (bregion x time)\n",
    "which_level = \"stroke\"\n",
    "version_distance = \"pearson\"\n",
    "PLOT = False\n",
    "\n",
    "savedir = f\"{SAVEDIR}/{animal}/{DATE}/{which_level}/{version_distance}\"\n",
    "path = f\"{savedir}/resthis.pkl\"\n",
    "print(\"Loading res from: \", path)\n",
    "try:\n",
    "    with open(path, \"rb\") as f:\n",
    "        res = pickle.load(f)\n",
    "except Exception as err:\n",
    "    print(path)\n",
    "    print(\"Couldnt load this data! *******************\", version_distance, animal, DATE, which_level)\n",
    "\n",
    "## EXTRACT\n",
    "DictBregionTwindClraw = res[\"DictBregionTwindClraw\"]\n",
    "DictBregionTwindClsim = res[\"DictBregionTwindClsim\"]\n",
    "DictBregionTwindCPA = res[\"DictBregionTwindPA\"]\n",
    "\n",
    "res = []\n",
    "for twind in list_twind:\n",
    "    for bregion in list_bregion:\n",
    "        # bregion = \"PMd_p\"\n",
    "        key = (bregion, twind)\n",
    "        Clraw = DictBregionTwindClraw[key]\n",
    "        Clsim = DictBregionTwindClsim[key]\n",
    "        PA = DictBregionTwindCPA[key]\n",
    "        \n",
    "        ##### 1. Given two variables, how similar are their theoretical sim mats?\n",
    "        if PLOT:\n",
    "            list_var1 =[]\n",
    "            list_var2 = []\n",
    "            list_cc = []\n",
    "            for i, var1 in enumerate(EFFECT_VARS):\n",
    "                for j, var2 in enumerate(EFFECT_VARS):\n",
    "                    if j>i:\n",
    "                        Cltheor1, _ = Clsim.rsa_distmat_construct_theoretical(var1, False)\n",
    "                        Cltheor2, _ = Clsim.rsa_distmat_construct_theoretical(var2, False)\n",
    "            \n",
    "                        vec1 = Cltheor1.dataextract_upper_triangular_flattened()\n",
    "                        vec2 = Cltheor2.dataextract_upper_triangular_flattened()\n",
    "                        c = np.corrcoef(vec1, vec2)[0,1]\n",
    "                        \n",
    "                        print(var1, \" -- \", var2, \" -- \", c)\n",
    "                        list_var1.append(var1)\n",
    "                        list_var2.append(var2)\n",
    "                        list_cc.append(c)\n",
    "            \n",
    "            dfthis = pd.DataFrame({\"var1\":list_var1, \"var2\":list_var2, \"cc\":list_cc})\n",
    "            convert_to_2d_dataframe(dfthis, \"var1\", \"var2\", True, \"mean\", \"cc\", annotate_heatmap=True, dosort_colnames=False)\n",
    "    \n",
    "        # from neuralmonkey.analyses.state_space_good import rsa_convert_PA_to_Cl\n",
    "        # rsa_convert_PA_to_Cl(DictBregionTwindPA.values[0])\n",
    "        \n",
    "        ##### Compare pair of vars\n",
    "        # Go thru all pairs of vars\n",
    "        PLOT = False\n",
    "        for ivar, var in enumerate(EFFECT_VARS):\n",
    "            for jvar, var_other in enumerate(EFFECT_VARS):\n",
    "                if not var==var_other:\n",
    "                # if jvar>ivar:\n",
    "                    # var = \"gridloc\"\n",
    "                    # var_other = \"gap_from_prev_angle_binned\"\n",
    "                    # var = \"shape_oriented\"\n",
    "                    # var_other = \"gridloc\"\n",
    "                    \n",
    "                    # find pairs of datapts which make different predictions across the two variables.\n",
    "                    Cltheor1, _ = Clsim.rsa_distmat_construct_theoretical(var, False)\n",
    "                    Cltheor2, _ = Clsim.rsa_distmat_construct_theoretical(var_other, False)\n",
    "                    \n",
    "                    # Extract actual data and theor data\n",
    "                    vec_dat = Clsim.dataextract_upper_triangular_flattened()\n",
    "                    vec1 = Cltheor1.dataextract_upper_triangular_flattened()\n",
    "                    vec2 = Cltheor2.dataextract_upper_triangular_flattened()\n",
    "                    \n",
    "                    cc1 = np.corrcoef(vec_dat, vec1)[0,1]\n",
    "                    cc2 = np.corrcoef(vec_dat, vec2)[0,1]\n",
    "                    print(var, cc1)\n",
    "                    print(var_other, cc2)\n",
    "                    \n",
    "                    cc_kind = \"actual\"\n",
    "                    res.append({\n",
    "                        \"var\":var,\n",
    "                        \"var_other\":var_other,\n",
    "                        \"cc1\":cc1,\n",
    "                        \"cc2\":cc2,\n",
    "                        \"cc_kind\":cc_kind,\n",
    "                        \"bregion\":bregion,\n",
    "                        \"twind\":twind\n",
    "                    })\n",
    "                    # res.append({\n",
    "                    #     \"var_or_other\":\"var\",\n",
    "                    #     \"var\":var,\n",
    "                    #     \"cc\":cc1,\n",
    "                    #     \"cc_kind\":cc_kind,\n",
    "                    #     \"bregion\":bregion,\n",
    "                    #     \"twind\":twind\n",
    "                    # })\n",
    "                    # res.append({\n",
    "                    #     \"var_or_other\":\"other\",\n",
    "                    #     \"var\":var_other,\n",
    "                    #     \"cc\":cc2,\n",
    "                    #     \"cc_kind\":cc_kind,\n",
    "                    #     \"bregion\":bregion,\n",
    "                    #     \"twind\":twind\n",
    "                    # })\n",
    "                    \n",
    "                    ##### Method 1: include only data-pairs that make different predictions across the var\n",
    "                    \n",
    "                    # - normalize so that 0 is same and 1 is most different. This is becuase some, e.g, for\n",
    "                    # ordinal, have larger range.\n",
    "                    vec1_norm = vec1/np.max(vec1)\n",
    "                    vec2_norm = vec2/np.max(vec2)\n",
    "                    \n",
    "                    inds_mask = vec1_norm!=vec2_norm\n",
    "                    print(f\"Keeping this many comparisons: {sum(inds_mask)}, out of this many total: {len(inds_mask)}\")\n",
    "                    \n",
    "                    cc1 = np.corrcoef(vec_dat[inds_mask], vec1[inds_mask])[0,1]\n",
    "                    cc2 = np.corrcoef(vec_dat[inds_mask], vec2[inds_mask])[0,1]\n",
    "                    print(var, cc1)\n",
    "                    print(var_other, cc2)\n",
    "                    \n",
    "                    cc_kind = \"method1\"\n",
    "                    res.append({\n",
    "                        \"var\":var,\n",
    "                        \"var_other\":var_other,\n",
    "                        \"cc1\":cc1,\n",
    "                        \"cc2\":cc2,\n",
    "                        \"cc_kind\":cc_kind,\n",
    "                        \"bregion\":bregion,\n",
    "                        \"twind\":twind\n",
    "                    })\n",
    "                    \n",
    "                    ##### Method 2: Constrain just to cases that are \"same\" (i.e., dist = 0) in the other var. \n",
    "                    # NO: this is not good. this removes all comparisons of var across levels of other_var. This stops \n",
    "                    # testing of \"abstraction\" of var.\n",
    "                    if False:\n",
    "                        inds_mask = vec2==1\n",
    "                        print(f\"Keeping this many comparisons: {sum(inds_mask)}, out of this many total: {len(inds_mask)}\")\n",
    "                        \n",
    "                        cc1 = np.corrcoef(vec_dat[inds_mask], vec1[inds_mask])[0,1]\n",
    "                        cc2 = np.corrcoef(vec_dat[inds_mask], vec2[inds_mask])[0,1]\n",
    "                        print(cc1, cc2)\n",
    "                    \n",
    "                    ##### Method 3: Constrain just to levels of \"othervar\" that have at least 2 levels for var. \n",
    "                    # - reason: otherwise that level of othervar isn't contributing.\n",
    "                    from pythonlib.tools.pandastools import conjunction_vars_prune_to_balance, extract_with_levels_of_conjunction_vars\n",
    "                    \n",
    "                    # First, get subset of rows that are good.\n",
    "                    dflab = Clsim.rsa_labels_return_as_df()\n",
    "                    if PLOT:\n",
    "                        savedir=\"/tmp/tmp.png\"\n",
    "                    else:\n",
    "                        savedir = None\n",
    "                    dfout1, _ = extract_with_levels_of_conjunction_vars(dflab, var, [var_other], n_min=2, lenient_allow_data_if_has_n_levels=2, plot_counts_heatmap_savedir=savedir, DEBUG=False);\n",
    "                    dfout2, _ = extract_with_levels_of_conjunction_vars(dflab, var_other, [var], n_min=2, lenient_allow_data_if_has_n_levels=2, plot_counts_heatmap_savedir=savedir, DEBUG=False);\n",
    "                    inds_rows = [i for i in dfout1[\"row_index\"].tolist() if i in dfout2[\"row_index\"].tolist()]\n",
    "                    \n",
    "                    print(len(dflab), \" datapts, pruned to --> \", len(inds_rows))\n",
    "                    \n",
    "                    vec_dat = Clsim.dataextract_upper_triangular_flattened(True, inds_rows)\n",
    "                    vec1 = Cltheor1.dataextract_upper_triangular_flattened(True, inds_rows)\n",
    "                    vec2 = Cltheor2.dataextract_upper_triangular_flattened(True, inds_rows)\n",
    "                    \n",
    "                    cc1 = np.corrcoef(vec_dat, vec1)[0,1]\n",
    "                    cc2 = np.corrcoef(vec_dat, vec2)[0,1]\n",
    "                    print(var, cc1)\n",
    "                    print(var_other, cc2)\n",
    "                    \n",
    "                    cc_kind = \"method3\"\n",
    "                    res.append({\n",
    "                        \"var\":var,\n",
    "                        \"var_other\":var_other,\n",
    "                        \"cc1\":cc1,\n",
    "                        \"cc2\":cc2,\n",
    "                        \"cc_kind\":cc_kind,\n",
    "                        \"bregion\":bregion,\n",
    "                        \"twind\":twind\n",
    "                    })\n",
    "                    \n",
    "                    if False:\n",
    "                        # To get fully square matrix. Not worth it - drops too much data.\n",
    "                        dfthisout, dfcounts = conjunction_vars_prune_to_balance(dflab, var, var_other, True, prefer_to_drop_which=var);\n",
    "                    \n",
    "                    if PLOT:    \n",
    "                        # Plot correlation\n",
    "                        fig, ax = plt.subplots()\n",
    "                        # ax.plot(vec1[inds_mask], vec_dat[inds_mask], \"xk\", alpha=0.1)\n",
    "                        ax.plot(vec2[inds_mask], vec_dat[inds_mask], \"xk\", alpha=0.1)\n",
    "                        ax.set_xlabel(\"dist(theor)\")\n",
    "                        ax.set_ylabel(\"dist(dat)\")\n",
    "                        \n",
    "                    plt.close(\"all\")\n",
    "\n",
    "# Plot summary\n",
    "dfres_cc_pairs = pd.DataFrame(res)\n",
    "\n",
    "# Heatmap (subplot for each bregion, each showing each pair of variables)\n",
    "cc_kind = \"method1\"\n",
    "\n",
    "if cc_kind==\"method1\":\n",
    "    diverge=True\n",
    "else:\n",
    "    diverge=False\n",
    "ncols = 3\n",
    "W = 4\n",
    "H = 4\n",
    "nrows = int(np.ceil(len(list_bregion)/ncols))\n",
    "\n",
    "# for norm_method in [\"all_sub\", None, \"row_sub\", \"col_sub\"]:\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*W, nrows*H))\n",
    "for bregion, ax in zip(list_bregion, axes.flatten()):\n",
    "    print(bregion)\n",
    "    a = dfres_cc_pairs[\"bregion\"]==bregion\n",
    "    b = dfres_cc_pairs[\"cc_kind\"]==cc_kind    \n",
    "    dfthis = dfres_cc_pairs[(a) & (b)]\n",
    "    convert_to_2d_dataframe(dfthis, \"var\", \"var_other\", True, \"mean\", \"cc1\", ax=ax, annotate_heatmap=False, diverge=diverge)\n",
    "    ax.set_title(bregion) \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1522c1037320b7eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Heatmap (subplot for each bregion, each showing each pair of variables)\n",
    "cc_kind = \"method3\"\n",
    "\n",
    "if cc_kind==\"method1\":\n",
    "    diverge=True\n",
    "else:\n",
    "    diverge=False\n",
    "ncols = 3\n",
    "W = 4\n",
    "H = 4\n",
    "nrows = int(np.ceil(len(list_bregion)/ncols))\n",
    "\n",
    "# for norm_method in [\"all_sub\", None, \"row_sub\", \"col_sub\"]:\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*W, nrows*H))\n",
    "for bregion, ax in zip(list_bregion, axes.flatten()):\n",
    "    print(bregion)\n",
    "    a = dfres_cc_pairs[\"bregion\"]==bregion\n",
    "    b = dfres_cc_pairs[\"cc_kind\"]==cc_kind    \n",
    "    dfthis = dfres_cc_pairs[(a) & (b)]\n",
    "    convert_to_2d_dataframe(dfthis, \"var\", \"var_other\", True, \"mean\", \"cc1\", ax=ax, annotate_heatmap=False, diverge=diverge)\n",
    "    ax.set_title(bregion) \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "570bc1f111904973"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Process results from method 1: for each var take mean over all other vars.\n",
    "from pythonlib.tools.pandastools import aggregGeneral\n",
    "dfres_cc_pairs_AGG = aggregGeneral(dfres_cc_pairs, [\"var\", \"cc_kind\", \"bregion\", \"twind\"], [\"cc1\"], aggmethod=[\"mean\"])\n",
    "dfres_cc_pairs_AGG"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b131b7eed795cdfa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_cc_method = dfres_cc_pairs_AGG[\"cc_kind\"].unique().tolist()\n",
    "cc_kind = \"method3\"\n",
    "\n",
    "ncols = 3\n",
    "W = 4\n",
    "H = 4\n",
    "nrows = int(np.ceil(len(list_cc_method)/ncols))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*W, nrows*H))\n",
    "for cc_kind, ax in zip(list_cc_method, axes.flatten()):\n",
    "    if cc_kind==\"method1\":\n",
    "        diverge=True\n",
    "    else:\n",
    "        diverge=False\n",
    "    print(cc_kind)\n",
    "    # a = dfres_cc_pairs[\"bregion\"]==bregion\n",
    "    b = dfres_cc_pairs_AGG[\"cc_kind\"]==cc_kind    \n",
    "    dfthis = dfres_cc_pairs_AGG[(b)]\n",
    "    convert_to_2d_dataframe(dfthis, \"bregion\", \"var\", True, \"mean\", \"cc1\", ax=ax, annotate_heatmap=False, diverge=diverge, dosort_colnames=False)\n",
    "    ax.set_title(cc_kind) \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fa816777e39092d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Post-hoc plotting things realtied to sim mat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b265fcf8c35b1e05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.state_space_good import _preprocess_rsa_scalar_population"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c175f7cd8ef1055d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# correlation between these variables\n",
    "# TODO: extract values from within _preprocess_rsa_scalar_population to do this.\n",
    "\n",
    "# %matplotlib inline\n",
    "# Cltheor = Clsim.rsa_distmat_construct_theoretical(\"shape_oriented\")[0]\n",
    "# Cltheor.rsa_plot_heatmap()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69f04cde01ad846c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Debug -- plot for specific hand-picked cases"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e70d37e6d163a2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bregion = \"preSMA_a\"\n",
    "twind = (0.1, 0.3)\n",
    "# twind = (-0.5, -0.3)\n",
    "which_level = \"stroke\"\n",
    "\n",
    "res, PA, Clraw, Clsim = load_single_data(RES, bregion, twind, which_level)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85cd575dfd96e004"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### 1) PRUNE DATASET\n",
    "# Restrict just to tasks with 4 prims\n",
    "print(PA.X.shape)\n",
    "PAthis = PA.slice_by_labels(\"trials\", \"FEAT_num_strokes_task\", [3, 4])\n",
    "print(PAthis.X.shape)\n",
    "### 2) KEEP SPECIFIC LEVELS\n",
    "# Keep only specific levels of each of the vars\n",
    "# var = \"stroke_index\"\n",
    "# levels = [0,1,2]\n",
    "var = \"stroke_index_fromlast\"\n",
    "levels = [-4, -3, -2]\n",
    "\n",
    "PAthis = PAthis.slice_by_labels(\"trials\", var, levels)\n",
    "print(PA.X.shape)\n",
    "print(PAthis.X.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42e1c27f4ee21847"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate new Clsim\n",
    "var = \"CTXT_loc_next\"\n",
    "var_other = \"shape_oriented\"\n",
    "vars = [var, var_other]\n",
    "version_distance = \"pearson\"\n",
    "subtract_mean_each_level_of_var = vars[1]\n",
    "# subtract_mean_each_level_of_var = None\n",
    "_, _, Clraw, Clsim, PAagg = _preprocess_rsa_scalar_population(PAthis, vars, version_distance, subtract_mean_each_level_of_var=subtract_mean_each_level_of_var)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "809b517689e6d18d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Cltheor = Clsim.rsa_distmat_construct_theoretical(var, False)[0]\n",
    "Clraw.rsa_plot_heatmap((0,))\n",
    "Cltheor.rsa_plot_heatmap((0,))\n",
    "Clsim.rsa_plot_heatmap((0,))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5e008d4e7dfd2e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3f373867c32cca85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "print(lev)\n",
    "\n",
    "ax = axes.flatten()[0]\n",
    "Clsim._rsa_matindex_plot_bool_mask(ma_same, ax)\n",
    "\n",
    "ax = axes.flatten()[1]\n",
    "Clsim._rsa_matindex_plot_bool_mask(ma_diff, ax)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8e40004cb25def9"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d131f1dbb9b9a45b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### DEbugging, constructing theoretical var"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a3d495c9940afc8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.state_space_good import rsa_convert_PA_to_Cl, popanal_preprocess_scalar\n",
    "grouping_vars = [\"task_kind\", \"shape_oriented\", \"stroke_index_fromlast_tskstks\"]\n",
    "PAnorm, PAagg, fig, axes, groupdict = popanal_preprocess_scalar(PA, grouping_vars,\n",
    "                                                                subtract_mean_each_level_of_var,\n",
    "                                                                plot_example_chan=False,\n",
    "                                                                plot_example_split_var=False)\n",
    "\n",
    "Clraw, Clsim = rsa_convert_PA_to_Cl(PAagg, grouping_vars)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c7b29125eb615b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Clsim.rsa_distmat_construct_theoretical(\"task_kind\", PLOT=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d16e14e8dca8ddef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PA.Xlabels[\"trials\"].columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0dcaac5cd722a6c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [OBSOLETE] Trying to plit automaticlaly into \"questions\" or \"task sets\"\n",
    "\n",
    "Defined as conjucntions of n strokes in task, beh stroke indices, etc.\n",
    "Problem: Best to determine by hand which params and datapts to include for each \"question\" above"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dc24ab88a5f2765"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### GENERATE DATA FOR EACH TASKSET\n",
    "# res[\"list_time_windows\"]\n",
    "DictBregionTwindCPA = res[\"DictBregionTwindPA\"]\n",
    "\n",
    "grp_task = [\"FEAT_num_strokes_task\", \"stroke_index_0\"]\n",
    "var_taskset = \"taskset_nstk_idx0\"\n",
    "min_n_trials_taskset = 20\n",
    "\n",
    "DictDictBregionTwindCPA = {} # task_set:{(bregion, twind):pa}}\n",
    "for key, PA in DictBregionTwindCPA.items():\n",
    "    \n",
    "    ### 1) PRUNE DATASET\n",
    "    # Restrict just to tasks with 4 prims\n",
    "    PA.Xlabels[\"trials\"][\"stroke_index_0\"] = PA.Xlabels[\"trials\"][\"stroke_index\"]==0\n",
    "    PA.Xlabels[\"trials\"] = append_col_with_grp_index(PA.Xlabels[\"trials\"], grp_task, var_taskset, use_strings=False)\n",
    "    \n",
    "    # Collect for each task set\n",
    "    list_task_set = PA.Xlabels[\"trials\"][var_taskset].unique().tolist()\n",
    "    \n",
    "    for task_set in list_task_set:\n",
    "        PAthis = PA.slice_by_labels(\"trials\", var_taskset, [task_set])\n",
    "        \n",
    "        print(task_set, PAthis.X.shape)\n",
    "        if PAthis.X.shape[1] < min_n_trials_taskset:\n",
    "            # Exlcude\n",
    "            print(\"Skipping this taskset, since not enough data: \", task_set, PAthis.X.shape)\n",
    "            continue\n",
    "        \n",
    "        # Collect data\n",
    "        if task_set in DictDictBregionTwindCPA.keys():\n",
    "            DictDictBregionTwindCPA[task_set][key] = PAthis\n",
    "        else:\n",
    "            DictDictBregionTwindCPA[task_set] = {key:PAthis}\n",
    "           \n",
    "        if False:\n",
    "            ### 2) KEEP SPECIFIC LEVELS\n",
    "            # Keep only specific levels of each of the vars\n",
    "            # var = \"stroke_index\"\n",
    "            # levels = [0,1,2]\n",
    "            var = \"stroke_index_fromlast\"\n",
    "            levels = [-4, -3, -2]\n",
    "            \n",
    "            PAthis = PAthis.slice_by_labels(\"trials\", var, levels)\n",
    "            print(PA.X.shape)\n",
    "            print(PAthis.X.shape)\n",
    "    # DictBregionTwindCPA_NEW[k] = pa\n",
    "\n",
    "# Summarize \n",
    "print(\" ========== FINAL SUMMARY (taskset, pa.X.shape)\")\n",
    "for ts, dat in DictDictBregionTwindCPA.items():\n",
    "    pa = list(dat.values())[0]\n",
    "    print(ts, \" --- \", pa.X.shape)\n",
    "savedir = f\"{SAVEDIR_MULT}/overview_split_by_taskset\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "# Different effect vars for each dataset...\n",
    "\n",
    "EffectvarsEachTaskset = {}\n",
    "list_task_set = list(DictDictBregionTwindCPA.keys())\n",
    "for ts in list_task_set:\n",
    "    DictBregionTwindCPA_THIS = DictDictBregionTwindCPA[ts]\n",
    "    \n",
    "    # Should be same for each bregion, so just take first.\n",
    "    pa = list(DictBregionTwindCPA_THIS.values())[0]\n",
    "    \n",
    "    # EFFECT_VARS = [\"shape_oriented\", \"gridloc\"]\n",
    "    ####### PRUNE VARS TO SUIT THIS PA\n",
    "    pa_new, res_check_before, res_check_after, vars_remove, reason_vars_remove = preprocess_prune_pa_enough_data(pa, EFFECT_VARS)\n",
    "    \n",
    "    if pa_new is None:\n",
    "        print(ts)\n",
    "        print(reason_vars_remove)\n",
    "        assert False, \"these vars just dont work..\"\n",
    "        \n",
    "    # Exclude all vars that fail because not enough levels, and try again\n",
    "    vars_exclude = [var for var, reason in reason_vars_remove.items() if reason==\"not_enough_levels\"]\n",
    "    EFFECT_VARS_PRUNED = [var for var in EFFECT_VARS if var not in vars_exclude]\n",
    "    \n",
    "    pa_new, res_check_before, res_check_after, vars_remove, reason_vars_remove = preprocess_prune_pa_enough_data(pa, EFFECT_VARS_PRUNED)\n",
    "    if pa_new is None:\n",
    "        print(\"Problem, why still pruning a var, after already removed the vars with < 2 levels?\")\n",
    "        print(reason_vars_remove)\n",
    "        assert False\n",
    "    else:\n",
    "        print(\"Good, vars ready.. got these, for ts:\", ts)\n",
    "        print(EFFECT_VARS_PRUNED)\n",
    "        \n",
    "    EffectvarsEachTaskset[ts] = EFFECT_VARS_PRUNED\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Check a specific pa\n",
    "ts = (4, True)\n",
    "DictBregionTwindCPA_THIS = DictDictBregionTwindCPA[ts]\n",
    "EFFECT_VARS_PRUNED = EffectvarsEachTaskset[ts]\n",
    "\n",
    "pa = list(DictBregionTwindCPA_THIS.values())[0]\n",
    "pa_new, res_check_before, res_check_after, vars_remove, reason_vars_remove = preprocess_prune_pa_enough_data(pa, EFFECT_VARS_PRUNED)\n",
    "\n",
    "print(vars_remove)\n",
    "print(reason_vars_remove)\n",
    "# display(res_check_after[\"stroke_index_semantic\"])\n",
    "\n",
    "#### First, check that the vars you inputed are actually collectable for the data\n",
    "# - ie enough data\n",
    "\n",
    "# Run for each taskset\n",
    "list_task_set = DictDictBregionTwindCPA.keys()\n",
    "subtract_mean_each_level_of_var = \"IGNORE\"\n",
    "EFFECT_VARS_THIS = res[\"EFFECT_VARS\"]\n",
    "\n",
    "# Track success\n",
    "successes = []\n",
    "for task_set in list_task_set:\n",
    "    DictBregionTwindCPA_THIS = DictDictBregionTwindCPA[task_set]\n",
    "\n",
    "#### SCORE EACH DATASET\n",
    "\n",
    "# Run for each taskset\n",
    "list_task_set = DictDictBregionTwindCPA.keys()\n",
    "# EFFECT_VARS = res[\"EFFECT_VARS\"]\n",
    "subtract_mean_each_level_of_var = \"IGNORE\"\n",
    "EFFECT_VARS_THIS = res[\"EFFECT_VARS\"]\n",
    "\n",
    "# Track success\n",
    "successes = []\n",
    "for task_set in list_task_set:\n",
    "    DictBregionTwindCPA_THIS = DictDictBregionTwindCPA[task_set]\n",
    "    \n",
    "    ##\n",
    "    sdir = f\"{savedir}/{task_set}\"\n",
    "    \n",
    "    PLOT = False\n",
    "    DFRES_SAMEDIFF, DFRES_THEOR, DictBregionTwindPA, \\\n",
    "        DictBregionTwindClraw, DictBregionTwindClsim, sdir = _pipeline_score_all_pa(DictBregionTwindCPA_THIS, EFFECT_VARS=EFFECT_VARS_THIS,\n",
    "                           savedir=sdir, PLOT=PLOT, subtract_mean_each_level_of_var=subtract_mean_each_level_of_var)\n",
    "\n",
    "    resthis = {\n",
    "        \"version_distance\":version_distance,\n",
    "        \"which_level\":which_level,\n",
    "        \"DFRES_SAMEDIFF\":DFRES_SAMEDIFF, \n",
    "        \"DFRES_THEOR\":DFRES_THEOR, \n",
    "        \"DictBregionTwindPA\":DictBregionTwindPA, \n",
    "        \"DictBregionTwindClraw\":DictBregionTwindClraw,\n",
    "        \"DictBregionTwindClsim\":DictBregionTwindClsim,\n",
    "        \"EFFECT_VARS\":EFFECT_VARS_THIS,\n",
    "        \"list_time_windows\":res[\"list_time_windows\"],\n",
    "        \"SAVEDIR\":sdir,\n",
    "        \"subtract_mean_each_level_of_var\":subtract_mean_each_level_of_var,\n",
    "    }\n",
    "    \n",
    "    # Save results temporarily\n",
    "    # Around 800 MB\n",
    "    import pickle\n",
    "    path = f\"{sdir}/resthis.pkl\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(resthis, f)\n",
    "        print(\"saved res to: \", path)\n",
    "        \n",
    "    for k, clraw in DictBregionTwindClraw.items():\n",
    "        successes.append({\n",
    "            \"task_set\":task_set,\n",
    "            \"bregion\":k[0],\n",
    "            \"twind\":k[1],\n",
    "            \"success\":clraw is not None\n",
    "        })\n",
    "        \n",
    "dfsucc = pd.DataFrame(successes)\n",
    "dfsucc[dfsucc[\"success\"]==False]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6c5fc8bfd545750"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Try using all trials"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75aab7cc6525e3ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "animal = \"Pancho\"\n",
    "DATE = 230623\n",
    "list_which_level=[\"stroke\"]\n",
    "RES, SAVEDIR_MULT, params, REGIONS_IN_ORDER = load_mult_data_helper(animal, DATE, \"pearson\", list_which_level)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6fdaacdb68a7d89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bregion = \"dlPFC_a\"\n",
    "twind = (0.1, 0.3)\n",
    "DictBregionTwindPA = RES[0][\"DictBregionTwindPA\"]\n",
    "\n",
    "PA = DictBregionTwindPA[(bregion, twind)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b50d9ffd3022256"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.rsa import _preprocess_rsa_scalar_population\n",
    "vars = [\"shape_oriented\", \"gridloc\"]\n",
    "DO_AGG_TRIALS = False\n",
    "# subtract_mean_each_level_of_var = \"gridloc\"\n",
    "subtract_mean_each_level_of_var = \"shape_oriented\"\n",
    "subtract_mean_each_level_of_var = None\n",
    "dfres_same_diff, dfres_theor, Clraw, Clsim, PAagg = _preprocess_rsa_scalar_population(PA, vars, \n",
    "                                                                                      subtract_mean_each_level_of_var=subtract_mean_each_level_of_var,\n",
    "                                                                                      PLOT=False, sdir=\"/tmp\", PLOT_THEORETICAL_SIMMATS=False, DO_AGG_TRIALS=DO_AGG_TRIALS)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "565d77a0ba9e1257"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Clraw.rsa_plot_heatmap(sort_order=(0,1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "185c2db82b57a905"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Clsim.rsa_plot_heatmap(sort_order=(0,1));\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be47d8264cd3d122"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Cltheor = Clsim.rsa_distmat_construct_theoretical(\"gridloc\")[0]\n",
    "Cltheor.rsa_plot_heatmap((0,1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67ac54f23aeb80c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
