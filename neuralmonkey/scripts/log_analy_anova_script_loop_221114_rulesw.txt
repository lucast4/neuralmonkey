Got these LIST_VAR and LIST_VARS_CONJUNCTION:
['epoch', 'epoch', 'character', 'seqc_0_loc_shape', 'seqc_0_loc', 'seqc_1_loc_shape']
[['epochset'], ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset', 'seqc_0_loc_shape']]
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*221114*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952
session:  0
1
Beh Sessions that exist on this date:  {221114: [(1, 'dirdir1b')]}
taking this beh session: 1
------------------------------
Loading this neural session: 0
Loading these beh expts: ['dirdir1b']
Loading these beh sessions: [1]
Using this beh_trial_map_list: [(1, 0)]
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*221114*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952
{'filename_components_hyphened': ['Pancho', '221114', '153952'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/221114'], 'basedirs_filenames': ['221114', 'Pancho-221114-153952'], 'filename_final_ext': 'Pancho-221114-153952', 'filename_final_noext': 'Pancho-221114-153952'}
FOund this path for spikes:  /mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952/spikes_tdt_quick-4
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952/Pancho-221114-153952
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952/spikes_tdt_quick-4
final_dir_name  --  Pancho-221114-153952
time  --  153952
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/221114.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
-  1 68.06931533813477
-  2 69.66489105224609
o  3 82.74347000122071
-  4 60.36389389038086
o  5 80.42985610961914
o  6 80.34103088378906
o  7 127.66825103759767
-  8 65.57163314819336
o  9 326.29052734375
o  10 79.26123275756837
o  11 123.41967391967773
o  12 97.26083679199219
o  13 191.08635559082035
o  14 86.96034317016601
o  15 204.19856567382814
o  16 84.02928161621094
o  17 81.344287109375
o  18 198.6181350708008
o  19 101.07905044555665
-  20 49.90549926757813
-  21 56.72679138183594
o  22 101.81901321411132
-  23 44.64807357788086
o  24 85.83126831054689
o  25 83.8583854675293
o  26 271.14560546875003
o  27 111.22440948486329
o  28 85.63344116210938
o  29 194.01446838378908
o  30 130.59820709228515
o  31 137.5751937866211
-  32 68.99211044311524
o  33 94.79967880249023
o  34 124.72103271484382
-  35 42.8513427734375
o  36 90.04633331298828
-  37 62.27242164611817
o  38 108.28256378173829
-  39 66.09671173095703
o  40 81.78657989501953
-  41 65.04173049926757
o  42 114.17992782592775
-  43 65.40102462768554
o  44 206.82770080566408
o  45 160.92139892578126
-  46 47.7468204498291
o  47 145.54843292236328
-  48 43.560595703125
o  49 108.19694595336914
o  50 97.56157836914063
o  51 97.6242057800293
o  52 73.15627746582031
o  53 397.5306121826172
-  54 68.50008544921876
o  55 154.47560272216796
-  56 59.45414505004883
o  57 183.99520568847657
o  58 88.72997131347657
o  59 74.47848434448242
o  60 79.84336395263672
o  61 89.95161895751953
o  62 76.19048461914062
o  63 160.7513168334961
o  64 94.96082916259766
o  65 83.42011260986328
o  66 82.18641815185546
o  67 94.33903427124024
o  68 212.85457763671877
-  69 69.11521682739257
-  70 50.37205200195312
o  71 73.88416137695313
o  72 99.70608901977539
-  73 65.56459274291993
o  74 74.54685287475586
-  75 63.693039703369145
o  76 72.68123626708984
-  77 68.03669052124023
o  78 118.5713996887207
-  79 67.2722869873047
o  80 78.67979888916015
-  81 58.910748672485354
-  82 63.69935874938965
o  83 75.75670852661133
o  84 73.50166702270508
-  85 59.31715393066406
o  86 71.4793601989746
-  87 46.93958053588867
-  88 65.52943191528321
-  89 56.06555404663086
-  90 69.29340057373047
-  91 61.29177894592285
o  92 79.21974487304688
-  93 59.9308780670166
o  94 73.1291717529297
-  95 59.35870513916016
-  96 66.83370513916016
o  97 207.66663513183593
o  98 100.53455505371095
o  99 99.74978179931641
o  100 86.40490493774413
o  101 100.62152938842773
o  102 94.93000793457031
-  103 54.18083076477051
-  104 68.89505386352539
o  105 75.39430313110351
-  106 50.54007034301758
-  107 40.494086837768556
-  108 63.91023559570313
-  109 46.923011016845706
-  110 57.33493614196778
-  111 63.673004150390625
o  112 179.99234771728516
o  113 75.54412918090821
o  114 75.28427734375
-  115 54.05173225402832
o  116 131.9329818725586
-  117 56.861985778808595
o  118 78.19854278564453
-  119 65.78610916137696
o  120 70.93653030395508
o  121 82.28889083862305
o  122 93.78357391357423
o  123 212.2505096435547
-  124 48.571590423583984
-  125 43.654574966430665
o  126 122.90284652709961
-  127 60.576484298706056
-  128 66.31521530151367
-  129 68.31191711425781
o  130 303.12504882812505
o  131 71.09255905151367
o  132 131.5561309814453
-  133 55.2003677368164
o  134 94.9905876159668
-  135 62.876564025878906
o  136 109.87889633178712
-  137 62.1809928894043
o  138 122.31454925537109
-  139 62.289025497436526
o  140 175.7999725341797
o  141 187.86309814453128
o  142 391.0502563476563
o  143 355.87952575683596
o  144 103.0286636352539
-  145 63.13205795288086
-  146 62.54127235412598
-  147 64.43988265991212
o  148 171.3584945678711
o  149 108.25636291503906
o  150 103.25330886840821
-  151 49.57059555053711
o  152 109.86503295898437
-  153 63.999796295166014
o  154 91.77690048217774
o  155 175.8883255004883
o  156 156.7129898071289
-  157 59.7891342163086
o  158 123.8092887878418
o  159 149.127783203125
o  160 78.02728652954103
o  161 87.66611938476562
o  162 120.71288375854492
o  163 123.5075881958008
o  164 79.52127075195312
o  165 103.16358108520508
-  166 66.9025032043457
o  167 136.97906646728515
-  168 64.81002426147461
-  169 67.89386520385743
o  170 88.46861267089844
o  171 195.044482421875
-  172 54.711785888671876
o  173 114.10876846313477
-  174 62.96176033020019
-  175 69.55742111206055
-  176 62.621219635009766
o  177 101.48421783447266
o  178 76.47903671264655
o  179 244.5767013549805
-  180 62.712752532958994
o  181 108.75244369506837
-  182 60.72160720825195
o  183 88.23031768798829
o  184 77.39754714965821
-  185 26.20863628387451
o  186 86.59875259399415
o  187 97.1904983520508
-  188 60.33813209533692
o  189 98.04969482421876
-  190 64.2657485961914
-  191 68.34085540771484
o  192 125.93445892333985
o  193 108.40975799560547
o  194 75.36485595703125
o  195 210.20851135253906
-  196 54.245041656494145
o  197 98.7213752746582
o  198 70.94248886108399
-  199 59.104195022583006
o  200 79.53477249145509
o  201 95.95826263427735
o  202 106.25816650390627
o  203 116.74761199951173
o  204 103.47704772949218
o  205 74.23085174560546
o  206 110.59509429931641
-  207 62.49543800354004
-  208 61.12764205932617
-  209 52.46098289489746
o  210 92.65691833496093
-  211 64.0324951171875
-  212 50.99794578552246
o  213 78.72339477539063
-  214 67.11008987426759
-  215 66.89288940429688
-  216 46.01769790649414
-  217 62.2868221282959
o  218 100.4020622253418
o  219 75.1237777709961
-  220 64.45398635864258
-  221 58.529079055786134
o  222 79.00638122558594
o  223 74.51407012939453
o  224 81.11997756958009
o  225 80.53787460327149
o  226 79.03496170043945
o  227 151.7420867919922
-  228 66.31306304931641
-  229 63.81632919311524
-  230 61.22932243347168
-  231 62.24059524536133
-  232 35.60774154663086
o  233 81.83422317504883
-  234 63.12645225524903
o  235 89.84893798828125
-  236 57.85363502502442
o  237 93.81177368164063
o  238 72.9800910949707
-  239 60.60012245178223
-  240 63.20091552734375
-  241 63.71261215209961
o  242 126.85375442504883
o  243 70.40879211425782
-  244 64.51042404174805
o  245 94.73720245361328
o  246 72.72991104125977
-  247 58.70638923645019
o  248 90.7659408569336
-  249 64.08270874023438
-  250 63.287212753295904
-  251 63.2353385925293
o  252 92.3044059753418
-  253 65.92598571777344
-  254 58.44234619140625
o  255 73.80102005004883
o  256 86.49599151611328
o  257 201.80299072265626
o  258 70.1256607055664
o  259 94.53732604980469
o  260 149.76595916748047
o  261 124.20758209228516
o  262 84.90264129638672
o  263 100.42024765014648
o  264 95.456298828125
-  265 68.13500747680663
o  266 104.22980422973633
o  267 114.75179748535156
-  268 53.74220504760742
o  269 105.71536483764649
o  270 93.13355560302735
-  271 58.7779712677002
o  272 196.84488525390626
o  273 84.72943801879883
o  274 89.14522247314453
o  275 83.39923324584962
o  276 88.57120971679687
o  277 71.3733268737793
o  278 102.1148193359375
o  279 110.88192901611329
o  280 86.50489196777345
o  281 86.33070831298828
o  282 115.01237030029297
-  283 65.06012725830078
o  284 92.15303649902344
o  285 134.95092010498047
o  286 82.28335952758789
-  287 60.003937530517575
o  288 82.32739639282227
-  289 58.3252513885498
o  290 78.75153198242188
-  291 66.44487991333008
-  292 42.19511413574219
-  293 65.43164825439453
o  294 81.89097747802734
-  295 54.85442810058594
-  296 68.05075149536133
-  297 55.82337493896485
-  298 63.17007141113282
o  299 73.0493293762207
-  300 56.974021911621094
-  301 69.41181182861328
o  302 71.28805389404297
o  303 104.02659072875977
o  304 78.4604461669922
-  305 48.038251113891604
-  306 65.09102020263671
-  307 68.82397613525391
-  308 52.46974792480469
-  309 67.43550567626953
o  310 70.3451416015625
-  311 56.55269546508789
-  312 65.64676361083984
-  313 69.63730850219727
o  314 98.30939559936525
-  315 58.712075805664064
o  316 85.31494903564453
-  317 48.982164001464845
o  318 82.6393669128418
-  319 60.88548164367676
-  320 67.05146102905273
-  321 59.475363159179686
-  322 53.834582901000985
-  323 59.76222381591797
-  324 58.34819145202637
o  325 87.52590637207047
-  326 63.921142196655275
o  327 162.75310668945312
o  328 84.22410430908204
-  329 67.53224411010743
o  330 72.07514343261718
-  331 69.34184951782227
-  332 52.28923416137695
o  333 92.50596160888672
o  334 96.23187103271485
-  335 43.62738952636719
-  336 57.39719848632813
-  337 53.00855941772461
-  338 55.49724426269531
-  339 66.76402740478515
-  340 39.8910774230957
-  341 52.47274169921875
-  342 56.04209899902344
o  343 71.22752304077149
o  344 335.0489807128906
-  345 57.534861373901364
o  346 81.68250427246095
-  347 54.141077804565434
-  348 52.74230270385742
o  349 81.03909606933594
-  350 69.55098495483398
o  351 85.44299468994141
o  352 78.73950653076173
o  353 72.90857543945313
o  354 82.6985092163086
-  355 59.84304924011231
-  356 62.36914100646973
-  357 39.46798820495606
-  358 65.35654220581054
-  359 46.97404747009278
-  360 56.03001251220703
-  361 57.07380981445313
-  362 58.02370338439942
o  363 71.88277816772461
o  364 74.81486740112305
-  365 44.60891342163086
-  366 55.16217269897461
o  367 73.39824523925782
o  368 70.97678680419922
o  369 86.02032165527343
-  370 46.47331275939941
o  371 82.6077995300293
-  372 61.74030380249023
o  373 73.0550521850586
-  374 62.72493667602539
o  375 84.92794570922852
o  376 78.49701766967775
-  377 52.00413856506348
-  378 62.9726978302002
-  379 55.69125900268555
-  380 47.6731201171875
o  381 85.09572372436524
o  382 71.48097534179688
o  383 76.04981689453125
-  384 57.07367095947266
o  385 141.1519302368164
o  386 76.46527938842773
o  387 133.41721649169924
o  388 163.48432159423828
o  389 222.2937438964844
o  390 115.1761474609375
-  391 44.16472396850586
-  392 63.43827667236328
o  393 90.97134170532227
o  394 106.13111419677739
o  395 170.3499481201172
o  396 89.35421981811525
o  397 72.85039520263672
o  398 75.74149322509766
o  399 90.72751159667969
o  400 116.50228729248047
o  401 148.01874694824218
o  402 139.43709564208987
o  403 195.55069580078126
o  404 178.6170883178711
o  405 136.94361419677733
o  406 95.19737243652344
o  407 140.1198715209961
-  408 65.21653289794922
o  409 71.95815429687501
o  410 260.83604125976564
o  411 165.54819946289064
-  412 62.9305534362793
o  413 125.0418441772461
o  414 197.58991088867188
o  415 126.31919860839844
o  416 101.0657455444336
o  417 97.45459899902343
o  418 99.62319641113281
o  419 71.92835083007813
-  420 67.37173385620117
o  421 80.13869247436524
o  422 93.35797729492188
o  423 113.08047256469729
-  424 61.30449676513672
o  425 76.24217224121094
-  426 51.276406097412114
-  427 69.78734970092773
-  428 26.545696449279784
o  429 91.65870742797851
o  430 81.71278533935546
-  431 50.07049369812012
-  432 51.8477066040039
o  433 126.89140548706055
o  434 102.00621337890627
o  435 169.6657653808594
o  436 144.25493774414062
o  437 99.8838966369629
o  438 122.42195434570313
o  439 87.08586730957032
-  440 59.672653961181645
o  441 98.23184661865234
-  442 60.63063735961914
o  443 218.3988037109375
-  444 34.39996109008789
o  445 79.94628524780273
-  446 33.57834091186523
o  447 95.2865005493164
-  448 29.363975715637206
o  449 233.23975677490236
o  450 134.82024078369142
o  451 107.76330108642578
o  452 110.87806701660156
o  453 89.89170837402344
o  454 117.67790985107422
o  455 153.3751953125
-  456 50.06908340454102
o  457 181.01205291748047
-  458 64.97798309326173
o  459 224.4985809326172
o  460 135.74433288574218
o  461 179.75297851562502
o  462 90.59456253051758
o  463 75.38699722290039
o  464 155.34880218505864
o  465 144.88835906982425
o  466 113.44417190551758
o  467 106.41199035644532
o  468 122.14490051269532
o  469 157.16061248779297
-  470 69.50756149291993
o  471 100.60200576782228
o  472 86.24369964599609
o  473 154.69929504394537
o  474 75.17743225097657
o  475 92.96099472045898
-  476 51.42523536682129
o  477 136.20855255126952
o  478 101.59756011962891
o  479 80.39283828735351
o  480 88.09938507080078
-  481 66.74043502807618
-  482 36.260274505615236
o  483 89.87595062255859
o  484 139.6338607788086
o  485 159.50121154785157
o  486 89.53620147705078
o  487 87.60205078125
o  488 92.90513381958009
o  489 143.6256561279297
o  490 75.61765975952149
o  491 159.7208938598633
o  492 126.0170967102051
o  493 118.45273284912109
o  494 123.40048294067383
o  495 73.73475646972656
o  496 136.04393310546874
o  497 112.10711059570312
o  498 505.1807556152344
-  499 58.0737606048584
o  500 159.7846832275391
o  501 70.44407424926757
o  502 113.03218460083008
o  503 74.68003692626954
-  504 68.55691299438477
o  505 91.21163711547852
-  506 62.66373252868652
-  507 30.45794677734375
o  508 73.7294204711914
o  509 73.88777313232423
o  510 101.55365982055665
-  511 34.94534187316894
o  512 102.29774932861329
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
... Generated these...
self.BehTrialMapList [(1, 0)]
self.BehTrialMapListGood {0: (0, 1), 1: (0, 2), 2: (0, 3), 3: (0, 4), 4: (0, 5), 5: (0, 6), 6: (0, 7), 7: (0, 8), 8: (0, 9), 9: (0, 10), 10: (0, 11), 11: (0, 12), 12: (0, 13), 13: (0, 14), 14: (0, 15), 15: (0, 16), 16: (0, 17), 17: (0, 18), 18: (0, 19), 19: (0, 20), 20: (0, 21), 21: (0, 22), 22: (0, 23), 23: (0, 24), 24: (0, 25), 25: (0, 26), 26: (0, 27), 27: (0, 28), 28: (0, 29), 29: (0, 30), 30: (0, 31), 31: (0, 32), 32: (0, 33), 33: (0, 34), 34: (0, 35), 35: (0, 36), 36: (0, 37), 37: (0, 38), 38: (0, 39), 39: (0, 40), 40: (0, 41), 41: (0, 42), 42: (0, 43), 43: (0, 44), 44: (0, 45), 45: (0, 46), 46: (0, 47), 47: (0, 48), 48: (0, 49), 49: (0, 50), 50: (0, 51), 51: (0, 52), 52: (0, 53), 53: (0, 54), 54: (0, 55), 55: (0, 56), 56: (0, 57), 57: (0, 58), 58: (0, 59), 59: (0, 60), 60: (0, 61), 61: (0, 62), 62: (0, 63), 63: (0, 64), 64: (0, 65), 65: (0, 66), 66: (0, 67), 67: (0, 68), 68: (0, 69), 69: (0, 70), 70: (0, 71), 71: (0, 72), 72: (0, 73), 73: (0, 74), 74: (0, 75), 75: (0, 76), 76: (0, 77), 77: (0, 78), 78: (0, 79), 79: (0, 80), 80: (0, 81), 81: (0, 82), 82: (0, 83), 83: (0, 84), 84: (0, 85), 85: (0, 86), 86: (0, 87), 87: (0, 88), 88: (0, 89), 89: (0, 90), 90: (0, 91), 91: (0, 92), 92: (0, 93), 93: (0, 94), 94: (0, 95), 95: (0, 96), 96: (0, 97), 97: (0, 98), 98: (0, 99), 99: (0, 100), 100: (0, 101), 101: (0, 102), 102: (0, 103), 103: (0, 104), 104: (0, 105), 105: (0, 106), 106: (0, 107), 107: (0, 108), 108: (0, 109), 109: (0, 110), 110: (0, 111), 111: (0, 112), 112: (0, 113), 113: (0, 114), 114: (0, 115), 115: (0, 116), 116: (0, 117), 117: (0, 118), 118: (0, 119), 119: (0, 120), 120: (0, 121), 121: (0, 122), 122: (0, 123), 123: (0, 124), 124: (0, 125), 125: (0, 126), 126: (0, 127), 127: (0, 128), 128: (0, 129), 129: (0, 130), 130: (0, 131), 131: (0, 132), 132: (0, 133), 133: (0, 134), 134: (0, 135), 135: (0, 136), 136: (0, 137), 137: (0, 138), 138: (0, 139), 139: (0, 140), 140: (0, 141), 141: (0, 142), 142: (0, 143), 143: (0, 144), 144: (0, 145), 145: (0, 146), 146: (0, 147), 147: (0, 148), 148: (0, 149), 149: (0, 150), 150: (0, 151), 151: (0, 152), 152: (0, 153), 153: (0, 154), 154: (0, 155), 155: (0, 156), 156: (0, 157), 157: (0, 158), 158: (0, 159), 159: (0, 160), 160: (0, 161), 161: (0, 162), 162: (0, 163), 163: (0, 164), 164: (0, 165), 165: (0, 166), 166: (0, 167), 167: (0, 168), 168: (0, 169), 169: (0, 170), 170: (0, 171), 171: (0, 172), 172: (0, 173), 173: (0, 174), 174: (0, 175), 175: (0, 176), 176: (0, 177), 177: (0, 178), 178: (0, 179), 179: (0, 180), 180: (0, 181), 181: (0, 182), 182: (0, 183), 183: (0, 184), 184: (0, 185), 185: (0, 186), 186: (0, 187), 187: (0, 188), 188: (0, 189), 189: (0, 190), 190: (0, 191), 191: (0, 192), 192: (0, 193), 193: (0, 194), 194: (0, 195), 195: (0, 196), 196: (0, 197), 197: (0, 198), 198: (0, 199), 199: (0, 200), 200: (0, 201), 201: (0, 202), 202: (0, 203), 203: (0, 204), 204: (0, 205), 205: (0, 206), 206: (0, 207), 207: (0, 208), 208: (0, 209), 209: (0, 210), 210: (0, 211), 211: (0, 212), 212: (0, 213), 213: (0, 214), 214: (0, 215), 215: (0, 216), 216: (0, 217), 217: (0, 218), 218: (0, 219), 219: (0, 220), 220: (0, 221), 221: (0, 222), 222: (0, 223), 223: (0, 224), 224: (0, 225), 225: (0, 226), 226: (0, 227), 227: (0, 228), 228: (0, 229), 229: (0, 230), 230: (0, 231), 231: (0, 232), 232: (0, 233), 233: (0, 234), 234: (0, 235), 235: (0, 236), 236: (0, 237), 237: (0, 238), 238: (0, 239), 239: (0, 240), 240: (0, 241), 241: (0, 242), 242: (0, 243), 243: (0, 244), 244: (0, 245), 245: (0, 246), 246: (0, 247), 247: (0, 248), 248: (0, 249), 249: (0, 250), 250: (0, 251), 251: (0, 252), 252: (0, 253), 253: (0, 254), 254: (0, 255), 255: (0, 256), 256: (0, 257), 257: (0, 258), 258: (0, 259), 259: (0, 260), 260: (0, 261), 261: (0, 262), 262: (0, 263), 263: (0, 264), 264: (0, 265), 265: (0, 266), 266: (0, 267), 267: (0, 268), 268: (0, 269), 269: (0, 270), 270: (0, 271), 271: (0, 272), 272: (0, 273), 273: (0, 274), 274: (0, 275), 275: (0, 276), 276: (0, 277), 277: (0, 278), 278: (0, 279), 279: (0, 280), 280: (0, 281), 281: (0, 282), 282: (0, 283), 283: (0, 284), 284: (0, 285), 285: (0, 286), 286: (0, 287), 287: (0, 288), 288: (0, 289), 289: (0, 290), 290: (0, 291), 291: (0, 292), 292: (0, 293), 293: (0, 294), 294: (0, 295), 295: (0, 296), 296: (0, 297), 297: (0, 298), 298: (0, 299), 299: (0, 300), 300: (0, 301), 301: (0, 302), 302: (0, 303), 303: (0, 304), 304: (0, 305), 305: (0, 306), 306: (0, 307), 307: (0, 308), 308: (0, 309), 309: (0, 310), 310: (0, 311), 311: (0, 312), 312: (0, 313), 313: (0, 314), 314: (0, 315), 315: (0, 316), 316: (0, 317), 317: (0, 318), 318: (0, 319), 319: (0, 320), 320: (0, 321), 321: (0, 322), 322: (0, 323), 323: (0, 324), 324: (0, 325), 325: (0, 326), 326: (0, 327), 327: (0, 328), 328: (0, 329), 329: (0, 330), 330: (0, 331), 331: (0, 332), 332: (0, 333), 333: (0, 334), 334: (0, 335), 335: (0, 336), 336: (0, 337), 337: (0, 338), 338: (0, 339), 339: (0, 340), 340: (0, 341), 341: (0, 342), 342: (0, 343), 343: (0, 344), 344: (0, 345), 345: (0, 346), 346: (0, 347), 347: (0, 348), 348: (0, 349), 349: (0, 350), 350: (0, 351), 351: (0, 352), 352: (0, 353), 353: (0, 354), 354: (0, 355), 355: (0, 356), 356: (0, 357), 357: (0, 358), 358: (0, 359), 359: (0, 360), 360: (0, 361), 361: (0, 362), 362: (0, 363), 363: (0, 364), 364: (0, 365), 365: (0, 366), 366: (0, 367), 367: (0, 368), 368: (0, 369), 369: (0, 370), 370: (0, 371), 371: (0, 372), 372: (0, 373), 373: (0, 374), 374: (0, 375), 375: (0, 376), 376: (0, 377), 377: (0, 378), 378: (0, 379), 379: (0, 380), 380: (0, 381), 381: (0, 382), 382: (0, 383), 383: (0, 384), 384: (0, 385), 385: (0, 386), 386: (0, 387), 387: (0, 388), 388: (0, 389), 389: (0, 390), 390: (0, 391), 391: (0, 392), 392: (0, 393), 393: (0, 394), 394: (0, 395), 395: (0, 396), 396: (0, 397), 397: (0, 398), 398: (0, 399), 399: (0, 400), 400: (0, 401), 401: (0, 402), 402: (0, 403), 403: (0, 404), 404: (0, 405), 405: (0, 406), 406: (0, 407), 407: (0, 408), 408: (0, 409), 409: (0, 410), 410: (0, 411), 411: (0, 412), 412: (0, 413), 413: (0, 414), 414: (0, 415), 415: (0, 416), 416: (0, 417), 417: (0, 418), 418: (0, 419), 419: (0, 420), 420: (0, 421), 421: (0, 422), 422: (0, 423), 423: (0, 424), 424: (0, 425), 425: (0, 426), 426: (0, 427), 427: (0, 428), 428: (0, 429), 429: (0, 430), 430: (0, 431), 431: (0, 432), 432: (0, 433), 433: (0, 434), 434: (0, 435), 435: (0, 436), 436: (0, 437), 437: (0, 438), 438: (0, 439), 439: (0, 440), 440: (0, 441), 441: (0, 442), 442: (0, 443), 443: (0, 444), 444: (0, 445), 445: (0, 446), 446: (0, 447), 447: (0, 448), 448: (0, 449), 449: (0, 450), 450: (0, 451), 451: (0, 452), 452: (0, 453), 453: (0, 454), 454: (0, 455), 455: (0, 456), 456: (0, 457), 457: (0, 458), 458: (0, 459), 459: (0, 460), 460: (0, 461), 461: (0, 462), 462: (0, 463), 463: (0, 464), 464: (0, 465), 465: (0, 466), 466: (0, 467), 467: (0, 468), 468: (0, 469), 469: (0, 470), 470: (0, 471), 471: (0, 472), 472: (0, 473), 473: (0, 474), 474: (0, 475), 475: (0, 476), 476: (0, 477), 477: (0, 478), 478: (0, 479), 479: (0, 480), 480: (0, 481), 481: (0, 482), 482: (0, 483), 483: (0, 484), 484: (0, 485), 485: (0, 486), 486: (0, 487), 487: (0, 488), 488: (0, 489), 489: (0, 490), 490: (0, 491), 491: (0, 492), 492: (0, 493), 493: (0, 494), 494: (0, 495), 495: (0, 496), 496: (0, 497), 497: (0, 498), 498: (0, 499), 499: (0, 500), 500: (0, 501), 501: (0, 502), 502: (0, 503), 503: (0, 504), 504: (0, 505), 505: (0, 506), 506: (0, 507), 507: (0, 508), 508: (0, 509), 509: (0, 510), 510: (0, 511), 511: (0, 512), 512: (0, 513), 513: (0, 514), 514: (0, 515), 515: (0, 516), 516: (0, 517), 517: (0, 518), 518: (0, 519), 519: (0, 520), 520: (0, 521), 521: (0, 522), 522: (0, 523), 523: (0, 524), 524: (0, 525), 525: (0, 526), 526: (0, 527), 527: (0, 528), 528: (0, 529), 529: (0, 530), 530: (0, 531), 531: (0, 532), 532: (0, 533), 533: (0, 534), 534: (0, 535), 535: (0, 536), 536: (0, 537), 537: (0, 538), 538: (0, 539), 539: (0, 540), 540: (0, 541), 541: (0, 542), 542: (0, 543), 543: (0, 544), 544: (0, 545), 545: (0, 546), 546: (0, 547), 547: (0, 548), 548: (0, 549), 549: (0, 550), 550: (0, 551), 551: (0, 552), 552: (0, 553), 553: (0, 554), 554: (0, 555), 555: (0, 556), 556: (0, 557), 557: (0, 558), 558: (0, 559), 559: (0, 560), 560: (0, 561), 561: (0, 562), 562: (0, 563), 563: (0, 564), 564: (0, 565), 565: (0, 566), 566: (0, 567), 567: (0, 568), 568: (0, 569), 569: (0, 570), 570: (0, 571), 571: (0, 572), 572: (0, 573), 573: (0, 574), 574: (0, 575), 575: (0, 576), 576: (0, 577), 577: (0, 578), 578: (0, 579), 579: (0, 580), 580: (0, 581), 581: (0, 582), 582: (0, 583), 583: (0, 584), 584: (0, 585), 585: (0, 586), 586: (0, 587), 587: (0, 588), 588: (0, 589), 589: (0, 590), 590: (0, 591), 591: (0, 592), 592: (0, 593), 593: (0, 594), 594: (0, 595), 595: (0, 596), 596: (0, 597), 597: (0, 598), 598: (0, 599), 599: (0, 600), 600: (0, 601), 601: (0, 602), 602: (0, 603), 603: (0, 604), 604: (0, 605), 605: (0, 606), 606: (0, 607), 607: (0, 608), 608: (0, 609), 609: (0, 610), 610: (0, 611), 611: (0, 612), 612: (0, 613), 613: (0, 614), 614: (0, 615), 615: (0, 616), 616: (0, 617), 617: (0, 618), 618: (0, 619), 619: (0, 620), 620: (0, 621), 621: (0, 622), 622: (0, 623), 623: (0, 624), 624: (0, 625), 625: (0, 626), 626: (0, 627), 627: (0, 628), 628: (0, 629), 629: (0, 630), 630: (0, 631), 631: (0, 632), 632: (0, 633), 633: (0, 634), 634: (0, 635), 635: (0, 636), 636: (0, 637), 637: (0, 638), 638: (0, 639), 639: (0, 640), 640: (0, 641), 641: (0, 642), 642: (0, 643), 643: (0, 644), 644: (0, 645), 645: (0, 646), 646: (0, 647), 647: (0, 648), 648: (0, 649), 649: (0, 650), 650: (0, 651), 651: (0, 652), 652: (0, 653), 653: (0, 654), 654: (0, 655), 655: (0, 656), 656: (0, 657), 657: (0, 658), 658: (0, 659), 659: (0, 660), 660: (0, 661), 661: (0, 662), 662: (0, 663), 663: (0, 664), 664: (0, 665), 665: (0, 666), 666: (0, 667), 667: (0, 668), 668: (0, 669), 669: (0, 670), 670: (0, 671), 671: (0, 672), 672: (0, 673), 673: (0, 674), 674: (0, 675), 675: (0, 676), 676: (0, 677), 677: (0, 678), 678: (0, 679), 679: (0, 680), 680: (0, 681), 681: (0, 682), 682: (0, 683), 683: (0, 684), 684: (0, 685), 685: (0, 686), 686: (0, 687), 687: (0, 688), 688: (0, 689), 689: (0, 690), 690: (0, 691), 691: (0, 692), 692: (0, 693), 693: (0, 694), 694: (0, 695), 695: (0, 696), 696: (0, 697), 697: (0, 698), 698: (0, 699), 699: (0, 700), 700: (0, 701), 701: (0, 702), 702: (0, 703), 703: (0, 704), 704: (0, 705), 705: (0, 706), 706: (0, 707), 707: (0, 708), 708: (0, 709), 709: (0, 710), 710: (0, 711), 711: (0, 712), 712: (0, 713), 713: (0, 714), 714: (0, 715), 715: (0, 716), 716: (0, 717), 717: (0, 718), 718: (0, 719), 719: (0, 720), 720: (0, 721), 721: (0, 722)}
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/Trials.pkl
** SKIPPING EXTRACTION, since was able to load snippets, for: 
(animal, DATE, which_level, ANALY_VER, session)
Pancho 221114 trial rulesw 0
Got these LIST_VAR and LIST_VARS_CONJUNCTION:
['epoch', 'epoch', 'character', 'seqc_0_loc_shape', 'seqc_0_loc', 'seqc_1_loc_shape']
[['epochset'], ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset', 'seqc_0_loc_shape']]
Got these LIST_VAR and LIST_VARS_CONJUNCTION:
['epoch', 'epoch', 'character', 'seqc_0_loc_shape', 'seqc_0_loc', 'seqc_1_loc_shape']
[['epochset'], ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset', 'seqc_0_loc_shape']]
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*221114*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952
session:  0
1
Beh Sessions that exist on this date:  {221114: [(1, 'dirdir1b')]}
taking this beh session: 1
------------------------------
Loading this neural session: 0
Loading these beh expts: ['dirdir1b']
Loading these beh sessions: [1]
Using this beh_trial_map_list: [(1, 0)]
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*221114*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952
{'filename_components_hyphened': ['Pancho', '221114', '153952'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/221114'], 'basedirs_filenames': ['221114', 'Pancho-221114-153952'], 'filename_final_ext': 'Pancho-221114-153952', 'filename_final_noext': 'Pancho-221114-153952'}
FOund this path for spikes:  /mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952/spikes_tdt_quick-4
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952/Pancho-221114-153952
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221114/Pancho-221114-153952/spikes_tdt_quick-4
final_dir_name  --  Pancho-221114-153952
time  --  153952
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/221114.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
-  1 68.06931533813477
-  2 69.66489105224609
o  3 82.74347000122071
-  4 60.36389389038086
o  5 80.42985610961914
o  6 80.34103088378906
o  7 127.66825103759767
-  8 65.57163314819336
o  9 326.29052734375
o  10 79.26123275756837
o  11 123.41967391967773
o  12 97.26083679199219
o  13 191.08635559082035
o  14 86.96034317016601
o  15 204.19856567382814
o  16 84.02928161621094
o  17 81.344287109375
o  18 198.6181350708008
o  19 101.07905044555665
-  20 49.90549926757813
-  21 56.72679138183594
o  22 101.81901321411132
-  23 44.64807357788086
o  24 85.83126831054689
o  25 83.8583854675293
o  26 271.14560546875003
o  27 111.22440948486329
o  28 85.63344116210938
o  29 194.01446838378908
o  30 130.59820709228515
o  31 137.5751937866211
-  32 68.99211044311524
o  33 94.79967880249023
o  34 124.72103271484382
-  35 42.8513427734375
o  36 90.04633331298828
-  37 62.27242164611817
o  38 108.28256378173829
-  39 66.09671173095703
o  40 81.78657989501953
-  41 65.04173049926757
o  42 114.17992782592775
-  43 65.40102462768554
o  44 206.82770080566408
o  45 160.92139892578126
-  46 47.7468204498291
o  47 145.54843292236328
-  48 43.560595703125
o  49 108.19694595336914
o  50 97.56157836914063
o  51 97.6242057800293
o  52 73.15627746582031
o  53 397.5306121826172
-  54 68.50008544921876
o  55 154.47560272216796
-  56 59.45414505004883
o  57 183.99520568847657
o  58 88.72997131347657
o  59 74.47848434448242
o  60 79.84336395263672
o  61 89.95161895751953
o  62 76.19048461914062
o  63 160.7513168334961
o  64 94.96082916259766
o  65 83.42011260986328
o  66 82.18641815185546
o  67 94.33903427124024
o  68 212.85457763671877
-  69 69.11521682739257
-  70 50.37205200195312
o  71 73.88416137695313
o  72 99.70608901977539
-  73 65.56459274291993
o  74 74.54685287475586
-  75 63.693039703369145
o  76 72.68123626708984
-  77 68.03669052124023
o  78 118.5713996887207
-  79 67.2722869873047
o  80 78.67979888916015
-  81 58.910748672485354
-  82 63.69935874938965
o  83 75.75670852661133
o  84 73.50166702270508
-  85 59.31715393066406
o  86 71.4793601989746
-  87 46.93958053588867
-  88 65.52943191528321
-  89 56.06555404663086
-  90 69.29340057373047
-  91 61.29177894592285
o  92 79.21974487304688
-  93 59.9308780670166
o  94 73.1291717529297
-  95 59.35870513916016
-  96 66.83370513916016
o  97 207.66663513183593
o  98 100.53455505371095
o  99 99.74978179931641
o  100 86.40490493774413
o  101 100.62152938842773
o  102 94.93000793457031
-  103 54.18083076477051
-  104 68.89505386352539
o  105 75.39430313110351
-  106 50.54007034301758
-  107 40.494086837768556
-  108 63.91023559570313
-  109 46.923011016845706
-  110 57.33493614196778
-  111 63.673004150390625
o  112 179.99234771728516
o  113 75.54412918090821
o  114 75.28427734375
-  115 54.05173225402832
o  116 131.9329818725586
-  117 56.861985778808595
o  118 78.19854278564453
-  119 65.78610916137696
o  120 70.93653030395508
o  121 82.28889083862305
o  122 93.78357391357423
o  123 212.2505096435547
-  124 48.571590423583984
-  125 43.654574966430665
o  126 122.90284652709961
-  127 60.576484298706056
-  128 66.31521530151367
-  129 68.31191711425781
o  130 303.12504882812505
o  131 71.09255905151367
o  132 131.5561309814453
-  133 55.2003677368164
o  134 94.9905876159668
-  135 62.876564025878906
o  136 109.87889633178712
-  137 62.1809928894043
o  138 122.31454925537109
-  139 62.289025497436526
o  140 175.7999725341797
o  141 187.86309814453128
o  142 391.0502563476563
o  143 355.87952575683596
o  144 103.0286636352539
-  145 63.13205795288086
-  146 62.54127235412598
-  147 64.43988265991212
o  148 171.3584945678711
o  149 108.25636291503906
o  150 103.25330886840821
-  151 49.57059555053711
o  152 109.86503295898437
-  153 63.999796295166014
o  154 91.77690048217774
o  155 175.8883255004883
o  156 156.7129898071289
-  157 59.7891342163086
o  158 123.8092887878418
o  159 149.127783203125
o  160 78.02728652954103
o  161 87.66611938476562
o  162 120.71288375854492
o  163 123.5075881958008
o  164 79.52127075195312
o  165 103.16358108520508
-  166 66.9025032043457
o  167 136.97906646728515
-  168 64.81002426147461
-  169 67.89386520385743
o  170 88.46861267089844
o  171 195.044482421875
-  172 54.711785888671876
o  173 114.10876846313477
-  174 62.96176033020019
-  175 69.55742111206055
-  176 62.621219635009766
o  177 101.48421783447266
o  178 76.47903671264655
o  179 244.5767013549805
-  180 62.712752532958994
o  181 108.75244369506837
-  182 60.72160720825195
o  183 88.23031768798829
o  184 77.39754714965821
-  185 26.20863628387451
o  186 86.59875259399415
o  187 97.1904983520508
-  188 60.33813209533692
o  189 98.04969482421876
-  190 64.2657485961914
-  191 68.34085540771484
o  192 125.93445892333985
o  193 108.40975799560547
o  194 75.36485595703125
o  195 210.20851135253906
-  196 54.245041656494145
o  197 98.7213752746582
o  198 70.94248886108399
-  199 59.104195022583006
o  200 79.53477249145509
o  201 95.95826263427735
o  202 106.25816650390627
o  203 116.74761199951173
o  204 103.47704772949218
o  205 74.23085174560546
o  206 110.59509429931641
-  207 62.49543800354004
-  208 61.12764205932617
-  209 52.46098289489746
o  210 92.65691833496093
-  211 64.0324951171875
-  212 50.99794578552246
o  213 78.72339477539063
-  214 67.11008987426759
-  215 66.89288940429688
-  216 46.01769790649414
-  217 62.2868221282959
o  218 100.4020622253418
o  219 75.1237777709961
-  220 64.45398635864258
-  221 58.529079055786134
o  222 79.00638122558594
o  223 74.51407012939453
o  224 81.11997756958009
o  225 80.53787460327149
o  226 79.03496170043945
o  227 151.7420867919922
-  228 66.31306304931641
-  229 63.81632919311524
-  230 61.22932243347168
-  231 62.24059524536133
-  232 35.60774154663086
o  233 81.83422317504883
-  234 63.12645225524903
o  235 89.84893798828125
-  236 57.85363502502442
o  237 93.81177368164063
o  238 72.9800910949707
-  239 60.60012245178223
-  240 63.20091552734375
-  241 63.71261215209961
o  242 126.85375442504883
o  243 70.40879211425782
-  244 64.51042404174805
o  245 94.73720245361328
o  246 72.72991104125977
-  247 58.70638923645019
o  248 90.7659408569336
-  249 64.08270874023438
-  250 63.287212753295904
-  251 63.2353385925293
o  252 92.3044059753418
-  253 65.92598571777344
-  254 58.44234619140625
o  255 73.80102005004883
o  256 86.49599151611328
o  257 201.80299072265626
o  258 70.1256607055664
o  259 94.53732604980469
o  260 149.76595916748047
o  261 124.20758209228516
o  262 84.90264129638672
o  263 100.42024765014648
o  264 95.456298828125
-  265 68.13500747680663
o  266 104.22980422973633
o  267 114.75179748535156
-  268 53.74220504760742
o  269 105.71536483764649
o  270 93.13355560302735
-  271 58.7779712677002
o  272 196.84488525390626
o  273 84.72943801879883
o  274 89.14522247314453
o  275 83.39923324584962
o  276 88.57120971679687
o  277 71.3733268737793
o  278 102.1148193359375
o  279 110.88192901611329
o  280 86.50489196777345
o  281 86.33070831298828
o  282 115.01237030029297
-  283 65.06012725830078
o  284 92.15303649902344
o  285 134.95092010498047
o  286 82.28335952758789
-  287 60.003937530517575
o  288 82.32739639282227
-  289 58.3252513885498
o  290 78.75153198242188
-  291 66.44487991333008
-  292 42.19511413574219
-  293 65.43164825439453
o  294 81.89097747802734
-  295 54.85442810058594
-  296 68.05075149536133
-  297 55.82337493896485
-  298 63.17007141113282
o  299 73.0493293762207
-  300 56.974021911621094
-  301 69.41181182861328
o  302 71.28805389404297
o  303 104.02659072875977
o  304 78.4604461669922
-  305 48.038251113891604
-  306 65.09102020263671
-  307 68.82397613525391
-  308 52.46974792480469
-  309 67.43550567626953
o  310 70.3451416015625
-  311 56.55269546508789
-  312 65.64676361083984
-  313 69.63730850219727
o  314 98.30939559936525
-  315 58.712075805664064
o  316 85.31494903564453
-  317 48.982164001464845
o  318 82.6393669128418
-  319 60.88548164367676
-  320 67.05146102905273
-  321 59.475363159179686
-  322 53.834582901000985
-  323 59.76222381591797
-  324 58.34819145202637
o  325 87.52590637207047
-  326 63.921142196655275
o  327 162.75310668945312
o  328 84.22410430908204
-  329 67.53224411010743
o  330 72.07514343261718
-  331 69.34184951782227
-  332 52.28923416137695
o  333 92.50596160888672
o  334 96.23187103271485
-  335 43.62738952636719
-  336 57.39719848632813
-  337 53.00855941772461
-  338 55.49724426269531
-  339 66.76402740478515
-  340 39.8910774230957
-  341 52.47274169921875
-  342 56.04209899902344
o  343 71.22752304077149
o  344 335.0489807128906
-  345 57.534861373901364
o  346 81.68250427246095
-  347 54.141077804565434
-  348 52.74230270385742
o  349 81.03909606933594
-  350 69.55098495483398
o  351 85.44299468994141
o  352 78.73950653076173
o  353 72.90857543945313
o  354 82.6985092163086
-  355 59.84304924011231
-  356 62.36914100646973
-  357 39.46798820495606
-  358 65.35654220581054
-  359 46.97404747009278
-  360 56.03001251220703
-  361 57.07380981445313
-  362 58.02370338439942
o  363 71.88277816772461
o  364 74.81486740112305
-  365 44.60891342163086
-  366 55.16217269897461
o  367 73.39824523925782
o  368 70.97678680419922
o  369 86.02032165527343
-  370 46.47331275939941
o  371 82.6077995300293
-  372 61.74030380249023
o  373 73.0550521850586
-  374 62.72493667602539
o  375 84.92794570922852
o  376 78.49701766967775
-  377 52.00413856506348
-  378 62.9726978302002
-  379 55.69125900268555
-  380 47.6731201171875
o  381 85.09572372436524
o  382 71.48097534179688
o  383 76.04981689453125
-  384 57.07367095947266
o  385 141.1519302368164
o  386 76.46527938842773
o  387 133.41721649169924
o  388 163.48432159423828
o  389 222.2937438964844
o  390 115.1761474609375
-  391 44.16472396850586
-  392 63.43827667236328
o  393 90.97134170532227
o  394 106.13111419677739
o  395 170.3499481201172
o  396 89.35421981811525
o  397 72.85039520263672
o  398 75.74149322509766
o  399 90.72751159667969
o  400 116.50228729248047
o  401 148.01874694824218
o  402 139.43709564208987
o  403 195.55069580078126
o  404 178.6170883178711
o  405 136.94361419677733
o  406 95.19737243652344
o  407 140.1198715209961
-  408 65.21653289794922
o  409 71.95815429687501
o  410 260.83604125976564
o  411 165.54819946289064
-  412 62.9305534362793
o  413 125.0418441772461
o  414 197.58991088867188
o  415 126.31919860839844
o  416 101.0657455444336
o  417 97.45459899902343
o  418 99.62319641113281
o  419 71.92835083007813
-  420 67.37173385620117
o  421 80.13869247436524
o  422 93.35797729492188
o  423 113.08047256469729
-  424 61.30449676513672
o  425 76.24217224121094
-  426 51.276406097412114
-  427 69.78734970092773
-  428 26.545696449279784
o  429 91.65870742797851
o  430 81.71278533935546
-  431 50.07049369812012
-  432 51.8477066040039
o  433 126.89140548706055
o  434 102.00621337890627
o  435 169.6657653808594
o  436 144.25493774414062
o  437 99.8838966369629
o  438 122.42195434570313
o  439 87.08586730957032
-  440 59.672653961181645
o  441 98.23184661865234
-  442 60.63063735961914
o  443 218.3988037109375
-  444 34.39996109008789
o  445 79.94628524780273
-  446 33.57834091186523
o  447 95.2865005493164
-  448 29.363975715637206
o  449 233.23975677490236
o  450 134.82024078369142
o  451 107.76330108642578
o  452 110.87806701660156
o  453 89.89170837402344
o  454 117.67790985107422
o  455 153.3751953125
-  456 50.06908340454102
o  457 181.01205291748047
-  458 64.97798309326173
o  459 224.4985809326172
o  460 135.74433288574218
o  461 179.75297851562502
o  462 90.59456253051758
o  463 75.38699722290039
o  464 155.34880218505864
o  465 144.88835906982425
o  466 113.44417190551758
o  467 106.41199035644532
o  468 122.14490051269532
o  469 157.16061248779297
-  470 69.50756149291993
o  471 100.60200576782228
o  472 86.24369964599609
o  473 154.69929504394537
o  474 75.17743225097657
o  475 92.96099472045898
-  476 51.42523536682129
o  477 136.20855255126952
o  478 101.59756011962891
o  479 80.39283828735351
o  480 88.09938507080078
-  481 66.74043502807618
-  482 36.260274505615236
o  483 89.87595062255859
o  484 139.6338607788086
o  485 159.50121154785157
o  486 89.53620147705078
o  487 87.60205078125
o  488 92.90513381958009
o  489 143.6256561279297
o  490 75.61765975952149
o  491 159.7208938598633
o  492 126.0170967102051
o  493 118.45273284912109
o  494 123.40048294067383
o  495 73.73475646972656
o  496 136.04393310546874
o  497 112.10711059570312
o  498 505.1807556152344
-  499 58.0737606048584
o  500 159.7846832275391
o  501 70.44407424926757
o  502 113.03218460083008
o  503 74.68003692626954
-  504 68.55691299438477
o  505 91.21163711547852
-  506 62.66373252868652
-  507 30.45794677734375
o  508 73.7294204711914
o  509 73.88777313232423
o  510 101.55365982055665
-  511 34.94534187316894
o  512 102.29774932861329
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/221114/Pancho-221114-153952/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
... Generated these...
self.BehTrialMapList [(1, 0)]
self.BehTrialMapListGood {0: (0, 1), 1: (0, 2), 2: (0, 3), 3: (0, 4), 4: (0, 5), 5: (0, 6), 6: (0, 7), 7: (0, 8), 8: (0, 9), 9: (0, 10), 10: (0, 11), 11: (0, 12), 12: (0, 13), 13: (0, 14), 14: (0, 15), 15: (0, 16), 16: (0, 17), 17: (0, 18), 18: (0, 19), 19: (0, 20), 20: (0, 21), 21: (0, 22), 22: (0, 23), 23: (0, 24), 24: (0, 25), 25: (0, 26), 26: (0, 27), 27: (0, 28), 28: (0, 29), 29: (0, 30), 30: (0, 31), 31: (0, 32), 32: (0, 33), 33: (0, 34), 34: (0, 35), 35: (0, 36), 36: (0, 37), 37: (0, 38), 38: (0, 39), 39: (0, 40), 40: (0, 41), 41: (0, 42), 42: (0, 43), 43: (0, 44), 44: (0, 45), 45: (0, 46), 46: (0, 47), 47: (0, 48), 48: (0, 49), 49: (0, 50), 50: (0, 51), 51: (0, 52), 52: (0, 53), 53: (0, 54), 54: (0, 55), 55: (0, 56), 56: (0, 57), 57: (0, 58), 58: (0, 59), 59: (0, 60), 60: (0, 61), 61: (0, 62), 62: (0, 63), 63: (0, 64), 64: (0, 65), 65: (0, 66), 66: (0, 67), 67: (0, 68), 68: (0, 69), 69: (0, 70), 70: (0, 71), 71: (0, 72), 72: (0, 73), 73: (0, 74), 74: (0, 75), 75: (0, 76), 76: (0, 77), 77: (0, 78), 78: (0, 79), 79: (0, 80), 80: (0, 81), 81: (0, 82), 82: (0, 83), 83: (0, 84), 84: (0, 85), 85: (0, 86), 86: (0, 87), 87: (0, 88), 88: (0, 89), 89: (0, 90), 90: (0, 91), 91: (0, 92), 92: (0, 93), 93: (0, 94), 94: (0, 95), 95: (0, 96), 96: (0, 97), 97: (0, 98), 98: (0, 99), 99: (0, 100), 100: (0, 101), 101: (0, 102), 102: (0, 103), 103: (0, 104), 104: (0, 105), 105: (0, 106), 106: (0, 107), 107: (0, 108), 108: (0, 109), 109: (0, 110), 110: (0, 111), 111: (0, 112), 112: (0, 113), 113: (0, 114), 114: (0, 115), 115: (0, 116), 116: (0, 117), 117: (0, 118), 118: (0, 119), 119: (0, 120), 120: (0, 121), 121: (0, 122), 122: (0, 123), 123: (0, 124), 124: (0, 125), 125: (0, 126), 126: (0, 127), 127: (0, 128), 128: (0, 129), 129: (0, 130), 130: (0, 131), 131: (0, 132), 132: (0, 133), 133: (0, 134), 134: (0, 135), 135: (0, 136), 136: (0, 137), 137: (0, 138), 138: (0, 139), 139: (0, 140), 140: (0, 141), 141: (0, 142), 142: (0, 143), 143: (0, 144), 144: (0, 145), 145: (0, 146), 146: (0, 147), 147: (0, 148), 148: (0, 149), 149: (0, 150), 150: (0, 151), 151: (0, 152), 152: (0, 153), 153: (0, 154), 154: (0, 155), 155: (0, 156), 156: (0, 157), 157: (0, 158), 158: (0, 159), 159: (0, 160), 160: (0, 161), 161: (0, 162), 162: (0, 163), 163: (0, 164), 164: (0, 165), 165: (0, 166), 166: (0, 167), 167: (0, 168), 168: (0, 169), 169: (0, 170), 170: (0, 171), 171: (0, 172), 172: (0, 173), 173: (0, 174), 174: (0, 175), 175: (0, 176), 176: (0, 177), 177: (0, 178), 178: (0, 179), 179: (0, 180), 180: (0, 181), 181: (0, 182), 182: (0, 183), 183: (0, 184), 184: (0, 185), 185: (0, 186), 186: (0, 187), 187: (0, 188), 188: (0, 189), 189: (0, 190), 190: (0, 191), 191: (0, 192), 192: (0, 193), 193: (0, 194), 194: (0, 195), 195: (0, 196), 196: (0, 197), 197: (0, 198), 198: (0, 199), 199: (0, 200), 200: (0, 201), 201: (0, 202), 202: (0, 203), 203: (0, 204), 204: (0, 205), 205: (0, 206), 206: (0, 207), 207: (0, 208), 208: (0, 209), 209: (0, 210), 210: (0, 211), 211: (0, 212), 212: (0, 213), 213: (0, 214), 214: (0, 215), 215: (0, 216), 216: (0, 217), 217: (0, 218), 218: (0, 219), 219: (0, 220), 220: (0, 221), 221: (0, 222), 222: (0, 223), 223: (0, 224), 224: (0, 225), 225: (0, 226), 226: (0, 227), 227: (0, 228), 228: (0, 229), 229: (0, 230), 230: (0, 231), 231: (0, 232), 232: (0, 233), 233: (0, 234), 234: (0, 235), 235: (0, 236), 236: (0, 237), 237: (0, 238), 238: (0, 239), 239: (0, 240), 240: (0, 241), 241: (0, 242), 242: (0, 243), 243: (0, 244), 244: (0, 245), 245: (0, 246), 246: (0, 247), 247: (0, 248), 248: (0, 249), 249: (0, 250), 250: (0, 251), 251: (0, 252), 252: (0, 253), 253: (0, 254), 254: (0, 255), 255: (0, 256), 256: (0, 257), 257: (0, 258), 258: (0, 259), 259: (0, 260), 260: (0, 261), 261: (0, 262), 262: (0, 263), 263: (0, 264), 264: (0, 265), 265: (0, 266), 266: (0, 267), 267: (0, 268), 268: (0, 269), 269: (0, 270), 270: (0, 271), 271: (0, 272), 272: (0, 273), 273: (0, 274), 274: (0, 275), 275: (0, 276), 276: (0, 277), 277: (0, 278), 278: (0, 279), 279: (0, 280), 280: (0, 281), 281: (0, 282), 282: (0, 283), 283: (0, 284), 284: (0, 285), 285: (0, 286), 286: (0, 287), 287: (0, 288), 288: (0, 289), 289: (0, 290), 290: (0, 291), 291: (0, 292), 292: (0, 293), 293: (0, 294), 294: (0, 295), 295: (0, 296), 296: (0, 297), 297: (0, 298), 298: (0, 299), 299: (0, 300), 300: (0, 301), 301: (0, 302), 302: (0, 303), 303: (0, 304), 304: (0, 305), 305: (0, 306), 306: (0, 307), 307: (0, 308), 308: (0, 309), 309: (0, 310), 310: (0, 311), 311: (0, 312), 312: (0, 313), 313: (0, 314), 314: (0, 315), 315: (0, 316), 316: (0, 317), 317: (0, 318), 318: (0, 319), 319: (0, 320), 320: (0, 321), 321: (0, 322), 322: (0, 323), 323: (0, 324), 324: (0, 325), 325: (0, 326), 326: (0, 327), 327: (0, 328), 328: (0, 329), 329: (0, 330), 330: (0, 331), 331: (0, 332), 332: (0, 333), 333: (0, 334), 334: (0, 335), 335: (0, 336), 336: (0, 337), 337: (0, 338), 338: (0, 339), 339: (0, 340), 340: (0, 341), 341: (0, 342), 342: (0, 343), 343: (0, 344), 344: (0, 345), 345: (0, 346), 346: (0, 347), 347: (0, 348), 348: (0, 349), 349: (0, 350), 350: (0, 351), 351: (0, 352), 352: (0, 353), 353: (0, 354), 354: (0, 355), 355: (0, 356), 356: (0, 357), 357: (0, 358), 358: (0, 359), 359: (0, 360), 360: (0, 361), 361: (0, 362), 362: (0, 363), 363: (0, 364), 364: (0, 365), 365: (0, 366), 366: (0, 367), 367: (0, 368), 368: (0, 369), 369: (0, 370), 370: (0, 371), 371: (0, 372), 372: (0, 373), 373: (0, 374), 374: (0, 375), 375: (0, 376), 376: (0, 377), 377: (0, 378), 378: (0, 379), 379: (0, 380), 380: (0, 381), 381: (0, 382), 382: (0, 383), 383: (0, 384), 384: (0, 385), 385: (0, 386), 386: (0, 387), 387: (0, 388), 388: (0, 389), 389: (0, 390), 390: (0, 391), 391: (0, 392), 392: (0, 393), 393: (0, 394), 394: (0, 395), 395: (0, 396), 396: (0, 397), 397: (0, 398), 398: (0, 399), 399: (0, 400), 400: (0, 401), 401: (0, 402), 402: (0, 403), 403: (0, 404), 404: (0, 405), 405: (0, 406), 406: (0, 407), 407: (0, 408), 408: (0, 409), 409: (0, 410), 410: (0, 411), 411: (0, 412), 412: (0, 413), 413: (0, 414), 414: (0, 415), 415: (0, 416), 416: (0, 417), 417: (0, 418), 418: (0, 419), 419: (0, 420), 420: (0, 421), 421: (0, 422), 422: (0, 423), 423: (0, 424), 424: (0, 425), 425: (0, 426), 426: (0, 427), 427: (0, 428), 428: (0, 429), 429: (0, 430), 430: (0, 431), 431: (0, 432), 432: (0, 433), 433: (0, 434), 434: (0, 435), 435: (0, 436), 436: (0, 437), 437: (0, 438), 438: (0, 439), 439: (0, 440), 440: (0, 441), 441: (0, 442), 442: (0, 443), 443: (0, 444), 444: (0, 445), 445: (0, 446), 446: (0, 447), 447: (0, 448), 448: (0, 449), 449: (0, 450), 450: (0, 451), 451: (0, 452), 452: (0, 453), 453: (0, 454), 454: (0, 455), 455: (0, 456), 456: (0, 457), 457: (0, 458), 458: (0, 459), 459: (0, 460), 460: (0, 461), 461: (0, 462), 462: (0, 463), 463: (0, 464), 464: (0, 465), 465: (0, 466), 466: (0, 467), 467: (0, 468), 468: (0, 469), 469: (0, 470), 470: (0, 471), 471: (0, 472), 472: (0, 473), 473: (0, 474), 474: (0, 475), 475: (0, 476), 476: (0, 477), 477: (0, 478), 478: (0, 479), 479: (0, 480), 480: (0, 481), 481: (0, 482), 482: (0, 483), 483: (0, 484), 484: (0, 485), 485: (0, 486), 486: (0, 487), 487: (0, 488), 488: (0, 489), 489: (0, 490), 490: (0, 491), 491: (0, 492), 492: (0, 493), 493: (0, 494), 494: (0, 495), 495: (0, 496), 496: (0, 497), 497: (0, 498), 498: (0, 499), 499: (0, 500), 500: (0, 501), 501: (0, 502), 502: (0, 503), 503: (0, 504), 504: (0, 505), 505: (0, 506), 506: (0, 507), 507: (0, 508), 508: (0, 509), 509: (0, 510), 510: (0, 511), 511: (0, 512), 512: (0, 513), 513: (0, 514), 514: (0, 515), 515: (0, 516), 516: (0, 517), 517: (0, 518), 518: (0, 519), 519: (0, 520), 520: (0, 521), 521: (0, 522), 522: (0, 523), 523: (0, 524), 524: (0, 525), 525: (0, 526), 526: (0, 527), 527: (0, 528), 528: (0, 529), 529: (0, 530), 530: (0, 531), 531: (0, 532), 532: (0, 533), 533: (0, 534), 534: (0, 535), 535: (0, 536), 536: (0, 537), 537: (0, 538), 538: (0, 539), 539: (0, 540), 540: (0, 541), 541: (0, 542), 542: (0, 543), 543: (0, 544), 544: (0, 545), 545: (0, 546), 546: (0, 547), 547: (0, 548), 548: (0, 549), 549: (0, 550), 550: (0, 551), 551: (0, 552), 552: (0, 553), 553: (0, 554), 554: (0, 555), 555: (0, 556), 556: (0, 557), 557: (0, 558), 558: (0, 559), 559: (0, 560), 560: (0, 561), 561: (0, 562), 562: (0, 563), 563: (0, 564), 564: (0, 565), 565: (0, 566), 566: (0, 567), 567: (0, 568), 568: (0, 569), 569: (0, 570), 570: (0, 571), 571: (0, 572), 572: (0, 573), 573: (0, 574), 574: (0, 575), 575: (0, 576), 576: (0, 577), 577: (0, 578), 578: (0, 579), 579: (0, 580), 580: (0, 581), 581: (0, 582), 582: (0, 583), 583: (0, 584), 584: (0, 585), 585: (0, 586), 586: (0, 587), 587: (0, 588), 588: (0, 589), 589: (0, 590), 590: (0, 591), 591: (0, 592), 592: (0, 593), 593: (0, 594), 594: (0, 595), 595: (0, 596), 596: (0, 597), 597: (0, 598), 598: (0, 599), 599: (0, 600), 600: (0, 601), 601: (0, 602), 602: (0, 603), 603: (0, 604), 604: (0, 605), 605: (0, 606), 606: (0, 607), 607: (0, 608), 608: (0, 609), 609: (0, 610), 610: (0, 611), 611: (0, 612), 612: (0, 613), 613: (0, 614), 614: (0, 615), 615: (0, 616), 616: (0, 617), 617: (0, 618), 618: (0, 619), 619: (0, 620), 620: (0, 621), 621: (0, 622), 622: (0, 623), 623: (0, 624), 624: (0, 625), 625: (0, 626), 626: (0, 627), 627: (0, 628), 628: (0, 629), 629: (0, 630), 630: (0, 631), 631: (0, 632), 632: (0, 633), 633: (0, 634), 634: (0, 635), 635: (0, 636), 636: (0, 637), 637: (0, 638), 638: (0, 639), 639: (0, 640), 640: (0, 641), 641: (0, 642), 642: (0, 643), 643: (0, 644), 644: (0, 645), 645: (0, 646), 646: (0, 647), 647: (0, 648), 648: (0, 649), 649: (0, 650), 650: (0, 651), 651: (0, 652), 652: (0, 653), 653: (0, 654), 654: (0, 655), 655: (0, 656), 656: (0, 657), 657: (0, 658), 658: (0, 659), 659: (0, 660), 660: (0, 661), 661: (0, 662), 662: (0, 663), 663: (0, 664), 664: (0, 665), 665: (0, 666), 666: (0, 667), 667: (0, 668), 668: (0, 669), 669: (0, 670), 670: (0, 671), 671: (0, 672), 672: (0, 673), 673: (0, 674), 674: (0, 675), 675: (0, 676), 676: (0, 677), 677: (0, 678), 678: (0, 679), 679: (0, 680), 680: (0, 681), 681: (0, 682), 682: (0, 683), 683: (0, 684), 684: (0, 685), 685: (0, 686), 686: (0, 687), 687: (0, 688), 688: (0, 689), 689: (0, 690), 690: (0, 691), 691: (0, 692), 692: (0, 693), 693: (0, 694), 694: (0, 695), 695: (0, 696), 696: (0, 697), 697: (0, 698), 698: (0, 699), 699: (0, 700), 700: (0, 701), 701: (0, 702), 702: (0, 703), 703: (0, 704), 704: (0, 705), 705: (0, 706), 706: (0, 707), 707: (0, 708), 708: (0, 709), 709: (0, 710), 710: (0, 711), 711: (0, 712), 712: (0, 713), 713: (0, 714), 714: (0, 715), 715: (0, 716), 716: (0, 717), 717: (0, 718), 718: (0, 719), 719: (0, 720), 720: (0, 721), 721: (0, 722)}
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/Trials.pkl
This many vals across loaded session
0 : 2161568
Assigning to SP.Params this item:
{'which_level': 'trial', '_list_events': ['fixcue', 'fix_touch', 'rulecue2', 'samp', 'go_cue', 'first_raise', 'on_strokeidx_0', 'off_stroke_last', 'doneb', 'post', 'reward_all'], 'list_events_uniqnames': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_features_extraction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_features_get_conjunction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_pre_dur': [-0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75], 'list_post_dur': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75], 'map_var_to_othervars': None, 'strokes_only_keep_single': False, 'tasks_only_keep_these': None, 'prune_feature_levels_min_n_trials': 1, 'fr_which_version': 'sqrt', 'map_var_to_levels': None}
Assigning to SP.ParamsGlobals this item:
{'n_min_trials_per_level': 5, 'lenient_allow_data_if_has_n_levels': 2, 'PRE_DUR_CALC': -0.75, 'POST_DUR_CALC': 0.75, 'list_events': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_pre_dur': [-0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75], 'list_post_dur': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]}
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
TODO!!! Merge this with other learning-related code
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
trial # 0
trial # 100
trial # 200
trial # 300
trial # 400
trial # 500
trial # 600
Generated column called 'agent', which connects agent_kind-rule
n samples for conjunctions of score_name, agent_rule, agent_kind:
('binsucc', 'R', 'model') :     336
('binsucc', 'U', 'model') :     345
TODO! _preprocess_sanity_check
Resulting taskgroup/probe combo, after taskgroup_reassign_simple_neural...
('I', 0) :     568
('same_beh', 0) :     113
.. Appended new column 'char_seq', version: task_matlab
Done!, new len of dataset 681
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
Appended columns gridsize!
Defined new column: epochset
... value_counts:
(R,)      284
(U,)      284
(R, U)    113
Name: epochset, dtype: int64
... merge_sets_with_only_single_epoch... 
('R',) only has one epoch!:  ['R']
('U',) only has one epoch!:  ['U']
Mergin these epochset's .. 
[('R',), ('U',)]
Into this new epochset: ('LEFTOVER',)
Final epochsets:
(LEFTOVER,)    568
(R, U)         113
Name: epochset, dtype: int64
Updating this column of SP.DfScalar with Dataset beh:
epoch
Updating this column of SP.DfScalar with Dataset beh:
epochset
Updating this column of SP.DfScalar with Dataset beh:
seqc_0_loc
Updating this column of SP.DfScalar with Dataset beh:
seqc_0_shape
Updating this column of SP.DfScalar with Dataset beh:
seqc_nstrokes_beh
Updating this column of SP.DfScalar with Dataset beh:
character
Updating this column of SP.DfScalar with Dataset beh:
seqc_0_loc_shape
Updating this column of SP.DfScalar with Dataset beh:
seqc_1_loc_shape
Starting length of D.Dat: 681
self.Dat modified!!
Len, after remove aborts: 521
############ TAKING ONLY NO SUPERVISION TRIALS
--BEFORE REMOVE; existing supervision_stage_concise:
off|1|solid|0     425
mask|1|solid|0     96
Name: supervision_stage_concise, dtype: int64
self.Dat modified!!
--AFTER REMOVE; existing supervision_stage_concise:
off|1|solid|0    425
Name: supervision_stage_concise, dtype: int64
Dataset final len: 425
-- Len of D, before applying this param: remove_repeated_trials, ... 425
appended col to self.Dat:
dummy
self.Dat starting legnth:  423
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  423
after: 423
-- Len of D, before applying this param: correct_sequencing_binary_score, ... 423
self.Dat starting legnth:  423
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  423
after: 423
-- Len of D, before applying this param: one_to_one_beh_task_strokes, ... 423
after: 422
-- Len of D, before applying this param: beh_strokes_at_least_one, ... 422
after: 422
Saving to: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff
starting sites:  306
starting sites:  [3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 24, 25, 27, 28, 29, 30, 31, 34, 36, 38, 40, 42, 45, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 78, 80, 83, 84, 86, 92, 94, 97, 98, 100, 101, 102, 112, 113, 114, 116, 118, 120, 121, 122, 123, 126, 130, 131, 132, 134, 136, 138, 140, 141, 142, 143, 144, 148, 149, 150, 152, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 167, 170, 171, 173, 177, 178, 179, 181, 183, 184, 186, 187, 189, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 204, 205, 206, 210, 213, 218, 219, 222, 223, 224, 225, 226, 227, 233, 235, 237, 238, 242, 243, 245, 246, 248, 252, 255, 256, 258, 259, 260, 261, 262, 263, 266, 267, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 286, 288, 290, 294, 299, 302, 303, 304, 310, 314, 316, 318, 325, 327, 328, 330, 333, 334, 343, 344, 346, 349, 351, 352, 353, 354, 363, 364, 367, 368, 369, 371, 373, 375, 376, 381, 382, 383, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 443, 445, 447, 449, 450, 451, 452, 453, 454, 455, 457, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 505, 508, 509, 510, 512]
For percentile 10, using this threshold: 11.906061228053144
sites_good:  275
sites_bad:  31
Updates self.Sites
ending sites:  275
ending sites:  [3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 24, 25, 27, 28, 29, 30, 31, 34, 36, 38, 40, 42, 45, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 78, 84, 86, 92, 94, 97, 98, 100, 101, 102, 112, 113, 114, 116, 118, 120, 121, 122, 123, 130, 132, 134, 136, 138, 140, 141, 142, 143, 144, 148, 149, 150, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 167, 171, 173, 177, 178, 179, 181, 183, 184, 186, 187, 189, 192, 193, 194, 195, 197, 198, 200, 202, 203, 205, 206, 210, 213, 218, 219, 222, 224, 225, 226, 227, 233, 235, 237, 242, 243, 248, 252, 255, 256, 259, 260, 261, 262, 266, 267, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 288, 290, 294, 302, 303, 304, 310, 314, 316, 318, 327, 328, 333, 344, 349, 351, 352, 354, 368, 371, 375, 376, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 443, 445, 447, 449, 450, 451, 452, 454, 455, 457, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 477, 478, 479, 480, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 505, 508, 509, 510, 512]
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.75
POST_DUR_CALC  =  0.75
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables
var -- vars_others:  epoch  ---  ['epochset']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-epoch-vs-varothers-levothers-levvar.txt
var -- vars_others:  epochset  ---  ['epoch']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-epochset-vs-varothers-levothers-levvar.txt
TODO: do fr scalar computation only once! takes too much time.
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/df_var.pkl
Searching for already-done df_var at this path:
df_var doesnt exist...!
COMPUTING df_var!!!
Running grouping_print_n_samples...
DOing these! ...
list_events ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
WILL SKIP THESE EVENTS...
[]
GOOD!, enough data, max n per grouping conjunction (nmin, nmax)  0 164
 
Updated ParamsGlobals for event 02_rulecue2 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  02_rulecue2_-600_to_-50
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 02_rulecue2 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.04
POST_DUR_CALC  =  0.24
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  02_rulecue2_40_to_240
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 02_rulecue2 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.26
POST_DUR_CALC  =  0.6
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  02_rulecue2_260_to_600
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.04
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_-600_to_-40
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.04
POST_DUR_CALC  =  0.24
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_40_to_240
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.26
POST_DUR_CALC  =  0.6
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_260_to_600
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 04_go_cue to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.04
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  04_go_cue_-600_to_-40
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 05_first_raise to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  05_first_raise_-600_to_-50
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 06_on_strokeidx_0 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.25
POST_DUR_CALC  =  0.35
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  06_on_strokeidx_0_-250_to_350
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 08_doneb to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.5
POST_DUR_CALC  =  0.3
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  08_doneb_-500_to_300
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 09_post to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  09_post_50_to_600
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 10_reward_all to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  10_reward_all_50_to_600
site : 40
site : 60
site : 100
site : 120
site : 140
site : 160
site : 200
site : 260
site : 280
site : 400
site : 460
site : 480
site : 500
SAving:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/df_var.pkl
SAving:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/list_eventwindow_event.pkl
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation
** Plotting summarystats
Saving at: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation
Found this var:  epoch
Found this var_others:  ('epochset',)
Aggregating dataframe over all othervars ...
Plotting ...
Plotting for specific single other var: epochset...
** Plotting heatmaps
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation_heatmap
Saving to:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation_heatmap/brainschem-event-val-modulation_subgroups.pdf
Saving to:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation_heatmap/brainschem-event-val-modulation_subgroups-NOMOTOR.pdf
** Plotting example strokes
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221114-sess_0/Trials.pkl
Plotting ..  (('R', 'U'),)
Plotting ..  (('LEFTOVER',),)
** Making plots for this event_window: 
09_post_50_to_600
Saving this event, 09_post_50_to_600, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/09_post_50_to_600
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/09_post_50_to_600/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/rasters/09_post
** Making plots for this event_window: 
08_doneb_-500_to_300
Saving this event, 08_doneb_-500_to_300, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/08_doneb_-500_to_300
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/08_doneb_-500_to_300/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/rasters/08_doneb
** Making plots for this event_window: 
04_go_cue_-600_to_-40
Saving this event, 04_go_cue_-600_to_-40, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221114-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/04_go_cue_-600_to_-40
./_analy_anova_script.sh: line 4: 17591 Killed                  python analy_anova_plot.py $@ n
