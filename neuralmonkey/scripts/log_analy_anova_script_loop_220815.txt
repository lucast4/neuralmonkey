Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220815*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
session:  0
1
Beh Sessions that exist on this date:  {220815: [(1, 'neuralbiasdir3d')]}
taking this beh session: 1
Loading these beh expts: ['neuralbiasdir3d']
Loading these beh sessions: [1]
Loading this neural session: 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220815*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
{'filename_components_hyphened': ['Pancho', '220815', '155758'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/220815'], 'basedirs_filenames': ['220815', 'Pancho-220815-155758'], 'filename_final_ext': 'Pancho-220815-155758', 'filename_final_noext': 'Pancho-220815-155758'}
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758/Pancho-220815-155758
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758/spikes_tdt_quick-4.5
final_dir_name  --  Pancho-220815-155758
time  --  155758
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/220815.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
o  1 94.90047686410036
o  2 87.39141821028944
o  3 95.13632341491193
o  4 78.51259460543025
o  5 93.38621090501714
o  6 108.91412526993155
o  7 133.25602959093422
o  8 81.09639266065642
o  9 283.0848820274897
o  10 86.64574651237173
o  11 201.15996629332986
o  12 90.24018761768176
o  13 259.1529779420843
o  14 119.0481853372888
o  15 111.97161455331994
o  16 112.969906910025
o  17 78.35609547948488
o  18 88.0195857741026
o  19 108.61668721874011
o  20 211.06193519905148
o  21 124.57828821294243
o  22 100.51417013772371
o  23 79.21134232274153
o  24 91.6958734002651
-  25 65.35877403282242
o  26 773.1358955826844
o  27 191.8091144755268
o  28 85.15796683419367
o  29 297.4549045616807
o  30 121.21324371573465
o  31 206.57756759859421
o  32 102.1309389755883
o  33 75.17680495740979
o  34 151.34393606651574
-  35 54.429291228900915
o  36 584.215494320239
o  37 154.5417439933255
o  38 81.62713458336584
o  39 96.2089273273472
o  40 140.01419866628893
o  41 145.74110697925772
o  42 132.29112697458748
o  43 192.97713543481132
o  44 93.13199722139908
o  45 648.3216255814115
-  46 52.91674811154517
o  47 227.69959991305498
-  48 48.44445616096673
o  49 109.27868463720316
o  50 72.63443437276747
o  51 275.4125381623009
o  52 76.1411633334884
o  53 135.0379842235452
o  54 109.62094123982938
o  55 555.0491951218668
o  56 95.09635867768758
o  57 144.8933259351754
o  58 117.76664081106975
o  59 278.28081235999673
o  60 76.56480282614284
o  61 148.9729826786529
o  62 142.25070814711054
o  63 248.0045149898806
o  64 78.98710904302443
o  65 95.6721253145156
o  66 153.25276618515053
o  67 82.37791955126487
o  68 96.79597884521755
o  69 102.33427854652837
o  70 80.5107864228833
o  71 121.21317876114773
o  72 100.68039736846549
o  73 99.72491125662005
o  74 97.20009650055563
o  75 78.7360997552014
-  76 64.23086081507617
o  77 78.20422752128775
o  78 118.94031592382017
-  79 67.70336304026742
o  80 129.48200672252315
o  81 77.65715927219598
o  82 81.86403116147766
-  83 65.63414146339221
o  84 72.11672967823834
-  85 68.40665620162545
o  86 91.64202763725116
o  87 78.34495692730721
o  88 70.85676509682507
-  89 60.99908819892808
o  90 100.2007777160678
-  91 63.68136622606945
o  92 103.13862557710054
o  93 74.92082609872243
o  94 81.14501120332429
o  95 87.67438092612579
o  96 71.49734919300067
o  97 160.37931864718084
o  98 126.19565477292826
o  99 92.65048570966465
o  100 164.2783981428831
o  101 71.32152735959608
o  102 111.1512059367873
o  103 72.95475740940829
o  104 188.19085689549496
o  105 205.80678563346157
o  106 124.37504133577117
o  107 78.84005445664188
o  108 103.61799598316038
-  109 61.712447678228564
-  110 68.54855415233655
-  111 68.54889701552892
o  112 173.92707707492528
o  113 116.0063342281317
o  114 80.33644731712283
o  115 207.47293923122552
o  116 159.22408767389618
o  117 140.72774451500064
o  118 80.06849901787427
o  119 106.94661498562996
-  120 56.29033343735964
o  121 117.32976689222942
o  122 89.57272412961575
o  123 72.83136721182328
o  124 106.45138349582776
o  125 78.49145225766419
o  126 84.1445006264785
o  127 83.86051414015165
o  128 70.62903997156991
-  129 51.69044208735959
o  130 85.00925825909091
-  131 49.13167431563829
o  132 289.4491196165551
-  133 64.84341858580099
o  134 107.86343682819167
-  135 52.71786029665782
o  136 119.04259965177205
o  137 101.52788194405667
o  138 188.37515365790432
-  139 67.99595402843178
o  140 92.1994146689779
o  141 152.82011923942008
o  142 154.47881484111457
o  143 229.59600932049275
o  144 113.61269172974549
o  145 70.76506916045138
o  146 78.71161322527632
o  147 83.46923611126141
o  148 83.52406681831673
o  149 75.02917186611958
o  150 100.49033551742669
-  151 55.60670225040276
o  152 77.31025147352325
o  153 88.05751590134837
o  154 129.02703267522293
-  155 66.49955343612365
-  156 57.595497685539065
-  157 69.51463401601941
o  158 91.72575307822476
o  159 166.8320933475032
o  160 92.79479950440947
o  161 124.0706747761894
o  162 116.31256379418691
o  163 147.01135768648473
o  164 79.0725486184313
o  165 92.94792276884587
o  166 86.25055372738552
o  167 129.44343972371263
-  168 50.475520221802796
o  169 80.17312976388976
o  170 115.7723058265232
o  171 146.50436571180668
o  172 86.18067094801864
o  173 240.95168597631366
-  174 69.63437430482463
o  175 84.316358271219
-  176 65.69626627829885
o  177 135.99507186167702
o  178 92.60630342347159
o  179 130.21596482270255
o  180 73.76402152576054
o  181 185.03143267563732
o  182 74.89771613347693
-  183 63.69147149562214
o  184 146.15323432457046
-  185 32.40908486118522
o  186 160.5471526672894
o  187 134.8583800675239
o  188 95.80662545177056
o  189 73.96135997943675
o  190 86.45549741939124
-  191 67.21116560309993
-  192 53.1330503579485
o  193 158.30651906107306
o  194 154.79467979822257
o  195 81.39362834478348
o  196 71.56096864638485
o  197 104.22512829428172
o  198 89.94723459712222
o  199 93.7751258642118
o  200 129.38371096461188
o  201 107.18563891354971
o  202 95.56616660215514
o  203 124.06677054065128
-  204 68.94992683406235
o  205 94.7230771685754
o  206 290.43903595673873
o  207 134.58610869607583
-  208 66.56972401176427
o  209 136.76440676087697
o  210 90.10657208064605
o  211 116.2662782995793
o  212 97.9507784509029
o  213 103.72513325620693
o  214 97.71770687994122
o  215 129.41017835020074
o  216 97.56807890132414
o  217 82.59588818926447
o  218 157.64129625874853
o  219 95.41175702800474
o  220 90.20844707737383
o  221 97.72446675082892
o  222 84.74807516623514
o  223 80.8201898063976
o  224 87.9066705825957
o  225 79.97893876437993
o  226 76.85058579322121
o  227 184.41411256335414
-  228 58.789455129866745
-  229 51.81153034797758
o  230 71.84213614629212
o  231 82.03275161860365
-  232 41.68984059986369
o  233 162.86337478126777
-  234 63.80242285422851
-  235 64.75946367673495
o  236 100.97838030381654
o  237 110.90382682221217
-  238 68.92175589915678
o  239 118.13379979942547
o  240 109.60732992460608
o  241 77.39677755686039
o  242 81.41822175816725
o  243 78.00197965474376
o  244 88.94234736951543
o  245 84.85293063423114
o  246 80.16204353663477
o  247 98.8093927453017
o  248 87.93405024579798
o  249 90.1880298517328
-  250 68.59967531329566
o  251 75.14990836943335
o  252 127.55292194635956
o  253 99.70322849944709
o  254 77.12368960945241
o  255 160.0895855327668
o  256 97.16986865736371
o  257 232.00995291590735
o  258 139.2617096971424
o  259 114.13851671674111
o  260 180.252543928872
o  261 102.1977710433719
o  262 126.07195001380006
o  263 167.8768361701022
o  264 151.93435625263155
o  265 172.7060614291628
o  266 104.5561682531068
o  267 178.77815747857406
o  268 85.11040447559259
o  269 126.16882547048507
o  270 133.15787507373756
o  271 122.06217108067115
o  272 119.67457971838958
o  273 226.78473640762672
o  274 171.12867950161407
o  275 81.39945443008874
o  276 91.53882620824098
o  277 133.38491009758727
o  278 145.31028519187896
o  279 110.4855004452305
o  280 85.33470788110426
o  281 103.60940266513447
o  282 73.65501746548848
o  283 106.43008411181683
-  284 62.1645693849865
o  285 88.92906258691784
-  286 63.96087125515542
o  287 83.87678453973326
o  288 113.08364616344925
o  289 120.22224819297672
o  290 82.69470948727394
o  291 75.52419897194105
-  292 43.746037270568195
o  293 77.6007557535435
o  294 126.07231341652532
o  295 124.51658430806802
o  296 129.3107849856269
o  297 107.71173298709664
o  298 98.80055424205666
-  299 59.834705117271724
-  300 60.42076111922652
o  301 89.88530654561437
o  302 99.30230127161848
o  303 99.26333184717328
o  304 73.24684665846158
-  305 54.72029480387646
o  306 72.15056228509111
-  307 55.48382667827646
o  308 72.72769969256078
-  309 58.891546912635754
o  310 95.50634802718433
o  311 76.78325836320911
o  312 134.91859643711905
-  313 53.51003712578154
o  314 119.611218680326
-  315 63.72131044799626
o  316 94.92941465909986
o  317 71.07218459478364
o  318 95.261298759681
o  319 77.70254704429362
o  320 117.2501940365807
o  321 80.70512424629888
-  322 59.32587185842004
o  323 141.19380601927406
-  324 64.70493720477393
-  325 61.84420498324744
-  326 69.11684628932599
o  327 127.36631800430332
o  328 80.97459209556828
o  329 78.85712179627109
o  330 84.73052075659902
o  331 128.56980998492165
o  332 86.02803688938347
o  333 121.37401686950834
o  334 214.8190961916863
-  335 53.942646450734266
-  336 45.36093754115109
-  337 52.91915760933143
-  338 61.381628674276925
-  339 63.98387326585653
-  340 42.46936366526402
-  341 58.96782317525344
-  342 59.52893568157238
o  343 83.72676774331741
o  344 85.61170268944943
o  345 90.62567036037304
-  346 62.50788127267988
o  347 81.13280486757807
o  348 114.74950621954486
o  349 104.219083468589
-  350 60.32116017693843
o  351 119.57092488725212
o  352 94.86919224622208
o  353 78.54010983529736
o  354 74.60104388145518
o  355 73.88493337032745
o  356 77.69867865268797
-  357 44.934155498061784
o  358 71.6008841443549
-  359 60.96283137235082
-  360 52.88206926279463
-  361 63.59777389884739
-  362 63.76564952439412
o  363 70.08187639414298
-  364 66.16683107222423
-  365 49.52753915468893
-  366 64.8653759068111
o  367 85.59304296840638
o  368 85.92228195529859
o  369 86.46655865636494
o  370 90.83473102218791
o  371 92.70002443004483
-  372 54.701765502202825
o  373 90.97658260542684
o  374 78.26101229878965
o  375 70.42630182787816
-  376 63.19861506911002
-  377 57.61144259557325
-  378 62.10995534743633
-  379 65.94369039782279
-  380 51.71316709399889
-  381 47.736593012708546
-  382 63.63672349043145
o  383 70.51700670247756
-  384 61.38515664307911
o  385 135.06140909199837
o  386 131.19422059155565
o  387 201.24670111572843
o  388 82.37021821059015
o  389 223.86461560384396
o  390 92.08694326588405
-  391 47.83883777290803
-  392 64.74856874714445
o  393 141.91947120267596
o  394 178.23768222722202
o  395 112.31802332901927
o  396 136.5100032603585
o  397 87.8822476240603
o  398 77.92934701740015
o  399 109.20199160145276
o  400 153.0045011681973
o  401 123.91369677056937
o  402 138.41266773847428
o  403 120.29760786723793
o  404 191.9363317386623
o  405 147.40827410162146
o  406 91.45113931254878
o  407 146.46511689889095
o  408 93.5703992180137
o  409 82.23142763340557
o  410 465.01661456051335
o  411 74.44579076864393
o  412 122.25874900832851
o  413 244.6458053977629
o  414 233.61949506033307
o  415 224.8709951830693
o  416 175.83550248003067
o  417 99.77760527423189
-  418 69.61944952698222
o  419 79.44199498116737
o  420 114.72125598499852
o  421 112.9983598118743
o  422 95.78581632521865
o  423 101.37135357872795
-  424 69.41766475010108
o  425 85.52725135966034
-  426 59.27414144495178
-  427 61.146836018396066
-  428 30.66619590557202
o  429 95.1798431895193
o  430 103.9239089368717
-  431 67.8674053883337
-  432 53.49557620044116
o  433 217.23519906747606
o  434 115.43514043509514
o  435 148.48966547408216
o  436 127.20070581176306
o  437 166.03505455077595
o  438 73.88155655234986
o  439 129.77314223856877
-  440 59.66399016568285
o  441 127.86987313378559
o  442 100.8629612809376
o  443 725.132856424893
-  444 57.6182413794667
o  445 83.70211144793537
-  446 36.286765140181885
o  447 125.18006450044379
-  448 37.44112723762478
o  449 104.37423294964111
o  450 97.15645210443296
o  451 123.46655784202511
o  452 166.7956838159369
o  453 101.80620688323782
o  454 98.28729089473416
o  455 125.12277774184629
-  456 63.33662685811178
o  457 128.53491290634497
o  458 75.19302123360757
o  459 215.90667448577665
o  460 146.25436297729902
o  461 107.56769171341149
o  462 174.14052257249097
o  463 152.9808655530316
o  464 122.66491051563989
o  465 181.2184139706239
-  466 52.92725380764673
o  467 150.47711125219305
o  468 178.35792876754894
o  469 109.05299628984963
o  470 80.4953020821686
o  471 215.24338194081332
o  472 165.4723345249296
o  473 124.21618938071265
o  474 174.3302519230603
o  475 137.6035970385241
o  476 88.2929653362851
o  477 154.7356607524182
o  478 96.6951267763513
o  479 94.9824336405076
o  480 118.53044293451804
o  481 99.2360048181298
-  482 34.950149712223904
o  483 135.79639669389744
o  484 134.05228243146485
o  485 108.27701959624429
o  486 136.99079262157392
-  487 59.128358468861904
o  488 127.87663822410735
o  489 125.59196239040098
o  490 91.80917721073003
o  491 108.01079210063428
o  492 143.7962203000133
o  493 99.88231265532117
o  494 181.43064260595222
o  495 79.75135159449839
o  496 155.00413764773114
o  497 180.48216654060315
o  498 103.91617184185301
-  499 67.7857770174387
o  500 157.30160796787771
o  501 76.83370800966713
o  502 335.4897218085986
o  503 182.80486530501068
o  504 303.5440057080724
o  505 93.31988857421129
o  506 88.08841442498088
-  507 36.11220561785321
o  508 85.92302907583999
o  509 208.6002537375767
o  510 136.99672368517378
o  511 71.55245084760838
o  512 129.9598603360968
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Trials.pkl
** SKIPPING EXTRACTION, since was able to load snippets, for: 
(animal, DATE, which_level, ANALY_VER, session)
Pancho 220815 trial rulesw 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220815*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
session:  0
1
Beh Sessions that exist on this date:  {220815: [(1, 'neuralbiasdir3d')]}
taking this beh session: 1
Loading these beh expts: ['neuralbiasdir3d']
Loading these beh sessions: [1]
Loading this neural session: 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220815*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
{'filename_components_hyphened': ['Pancho', '220815', '155758'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/220815'], 'basedirs_filenames': ['220815', 'Pancho-220815-155758'], 'filename_final_ext': 'Pancho-220815-155758', 'filename_final_noext': 'Pancho-220815-155758'}
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758/Pancho-220815-155758
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758/spikes_tdt_quick-4.5
final_dir_name  --  Pancho-220815-155758
time  --  155758
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/220815.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
o  1 94.90047686410036
o  2 87.39141821028944
o  3 95.13632341491193
o  4 78.51259460543025
o  5 93.38621090501714
o  6 108.91412526993155
o  7 133.25602959093422
o  8 81.09639266065642
o  9 283.0848820274897
o  10 86.64574651237173
o  11 201.15996629332986
o  12 90.24018761768176
o  13 259.1529779420843
o  14 119.0481853372888
o  15 111.97161455331994
o  16 112.969906910025
o  17 78.35609547948488
o  18 88.0195857741026
o  19 108.61668721874011
o  20 211.06193519905148
o  21 124.57828821294243
o  22 100.51417013772371
o  23 79.21134232274153
o  24 91.6958734002651
-  25 65.35877403282242
o  26 773.1358955826844
o  27 191.8091144755268
o  28 85.15796683419367
o  29 297.4549045616807
o  30 121.21324371573465
o  31 206.57756759859421
o  32 102.1309389755883
o  33 75.17680495740979
o  34 151.34393606651574
-  35 54.429291228900915
o  36 584.215494320239
o  37 154.5417439933255
o  38 81.62713458336584
o  39 96.2089273273472
o  40 140.01419866628893
o  41 145.74110697925772
o  42 132.29112697458748
o  43 192.97713543481132
o  44 93.13199722139908
o  45 648.3216255814115
-  46 52.91674811154517
o  47 227.69959991305498
-  48 48.44445616096673
o  49 109.27868463720316
o  50 72.63443437276747
o  51 275.4125381623009
o  52 76.1411633334884
o  53 135.0379842235452
o  54 109.62094123982938
o  55 555.0491951218668
o  56 95.09635867768758
o  57 144.8933259351754
o  58 117.76664081106975
o  59 278.28081235999673
o  60 76.56480282614284
o  61 148.9729826786529
o  62 142.25070814711054
o  63 248.0045149898806
o  64 78.98710904302443
o  65 95.6721253145156
o  66 153.25276618515053
o  67 82.37791955126487
o  68 96.79597884521755
o  69 102.33427854652837
o  70 80.5107864228833
o  71 121.21317876114773
o  72 100.68039736846549
o  73 99.72491125662005
o  74 97.20009650055563
o  75 78.7360997552014
-  76 64.23086081507617
o  77 78.20422752128775
o  78 118.94031592382017
-  79 67.70336304026742
o  80 129.48200672252315
o  81 77.65715927219598
o  82 81.86403116147766
-  83 65.63414146339221
o  84 72.11672967823834
-  85 68.40665620162545
o  86 91.64202763725116
o  87 78.34495692730721
o  88 70.85676509682507
-  89 60.99908819892808
o  90 100.2007777160678
-  91 63.68136622606945
o  92 103.13862557710054
o  93 74.92082609872243
o  94 81.14501120332429
o  95 87.67438092612579
o  96 71.49734919300067
o  97 160.37931864718084
o  98 126.19565477292826
o  99 92.65048570966465
o  100 164.2783981428831
o  101 71.32152735959608
o  102 111.1512059367873
o  103 72.95475740940829
o  104 188.19085689549496
o  105 205.80678563346157
o  106 124.37504133577117
o  107 78.84005445664188
o  108 103.61799598316038
-  109 61.712447678228564
-  110 68.54855415233655
-  111 68.54889701552892
o  112 173.92707707492528
o  113 116.0063342281317
o  114 80.33644731712283
o  115 207.47293923122552
o  116 159.22408767389618
o  117 140.72774451500064
o  118 80.06849901787427
o  119 106.94661498562996
-  120 56.29033343735964
o  121 117.32976689222942
o  122 89.57272412961575
o  123 72.83136721182328
o  124 106.45138349582776
o  125 78.49145225766419
o  126 84.1445006264785
o  127 83.86051414015165
o  128 70.62903997156991
-  129 51.69044208735959
o  130 85.00925825909091
-  131 49.13167431563829
o  132 289.4491196165551
-  133 64.84341858580099
o  134 107.86343682819167
-  135 52.71786029665782
o  136 119.04259965177205
o  137 101.52788194405667
o  138 188.37515365790432
-  139 67.99595402843178
o  140 92.1994146689779
o  141 152.82011923942008
o  142 154.47881484111457
o  143 229.59600932049275
o  144 113.61269172974549
o  145 70.76506916045138
o  146 78.71161322527632
o  147 83.46923611126141
o  148 83.52406681831673
o  149 75.02917186611958
o  150 100.49033551742669
-  151 55.60670225040276
o  152 77.31025147352325
o  153 88.05751590134837
o  154 129.02703267522293
-  155 66.49955343612365
-  156 57.595497685539065
-  157 69.51463401601941
o  158 91.72575307822476
o  159 166.8320933475032
o  160 92.79479950440947
o  161 124.0706747761894
o  162 116.31256379418691
o  163 147.01135768648473
o  164 79.0725486184313
o  165 92.94792276884587
o  166 86.25055372738552
o  167 129.44343972371263
-  168 50.475520221802796
o  169 80.17312976388976
o  170 115.7723058265232
o  171 146.50436571180668
o  172 86.18067094801864
o  173 240.95168597631366
-  174 69.63437430482463
o  175 84.316358271219
-  176 65.69626627829885
o  177 135.99507186167702
o  178 92.60630342347159
o  179 130.21596482270255
o  180 73.76402152576054
o  181 185.03143267563732
o  182 74.89771613347693
-  183 63.69147149562214
o  184 146.15323432457046
-  185 32.40908486118522
o  186 160.5471526672894
o  187 134.8583800675239
o  188 95.80662545177056
o  189 73.96135997943675
o  190 86.45549741939124
-  191 67.21116560309993
-  192 53.1330503579485
o  193 158.30651906107306
o  194 154.79467979822257
o  195 81.39362834478348
o  196 71.56096864638485
o  197 104.22512829428172
o  198 89.94723459712222
o  199 93.7751258642118
o  200 129.38371096461188
o  201 107.18563891354971
o  202 95.56616660215514
o  203 124.06677054065128
-  204 68.94992683406235
o  205 94.7230771685754
o  206 290.43903595673873
o  207 134.58610869607583
-  208 66.56972401176427
o  209 136.76440676087697
o  210 90.10657208064605
o  211 116.2662782995793
o  212 97.9507784509029
o  213 103.72513325620693
o  214 97.71770687994122
o  215 129.41017835020074
o  216 97.56807890132414
o  217 82.59588818926447
o  218 157.64129625874853
o  219 95.41175702800474
o  220 90.20844707737383
o  221 97.72446675082892
o  222 84.74807516623514
o  223 80.8201898063976
o  224 87.9066705825957
o  225 79.97893876437993
o  226 76.85058579322121
o  227 184.41411256335414
-  228 58.789455129866745
-  229 51.81153034797758
o  230 71.84213614629212
o  231 82.03275161860365
-  232 41.68984059986369
o  233 162.86337478126777
-  234 63.80242285422851
-  235 64.75946367673495
o  236 100.97838030381654
o  237 110.90382682221217
-  238 68.92175589915678
o  239 118.13379979942547
o  240 109.60732992460608
o  241 77.39677755686039
o  242 81.41822175816725
o  243 78.00197965474376
o  244 88.94234736951543
o  245 84.85293063423114
o  246 80.16204353663477
o  247 98.8093927453017
o  248 87.93405024579798
o  249 90.1880298517328
-  250 68.59967531329566
o  251 75.14990836943335
o  252 127.55292194635956
o  253 99.70322849944709
o  254 77.12368960945241
o  255 160.0895855327668
o  256 97.16986865736371
o  257 232.00995291590735
o  258 139.2617096971424
o  259 114.13851671674111
o  260 180.252543928872
o  261 102.1977710433719
o  262 126.07195001380006
o  263 167.8768361701022
o  264 151.93435625263155
o  265 172.7060614291628
o  266 104.5561682531068
o  267 178.77815747857406
o  268 85.11040447559259
o  269 126.16882547048507
o  270 133.15787507373756
o  271 122.06217108067115
o  272 119.67457971838958
o  273 226.78473640762672
o  274 171.12867950161407
o  275 81.39945443008874
o  276 91.53882620824098
o  277 133.38491009758727
o  278 145.31028519187896
o  279 110.4855004452305
o  280 85.33470788110426
o  281 103.60940266513447
o  282 73.65501746548848
o  283 106.43008411181683
-  284 62.1645693849865
o  285 88.92906258691784
-  286 63.96087125515542
o  287 83.87678453973326
o  288 113.08364616344925
o  289 120.22224819297672
o  290 82.69470948727394
o  291 75.52419897194105
-  292 43.746037270568195
o  293 77.6007557535435
o  294 126.07231341652532
o  295 124.51658430806802
o  296 129.3107849856269
o  297 107.71173298709664
o  298 98.80055424205666
-  299 59.834705117271724
-  300 60.42076111922652
o  301 89.88530654561437
o  302 99.30230127161848
o  303 99.26333184717328
o  304 73.24684665846158
-  305 54.72029480387646
o  306 72.15056228509111
-  307 55.48382667827646
o  308 72.72769969256078
-  309 58.891546912635754
o  310 95.50634802718433
o  311 76.78325836320911
o  312 134.91859643711905
-  313 53.51003712578154
o  314 119.611218680326
-  315 63.72131044799626
o  316 94.92941465909986
o  317 71.07218459478364
o  318 95.261298759681
o  319 77.70254704429362
o  320 117.2501940365807
o  321 80.70512424629888
-  322 59.32587185842004
o  323 141.19380601927406
-  324 64.70493720477393
-  325 61.84420498324744
-  326 69.11684628932599
o  327 127.36631800430332
o  328 80.97459209556828
o  329 78.85712179627109
o  330 84.73052075659902
o  331 128.56980998492165
o  332 86.02803688938347
o  333 121.37401686950834
o  334 214.8190961916863
-  335 53.942646450734266
-  336 45.36093754115109
-  337 52.91915760933143
-  338 61.381628674276925
-  339 63.98387326585653
-  340 42.46936366526402
-  341 58.96782317525344
-  342 59.52893568157238
o  343 83.72676774331741
o  344 85.61170268944943
o  345 90.62567036037304
-  346 62.50788127267988
o  347 81.13280486757807
o  348 114.74950621954486
o  349 104.219083468589
-  350 60.32116017693843
o  351 119.57092488725212
o  352 94.86919224622208
o  353 78.54010983529736
o  354 74.60104388145518
o  355 73.88493337032745
o  356 77.69867865268797
-  357 44.934155498061784
o  358 71.6008841443549
-  359 60.96283137235082
-  360 52.88206926279463
-  361 63.59777389884739
-  362 63.76564952439412
o  363 70.08187639414298
-  364 66.16683107222423
-  365 49.52753915468893
-  366 64.8653759068111
o  367 85.59304296840638
o  368 85.92228195529859
o  369 86.46655865636494
o  370 90.83473102218791
o  371 92.70002443004483
-  372 54.701765502202825
o  373 90.97658260542684
o  374 78.26101229878965
o  375 70.42630182787816
-  376 63.19861506911002
-  377 57.61144259557325
-  378 62.10995534743633
-  379 65.94369039782279
-  380 51.71316709399889
-  381 47.736593012708546
-  382 63.63672349043145
o  383 70.51700670247756
-  384 61.38515664307911
o  385 135.06140909199837
o  386 131.19422059155565
o  387 201.24670111572843
o  388 82.37021821059015
o  389 223.86461560384396
o  390 92.08694326588405
-  391 47.83883777290803
-  392 64.74856874714445
o  393 141.91947120267596
o  394 178.23768222722202
o  395 112.31802332901927
o  396 136.5100032603585
o  397 87.8822476240603
o  398 77.92934701740015
o  399 109.20199160145276
o  400 153.0045011681973
o  401 123.91369677056937
o  402 138.41266773847428
o  403 120.29760786723793
o  404 191.9363317386623
o  405 147.40827410162146
o  406 91.45113931254878
o  407 146.46511689889095
o  408 93.5703992180137
o  409 82.23142763340557
o  410 465.01661456051335
o  411 74.44579076864393
o  412 122.25874900832851
o  413 244.6458053977629
o  414 233.61949506033307
o  415 224.8709951830693
o  416 175.83550248003067
o  417 99.77760527423189
-  418 69.61944952698222
o  419 79.44199498116737
o  420 114.72125598499852
o  421 112.9983598118743
o  422 95.78581632521865
o  423 101.37135357872795
-  424 69.41766475010108
o  425 85.52725135966034
-  426 59.27414144495178
-  427 61.146836018396066
-  428 30.66619590557202
o  429 95.1798431895193
o  430 103.9239089368717
-  431 67.8674053883337
-  432 53.49557620044116
o  433 217.23519906747606
o  434 115.43514043509514
o  435 148.48966547408216
o  436 127.20070581176306
o  437 166.03505455077595
o  438 73.88155655234986
o  439 129.77314223856877
-  440 59.66399016568285
o  441 127.86987313378559
o  442 100.8629612809376
o  443 725.132856424893
-  444 57.6182413794667
o  445 83.70211144793537
-  446 36.286765140181885
o  447 125.18006450044379
-  448 37.44112723762478
o  449 104.37423294964111
o  450 97.15645210443296
o  451 123.46655784202511
o  452 166.7956838159369
o  453 101.80620688323782
o  454 98.28729089473416
o  455 125.12277774184629
-  456 63.33662685811178
o  457 128.53491290634497
o  458 75.19302123360757
o  459 215.90667448577665
o  460 146.25436297729902
o  461 107.56769171341149
o  462 174.14052257249097
o  463 152.9808655530316
o  464 122.66491051563989
o  465 181.2184139706239
-  466 52.92725380764673
o  467 150.47711125219305
o  468 178.35792876754894
o  469 109.05299628984963
o  470 80.4953020821686
o  471 215.24338194081332
o  472 165.4723345249296
o  473 124.21618938071265
o  474 174.3302519230603
o  475 137.6035970385241
o  476 88.2929653362851
o  477 154.7356607524182
o  478 96.6951267763513
o  479 94.9824336405076
o  480 118.53044293451804
o  481 99.2360048181298
-  482 34.950149712223904
o  483 135.79639669389744
o  484 134.05228243146485
o  485 108.27701959624429
o  486 136.99079262157392
-  487 59.128358468861904
o  488 127.87663822410735
o  489 125.59196239040098
o  490 91.80917721073003
o  491 108.01079210063428
o  492 143.7962203000133
o  493 99.88231265532117
o  494 181.43064260595222
o  495 79.75135159449839
o  496 155.00413764773114
o  497 180.48216654060315
o  498 103.91617184185301
-  499 67.7857770174387
o  500 157.30160796787771
o  501 76.83370800966713
o  502 335.4897218085986
o  503 182.80486530501068
o  504 303.5440057080724
o  505 93.31988857421129
o  506 88.08841442498088
-  507 36.11220561785321
o  508 85.92302907583999
o  509 208.6002537375767
o  510 136.99672368517378
o  511 71.55245084760838
o  512 129.9598603360968
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Trials.pkl
This many vals across loaded session
0 : 2688106
Assigning to SP.Params this item:
{'which_level': 'trial', '_list_events': ['fixcue', 'fix_touch', 'rulecue2', 'samp', 'go_cue', 'first_raise', 'on_strokeidx_0', 'off_stroke_last', 'doneb', 'post', 'reward_all'], 'list_events_uniqnames': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_features_extraction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_features_get_conjunction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_pre_dur': [-0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65], 'list_post_dur': [0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65], 'map_var_to_othervars': None, 'strokes_only_keep_single': False, 'tasks_only_keep_these': None, 'prune_feature_levels_min_n_trials': 1, 'fr_which_version': 'sqrt', 'map_var_to_levels': None}
Assigning to SP.ParamsGlobals this item:
{'n_min_trials_per_level': 5, 'lenient_allow_data_if_has_n_levels': 2, 'PRE_DUR_CALC': -0.65, 'POST_DUR_CALC': 0.65, 'list_events': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_pre_dur': [-0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65], 'list_post_dur': [0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65]}
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
TODO!!! Merge this with other learning-related code
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
trial # 0
trial # 100
trial # 200
trial # 300
trial # 400
trial # 500
trial # 600
Generated column called 'agent', which connects agent_kind-rule
n samples for conjunctions of score_name, agent_rule, agent_kind:
('binsucc', 'D', 'model') :     371
('binsucc', 'L', 'model') :     320
('binsucc', 'base', 'model') :     3
TODO! _preprocess_sanity_check
Starting length of D.Dat: 694
self.Dat modified!!
Len, after remove aborts: 625
############ TAKING ONLY NO SUPERVISION TRIALS
--BEFORE REMOVE; existing supervision_stage_concise:
off|0||0     470
mask|0||0    155
Name: supervision_stage_concise, dtype: int64
self.Dat modified!!
--AFTER REMOVE; existing supervision_stage_concise:
off|0||0    470
Name: supervision_stage_concise, dtype: int64
Dataset final len: 470
-- Len of D, before applying this param: remove_repeated_trials, ... 470
appended col to self.Dat:
dummy
self.Dat starting legnth:  468
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  468
after: 468
-- Len of D, before applying this param: correct_sequencing_binary_score, ... 468
self.Dat starting legnth:  464
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  464
after: 464
-- Len of D, before applying this param: one_to_one_beh_task_strokes, ... 464
after: 443
Done!, new len of dataset 443
Saving to: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_taskgroup_probe/SV_r2_maxtime_1way_mshuff
starting sites:  400
starting sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 81, 82, 84, 86, 87, 88, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 112, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 134, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 230, 231, 233, 236, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 285, 287, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 301, 302, 303, 304, 306, 308, 310, 311, 312, 314, 316, 317, 318, 319, 320, 327, 328, 329, 330, 331, 332, 333, 334, 343, 344, 345, 347, 349, 351, 352, 353, 354, 355, 356, 358, 363, 367, 368, 369, 370, 371, 373, 374, 375, 383, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512]
For percentile 10, using this threshold: 3.4090755921493487
sites_good:  360
sites_bad:  40
Updates self.Sites
ending sites:  360
ending sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 84, 87, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 112, 113, 114, 116, 117, 119, 121, 122, 123, 124, 125, 126, 130, 132, 134, 136, 138, 140, 141, 142, 143, 144, 148, 149, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 227, 233, 237, 239, 240, 241, 244, 245, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 283, 285, 287, 288, 290, 294, 295, 296, 297, 301, 302, 303, 304, 308, 310, 312, 314, 316, 320, 327, 328, 329, 330, 331, 332, 333, 334, 343, 344, 345, 347, 349, 351, 352, 353, 354, 355, 356, 367, 369, 370, 371, 373, 374, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 455, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 481, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512]
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.65
POST_DUR_CALC  =  0.65
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
TODO: do fr scalar computation only once! takes too much time.
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_taskgroup_probe/SV_r2_maxtime_1way_mshuff/df_var.pkl
Searching for already-done df_var at this path:
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_taskgroup_probe/SV_r2_maxtime_1way_mshuff/df_var.pkl
RELOADED df_var!!!
... from: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_taskgroup_probe/SV_r2_maxtime_1way_mshuff/df_var.pkl
Events already done: (will skip these when recomputing)...
['03_samp_-600_to_-50', '03_samp_50_to_600', '05_first_raise_-600_to_-50', '06_on_strokeidx_0_-100_to_600', '08_doneb_-500_to_300', '09_post_50_to_600', '10_reward_all_50_to_600']
COMPUTING df_var!!!
DOing these! ...
list_events ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
WILL SKIP THESE EVENTS...
['03_samp_-600_to_-50', '03_samp_50_to_600', '05_first_raise_-600_to_-50', '06_on_strokeidx_0_-100_to_600', '08_doneb_-500_to_300', '09_post_50_to_600', '10_reward_all_50_to_600']
Running grouping_print_n_samples...
GOOD!, enough data, max n per grouping conjunction (nmin, nmax)  0 107
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_-600_to_-50
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
03_samp_-600_to_-50
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_50_to_600
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
03_samp_50_to_600
 
Updated ParamsGlobals for event 05_first_raise to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  05_first_raise_-600_to_-50
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
05_first_raise_-600_to_-50
 
Updated ParamsGlobals for event 06_on_strokeidx_0 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.1
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  06_on_strokeidx_0_-100_to_600
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
06_on_strokeidx_0_-100_to_600
 
Updated ParamsGlobals for event 08_doneb to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.5
POST_DUR_CALC  =  0.3
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  08_doneb_-500_to_300
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
08_doneb_-500_to_300
 
Updated ParamsGlobals for event 09_post to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  09_post_50_to_600
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
09_post_50_to_600
 
Updated ParamsGlobals for event 10_reward_all to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  10_reward_all_50_to_600
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
10_reward_all_50_to_600
SKIPPING, extracted df_var is empty. Probably you have not enough data for this conjunctions, try setting DEBUG_CONJUNCTIONS=True and reading the low-level data it prints.
!! SKIPPING:  epoch ['taskgroup', 'probe']
Saving to: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff
starting sites:  360
starting sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 84, 87, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 112, 113, 114, 116, 117, 119, 121, 122, 123, 124, 125, 126, 130, 132, 134, 136, 138, 140, 141, 142, 143, 144, 148, 149, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 227, 233, 237, 239, 240, 241, 244, 245, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 283, 285, 287, 288, 290, 294, 295, 296, 297, 301, 302, 303, 304, 308, 310, 312, 314, 316, 320, 327, 328, 329, 330, 331, 332, 333, 334, 343, 344, 345, 347, 349, 351, 352, 353, 354, 355, 356, 367, 369, 370, 371, 373, 374, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 455, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 481, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512]
For percentile 10, using this threshold: 3.4090755921493487
sites_good:  360
sites_bad:  40
Updates self.Sites
ending sites:  360
ending sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 84, 87, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 112, 113, 114, 116, 117, 119, 121, 122, 123, 124, 125, 126, 130, 132, 134, 136, 138, 140, 141, 142, 143, 144, 148, 149, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 227, 233, 237, 239, 240, 241, 244, 245, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 283, 285, 287, 288, 290, 294, 295, 296, 297, 301, 302, 303, 304, 308, 310, 312, 314, 316, 320, 327, 328, 329, 330, 331, 332, 333, 334, 343, 344, 345, 347, 349, 351, 352, 353, 354, 355, 356, 367, 369, 370, 371, 373, 374, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 455, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 481, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512]
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.65
POST_DUR_CALC  =  0.65
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
TODO: do fr scalar computation only once! takes too much time.
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/df_var.pkl
Searching for already-done df_var at this path:
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/df_var.pkl
df_var doesnt exist...!
COMPUTING df_var!!!
DOing these! ...
list_events ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
WILL SKIP THESE EVENTS...
[]
Running grouping_print_n_samples...
GOOD!, enough data, max n per grouping conjunction (nmin, nmax)  0 60
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_-600_to_-50
site : 20
site : 40
site : 60
site : 80
site : 140
site : 160
site : 180
site : 200
site : 220
site : 240
site : 260
site : 320
site : 400
site : 420
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_50_to_600
site : 20
site : 40
site : 60
site : 80
site : 140
site : 160
site : 180
site : 200
site : 220
site : 240
site : 260
site : 320
site : 400
site : 420
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 05_first_raise to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  05_first_raise_-600_to_-50
site : 20
site : 40
site : 60
site : 80
site : 140
site : 160
site : 180
site : 200
site : 220
site : 240
site : 260
site : 320
site : 400
site : 420
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 06_on_strokeidx_0 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.1
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  06_on_strokeidx_0_-100_to_600
site : 20
site : 40
site : 60
site : 80
site : 140
site : 160
site : 180
site : 200
site : 220
site : 240
site : 260
site : 320
site : 400
site : 420
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 08_doneb to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.5
POST_DUR_CALC  =  0.3
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  08_doneb_-500_to_300
site : 20
site : 40
site : 60
site : 80
site : 140
site : 160
site : 180
site : 200
site : 220
site : 240
site : 260
site : 320
site : 400
site : 420
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 09_post to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  09_post_50_to_600
site : 20
site : 40
site : 60
site : 80
site : 140
site : 160
site : 180
site : 200
site : 220
site : 240
site : 260
site : 320
site : 400
site : 420
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 10_reward_all to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  10_reward_all_50_to_600
site : 20
site : 40
site : 60
site : 80
site : 140
site : 160
site : 180
site : 200
site : 220
site : 240
site : 260
site : 320
site : 400
site : 420
site : 460
site : 480
site : 500
SAving:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/df_var.pkl
SAving:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/list_eventwindow_event.pkl
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables
var -- vars_others:  epoch  ---  ['seqc_0_loc']
var -- vars_others:  epoch  ---  ['seqc_0_shape']
var -- vars_others:  epoch  ---  ['seqc_nstrokes_beh']
var -- vars_others:  epoch  ---  ['seqc_0_loc', 'seqc_0_shape']
var -- vars_others:  epoch  ---  ['seqc_0_loc', 'seqc_nstrokes_beh']
var -- vars_others:  epoch  ---  ['seqc_0_shape', 'seqc_nstrokes_beh']
var -- vars_others:  epoch  ---  ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-epoch-vs-varothers-levothers-levvar.txt
var -- vars_others:  seqc_0_loc  ---  ['epoch']
var -- vars_others:  seqc_0_loc  ---  ['seqc_0_shape']
var -- vars_others:  seqc_0_loc  ---  ['seqc_nstrokes_beh']
var -- vars_others:  seqc_0_loc  ---  ['epoch', 'seqc_0_shape']
var -- vars_others:  seqc_0_loc  ---  ['epoch', 'seqc_nstrokes_beh']
var -- vars_others:  seqc_0_loc  ---  ['seqc_0_shape', 'seqc_nstrokes_beh']
var -- vars_others:  seqc_0_loc  ---  ['epoch', 'seqc_0_shape', 'seqc_nstrokes_beh']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-seqc_0_loc-vs-varothers-levothers-levvar.txt
var -- vars_others:  seqc_0_shape  ---  ['epoch']
var -- vars_others:  seqc_0_shape  ---  ['seqc_0_loc']
var -- vars_others:  seqc_0_shape  ---  ['seqc_nstrokes_beh']
var -- vars_others:  seqc_0_shape  ---  ['epoch', 'seqc_0_loc']
var -- vars_others:  seqc_0_shape  ---  ['epoch', 'seqc_nstrokes_beh']
var -- vars_others:  seqc_0_shape  ---  ['seqc_0_loc', 'seqc_nstrokes_beh']
var -- vars_others:  seqc_0_shape  ---  ['epoch', 'seqc_0_loc', 'seqc_nstrokes_beh']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-seqc_0_shape-vs-varothers-levothers-levvar.txt
var -- vars_others:  seqc_nstrokes_beh  ---  ['epoch']
var -- vars_others:  seqc_nstrokes_beh  ---  ['seqc_0_loc']
var -- vars_others:  seqc_nstrokes_beh  ---  ['seqc_0_shape']
var -- vars_others:  seqc_nstrokes_beh  ---  ['epoch', 'seqc_0_loc']
var -- vars_others:  seqc_nstrokes_beh  ---  ['epoch', 'seqc_0_shape']
var -- vars_others:  seqc_nstrokes_beh  ---  ['seqc_0_loc', 'seqc_0_shape']
var -- vars_others:  seqc_nstrokes_beh  ---  ['epoch', 'seqc_0_loc', 'seqc_0_shape']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-seqc_nstrokes_beh-vs-varothers-levothers-levvar.txt
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation
** Plotting summarystats
Saving at: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation
Found this var:  epoch
Found this var_others:  ('seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh')
Aggregating dataframe over all othervars ...
Plotting ...
Plotting for specific single other var: seqc_0_loc...
Plotting for specific single other var: seqc_0_shape...
Plotting for specific single other var: seqc_nstrokes_beh...
** Plotting heatmaps
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation_heatmap
Saving to:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation_heatmap/brainschem-event-val-modulation_subgroups.pdf
Saving to:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation_heatmap/brainschem-event-val-modulation_subgroups-NOMOTOR.pdf
** Plotting example strokes
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Trials.pkl
Plotting ..  ((1, 1), 'V-2-4-0', 3)
Plotting ..  ((1, 1), 'line-8-3-0', 3)
Plotting ..  ((1, 1), 'Lcentered-4-3-0', 3)
** Making plots for this event_window: 
08_doneb_-500_to_300
Saving this event, 08_doneb_-500_to_300, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/08_doneb_-500_to_300
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/08_doneb_-500_to_300/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/08_doneb
** Making plots for this event_window: 
03_samp_50_to_600
Saving this event, 03_samp_50_to_600, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/03_samp_50_to_600
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/03_samp_50_to_600/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/03_samp
** Making plots for this event_window: 
06_on_strokeidx_0_-100_to_600
Saving this event, 06_on_strokeidx_0_-100_to_600, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/06_on_strokeidx_0_-100_to_600
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/06_on_strokeidx_0_-100_to_600/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/06_on_strokeidx_0
** Making plots for this event_window: 
09_post_50_to_600
Saving this event, 09_post_50_to_600, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/09_post_50_to_600
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/09_post_50_to_600/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/09_post
** Making plots for this event_window: 
05_first_raise_-600_to_-50
Saving this event, 05_first_raise_-600_to_-50, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/05_first_raise_-600_to_-50
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/05_first_raise_-600_to_-50/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/05_first_raise
** Making plots for this event_window: 
10_reward_all_50_to_600
Saving this event, 10_reward_all_50_to_600, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/10_reward_all_50_to_600
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/10_reward_all_50_to_600/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/10_reward_all
** Making plots for this event_window: 
03_samp_-600_to_-50
Saving this event, 03_samp_-600_to_-50, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/03_samp_-600_to_-50
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/03_samp_-600_to_-50/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/03_samp
Saving to: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff
starting sites:  360
starting sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 84, 87, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 112, 113, 114, 116, 117, 119, 121, 122, 123, 124, 125, 126, 130, 132, 134, 136, 138, 140, 141, 142, 143, 144, 148, 149, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 227, 233, 237, 239, 240, 241, 244, 245, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 283, 285, 287, 288, 290, 294, 295, 296, 297, 301, 302, 303, 304, 308, 310, 312, 314, 316, 320, 327, 328, 329, 330, 331, 332, 333, 334, 343, 344, 345, 347, 349, 351, 352, 353, 354, 355, 356, 367, 369, 370, 371, 373, 374, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 455, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 481, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512]
For percentile 10, using this threshold: 3.4090755921493487
sites_good:  360
sites_bad:  40
Updates self.Sites
ending sites:  360
ending sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 84, 87, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 108, 112, 113, 114, 116, 117, 119, 121, 122, 123, 124, 125, 126, 130, 132, 134, 136, 138, 140, 141, 142, 143, 144, 148, 149, 152, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 170, 171, 172, 173, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 227, 233, 237, 239, 240, 241, 244, 245, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 283, 285, 287, 288, 290, 294, 295, 296, 297, 301, 302, 303, 304, 308, 310, 312, 314, 316, 320, 327, 328, 329, 330, 331, 332, 333, 334, 343, 344, 345, 347, 349, 351, 352, 353, 354, 355, 356, 367, 369, 370, 371, 373, 374, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 455, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 479, 480, 481, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 512]
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.65
POST_DUR_CALC  =  0.65
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
TODO: do fr scalar computation only once! takes too much time.
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/df_var.pkl
Searching for already-done df_var at this path:
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220815-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/df_var.pkl
df_var doesnt exist...!
COMPUTING df_var!!!
DOing these! ...
list_events ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
WILL SKIP THESE EVENTS...
[]
Running grouping_print_n_samples...
These are the existing columns
/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.2, the latest is 0.5.3.
Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.
  return warn(
/gorilla1/code/pythonlib/pythonlib/tools/snstools.py:12: UserWarning: FixedFormatter should only be used together with FixedLocator
  a.set_xticklabels(a.get_xticklabels(), rotation=rotation,
Index(['trialcode', 'chan', 'event_aligned', '_event_aligned', 'spike_times',
       'trial_neural', 'event_time', 'fr_sm', 'probe', 'taskgroup',
       'character', 'epoch', 'task_kind', 'supervision_stage_concise',
       'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc',
       'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc',
       'seqc_3_shape', 'seqc_3_loc', 'gridsize', 'event', 'fr_sm_times',
       'fr_sm_sqrt', 'session_idx', 'fr_scalar_raw'],
      dtype='object')
failed searchign for these columns:
['chan', 'event', 'epoch', 'epochset']
Traceback (most recent call last):
  File "analy_anova_plot.py", line 115, in <module>
    SP.modulationgood_compute_plot_ALL(var, vars_conjuction, 
  File "/gorilla1/code/neuralmonkey/neuralmonkey/classes/snippets.py", line 1412, in modulationgood_compute_plot_ALL
    df_var, list_eventwindow_event = self.modulationgood_compute_wrapper(var, 
  File "/gorilla1/code/neuralmonkey/neuralmonkey/classes/snippets.py", line 1756, in modulationgood_compute_wrapper
    raise err
  File "/gorilla1/code/neuralmonkey/neuralmonkey/classes/snippets.py", line 1750, in modulationgood_compute_wrapper
    n_min, n_max = grouping_count_n_samples_quick(self.DfScalar, list_grp)
  File "/gorilla1/code/pythonlib/pythonlib/tools/pandastools.py", line 1315, in grouping_count_n_samples_quick
    dftmp = df.groupby(list_groupouter_grouping_vars).count()
  File "/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/core/frame.py", line 7718, in groupby
    return DataFrameGroupBy(
  File "/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/core/groupby/groupby.py", line 882, in __init__
    grouper, exclusions, obj = get_grouper(
  File "/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/core/groupby/grouper.py", line 882, in get_grouper
    raise KeyError(gpr)
KeyError: 'epochset'
./_analy_anova_script.sh: line 6: syntax error: unexpected end of file
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220815*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
session:  0
1
Beh Sessions that exist on this date:  {220815: [(1, 'neuralbiasdir3d')]}
taking this beh session: 1
Loading these beh expts: ['neuralbiasdir3d']
Loading these beh sessions: [1]
Loading this neural session: 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220815*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
{'filename_components_hyphened': ['Pancho', '220815', '155758'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/220815'], 'basedirs_filenames': ['220815', 'Pancho-220815-155758'], 'filename_final_ext': 'Pancho-220815-155758', 'filename_final_noext': 'Pancho-220815-155758'}
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758/Pancho-220815-155758
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758/spikes_tdt_quick-4.5
final_dir_name  --  Pancho-220815-155758
time  --  155758
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/220815.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
o  1 94.90047686410036
o  2 87.39141821028944
o  3 95.13632341491193
o  4 78.51259460543025
o  5 93.38621090501714
o  6 108.91412526993155
o  7 133.25602959093422
o  8 81.09639266065642
o  9 283.0848820274897
o  10 86.64574651237173
o  11 201.15996629332986
o  12 90.24018761768176
o  13 259.1529779420843
o  14 119.0481853372888
o  15 111.97161455331994
o  16 112.969906910025
o  17 78.35609547948488
o  18 88.0195857741026
o  19 108.61668721874011
o  20 211.06193519905148
o  21 124.57828821294243
o  22 100.51417013772371
o  23 79.21134232274153
o  24 91.6958734002651
-  25 65.35877403282242
o  26 773.1358955826844
o  27 191.8091144755268
o  28 85.15796683419367
o  29 297.4549045616807
o  30 121.21324371573465
o  31 206.57756759859421
o  32 102.1309389755883
o  33 75.17680495740979
o  34 151.34393606651574
-  35 54.429291228900915
o  36 584.215494320239
o  37 154.5417439933255
o  38 81.62713458336584
o  39 96.2089273273472
o  40 140.01419866628893
o  41 145.74110697925772
o  42 132.29112697458748
o  43 192.97713543481132
o  44 93.13199722139908
o  45 648.3216255814115
-  46 52.91674811154517
o  47 227.69959991305498
-  48 48.44445616096673
o  49 109.27868463720316
o  50 72.63443437276747
o  51 275.4125381623009
o  52 76.1411633334884
o  53 135.0379842235452
o  54 109.62094123982938
o  55 555.0491951218668
o  56 95.09635867768758
o  57 144.8933259351754
o  58 117.76664081106975
o  59 278.28081235999673
o  60 76.56480282614284
o  61 148.9729826786529
o  62 142.25070814711054
o  63 248.0045149898806
o  64 78.98710904302443
o  65 95.6721253145156
o  66 153.25276618515053
o  67 82.37791955126487
o  68 96.79597884521755
o  69 102.33427854652837
o  70 80.5107864228833
o  71 121.21317876114773
o  72 100.68039736846549
o  73 99.72491125662005
o  74 97.20009650055563
o  75 78.7360997552014
-  76 64.23086081507617
o  77 78.20422752128775
o  78 118.94031592382017
-  79 67.70336304026742
o  80 129.48200672252315
o  81 77.65715927219598
o  82 81.86403116147766
-  83 65.63414146339221
o  84 72.11672967823834
-  85 68.40665620162545
o  86 91.64202763725116
o  87 78.34495692730721
o  88 70.85676509682507
-  89 60.99908819892808
o  90 100.2007777160678
-  91 63.68136622606945
o  92 103.13862557710054
o  93 74.92082609872243
o  94 81.14501120332429
o  95 87.67438092612579
o  96 71.49734919300067
o  97 160.37931864718084
o  98 126.19565477292826
o  99 92.65048570966465
o  100 164.2783981428831
o  101 71.32152735959608
o  102 111.1512059367873
o  103 72.95475740940829
o  104 188.19085689549496
o  105 205.80678563346157
o  106 124.37504133577117
o  107 78.84005445664188
o  108 103.61799598316038
-  109 61.712447678228564
-  110 68.54855415233655
-  111 68.54889701552892
o  112 173.92707707492528
o  113 116.0063342281317
o  114 80.33644731712283
o  115 207.47293923122552
o  116 159.22408767389618
o  117 140.72774451500064
o  118 80.06849901787427
o  119 106.94661498562996
-  120 56.29033343735964
o  121 117.32976689222942
o  122 89.57272412961575
o  123 72.83136721182328
o  124 106.45138349582776
o  125 78.49145225766419
o  126 84.1445006264785
o  127 83.86051414015165
o  128 70.62903997156991
-  129 51.69044208735959
o  130 85.00925825909091
-  131 49.13167431563829
o  132 289.4491196165551
-  133 64.84341858580099
o  134 107.86343682819167
-  135 52.71786029665782
o  136 119.04259965177205
o  137 101.52788194405667
o  138 188.37515365790432
-  139 67.99595402843178
o  140 92.1994146689779
o  141 152.82011923942008
o  142 154.47881484111457
o  143 229.59600932049275
o  144 113.61269172974549
o  145 70.76506916045138
o  146 78.71161322527632
o  147 83.46923611126141
o  148 83.52406681831673
o  149 75.02917186611958
o  150 100.49033551742669
-  151 55.60670225040276
o  152 77.31025147352325
o  153 88.05751590134837
o  154 129.02703267522293
-  155 66.49955343612365
-  156 57.595497685539065
-  157 69.51463401601941
o  158 91.72575307822476
o  159 166.8320933475032
o  160 92.79479950440947
o  161 124.0706747761894
o  162 116.31256379418691
o  163 147.01135768648473
o  164 79.0725486184313
o  165 92.94792276884587
o  166 86.25055372738552
o  167 129.44343972371263
-  168 50.475520221802796
o  169 80.17312976388976
o  170 115.7723058265232
o  171 146.50436571180668
o  172 86.18067094801864
o  173 240.95168597631366
-  174 69.63437430482463
o  175 84.316358271219
-  176 65.69626627829885
o  177 135.99507186167702
o  178 92.60630342347159
o  179 130.21596482270255
o  180 73.76402152576054
o  181 185.03143267563732
o  182 74.89771613347693
-  183 63.69147149562214
o  184 146.15323432457046
-  185 32.40908486118522
o  186 160.5471526672894
o  187 134.8583800675239
o  188 95.80662545177056
o  189 73.96135997943675
o  190 86.45549741939124
-  191 67.21116560309993
-  192 53.1330503579485
o  193 158.30651906107306
o  194 154.79467979822257
o  195 81.39362834478348
o  196 71.56096864638485
o  197 104.22512829428172
o  198 89.94723459712222
o  199 93.7751258642118
o  200 129.38371096461188
o  201 107.18563891354971
o  202 95.56616660215514
o  203 124.06677054065128
-  204 68.94992683406235
o  205 94.7230771685754
o  206 290.43903595673873
o  207 134.58610869607583
-  208 66.56972401176427
o  209 136.76440676087697
o  210 90.10657208064605
o  211 116.2662782995793
o  212 97.9507784509029
o  213 103.72513325620693
o  214 97.71770687994122
o  215 129.41017835020074
o  216 97.56807890132414
o  217 82.59588818926447
o  218 157.64129625874853
o  219 95.41175702800474
o  220 90.20844707737383
o  221 97.72446675082892
o  222 84.74807516623514
o  223 80.8201898063976
o  224 87.9066705825957
o  225 79.97893876437993
o  226 76.85058579322121
o  227 184.41411256335414
-  228 58.789455129866745
-  229 51.81153034797758
o  230 71.84213614629212
o  231 82.03275161860365
-  232 41.68984059986369
o  233 162.86337478126777
-  234 63.80242285422851
-  235 64.75946367673495
o  236 100.97838030381654
o  237 110.90382682221217
-  238 68.92175589915678
o  239 118.13379979942547
o  240 109.60732992460608
o  241 77.39677755686039
o  242 81.41822175816725
o  243 78.00197965474376
o  244 88.94234736951543
o  245 84.85293063423114
o  246 80.16204353663477
o  247 98.8093927453017
o  248 87.93405024579798
o  249 90.1880298517328
-  250 68.59967531329566
o  251 75.14990836943335
o  252 127.55292194635956
o  253 99.70322849944709
o  254 77.12368960945241
o  255 160.0895855327668
o  256 97.16986865736371
o  257 232.00995291590735
o  258 139.2617096971424
o  259 114.13851671674111
o  260 180.252543928872
o  261 102.1977710433719
o  262 126.07195001380006
o  263 167.8768361701022
o  264 151.93435625263155
o  265 172.7060614291628
o  266 104.5561682531068
o  267 178.77815747857406
o  268 85.11040447559259
o  269 126.16882547048507
o  270 133.15787507373756
o  271 122.06217108067115
o  272 119.67457971838958
o  273 226.78473640762672
o  274 171.12867950161407
o  275 81.39945443008874
o  276 91.53882620824098
o  277 133.38491009758727
o  278 145.31028519187896
o  279 110.4855004452305
o  280 85.33470788110426
o  281 103.60940266513447
o  282 73.65501746548848
o  283 106.43008411181683
-  284 62.1645693849865
o  285 88.92906258691784
-  286 63.96087125515542
o  287 83.87678453973326
o  288 113.08364616344925
o  289 120.22224819297672
o  290 82.69470948727394
o  291 75.52419897194105
-  292 43.746037270568195
o  293 77.6007557535435
o  294 126.07231341652532
o  295 124.51658430806802
o  296 129.3107849856269
o  297 107.71173298709664
o  298 98.80055424205666
-  299 59.834705117271724
-  300 60.42076111922652
o  301 89.88530654561437
o  302 99.30230127161848
o  303 99.26333184717328
o  304 73.24684665846158
-  305 54.72029480387646
o  306 72.15056228509111
-  307 55.48382667827646
o  308 72.72769969256078
-  309 58.891546912635754
o  310 95.50634802718433
o  311 76.78325836320911
o  312 134.91859643711905
-  313 53.51003712578154
o  314 119.611218680326
-  315 63.72131044799626
o  316 94.92941465909986
o  317 71.07218459478364
o  318 95.261298759681
o  319 77.70254704429362
o  320 117.2501940365807
o  321 80.70512424629888
-  322 59.32587185842004
o  323 141.19380601927406
-  324 64.70493720477393
-  325 61.84420498324744
-  326 69.11684628932599
o  327 127.36631800430332
o  328 80.97459209556828
o  329 78.85712179627109
o  330 84.73052075659902
o  331 128.56980998492165
o  332 86.02803688938347
o  333 121.37401686950834
o  334 214.8190961916863
-  335 53.942646450734266
-  336 45.36093754115109
-  337 52.91915760933143
-  338 61.381628674276925
-  339 63.98387326585653
-  340 42.46936366526402
-  341 58.96782317525344
-  342 59.52893568157238
o  343 83.72676774331741
o  344 85.61170268944943
o  345 90.62567036037304
-  346 62.50788127267988
o  347 81.13280486757807
o  348 114.74950621954486
o  349 104.219083468589
-  350 60.32116017693843
o  351 119.57092488725212
o  352 94.86919224622208
o  353 78.54010983529736
o  354 74.60104388145518
o  355 73.88493337032745
o  356 77.69867865268797
-  357 44.934155498061784
o  358 71.6008841443549
-  359 60.96283137235082
-  360 52.88206926279463
-  361 63.59777389884739
-  362 63.76564952439412
o  363 70.08187639414298
-  364 66.16683107222423
-  365 49.52753915468893
-  366 64.8653759068111
o  367 85.59304296840638
o  368 85.92228195529859
o  369 86.46655865636494
o  370 90.83473102218791
o  371 92.70002443004483
-  372 54.701765502202825
o  373 90.97658260542684
o  374 78.26101229878965
o  375 70.42630182787816
-  376 63.19861506911002
-  377 57.61144259557325
-  378 62.10995534743633
-  379 65.94369039782279
-  380 51.71316709399889
-  381 47.736593012708546
-  382 63.63672349043145
o  383 70.51700670247756
-  384 61.38515664307911
o  385 135.06140909199837
o  386 131.19422059155565
o  387 201.24670111572843
o  388 82.37021821059015
o  389 223.86461560384396
o  390 92.08694326588405
-  391 47.83883777290803
-  392 64.74856874714445
o  393 141.91947120267596
o  394 178.23768222722202
o  395 112.31802332901927
o  396 136.5100032603585
o  397 87.8822476240603
o  398 77.92934701740015
o  399 109.20199160145276
o  400 153.0045011681973
o  401 123.91369677056937
o  402 138.41266773847428
o  403 120.29760786723793
o  404 191.9363317386623
o  405 147.40827410162146
o  406 91.45113931254878
o  407 146.46511689889095
o  408 93.5703992180137
o  409 82.23142763340557
o  410 465.01661456051335
o  411 74.44579076864393
o  412 122.25874900832851
o  413 244.6458053977629
o  414 233.61949506033307
o  415 224.8709951830693
o  416 175.83550248003067
o  417 99.77760527423189
-  418 69.61944952698222
o  419 79.44199498116737
o  420 114.72125598499852
o  421 112.9983598118743
o  422 95.78581632521865
o  423 101.37135357872795
-  424 69.41766475010108
o  425 85.52725135966034
-  426 59.27414144495178
-  427 61.146836018396066
-  428 30.66619590557202
o  429 95.1798431895193
o  430 103.9239089368717
-  431 67.8674053883337
-  432 53.49557620044116
o  433 217.23519906747606
o  434 115.43514043509514
o  435 148.48966547408216
o  436 127.20070581176306
o  437 166.03505455077595
o  438 73.88155655234986
o  439 129.77314223856877
-  440 59.66399016568285
o  441 127.86987313378559
o  442 100.8629612809376
o  443 725.132856424893
-  444 57.6182413794667
o  445 83.70211144793537
-  446 36.286765140181885
o  447 125.18006450044379
-  448 37.44112723762478
o  449 104.37423294964111
o  450 97.15645210443296
o  451 123.46655784202511
o  452 166.7956838159369
o  453 101.80620688323782
o  454 98.28729089473416
o  455 125.12277774184629
-  456 63.33662685811178
o  457 128.53491290634497
o  458 75.19302123360757
o  459 215.90667448577665
o  460 146.25436297729902
o  461 107.56769171341149
o  462 174.14052257249097
o  463 152.9808655530316
o  464 122.66491051563989
o  465 181.2184139706239
-  466 52.92725380764673
o  467 150.47711125219305
o  468 178.35792876754894
o  469 109.05299628984963
o  470 80.4953020821686
o  471 215.24338194081332
o  472 165.4723345249296
o  473 124.21618938071265
o  474 174.3302519230603
o  475 137.6035970385241
o  476 88.2929653362851
o  477 154.7356607524182
o  478 96.6951267763513
o  479 94.9824336405076
o  480 118.53044293451804
o  481 99.2360048181298
-  482 34.950149712223904
o  483 135.79639669389744
o  484 134.05228243146485
o  485 108.27701959624429
o  486 136.99079262157392
-  487 59.128358468861904
o  488 127.87663822410735
o  489 125.59196239040098
o  490 91.80917721073003
o  491 108.01079210063428
o  492 143.7962203000133
o  493 99.88231265532117
o  494 181.43064260595222
o  495 79.75135159449839
o  496 155.00413764773114
o  497 180.48216654060315
o  498 103.91617184185301
-  499 67.7857770174387
o  500 157.30160796787771
o  501 76.83370800966713
o  502 335.4897218085986
o  503 182.80486530501068
o  504 303.5440057080724
o  505 93.31988857421129
o  506 88.08841442498088
-  507 36.11220561785321
o  508 85.92302907583999
o  509 208.6002537375767
o  510 136.99672368517378
o  511 71.55245084760838
o  512 129.9598603360968
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Trials.pkl
** SKIPPING EXTRACTION, since was able to load snippets, for: 
(animal, DATE, which_level, ANALY_VER, session)
Pancho 220815 trial ruleswERROR 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220815*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
session:  0
1
Beh Sessions that exist on this date:  {220815: [(1, 'neuralbiasdir3d')]}
taking this beh session: 1
Loading these beh expts: ['neuralbiasdir3d']
Loading these beh sessions: [1]
Loading this neural session: 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220815*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
{'filename_components_hyphened': ['Pancho', '220815', '155758'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/220815'], 'basedirs_filenames': ['220815', 'Pancho-220815-155758'], 'filename_final_ext': 'Pancho-220815-155758', 'filename_final_noext': 'Pancho-220815-155758'}
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758/Pancho-220815-155758
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220815/Pancho-220815-155758/spikes_tdt_quick-4.5
final_dir_name  --  Pancho-220815-155758
time  --  155758
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/220815.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
o  1 94.90047686410036
o  2 87.39141821028944
o  3 95.13632341491193
o  4 78.51259460543025
o  5 93.38621090501714
o  6 108.91412526993155
o  7 133.25602959093422
o  8 81.09639266065642
o  9 283.0848820274897
o  10 86.64574651237173
o  11 201.15996629332986
o  12 90.24018761768176
o  13 259.1529779420843
o  14 119.0481853372888
o  15 111.97161455331994
o  16 112.969906910025
o  17 78.35609547948488
o  18 88.0195857741026
o  19 108.61668721874011
o  20 211.06193519905148
o  21 124.57828821294243
o  22 100.51417013772371
o  23 79.21134232274153
o  24 91.6958734002651
-  25 65.35877403282242
o  26 773.1358955826844
o  27 191.8091144755268
o  28 85.15796683419367
o  29 297.4549045616807
o  30 121.21324371573465
o  31 206.57756759859421
o  32 102.1309389755883
o  33 75.17680495740979
o  34 151.34393606651574
-  35 54.429291228900915
o  36 584.215494320239
o  37 154.5417439933255
o  38 81.62713458336584
o  39 96.2089273273472
o  40 140.01419866628893
o  41 145.74110697925772
o  42 132.29112697458748
o  43 192.97713543481132
o  44 93.13199722139908
o  45 648.3216255814115
-  46 52.91674811154517
o  47 227.69959991305498
-  48 48.44445616096673
o  49 109.27868463720316
o  50 72.63443437276747
o  51 275.4125381623009
o  52 76.1411633334884
o  53 135.0379842235452
o  54 109.62094123982938
o  55 555.0491951218668
o  56 95.09635867768758
o  57 144.8933259351754
o  58 117.76664081106975
o  59 278.28081235999673
o  60 76.56480282614284
o  61 148.9729826786529
o  62 142.25070814711054
o  63 248.0045149898806
o  64 78.98710904302443
o  65 95.6721253145156
o  66 153.25276618515053
o  67 82.37791955126487
o  68 96.79597884521755
o  69 102.33427854652837
o  70 80.5107864228833
o  71 121.21317876114773
o  72 100.68039736846549
o  73 99.72491125662005
o  74 97.20009650055563
o  75 78.7360997552014
-  76 64.23086081507617
o  77 78.20422752128775
o  78 118.94031592382017
-  79 67.70336304026742
o  80 129.48200672252315
o  81 77.65715927219598
o  82 81.86403116147766
-  83 65.63414146339221
o  84 72.11672967823834
-  85 68.40665620162545
o  86 91.64202763725116
o  87 78.34495692730721
o  88 70.85676509682507
-  89 60.99908819892808
o  90 100.2007777160678
-  91 63.68136622606945
o  92 103.13862557710054
o  93 74.92082609872243
o  94 81.14501120332429
o  95 87.67438092612579
o  96 71.49734919300067
o  97 160.37931864718084
o  98 126.19565477292826
o  99 92.65048570966465
o  100 164.2783981428831
o  101 71.32152735959608
o  102 111.1512059367873
o  103 72.95475740940829
o  104 188.19085689549496
o  105 205.80678563346157
o  106 124.37504133577117
o  107 78.84005445664188
o  108 103.61799598316038
-  109 61.712447678228564
-  110 68.54855415233655
-  111 68.54889701552892
o  112 173.92707707492528
o  113 116.0063342281317
o  114 80.33644731712283
o  115 207.47293923122552
o  116 159.22408767389618
o  117 140.72774451500064
o  118 80.06849901787427
o  119 106.94661498562996
-  120 56.29033343735964
o  121 117.32976689222942
o  122 89.57272412961575
o  123 72.83136721182328
o  124 106.45138349582776
o  125 78.49145225766419
o  126 84.1445006264785
o  127 83.86051414015165
o  128 70.62903997156991
-  129 51.69044208735959
o  130 85.00925825909091
-  131 49.13167431563829
o  132 289.4491196165551
-  133 64.84341858580099
o  134 107.86343682819167
-  135 52.71786029665782
o  136 119.04259965177205
o  137 101.52788194405667
o  138 188.37515365790432
-  139 67.99595402843178
o  140 92.1994146689779
o  141 152.82011923942008
o  142 154.47881484111457
o  143 229.59600932049275
o  144 113.61269172974549
o  145 70.76506916045138
o  146 78.71161322527632
o  147 83.46923611126141
o  148 83.52406681831673
o  149 75.02917186611958
o  150 100.49033551742669
-  151 55.60670225040276
o  152 77.31025147352325
o  153 88.05751590134837
o  154 129.02703267522293
-  155 66.49955343612365
-  156 57.595497685539065
-  157 69.51463401601941
o  158 91.72575307822476
o  159 166.8320933475032
o  160 92.79479950440947
o  161 124.0706747761894
o  162 116.31256379418691
o  163 147.01135768648473
o  164 79.0725486184313
o  165 92.94792276884587
o  166 86.25055372738552
o  167 129.44343972371263
-  168 50.475520221802796
o  169 80.17312976388976
o  170 115.7723058265232
o  171 146.50436571180668
o  172 86.18067094801864
o  173 240.95168597631366
-  174 69.63437430482463
o  175 84.316358271219
-  176 65.69626627829885
o  177 135.99507186167702
o  178 92.60630342347159
o  179 130.21596482270255
o  180 73.76402152576054
o  181 185.03143267563732
o  182 74.89771613347693
-  183 63.69147149562214
o  184 146.15323432457046
-  185 32.40908486118522
o  186 160.5471526672894
o  187 134.8583800675239
o  188 95.80662545177056
o  189 73.96135997943675
o  190 86.45549741939124
-  191 67.21116560309993
-  192 53.1330503579485
o  193 158.30651906107306
o  194 154.79467979822257
o  195 81.39362834478348
o  196 71.56096864638485
o  197 104.22512829428172
o  198 89.94723459712222
o  199 93.7751258642118
o  200 129.38371096461188
o  201 107.18563891354971
o  202 95.56616660215514
o  203 124.06677054065128
-  204 68.94992683406235
o  205 94.7230771685754
o  206 290.43903595673873
o  207 134.58610869607583
-  208 66.56972401176427
o  209 136.76440676087697
o  210 90.10657208064605
o  211 116.2662782995793
o  212 97.9507784509029
o  213 103.72513325620693
o  214 97.71770687994122
o  215 129.41017835020074
o  216 97.56807890132414
o  217 82.59588818926447
o  218 157.64129625874853
o  219 95.41175702800474
o  220 90.20844707737383
o  221 97.72446675082892
o  222 84.74807516623514
o  223 80.8201898063976
o  224 87.9066705825957
o  225 79.97893876437993
o  226 76.85058579322121
o  227 184.41411256335414
-  228 58.789455129866745
-  229 51.81153034797758
o  230 71.84213614629212
o  231 82.03275161860365
-  232 41.68984059986369
o  233 162.86337478126777
-  234 63.80242285422851
-  235 64.75946367673495
o  236 100.97838030381654
o  237 110.90382682221217
-  238 68.92175589915678
o  239 118.13379979942547
o  240 109.60732992460608
o  241 77.39677755686039
o  242 81.41822175816725
o  243 78.00197965474376
o  244 88.94234736951543
o  245 84.85293063423114
o  246 80.16204353663477
o  247 98.8093927453017
o  248 87.93405024579798
o  249 90.1880298517328
-  250 68.59967531329566
o  251 75.14990836943335
o  252 127.55292194635956
o  253 99.70322849944709
o  254 77.12368960945241
o  255 160.0895855327668
o  256 97.16986865736371
o  257 232.00995291590735
o  258 139.2617096971424
o  259 114.13851671674111
o  260 180.252543928872
o  261 102.1977710433719
o  262 126.07195001380006
o  263 167.8768361701022
o  264 151.93435625263155
o  265 172.7060614291628
o  266 104.5561682531068
o  267 178.77815747857406
o  268 85.11040447559259
o  269 126.16882547048507
o  270 133.15787507373756
o  271 122.06217108067115
o  272 119.67457971838958
o  273 226.78473640762672
o  274 171.12867950161407
o  275 81.39945443008874
o  276 91.53882620824098
o  277 133.38491009758727
o  278 145.31028519187896
o  279 110.4855004452305
o  280 85.33470788110426
o  281 103.60940266513447
o  282 73.65501746548848
o  283 106.43008411181683
-  284 62.1645693849865
o  285 88.92906258691784
-  286 63.96087125515542
o  287 83.87678453973326
o  288 113.08364616344925
o  289 120.22224819297672
o  290 82.69470948727394
o  291 75.52419897194105
-  292 43.746037270568195
o  293 77.6007557535435
o  294 126.07231341652532
o  295 124.51658430806802
o  296 129.3107849856269
o  297 107.71173298709664
o  298 98.80055424205666
-  299 59.834705117271724
-  300 60.42076111922652
o  301 89.88530654561437
o  302 99.30230127161848
o  303 99.26333184717328
o  304 73.24684665846158
-  305 54.72029480387646
o  306 72.15056228509111
-  307 55.48382667827646
o  308 72.72769969256078
-  309 58.891546912635754
o  310 95.50634802718433
o  311 76.78325836320911
o  312 134.91859643711905
-  313 53.51003712578154
o  314 119.611218680326
-  315 63.72131044799626
o  316 94.92941465909986
o  317 71.07218459478364
o  318 95.261298759681
o  319 77.70254704429362
o  320 117.2501940365807
o  321 80.70512424629888
-  322 59.32587185842004
o  323 141.19380601927406
-  324 64.70493720477393
-  325 61.84420498324744
-  326 69.11684628932599
o  327 127.36631800430332
o  328 80.97459209556828
o  329 78.85712179627109
o  330 84.73052075659902
o  331 128.56980998492165
o  332 86.02803688938347
o  333 121.37401686950834
o  334 214.8190961916863
-  335 53.942646450734266
-  336 45.36093754115109
-  337 52.91915760933143
-  338 61.381628674276925
-  339 63.98387326585653
-  340 42.46936366526402
-  341 58.96782317525344
-  342 59.52893568157238
o  343 83.72676774331741
o  344 85.61170268944943
o  345 90.62567036037304
-  346 62.50788127267988
o  347 81.13280486757807
o  348 114.74950621954486
o  349 104.219083468589
-  350 60.32116017693843
o  351 119.57092488725212
o  352 94.86919224622208
o  353 78.54010983529736
o  354 74.60104388145518
o  355 73.88493337032745
o  356 77.69867865268797
-  357 44.934155498061784
o  358 71.6008841443549
-  359 60.96283137235082
-  360 52.88206926279463
-  361 63.59777389884739
-  362 63.76564952439412
o  363 70.08187639414298
-  364 66.16683107222423
-  365 49.52753915468893
-  366 64.8653759068111
o  367 85.59304296840638
o  368 85.92228195529859
o  369 86.46655865636494
o  370 90.83473102218791
o  371 92.70002443004483
-  372 54.701765502202825
o  373 90.97658260542684
o  374 78.26101229878965
o  375 70.42630182787816
-  376 63.19861506911002
-  377 57.61144259557325
-  378 62.10995534743633
-  379 65.94369039782279
-  380 51.71316709399889
-  381 47.736593012708546
-  382 63.63672349043145
o  383 70.51700670247756
-  384 61.38515664307911
o  385 135.06140909199837
o  386 131.19422059155565
o  387 201.24670111572843
o  388 82.37021821059015
o  389 223.86461560384396
o  390 92.08694326588405
-  391 47.83883777290803
-  392 64.74856874714445
o  393 141.91947120267596
o  394 178.23768222722202
o  395 112.31802332901927
o  396 136.5100032603585
o  397 87.8822476240603
o  398 77.92934701740015
o  399 109.20199160145276
o  400 153.0045011681973
o  401 123.91369677056937
o  402 138.41266773847428
o  403 120.29760786723793
o  404 191.9363317386623
o  405 147.40827410162146
o  406 91.45113931254878
o  407 146.46511689889095
o  408 93.5703992180137
o  409 82.23142763340557
o  410 465.01661456051335
o  411 74.44579076864393
o  412 122.25874900832851
o  413 244.6458053977629
o  414 233.61949506033307
o  415 224.8709951830693
o  416 175.83550248003067
o  417 99.77760527423189
-  418 69.61944952698222
o  419 79.44199498116737
o  420 114.72125598499852
o  421 112.9983598118743
o  422 95.78581632521865
o  423 101.37135357872795
-  424 69.41766475010108
o  425 85.52725135966034
-  426 59.27414144495178
-  427 61.146836018396066
-  428 30.66619590557202
o  429 95.1798431895193
o  430 103.9239089368717
-  431 67.8674053883337
-  432 53.49557620044116
o  433 217.23519906747606
o  434 115.43514043509514
o  435 148.48966547408216
o  436 127.20070581176306
o  437 166.03505455077595
o  438 73.88155655234986
o  439 129.77314223856877
-  440 59.66399016568285
o  441 127.86987313378559
o  442 100.8629612809376
o  443 725.132856424893
-  444 57.6182413794667
o  445 83.70211144793537
-  446 36.286765140181885
o  447 125.18006450044379
-  448 37.44112723762478
o  449 104.37423294964111
o  450 97.15645210443296
o  451 123.46655784202511
o  452 166.7956838159369
o  453 101.80620688323782
o  454 98.28729089473416
o  455 125.12277774184629
-  456 63.33662685811178
o  457 128.53491290634497
o  458 75.19302123360757
o  459 215.90667448577665
o  460 146.25436297729902
o  461 107.56769171341149
o  462 174.14052257249097
o  463 152.9808655530316
o  464 122.66491051563989
o  465 181.2184139706239
-  466 52.92725380764673
o  467 150.47711125219305
o  468 178.35792876754894
o  469 109.05299628984963
o  470 80.4953020821686
o  471 215.24338194081332
o  472 165.4723345249296
o  473 124.21618938071265
o  474 174.3302519230603
o  475 137.6035970385241
o  476 88.2929653362851
o  477 154.7356607524182
o  478 96.6951267763513
o  479 94.9824336405076
o  480 118.53044293451804
o  481 99.2360048181298
-  482 34.950149712223904
o  483 135.79639669389744
o  484 134.05228243146485
o  485 108.27701959624429
o  486 136.99079262157392
-  487 59.128358468861904
o  488 127.87663822410735
o  489 125.59196239040098
o  490 91.80917721073003
o  491 108.01079210063428
o  492 143.7962203000133
o  493 99.88231265532117
o  494 181.43064260595222
o  495 79.75135159449839
o  496 155.00413764773114
o  497 180.48216654060315
o  498 103.91617184185301
-  499 67.7857770174387
o  500 157.30160796787771
o  501 76.83370800966713
o  502 335.4897218085986
o  503 182.80486530501068
o  504 303.5440057080724
o  505 93.31988857421129
o  506 88.08841442498088
-  507 36.11220561785321
o  508 85.92302907583999
o  509 208.6002537375767
o  510 136.99672368517378
o  511 71.55245084760838
o  512 129.9598603360968
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/220815/Pancho-220815-155758/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220815-sess_0/Trials.pkl
This many vals across loaded session
0 : 2688106
Assigning to SP.Params this item:
{'which_level': 'trial', '_list_events': ['fixcue', 'fix_touch', 'rulecue2', 'samp', 'go_cue', 'first_raise', 'on_strokeidx_0', 'off_stroke_last', 'doneb', 'post', 'reward_all'], 'list_events_uniqnames': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_features_extraction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_features_get_conjunction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_pre_dur': [-0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65], 'list_post_dur': [0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65], 'map_var_to_othervars': None, 'strokes_only_keep_single': False, 'tasks_only_keep_these': None, 'prune_feature_levels_min_n_trials': 1, 'fr_which_version': 'sqrt', 'map_var_to_levels': None}
Assigning to SP.ParamsGlobals this item:
{'n_min_trials_per_level': 5, 'lenient_allow_data_if_has_n_levels': 2, 'PRE_DUR_CALC': -0.65, 'POST_DUR_CALC': 0.65, 'list_events': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_pre_dur': [-0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65, -0.65], 'list_post_dur': [0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65]}
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
TODO!!! Merge this with other learning-related code
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
trial # 0
trial # 100
trial # 200
trial # 300
trial # 400
trial # 500
trial # 600
Generated column called 'agent', which connects agent_kind-rule
n samples for conjunctions of score_name, agent_rule, agent_kind:
('binsucc', 'D', 'model') :     371
('binsucc', 'L', 'model') :     320
('binsucc', 'base', 'model') :     3
TODO! _preprocess_sanity_check
Starting length of D.Dat: 694
############ TAKING ONLY NO SUPERVISION TRIALS
--BEFORE REMOVE; existing supervision_stage_concise:
off|0||0     523
mask|0||0    171
Name: supervision_stage_concise, dtype: int64
self.Dat modified!!
--AFTER REMOVE; existing supervision_stage_concise:
off|0||0    523
Name: supervision_stage_concise, dtype: int64
Dataset final len: 523
-- Len of D, before applying this param: remove_repeated_trials, ... 523
appended col to self.Dat:
dummy
self.Dat starting legnth:  508
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  508
after: 508
-- Len of D, before applying this param: wrong_sequencing_binary_score, ... 508
self.Dat starting legnth:  39
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  39
after: 39
{'LIST_VAR': ['epoch', 'epoch'], 'LIST_VARS_CONJUNCTION': [['taskgroup', 'probe'], ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh']], 'PRE_DUR_CALC': None, 'POST_DUR_CALC': None, 'globals_nmin': 8, 'globals_lenient_allow_data_if_has_n_levels': 2, 'score_ver': 'r2_maxtime_1way_mshuff', 'list_events': ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all'], 'list_pre_dur': [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05], 'list_post_dur': [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6], 'ANALY_VER': 'ruleswERROR', 'which_level': 'trial', 'DATE': 220815, 'animal': 'Pancho', 'get_z_score': True, 'list_superv_keep': None, 'preprocess_steps_append': ['remove_repeated_trials', 'wrong_sequencing_binary_score'], 'remove_aborts': False, 'DO_SCORE_SEQUENCE_VER': 'matlab', 'list_superv_keep_full': None}
Traceback (most recent call last):
  File "analy_anova_plot.py", line 102, in <module>
    assert False, "dataset pruning removed >0.75 of data. Are you sure correct? Maybe removing a supervisiuon stage that is actually important?"
AssertionError: dataset pruning removed >0.75 of data. Are you sure correct? Maybe removing a supervisiuon stage that is actually important?
