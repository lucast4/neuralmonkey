Got these LIST_VAR and LIST_VARS_CONJUNCTION:
['epoch', 'epoch', 'character', 'seqc_0_loc_shape', 'seqc_0_loc', 'seqc_1_loc_shape']
[['epochset'], ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset', 'seqc_0_loc_shape']]
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*221107*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621
session:  0
1
Beh Sessions that exist on this date:  {221107: [(1, 'dirfullvar1b')]}
taking this beh session: 1
------------------------------
Loading this neural session: 0
Loading these beh expts: ['dirfullvar1b']
Loading these beh sessions: [1]
Using this beh_trial_map_list: [(1, 0)]
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*221107*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621
{'filename_components_hyphened': ['Pancho', '221107', '152621'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/221107'], 'basedirs_filenames': ['221107', 'Pancho-221107-152621'], 'filename_final_ext': 'Pancho-221107-152621', 'filename_final_noext': 'Pancho-221107-152621'}
FOund this path for spikes:  /mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621/spikes_tdt_quick-4
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621/Pancho-221107-152621
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621/spikes_tdt_quick-4
final_dir_name  --  Pancho-221107-152621
time  --  152621
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/221107.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
-  1 69.56427764892578
o  2 81.50224075317384
o  3 74.15705718994141
-  4 68.11968154907227
o  5 71.87969436645508
-  6 64.17504577636718
o  7 109.38502349853516
-  8 68.3540252685547
o  9 299.0131561279297
o  10 89.98177032470703
o  11 147.43990631103517
o  12 84.5823356628418
o  13 182.5012008666992
-  14 58.75174789428711
o  15 166.5312942504883
o  16 80.59950027465821
o  17 80.29354324340821
o  18 94.80696716308594
o  19 100.75848770141602
-  20 48.037646484375
o  21 136.8928421020508
o  22 113.87927932739258
-  23 41.888448333740236
o  24 74.14848327636719
-  25 61.70714263916016
o  26 307.00298461914065
o  27 101.2887191772461
o  28 71.56111526489258
o  29 227.6403350830078
o  30 91.98388214111328
o  31 145.65886840820312
o  32 78.95593261718751
o  33 76.99478912353516
o  34 105.74909286499025
-  35 43.497721099853514
o  36 149.92131652832032
-  37 62.71798324584961
o  38 90.63256988525391
o  39 83.37065124511719
o  40 177.436930847168
o  41 82.94834747314454
o  42 138.34842529296876
o  43 85.96428680419922
o  44 197.84974212646486
o  45 148.58173065185548
-  46 48.67895698547363
o  47 156.59958190917968
-  48 46.04757919311523
o  49 117.07863769531251
o  50 88.54730758666992
o  51 116.82428131103516
o  52 95.63519287109375
o  53 675.9277282714844
o  54 72.99294738769531
o  55 162.48952636718752
-  56 58.90813674926758
o  57 166.53655700683595
o  58 83.080419921875
o  59 125.05319442749024
o  60 85.99052734375
o  61 93.7140884399414
o  62 79.11741485595704
o  63 235.45345001220704
-  64 66.73812789916992
o  65 106.70694580078126
o  66 77.9548812866211
o  67 257.13367614746096
o  68 122.69444122314454
o  69 71.88569030761718
-  70 54.35144271850586
o  71 71.24311294555665
o  72 82.1689956665039
o  73 71.50927734375
o  74 156.6845474243164
-  75 68.61415328979493
o  76 78.70907440185547
o  77 70.86668701171875
o  78 113.38264465332041
-  79 62.2936954498291
o  80 83.57393875122071
-  81 66.5847885131836
-  82 61.4283805847168
-  83 65.63325576782228
-  84 56.648563385009766
o  85 71.28802185058593
o  86 90.78714141845703
-  87 49.10846633911133
o  88 85.47634582519532
-  89 55.99948234558106
o  90 79.49051818847657
-  91 65.63689270019532
o  92 75.07665328979492
-  93 68.01433944702148
-  94 65.5036491394043
-  95 63.466009521484374
-  96 66.85879211425782
o  97 174.44409942626953
o  98 73.30914154052735
o  99 94.658406829834
o  100 107.31455078125
o  101 97.28027801513672
o  102 120.30650634765625
-  103 56.17182769775391
o  104 103.95919342041016
o  105 103.26299743652343
-  106 57.17966918945313
-  107 45.79605140686035
o  108 70.49427032470703
-  109 49.1723445892334
-  110 57.46366500854492
-  111 66.76972122192383
-  112 59.62185173034668
o  113 88.40170516967774
o  114 175.02818298339844
-  115 62.89888458251954
o  116 130.6942932128906
-  117 51.68969612121582
o  118 89.4641326904297
o  119 125.81076507568359
-  120 50.38909225463867
o  121 143.7449920654297
o  122 72.77058258056641
o  123 102.34951171875001
-  124 56.520883560180664
-  125 68.09090652465821
o  126 74.73261108398438
o  127 71.05633926391603
-  128 48.50476837158203
o  129 75.22081604003907
o  130 388.8092346191407
o  131 92.35172271728516
o  132 199.2880615234375
-  133 67.46532821655273
o  134 112.2642807006836
-  135 66.96928253173829
o  136 103.75241928100587
-  137 63.02683334350586
o  138 166.23226928710938
o  139 86.86785583496095
o  140 178.6272689819336
o  141 150.8445571899414
o  142 492.9408813476563
o  143 136.20085906982425
o  144 140.17784423828127
-  145 49.96257553100586
-  146 65.0479248046875
-  147 45.632878112792966
o  148 83.22244110107422
-  149 57.28435707092285
o  150 254.59427642822266
-  151 46.194169235229495
o  152 79.62532196044923
-  153 69.1133903503418
o  154 105.29587936401369
-  155 52.604306030273435
o  156 75.899373626709
-  157 56.37504539489746
o  158 90.85408630371094
-  159 67.04087448120119
o  160 94.89972457885743
o  161 94.7409538269043
o  162 85.57436141967773
o  163 75.37461395263672
o  164 71.64049606323243
o  165 168.68158569335938
-  166 67.63265914916992
o  167 115.96251831054688
-  168 63.166392135620114
-  169 66.87057495117188
o  170 93.00088043212892
o  171 158.14834289550782
-  172 53.95572776794434
o  173 262.93164062500006
-  174 64.05095977783203
-  175 64.67571182250977
-  176 58.09596176147461
-  177 55.70267105102539
o  178 253.38496398925787
o  179 330.7043212890625
-  180 64.15622406005859
o  181 94.09546585083008
-  182 54.42940483093262
-  183 58.143890380859375
o  184 83.12727279663086
-  185 26.21141414642334
-  186 69.3423828125
o  187 84.32209396362305
-  188 58.68371734619141
o  189 83.54303131103515
-  190 62.147148895263676
-  191 64.09633560180664
o  192 77.70203399658203
o  193 272.51971435546875
o  194 99.36101531982422
o  195 158.87229614257814
-  196 56.255027770996094
o  197 172.1740493774414
o  198 112.89850234985353
-  199 57.92655029296875
o  200 75.17970504760743
o  201 84.69873123168946
o  202 85.90690307617187
o  203 131.36550903320315
-  204 69.53072586059571
o  205 72.04321517944337
o  206 82.9554931640625
-  207 65.0984733581543
-  208 61.529718017578126
-  209 47.44778938293457
o  210 78.24779663085938
-  211 66.62992248535156
-  212 57.422613525390624
o  213 89.4068000793457
-  214 56.61251602172852
o  215 78.08397521972657
-  216 65.01408233642579
o  217 87.31202850341798
o  218 97.47405471801758
o  219 78.14814529418946
-  220 65.29342041015626
-  221 61.36292572021485
o  222 84.73948364257812
o  223 73.62271347045899
o  224 121.82287063598633
o  225 94.04808120727539
o  226 71.50922241210938
o  227 129.94450836181642
-  228 59.68842353820801
o  229 80.00333557128907
-  230 64.84689865112304
-  231 66.14053726196289
-  232 34.23581466674805
o  233 86.8570343017578
-  234 67.82227325439453
o  235 113.66969146728516
-  236 64.20184478759765
o  237 89.74697341918946
-  238 60.747144317626955
-  239 61.26155242919922
-  240 66.59852294921875
-  241 69.94957275390625
-  242 65.20124053955078
o  243 83.94603881835938
-  244 69.6571029663086
o  245 79.4787498474121
-  246 54.57755966186524
o  247 78.00775756835938
o  248 82.28647155761719
-  249 66.36073684692383
-  250 48.39621124267578
o  251 81.73920135498047
o  252 88.57133483886719
o  253 75.04097595214844
o  254 77.58231201171876
o  255 71.36574783325196
o  256 104.86773529052735
o  257 282.6453338623047
o  258 134.91344604492187
o  259 103.66339492797853
o  260 153.4899688720703
o  261 102.0167938232422
o  262 128.08163146972657
o  263 118.57413787841799
o  264 111.64312438964843
o  265 114.16120529174805
o  266 97.0021842956543
o  267 140.22715911865234
-  268 60.24104995727539
o  269 115.17227935791016
o  270 108.64215545654297
o  271 88.31507949829103
o  272 511.42510681152345
o  273 106.07266464233399
o  274 85.97002410888672
o  275 72.80101776123047
o  276 84.84232711791992
o  277 160.9328155517578
o  278 112.43159484863281
o  279 113.62675476074219
o  280 103.29455108642578
o  281 101.87090759277345
o  282 100.88661880493166
o  283 71.80266342163087
o  284 134.81947479248046
o  285 81.671435546875
o  286 106.04388885498047
-  287 66.14685134887695
o  288 78.34494476318359
-  289 59.002982711791994
o  290 79.55920486450195
o  291 70.53397979736329
-  292 40.506640625
-  293 55.240075302124026
o  294 77.19015350341797
-  295 61.91262283325196
-  296 66.88828125
-  297 57.52100944519043
o  298 100.47144470214845
o  299 87.4599838256836
o  300 154.16922302246095
o  301 77.17546844482422
o  302 96.25489425659183
-  303 60.07499732971191
o  304 87.46225509643556
-  305 50.7933853149414
o  306 70.71959838867187
o  307 75.05050048828124
-  308 58.22414741516114
-  309 66.44418869018556
o  310 74.09783782958985
-  311 58.559487915039064
o  312 90.99221267700196
-  313 53.99802398681641
-  314 55.74238815307617
-  315 55.950537109375
o  316 81.50906448364258
-  317 50.65001602172852
o  318 70.90742492675781
-  319 47.17928466796875
o  320 77.58518142700196
-  321 59.28757743835449
-  322 44.00800552368164
o  323 70.01873931884766
-  324 47.18910446166992
o  325 72.04536895751953
-  326 62.757025527954106
-  327 66.12927398681641
o  328 77.58480758666992
o  329 75.83914260864258
-  330 68.33816375732422
o  331 76.8374412536621
-  332 52.869597625732425
o  333 71.93681564331055
o  334 152.50841369628907
-  335 41.49773597717285
-  336 58.49101867675781
-  337 45.466651916503906
-  338 53.83418350219726
-  339 45.50362319946289
-  340 39.60502624511719
o  341 74.33835067749024
o  342 73.39143600463868
o  343 77.73509140014649
o  344 70.14033966064453
-  345 59.140113067626956
o  346 73.26717376708984
-  347 55.075102996826175
o  348 82.98857192993164
o  349 131.34803314208986
-  350 66.2791732788086
o  351 93.9428596496582
o  352 104.15456771850586
o  353 108.40376968383791
-  354 53.495201873779294
-  355 62.532402801513676
-  356 61.438787841796874
-  357 39.59751167297363
-  358 64.09367065429687
-  359 50.623209381103514
o  360 71.76509017944336
-  361 62.38629570007324
-  362 65.2702247619629
-  363 67.96203689575195
-  364 67.14391326904297
-  365 41.89004249572754
o  366 90.42966537475587
-  367 61.639862060546875
o  368 201.48331298828126
o  369 77.34384841918946
-  370 46.23814582824707
o  371 83.87848892211915
-  372 53.9670051574707
o  373 71.56175231933594
o  374 74.31787948608398
o  375 71.3803581237793
o  376 94.19599685668946
-  377 54.55766830444336
o  378 73.6924430847168
o  379 94.25499267578127
-  380 49.441597366333006
-  381 54.64565887451172
-  382 54.48998146057129
-  383 54.93829002380372
o  384 74.27401275634767
o  385 301.8705749511719
o  386 78.70696487426758
o  387 125.29112243652345
o  388 102.93749542236328
o  389 170.05655822753909
o  390 129.5114471435547
-  391 42.68714141845703
-  392 69.58520431518555
o  393 126.17913360595703
o  394 79.5630111694336
o  395 92.99101638793945
o  396 96.95766983032227
o  397 80.73338088989259
-  398 68.48885498046876
o  399 81.85680770874023
o  400 131.15652160644532
o  401 110.77040405273438
o  402 127.56638565063477
o  403 108.15475158691406
o  404 123.53155822753907
o  405 103.48341369628906
o  406 108.81312103271485
o  407 132.17883605957033
o  408 113.70934448242188
o  409 79.5315071105957
o  410 175.7653579711914
o  411 229.33462371826172
-  412 64.53724975585938
o  413 95.4756362915039
o  414 139.3131561279297
o  415 126.94188842773438
o  416 142.4588394165039
o  417 88.772176361084
o  418 80.88365478515625
o  419 71.89403381347657
-  420 55.75474967956543
o  421 80.55472030639649
o  422 91.44283294677734
o  423 109.54998779296876
-  424 61.53781089782715
o  425 96.7106414794922
-  426 53.3388111114502
-  427 66.10412902832032
-  428 26.24584140777588
o  429 94.29757690429688
o  430 84.24338989257814
-  431 53.7937557220459
-  432 48.241156387329106
o  433 126.24564361572267
o  434 102.02798309326172
o  435 150.60782318115236
o  436 163.5270217895508
o  437 86.9962257385254
o  438 129.01896057128909
o  439 97.19865875244142
-  440 59.33177108764649
o  441 91.25004272460937
-  442 50.65458450317383
o  443 137.09304504394532
-  444 31.558024406433105
o  445 95.6382064819336
-  446 34.24122772216797
o  447 92.66251220703126
-  448 28.647762680053713
o  449 123.16914672851563
o  450 74.93341522216797
-  451 66.03816528320313
o  452 80.7138771057129
o  453 99.15674896240235
o  454 82.49758987426758
o  455 87.2372932434082
-  456 48.34036483764648
o  457 214.1776824951172
o  458 130.9373809814453
o  459 122.15629959106445
o  460 127.2711570739746
o  461 107.87880096435548
o  462 72.11548461914063
o  463 80.51787719726562
o  464 129.13386535644534
o  465 121.28791809082034
-  466 57.73492965698242
o  467 90.09525299072266
o  468 121.50847396850587
o  469 142.20945434570314
o  470 75.96639556884766
o  471 85.280078125
o  472 91.86913146972658
o  473 181.66998901367188
o  474 109.57551727294923
o  475 108.77061157226562
-  476 53.90928840637207
o  477 107.91233215332032
o  478 84.09552230834962
-  479 66.23923034667969
o  480 86.66543273925781
o  481 76.51796264648438
-  482 36.77154693603516
o  483 93.60541763305665
o  484 123.89273071289067
o  485 184.47123107910159
o  486 89.22796020507812
o  487 89.7915023803711
o  488 91.8265480041504
o  489 79.0528953552246
o  490 73.36190643310547
o  491 75.98698348999024
o  492 73.66757507324219
o  493 116.17911300659179
o  494 95.15696563720704
o  495 85.9266586303711
-  496 69.45773315429688
o  497 122.75893783569336
o  498 77.04817504882813
-  499 61.58419990539551
o  500 178.9237274169922
o  501 129.42261657714846
o  502 122.44577407836914
o  503 72.92247924804687
o  504 71.2812614440918
o  505 173.48302001953127
-  506 66.49289093017578
-  507 32.403160858154294
o  508 119.82119216918946
o  509 78.54566192626953
o  510 85.20180282592774
-  511 37.41677055358887
o  512 74.89456634521486
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
... Generated these...
self.BehTrialMapList [(1, 0)]
self.BehTrialMapListGood {0: (0, 1), 1: (0, 2), 2: (0, 3), 3: (0, 4), 4: (0, 5), 5: (0, 6), 6: (0, 7), 7: (0, 8), 8: (0, 9), 9: (0, 10), 10: (0, 11), 11: (0, 12), 12: (0, 13), 13: (0, 14), 14: (0, 15), 15: (0, 16), 16: (0, 17), 17: (0, 18), 18: (0, 19), 19: (0, 20), 20: (0, 21), 21: (0, 22), 22: (0, 23), 23: (0, 24), 24: (0, 25), 25: (0, 26), 26: (0, 27), 27: (0, 28), 28: (0, 29), 29: (0, 30), 30: (0, 31), 31: (0, 32), 32: (0, 33), 33: (0, 34), 34: (0, 35), 35: (0, 36), 36: (0, 37), 37: (0, 38), 38: (0, 39), 39: (0, 40), 40: (0, 41), 41: (0, 42), 42: (0, 43), 43: (0, 44), 44: (0, 45), 45: (0, 46), 46: (0, 47), 47: (0, 48), 48: (0, 49), 49: (0, 50), 50: (0, 51), 51: (0, 52), 52: (0, 53), 53: (0, 54), 54: (0, 55), 55: (0, 56), 56: (0, 57), 57: (0, 58), 58: (0, 59), 59: (0, 60), 60: (0, 61), 61: (0, 62), 62: (0, 63), 63: (0, 64), 64: (0, 65), 65: (0, 66), 66: (0, 67), 67: (0, 68), 68: (0, 69), 69: (0, 70), 70: (0, 71), 71: (0, 72), 72: (0, 73), 73: (0, 74), 74: (0, 75), 75: (0, 76), 76: (0, 77), 77: (0, 78), 78: (0, 79), 79: (0, 80), 80: (0, 81), 81: (0, 82), 82: (0, 83), 83: (0, 84), 84: (0, 85), 85: (0, 86), 86: (0, 87), 87: (0, 88), 88: (0, 89), 89: (0, 90), 90: (0, 91), 91: (0, 92), 92: (0, 93), 93: (0, 94), 94: (0, 95), 95: (0, 96), 96: (0, 97), 97: (0, 98), 98: (0, 99), 99: (0, 100), 100: (0, 101), 101: (0, 102), 102: (0, 103), 103: (0, 104), 104: (0, 105), 105: (0, 106), 106: (0, 107), 107: (0, 108), 108: (0, 109), 109: (0, 110), 110: (0, 111), 111: (0, 112), 112: (0, 113), 113: (0, 114), 114: (0, 115), 115: (0, 116), 116: (0, 117), 117: (0, 118), 118: (0, 119), 119: (0, 120), 120: (0, 121), 121: (0, 122), 122: (0, 123), 123: (0, 124), 124: (0, 125), 125: (0, 126), 126: (0, 127), 127: (0, 128), 128: (0, 129), 129: (0, 130), 130: (0, 131), 131: (0, 132), 132: (0, 133), 133: (0, 134), 134: (0, 135), 135: (0, 136), 136: (0, 137), 137: (0, 138), 138: (0, 139), 139: (0, 140), 140: (0, 141), 141: (0, 142), 142: (0, 143), 143: (0, 144), 144: (0, 145), 145: (0, 146), 146: (0, 147), 147: (0, 148), 148: (0, 149), 149: (0, 150), 150: (0, 151), 151: (0, 152), 152: (0, 153), 153: (0, 154), 154: (0, 155), 155: (0, 156), 156: (0, 157), 157: (0, 158), 158: (0, 159), 159: (0, 160), 160: (0, 161), 161: (0, 162), 162: (0, 163), 163: (0, 164), 164: (0, 165), 165: (0, 166), 166: (0, 167), 167: (0, 168), 168: (0, 169), 169: (0, 170), 170: (0, 171), 171: (0, 172), 172: (0, 173), 173: (0, 174), 174: (0, 175), 175: (0, 176), 176: (0, 177), 177: (0, 178), 178: (0, 179), 179: (0, 180), 180: (0, 181), 181: (0, 182), 182: (0, 183), 183: (0, 184), 184: (0, 185), 185: (0, 186), 186: (0, 187), 187: (0, 188), 188: (0, 189), 189: (0, 190), 190: (0, 191), 191: (0, 192), 192: (0, 193), 193: (0, 194), 194: (0, 195), 195: (0, 196), 196: (0, 197), 197: (0, 198), 198: (0, 199), 199: (0, 200), 200: (0, 201), 201: (0, 202), 202: (0, 203), 203: (0, 204), 204: (0, 205), 205: (0, 206), 206: (0, 207), 207: (0, 208), 208: (0, 209), 209: (0, 210), 210: (0, 211), 211: (0, 212), 212: (0, 213), 213: (0, 214), 214: (0, 215), 215: (0, 216), 216: (0, 217), 217: (0, 218), 218: (0, 219), 219: (0, 220), 220: (0, 221), 221: (0, 222), 222: (0, 223), 223: (0, 224), 224: (0, 225), 225: (0, 226), 226: (0, 227), 227: (0, 228), 228: (0, 229), 229: (0, 230), 230: (0, 231), 231: (0, 232), 232: (0, 233), 233: (0, 234), 234: (0, 235), 235: (0, 236), 236: (0, 237), 237: (0, 238), 238: (0, 239), 239: (0, 240), 240: (0, 241), 241: (0, 242), 242: (0, 243), 243: (0, 244), 244: (0, 245), 245: (0, 246), 246: (0, 247), 247: (0, 248), 248: (0, 249), 249: (0, 250), 250: (0, 251), 251: (0, 252), 252: (0, 253), 253: (0, 254), 254: (0, 255), 255: (0, 256), 256: (0, 257), 257: (0, 258), 258: (0, 259), 259: (0, 260), 260: (0, 261), 261: (0, 262), 262: (0, 263), 263: (0, 264), 264: (0, 265), 265: (0, 266), 266: (0, 267), 267: (0, 268), 268: (0, 269), 269: (0, 270), 270: (0, 271), 271: (0, 272), 272: (0, 273), 273: (0, 274), 274: (0, 275), 275: (0, 276), 276: (0, 277), 277: (0, 278), 278: (0, 279), 279: (0, 280), 280: (0, 281), 281: (0, 282), 282: (0, 283), 283: (0, 284), 284: (0, 285), 285: (0, 286), 286: (0, 287), 287: (0, 288), 288: (0, 289), 289: (0, 290), 290: (0, 291), 291: (0, 292), 292: (0, 293), 293: (0, 294), 294: (0, 295), 295: (0, 296), 296: (0, 297), 297: (0, 298), 298: (0, 299), 299: (0, 300), 300: (0, 301), 301: (0, 302), 302: (0, 303), 303: (0, 304), 304: (0, 305), 305: (0, 306), 306: (0, 307), 307: (0, 308), 308: (0, 309), 309: (0, 310), 310: (0, 311), 311: (0, 312), 312: (0, 313), 313: (0, 314), 314: (0, 315), 315: (0, 316), 316: (0, 317), 317: (0, 318), 318: (0, 319), 319: (0, 320), 320: (0, 321), 321: (0, 322), 322: (0, 323), 323: (0, 324), 324: (0, 325), 325: (0, 326), 326: (0, 327), 327: (0, 328), 328: (0, 329), 329: (0, 330), 330: (0, 331), 331: (0, 332), 332: (0, 333), 333: (0, 334), 334: (0, 335), 335: (0, 336), 336: (0, 337), 337: (0, 338), 338: (0, 339), 339: (0, 340), 340: (0, 341), 341: (0, 342), 342: (0, 343), 343: (0, 344), 344: (0, 345), 345: (0, 346), 346: (0, 347), 347: (0, 348), 348: (0, 349), 349: (0, 350), 350: (0, 351), 351: (0, 352), 352: (0, 353), 353: (0, 354), 354: (0, 355), 355: (0, 356), 356: (0, 357), 357: (0, 358), 358: (0, 359), 359: (0, 360), 360: (0, 361), 361: (0, 362), 362: (0, 363), 363: (0, 364), 364: (0, 365), 365: (0, 366), 366: (0, 367), 367: (0, 368), 368: (0, 369), 369: (0, 370), 370: (0, 371), 371: (0, 372), 372: (0, 373), 373: (0, 374), 374: (0, 375), 375: (0, 376), 376: (0, 377), 377: (0, 378), 378: (0, 379), 379: (0, 380), 380: (0, 381), 381: (0, 382), 382: (0, 383), 383: (0, 384), 384: (0, 385), 385: (0, 386), 386: (0, 387), 387: (0, 388), 388: (0, 389), 389: (0, 390), 390: (0, 391), 391: (0, 392), 392: (0, 393), 393: (0, 394), 394: (0, 395), 395: (0, 396), 396: (0, 397), 397: (0, 398), 398: (0, 399), 399: (0, 400), 400: (0, 401), 401: (0, 402), 402: (0, 403), 403: (0, 404), 404: (0, 405), 405: (0, 406), 406: (0, 407), 407: (0, 408), 408: (0, 409), 409: (0, 410), 410: (0, 411), 411: (0, 412), 412: (0, 413), 413: (0, 414), 414: (0, 415), 415: (0, 416), 416: (0, 417), 417: (0, 418), 418: (0, 419), 419: (0, 420), 420: (0, 421), 421: (0, 422), 422: (0, 423), 423: (0, 424), 424: (0, 425), 425: (0, 426), 426: (0, 427), 427: (0, 428), 428: (0, 429), 429: (0, 430), 430: (0, 431), 431: (0, 432), 432: (0, 433), 433: (0, 434), 434: (0, 435), 435: (0, 436), 436: (0, 437), 437: (0, 438), 438: (0, 439), 439: (0, 440), 440: (0, 441), 441: (0, 442), 442: (0, 443), 443: (0, 444), 444: (0, 445), 445: (0, 446), 446: (0, 447), 447: (0, 448), 448: (0, 449), 449: (0, 450), 450: (0, 451), 451: (0, 452), 452: (0, 453), 453: (0, 454), 454: (0, 455), 455: (0, 456), 456: (0, 457), 457: (0, 458), 458: (0, 459), 459: (0, 460), 460: (0, 461), 461: (0, 462), 462: (0, 463), 463: (0, 464), 464: (0, 465), 465: (0, 466), 466: (0, 467), 467: (0, 468), 468: (0, 469), 469: (0, 470), 470: (0, 471), 471: (0, 472), 472: (0, 473), 473: (0, 474), 474: (0, 475), 475: (0, 476), 476: (0, 477), 477: (0, 478), 478: (0, 479), 479: (0, 480), 480: (0, 481), 481: (0, 482), 482: (0, 483), 483: (0, 484), 484: (0, 485), 485: (0, 486), 486: (0, 487), 487: (0, 488), 488: (0, 489), 489: (0, 490), 490: (0, 491), 491: (0, 492), 492: (0, 493), 493: (0, 494), 494: (0, 495), 495: (0, 496), 496: (0, 497), 497: (0, 498), 498: (0, 499), 499: (0, 500), 500: (0, 501), 501: (0, 502), 502: (0, 503), 503: (0, 504), 504: (0, 505), 505: (0, 506), 506: (0, 507), 507: (0, 508), 508: (0, 509), 509: (0, 510), 510: (0, 511), 511: (0, 512), 512: (0, 513), 513: (0, 514), 514: (0, 515), 515: (0, 516), 516: (0, 517), 517: (0, 518), 518: (0, 519), 519: (0, 520), 520: (0, 521), 521: (0, 522), 522: (0, 523), 523: (0, 524), 524: (0, 525), 525: (0, 526), 526: (0, 527), 527: (0, 528), 528: (0, 529), 529: (0, 530), 530: (0, 531), 531: (0, 532), 532: (0, 533), 533: (0, 534), 534: (0, 535), 535: (0, 536), 536: (0, 537), 537: (0, 538), 538: (0, 539), 539: (0, 540), 540: (0, 541), 541: (0, 542), 542: (0, 543), 543: (0, 544), 544: (0, 545), 545: (0, 546), 546: (0, 547), 547: (0, 548), 548: (0, 549), 549: (0, 550), 550: (0, 551), 551: (0, 552), 552: (0, 553), 553: (0, 554), 554: (0, 555), 555: (0, 556), 556: (0, 557), 557: (0, 558), 558: (0, 559), 559: (0, 560), 560: (0, 561), 561: (0, 562), 562: (0, 563), 563: (0, 564), 564: (0, 565), 565: (0, 566), 566: (0, 567), 567: (0, 568), 568: (0, 569), 569: (0, 570), 570: (0, 571), 571: (0, 572), 572: (0, 573), 573: (0, 574), 574: (0, 575), 575: (0, 576), 576: (0, 577), 577: (0, 578), 578: (0, 579), 579: (0, 580), 580: (0, 581), 581: (0, 582), 582: (0, 583), 583: (0, 584), 584: (0, 585), 585: (0, 586), 586: (0, 587), 587: (0, 588), 588: (0, 589), 589: (0, 590), 590: (0, 591), 591: (0, 592), 592: (0, 593), 593: (0, 594), 594: (0, 595), 595: (0, 596), 596: (0, 597), 597: (0, 598), 598: (0, 599), 599: (0, 600), 600: (0, 601), 601: (0, 602), 602: (0, 603), 603: (0, 604), 604: (0, 605), 605: (0, 606), 606: (0, 607), 607: (0, 608), 608: (0, 609), 609: (0, 610), 610: (0, 611), 611: (0, 612), 612: (0, 613), 613: (0, 614), 614: (0, 615), 615: (0, 616), 616: (0, 617), 617: (0, 618), 618: (0, 619), 619: (0, 620), 620: (0, 621), 621: (0, 622), 622: (0, 623), 623: (0, 624), 624: (0, 625), 625: (0, 626), 626: (0, 627), 627: (0, 628), 628: (0, 629), 629: (0, 630), 630: (0, 631), 631: (0, 632), 632: (0, 633), 633: (0, 634), 634: (0, 635), 635: (0, 636), 636: (0, 637), 637: (0, 638), 638: (0, 639), 639: (0, 640), 640: (0, 641), 641: (0, 642), 642: (0, 643), 643: (0, 644), 644: (0, 645), 645: (0, 646), 646: (0, 647), 647: (0, 648), 648: (0, 649), 649: (0, 650), 650: (0, 651), 651: (0, 652), 652: (0, 653), 653: (0, 654), 654: (0, 655), 655: (0, 656), 656: (0, 657), 657: (0, 658), 658: (0, 659), 659: (0, 660), 660: (0, 661), 661: (0, 662), 662: (0, 663), 663: (0, 664), 664: (0, 665), 665: (0, 666), 666: (0, 667), 667: (0, 668), 668: (0, 669), 669: (0, 670), 670: (0, 671), 671: (0, 672), 672: (0, 673), 673: (0, 674), 674: (0, 675), 675: (0, 676), 676: (0, 677), 677: (0, 678), 678: (0, 679), 679: (0, 680), 680: (0, 681), 681: (0, 682), 682: (0, 683), 683: (0, 684), 684: (0, 685), 685: (0, 686), 686: (0, 687), 687: (0, 688), 688: (0, 689), 689: (0, 690), 690: (0, 691), 691: (0, 692), 692: (0, 693), 693: (0, 694), 694: (0, 695), 695: (0, 696), 696: (0, 697), 697: (0, 698), 698: (0, 699), 699: (0, 700), 700: (0, 701), 701: (0, 702), 702: (0, 703), 703: (0, 704), 704: (0, 705), 705: (0, 706), 706: (0, 707), 707: (0, 708), 708: (0, 709), 709: (0, 710), 710: (0, 711), 711: (0, 712), 712: (0, 713), 713: (0, 714), 714: (0, 715), 715: (0, 716), 716: (0, 717), 717: (0, 718), 718: (0, 719), 719: (0, 720), 720: (0, 721), 721: (0, 722), 722: (0, 723), 723: (0, 724), 724: (0, 725), 725: (0, 726), 726: (0, 727), 727: (0, 728), 728: (0, 729), 729: (0, 730), 730: (0, 731), 731: (0, 732), 732: (0, 733), 733: (0, 734), 734: (0, 735), 735: (0, 736), 736: (0, 737), 737: (0, 738), 738: (0, 739), 739: (0, 740), 740: (0, 741), 741: (0, 742), 742: (0, 743), 743: (0, 744), 744: (0, 745), 745: (0, 746), 746: (0, 747), 747: (0, 748), 748: (0, 749), 749: (0, 750), 750: (0, 751), 751: (0, 752), 752: (0, 753), 753: (0, 754), 754: (0, 755), 755: (0, 756), 756: (0, 757), 757: (0, 758), 758: (0, 759), 759: (0, 760), 760: (0, 761), 761: (0, 762), 762: (0, 763), 763: (0, 764), 764: (0, 765), 765: (0, 766), 766: (0, 767), 767: (0, 768), 768: (0, 769), 769: (0, 770), 770: (0, 771), 771: (0, 772), 772: (0, 773), 773: (0, 774), 774: (0, 775), 775: (0, 776), 776: (0, 777), 777: (0, 778), 778: (0, 779), 779: (0, 780), 780: (0, 781), 781: (0, 782), 782: (0, 783), 783: (0, 784), 784: (0, 785), 785: (0, 786), 786: (0, 787), 787: (0, 788), 788: (0, 789), 789: (0, 790), 790: (0, 791), 791: (0, 792), 792: (0, 793), 793: (0, 794), 794: (0, 795), 795: (0, 796), 796: (0, 797), 797: (0, 798), 798: (0, 799), 799: (0, 800), 800: (0, 801), 801: (0, 802), 802: (0, 803), 803: (0, 804), 804: (0, 805), 805: (0, 806), 806: (0, 807), 807: (0, 808), 808: (0, 809), 809: (0, 810), 810: (0, 811), 811: (0, 812), 812: (0, 813), 813: (0, 814), 814: (0, 815), 815: (0, 816), 816: (0, 817), 817: (0, 818), 818: (0, 819), 819: (0, 820), 820: (0, 821), 821: (0, 822), 822: (0, 823), 823: (0, 824), 824: (0, 825), 825: (0, 826), 826: (0, 827), 827: (0, 828), 828: (0, 829), 829: (0, 830), 830: (0, 831), 831: (0, 832), 832: (0, 833), 833: (0, 834), 834: (0, 835), 835: (0, 836), 836: (0, 837), 837: (0, 838), 838: (0, 839), 839: (0, 840), 840: (0, 841), 841: (0, 842), 842: (0, 843), 843: (0, 844), 844: (0, 845), 845: (0, 846), 846: (0, 847), 847: (0, 848), 848: (0, 849), 849: (0, 850), 850: (0, 851), 851: (0, 852), 852: (0, 853), 853: (0, 854), 854: (0, 855), 855: (0, 856), 856: (0, 857), 857: (0, 858), 858: (0, 859), 859: (0, 860), 860: (0, 861), 861: (0, 862), 862: (0, 863), 863: (0, 864), 864: (0, 865), 865: (0, 866), 866: (0, 867), 867: (0, 868), 868: (0, 869), 869: (0, 870), 870: (0, 871), 871: (0, 872), 872: (0, 873), 873: (0, 874), 874: (0, 875), 875: (0, 876), 876: (0, 877), 877: (0, 878), 878: (0, 879), 879: (0, 880), 880: (0, 881), 881: (0, 882), 882: (0, 883), 883: (0, 884), 884: (0, 885), 885: (0, 886), 886: (0, 887), 887: (0, 888), 888: (0, 889), 889: (0, 890), 890: (0, 891), 891: (0, 892), 892: (0, 893), 893: (0, 894)}
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/Trials.pkl
** SKIPPING EXTRACTION, since was able to load snippets, for: 
(animal, DATE, which_level, ANALY_VER, session)
Pancho 221107 trial rulesw 0
Got these LIST_VAR and LIST_VARS_CONJUNCTION:
['epoch', 'epoch', 'character', 'seqc_0_loc_shape', 'seqc_0_loc', 'seqc_1_loc_shape']
[['epochset'], ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset', 'seqc_0_loc_shape']]
Got these LIST_VAR and LIST_VARS_CONJUNCTION:
['epoch', 'epoch', 'character', 'seqc_0_loc_shape', 'seqc_0_loc', 'seqc_1_loc_shape']
[['epochset'], ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset'], ['epoch', 'epochset', 'seqc_0_loc_shape']]
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*221107*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621
session:  0
1
Beh Sessions that exist on this date:  {221107: [(1, 'dirfullvar1b')]}
taking this beh session: 1
------------------------------
Loading this neural session: 0
Loading these beh expts: ['dirfullvar1b']
Loading these beh sessions: [1]
Using this beh_trial_map_list: [(1, 0)]
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*221107*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621
{'filename_components_hyphened': ['Pancho', '221107', '152621'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/221107'], 'basedirs_filenames': ['221107', 'Pancho-221107-152621'], 'filename_final_ext': 'Pancho-221107-152621', 'filename_final_noext': 'Pancho-221107-152621'}
FOund this path for spikes:  /mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621/spikes_tdt_quick-4
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621/Pancho-221107-152621
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/221107/Pancho-221107-152621/spikes_tdt_quick-4
final_dir_name  --  Pancho-221107-152621
time  --  152621
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/221107.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
-  1 69.56427764892578
o  2 81.50224075317384
o  3 74.15705718994141
-  4 68.11968154907227
o  5 71.87969436645508
-  6 64.17504577636718
o  7 109.38502349853516
-  8 68.3540252685547
o  9 299.0131561279297
o  10 89.98177032470703
o  11 147.43990631103517
o  12 84.5823356628418
o  13 182.5012008666992
-  14 58.75174789428711
o  15 166.5312942504883
o  16 80.59950027465821
o  17 80.29354324340821
o  18 94.80696716308594
o  19 100.75848770141602
-  20 48.037646484375
o  21 136.8928421020508
o  22 113.87927932739258
-  23 41.888448333740236
o  24 74.14848327636719
-  25 61.70714263916016
o  26 307.00298461914065
o  27 101.2887191772461
o  28 71.56111526489258
o  29 227.6403350830078
o  30 91.98388214111328
o  31 145.65886840820312
o  32 78.95593261718751
o  33 76.99478912353516
o  34 105.74909286499025
-  35 43.497721099853514
o  36 149.92131652832032
-  37 62.71798324584961
o  38 90.63256988525391
o  39 83.37065124511719
o  40 177.436930847168
o  41 82.94834747314454
o  42 138.34842529296876
o  43 85.96428680419922
o  44 197.84974212646486
o  45 148.58173065185548
-  46 48.67895698547363
o  47 156.59958190917968
-  48 46.04757919311523
o  49 117.07863769531251
o  50 88.54730758666992
o  51 116.82428131103516
o  52 95.63519287109375
o  53 675.9277282714844
o  54 72.99294738769531
o  55 162.48952636718752
-  56 58.90813674926758
o  57 166.53655700683595
o  58 83.080419921875
o  59 125.05319442749024
o  60 85.99052734375
o  61 93.7140884399414
o  62 79.11741485595704
o  63 235.45345001220704
-  64 66.73812789916992
o  65 106.70694580078126
o  66 77.9548812866211
o  67 257.13367614746096
o  68 122.69444122314454
o  69 71.88569030761718
-  70 54.35144271850586
o  71 71.24311294555665
o  72 82.1689956665039
o  73 71.50927734375
o  74 156.6845474243164
-  75 68.61415328979493
o  76 78.70907440185547
o  77 70.86668701171875
o  78 113.38264465332041
-  79 62.2936954498291
o  80 83.57393875122071
-  81 66.5847885131836
-  82 61.4283805847168
-  83 65.63325576782228
-  84 56.648563385009766
o  85 71.28802185058593
o  86 90.78714141845703
-  87 49.10846633911133
o  88 85.47634582519532
-  89 55.99948234558106
o  90 79.49051818847657
-  91 65.63689270019532
o  92 75.07665328979492
-  93 68.01433944702148
-  94 65.5036491394043
-  95 63.466009521484374
-  96 66.85879211425782
o  97 174.44409942626953
o  98 73.30914154052735
o  99 94.658406829834
o  100 107.31455078125
o  101 97.28027801513672
o  102 120.30650634765625
-  103 56.17182769775391
o  104 103.95919342041016
o  105 103.26299743652343
-  106 57.17966918945313
-  107 45.79605140686035
o  108 70.49427032470703
-  109 49.1723445892334
-  110 57.46366500854492
-  111 66.76972122192383
-  112 59.62185173034668
o  113 88.40170516967774
o  114 175.02818298339844
-  115 62.89888458251954
o  116 130.6942932128906
-  117 51.68969612121582
o  118 89.4641326904297
o  119 125.81076507568359
-  120 50.38909225463867
o  121 143.7449920654297
o  122 72.77058258056641
o  123 102.34951171875001
-  124 56.520883560180664
-  125 68.09090652465821
o  126 74.73261108398438
o  127 71.05633926391603
-  128 48.50476837158203
o  129 75.22081604003907
o  130 388.8092346191407
o  131 92.35172271728516
o  132 199.2880615234375
-  133 67.46532821655273
o  134 112.2642807006836
-  135 66.96928253173829
o  136 103.75241928100587
-  137 63.02683334350586
o  138 166.23226928710938
o  139 86.86785583496095
o  140 178.6272689819336
o  141 150.8445571899414
o  142 492.9408813476563
o  143 136.20085906982425
o  144 140.17784423828127
-  145 49.96257553100586
-  146 65.0479248046875
-  147 45.632878112792966
o  148 83.22244110107422
-  149 57.28435707092285
o  150 254.59427642822266
-  151 46.194169235229495
o  152 79.62532196044923
-  153 69.1133903503418
o  154 105.29587936401369
-  155 52.604306030273435
o  156 75.899373626709
-  157 56.37504539489746
o  158 90.85408630371094
-  159 67.04087448120119
o  160 94.89972457885743
o  161 94.7409538269043
o  162 85.57436141967773
o  163 75.37461395263672
o  164 71.64049606323243
o  165 168.68158569335938
-  166 67.63265914916992
o  167 115.96251831054688
-  168 63.166392135620114
-  169 66.87057495117188
o  170 93.00088043212892
o  171 158.14834289550782
-  172 53.95572776794434
o  173 262.93164062500006
-  174 64.05095977783203
-  175 64.67571182250977
-  176 58.09596176147461
-  177 55.70267105102539
o  178 253.38496398925787
o  179 330.7043212890625
-  180 64.15622406005859
o  181 94.09546585083008
-  182 54.42940483093262
-  183 58.143890380859375
o  184 83.12727279663086
-  185 26.21141414642334
-  186 69.3423828125
o  187 84.32209396362305
-  188 58.68371734619141
o  189 83.54303131103515
-  190 62.147148895263676
-  191 64.09633560180664
o  192 77.70203399658203
o  193 272.51971435546875
o  194 99.36101531982422
o  195 158.87229614257814
-  196 56.255027770996094
o  197 172.1740493774414
o  198 112.89850234985353
-  199 57.92655029296875
o  200 75.17970504760743
o  201 84.69873123168946
o  202 85.90690307617187
o  203 131.36550903320315
-  204 69.53072586059571
o  205 72.04321517944337
o  206 82.9554931640625
-  207 65.0984733581543
-  208 61.529718017578126
-  209 47.44778938293457
o  210 78.24779663085938
-  211 66.62992248535156
-  212 57.422613525390624
o  213 89.4068000793457
-  214 56.61251602172852
o  215 78.08397521972657
-  216 65.01408233642579
o  217 87.31202850341798
o  218 97.47405471801758
o  219 78.14814529418946
-  220 65.29342041015626
-  221 61.36292572021485
o  222 84.73948364257812
o  223 73.62271347045899
o  224 121.82287063598633
o  225 94.04808120727539
o  226 71.50922241210938
o  227 129.94450836181642
-  228 59.68842353820801
o  229 80.00333557128907
-  230 64.84689865112304
-  231 66.14053726196289
-  232 34.23581466674805
o  233 86.8570343017578
-  234 67.82227325439453
o  235 113.66969146728516
-  236 64.20184478759765
o  237 89.74697341918946
-  238 60.747144317626955
-  239 61.26155242919922
-  240 66.59852294921875
-  241 69.94957275390625
-  242 65.20124053955078
o  243 83.94603881835938
-  244 69.6571029663086
o  245 79.4787498474121
-  246 54.57755966186524
o  247 78.00775756835938
o  248 82.28647155761719
-  249 66.36073684692383
-  250 48.39621124267578
o  251 81.73920135498047
o  252 88.57133483886719
o  253 75.04097595214844
o  254 77.58231201171876
o  255 71.36574783325196
o  256 104.86773529052735
o  257 282.6453338623047
o  258 134.91344604492187
o  259 103.66339492797853
o  260 153.4899688720703
o  261 102.0167938232422
o  262 128.08163146972657
o  263 118.57413787841799
o  264 111.64312438964843
o  265 114.16120529174805
o  266 97.0021842956543
o  267 140.22715911865234
-  268 60.24104995727539
o  269 115.17227935791016
o  270 108.64215545654297
o  271 88.31507949829103
o  272 511.42510681152345
o  273 106.07266464233399
o  274 85.97002410888672
o  275 72.80101776123047
o  276 84.84232711791992
o  277 160.9328155517578
o  278 112.43159484863281
o  279 113.62675476074219
o  280 103.29455108642578
o  281 101.87090759277345
o  282 100.88661880493166
o  283 71.80266342163087
o  284 134.81947479248046
o  285 81.671435546875
o  286 106.04388885498047
-  287 66.14685134887695
o  288 78.34494476318359
-  289 59.002982711791994
o  290 79.55920486450195
o  291 70.53397979736329
-  292 40.506640625
-  293 55.240075302124026
o  294 77.19015350341797
-  295 61.91262283325196
-  296 66.88828125
-  297 57.52100944519043
o  298 100.47144470214845
o  299 87.4599838256836
o  300 154.16922302246095
o  301 77.17546844482422
o  302 96.25489425659183
-  303 60.07499732971191
o  304 87.46225509643556
-  305 50.7933853149414
o  306 70.71959838867187
o  307 75.05050048828124
-  308 58.22414741516114
-  309 66.44418869018556
o  310 74.09783782958985
-  311 58.559487915039064
o  312 90.99221267700196
-  313 53.99802398681641
-  314 55.74238815307617
-  315 55.950537109375
o  316 81.50906448364258
-  317 50.65001602172852
o  318 70.90742492675781
-  319 47.17928466796875
o  320 77.58518142700196
-  321 59.28757743835449
-  322 44.00800552368164
o  323 70.01873931884766
-  324 47.18910446166992
o  325 72.04536895751953
-  326 62.757025527954106
-  327 66.12927398681641
o  328 77.58480758666992
o  329 75.83914260864258
-  330 68.33816375732422
o  331 76.8374412536621
-  332 52.869597625732425
o  333 71.93681564331055
o  334 152.50841369628907
-  335 41.49773597717285
-  336 58.49101867675781
-  337 45.466651916503906
-  338 53.83418350219726
-  339 45.50362319946289
-  340 39.60502624511719
o  341 74.33835067749024
o  342 73.39143600463868
o  343 77.73509140014649
o  344 70.14033966064453
-  345 59.140113067626956
o  346 73.26717376708984
-  347 55.075102996826175
o  348 82.98857192993164
o  349 131.34803314208986
-  350 66.2791732788086
o  351 93.9428596496582
o  352 104.15456771850586
o  353 108.40376968383791
-  354 53.495201873779294
-  355 62.532402801513676
-  356 61.438787841796874
-  357 39.59751167297363
-  358 64.09367065429687
-  359 50.623209381103514
o  360 71.76509017944336
-  361 62.38629570007324
-  362 65.2702247619629
-  363 67.96203689575195
-  364 67.14391326904297
-  365 41.89004249572754
o  366 90.42966537475587
-  367 61.639862060546875
o  368 201.48331298828126
o  369 77.34384841918946
-  370 46.23814582824707
o  371 83.87848892211915
-  372 53.9670051574707
o  373 71.56175231933594
o  374 74.31787948608398
o  375 71.3803581237793
o  376 94.19599685668946
-  377 54.55766830444336
o  378 73.6924430847168
o  379 94.25499267578127
-  380 49.441597366333006
-  381 54.64565887451172
-  382 54.48998146057129
-  383 54.93829002380372
o  384 74.27401275634767
o  385 301.8705749511719
o  386 78.70696487426758
o  387 125.29112243652345
o  388 102.93749542236328
o  389 170.05655822753909
o  390 129.5114471435547
-  391 42.68714141845703
-  392 69.58520431518555
o  393 126.17913360595703
o  394 79.5630111694336
o  395 92.99101638793945
o  396 96.95766983032227
o  397 80.73338088989259
-  398 68.48885498046876
o  399 81.85680770874023
o  400 131.15652160644532
o  401 110.77040405273438
o  402 127.56638565063477
o  403 108.15475158691406
o  404 123.53155822753907
o  405 103.48341369628906
o  406 108.81312103271485
o  407 132.17883605957033
o  408 113.70934448242188
o  409 79.5315071105957
o  410 175.7653579711914
o  411 229.33462371826172
-  412 64.53724975585938
o  413 95.4756362915039
o  414 139.3131561279297
o  415 126.94188842773438
o  416 142.4588394165039
o  417 88.772176361084
o  418 80.88365478515625
o  419 71.89403381347657
-  420 55.75474967956543
o  421 80.55472030639649
o  422 91.44283294677734
o  423 109.54998779296876
-  424 61.53781089782715
o  425 96.7106414794922
-  426 53.3388111114502
-  427 66.10412902832032
-  428 26.24584140777588
o  429 94.29757690429688
o  430 84.24338989257814
-  431 53.7937557220459
-  432 48.241156387329106
o  433 126.24564361572267
o  434 102.02798309326172
o  435 150.60782318115236
o  436 163.5270217895508
o  437 86.9962257385254
o  438 129.01896057128909
o  439 97.19865875244142
-  440 59.33177108764649
o  441 91.25004272460937
-  442 50.65458450317383
o  443 137.09304504394532
-  444 31.558024406433105
o  445 95.6382064819336
-  446 34.24122772216797
o  447 92.66251220703126
-  448 28.647762680053713
o  449 123.16914672851563
o  450 74.93341522216797
-  451 66.03816528320313
o  452 80.7138771057129
o  453 99.15674896240235
o  454 82.49758987426758
o  455 87.2372932434082
-  456 48.34036483764648
o  457 214.1776824951172
o  458 130.9373809814453
o  459 122.15629959106445
o  460 127.2711570739746
o  461 107.87880096435548
o  462 72.11548461914063
o  463 80.51787719726562
o  464 129.13386535644534
o  465 121.28791809082034
-  466 57.73492965698242
o  467 90.09525299072266
o  468 121.50847396850587
o  469 142.20945434570314
o  470 75.96639556884766
o  471 85.280078125
o  472 91.86913146972658
o  473 181.66998901367188
o  474 109.57551727294923
o  475 108.77061157226562
-  476 53.90928840637207
o  477 107.91233215332032
o  478 84.09552230834962
-  479 66.23923034667969
o  480 86.66543273925781
o  481 76.51796264648438
-  482 36.77154693603516
o  483 93.60541763305665
o  484 123.89273071289067
o  485 184.47123107910159
o  486 89.22796020507812
o  487 89.7915023803711
o  488 91.8265480041504
o  489 79.0528953552246
o  490 73.36190643310547
o  491 75.98698348999024
o  492 73.66757507324219
o  493 116.17911300659179
o  494 95.15696563720704
o  495 85.9266586303711
-  496 69.45773315429688
o  497 122.75893783569336
o  498 77.04817504882813
-  499 61.58419990539551
o  500 178.9237274169922
o  501 129.42261657714846
o  502 122.44577407836914
o  503 72.92247924804687
o  504 71.2812614440918
o  505 173.48302001953127
-  506 66.49289093017578
-  507 32.403160858154294
o  508 119.82119216918946
o  509 78.54566192626953
o  510 85.20180282592774
-  511 37.41677055358887
o  512 74.89456634521486
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/221107/Pancho-221107-152621/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
... Generated these...
self.BehTrialMapList [(1, 0)]
self.BehTrialMapListGood {0: (0, 1), 1: (0, 2), 2: (0, 3), 3: (0, 4), 4: (0, 5), 5: (0, 6), 6: (0, 7), 7: (0, 8), 8: (0, 9), 9: (0, 10), 10: (0, 11), 11: (0, 12), 12: (0, 13), 13: (0, 14), 14: (0, 15), 15: (0, 16), 16: (0, 17), 17: (0, 18), 18: (0, 19), 19: (0, 20), 20: (0, 21), 21: (0, 22), 22: (0, 23), 23: (0, 24), 24: (0, 25), 25: (0, 26), 26: (0, 27), 27: (0, 28), 28: (0, 29), 29: (0, 30), 30: (0, 31), 31: (0, 32), 32: (0, 33), 33: (0, 34), 34: (0, 35), 35: (0, 36), 36: (0, 37), 37: (0, 38), 38: (0, 39), 39: (0, 40), 40: (0, 41), 41: (0, 42), 42: (0, 43), 43: (0, 44), 44: (0, 45), 45: (0, 46), 46: (0, 47), 47: (0, 48), 48: (0, 49), 49: (0, 50), 50: (0, 51), 51: (0, 52), 52: (0, 53), 53: (0, 54), 54: (0, 55), 55: (0, 56), 56: (0, 57), 57: (0, 58), 58: (0, 59), 59: (0, 60), 60: (0, 61), 61: (0, 62), 62: (0, 63), 63: (0, 64), 64: (0, 65), 65: (0, 66), 66: (0, 67), 67: (0, 68), 68: (0, 69), 69: (0, 70), 70: (0, 71), 71: (0, 72), 72: (0, 73), 73: (0, 74), 74: (0, 75), 75: (0, 76), 76: (0, 77), 77: (0, 78), 78: (0, 79), 79: (0, 80), 80: (0, 81), 81: (0, 82), 82: (0, 83), 83: (0, 84), 84: (0, 85), 85: (0, 86), 86: (0, 87), 87: (0, 88), 88: (0, 89), 89: (0, 90), 90: (0, 91), 91: (0, 92), 92: (0, 93), 93: (0, 94), 94: (0, 95), 95: (0, 96), 96: (0, 97), 97: (0, 98), 98: (0, 99), 99: (0, 100), 100: (0, 101), 101: (0, 102), 102: (0, 103), 103: (0, 104), 104: (0, 105), 105: (0, 106), 106: (0, 107), 107: (0, 108), 108: (0, 109), 109: (0, 110), 110: (0, 111), 111: (0, 112), 112: (0, 113), 113: (0, 114), 114: (0, 115), 115: (0, 116), 116: (0, 117), 117: (0, 118), 118: (0, 119), 119: (0, 120), 120: (0, 121), 121: (0, 122), 122: (0, 123), 123: (0, 124), 124: (0, 125), 125: (0, 126), 126: (0, 127), 127: (0, 128), 128: (0, 129), 129: (0, 130), 130: (0, 131), 131: (0, 132), 132: (0, 133), 133: (0, 134), 134: (0, 135), 135: (0, 136), 136: (0, 137), 137: (0, 138), 138: (0, 139), 139: (0, 140), 140: (0, 141), 141: (0, 142), 142: (0, 143), 143: (0, 144), 144: (0, 145), 145: (0, 146), 146: (0, 147), 147: (0, 148), 148: (0, 149), 149: (0, 150), 150: (0, 151), 151: (0, 152), 152: (0, 153), 153: (0, 154), 154: (0, 155), 155: (0, 156), 156: (0, 157), 157: (0, 158), 158: (0, 159), 159: (0, 160), 160: (0, 161), 161: (0, 162), 162: (0, 163), 163: (0, 164), 164: (0, 165), 165: (0, 166), 166: (0, 167), 167: (0, 168), 168: (0, 169), 169: (0, 170), 170: (0, 171), 171: (0, 172), 172: (0, 173), 173: (0, 174), 174: (0, 175), 175: (0, 176), 176: (0, 177), 177: (0, 178), 178: (0, 179), 179: (0, 180), 180: (0, 181), 181: (0, 182), 182: (0, 183), 183: (0, 184), 184: (0, 185), 185: (0, 186), 186: (0, 187), 187: (0, 188), 188: (0, 189), 189: (0, 190), 190: (0, 191), 191: (0, 192), 192: (0, 193), 193: (0, 194), 194: (0, 195), 195: (0, 196), 196: (0, 197), 197: (0, 198), 198: (0, 199), 199: (0, 200), 200: (0, 201), 201: (0, 202), 202: (0, 203), 203: (0, 204), 204: (0, 205), 205: (0, 206), 206: (0, 207), 207: (0, 208), 208: (0, 209), 209: (0, 210), 210: (0, 211), 211: (0, 212), 212: (0, 213), 213: (0, 214), 214: (0, 215), 215: (0, 216), 216: (0, 217), 217: (0, 218), 218: (0, 219), 219: (0, 220), 220: (0, 221), 221: (0, 222), 222: (0, 223), 223: (0, 224), 224: (0, 225), 225: (0, 226), 226: (0, 227), 227: (0, 228), 228: (0, 229), 229: (0, 230), 230: (0, 231), 231: (0, 232), 232: (0, 233), 233: (0, 234), 234: (0, 235), 235: (0, 236), 236: (0, 237), 237: (0, 238), 238: (0, 239), 239: (0, 240), 240: (0, 241), 241: (0, 242), 242: (0, 243), 243: (0, 244), 244: (0, 245), 245: (0, 246), 246: (0, 247), 247: (0, 248), 248: (0, 249), 249: (0, 250), 250: (0, 251), 251: (0, 252), 252: (0, 253), 253: (0, 254), 254: (0, 255), 255: (0, 256), 256: (0, 257), 257: (0, 258), 258: (0, 259), 259: (0, 260), 260: (0, 261), 261: (0, 262), 262: (0, 263), 263: (0, 264), 264: (0, 265), 265: (0, 266), 266: (0, 267), 267: (0, 268), 268: (0, 269), 269: (0, 270), 270: (0, 271), 271: (0, 272), 272: (0, 273), 273: (0, 274), 274: (0, 275), 275: (0, 276), 276: (0, 277), 277: (0, 278), 278: (0, 279), 279: (0, 280), 280: (0, 281), 281: (0, 282), 282: (0, 283), 283: (0, 284), 284: (0, 285), 285: (0, 286), 286: (0, 287), 287: (0, 288), 288: (0, 289), 289: (0, 290), 290: (0, 291), 291: (0, 292), 292: (0, 293), 293: (0, 294), 294: (0, 295), 295: (0, 296), 296: (0, 297), 297: (0, 298), 298: (0, 299), 299: (0, 300), 300: (0, 301), 301: (0, 302), 302: (0, 303), 303: (0, 304), 304: (0, 305), 305: (0, 306), 306: (0, 307), 307: (0, 308), 308: (0, 309), 309: (0, 310), 310: (0, 311), 311: (0, 312), 312: (0, 313), 313: (0, 314), 314: (0, 315), 315: (0, 316), 316: (0, 317), 317: (0, 318), 318: (0, 319), 319: (0, 320), 320: (0, 321), 321: (0, 322), 322: (0, 323), 323: (0, 324), 324: (0, 325), 325: (0, 326), 326: (0, 327), 327: (0, 328), 328: (0, 329), 329: (0, 330), 330: (0, 331), 331: (0, 332), 332: (0, 333), 333: (0, 334), 334: (0, 335), 335: (0, 336), 336: (0, 337), 337: (0, 338), 338: (0, 339), 339: (0, 340), 340: (0, 341), 341: (0, 342), 342: (0, 343), 343: (0, 344), 344: (0, 345), 345: (0, 346), 346: (0, 347), 347: (0, 348), 348: (0, 349), 349: (0, 350), 350: (0, 351), 351: (0, 352), 352: (0, 353), 353: (0, 354), 354: (0, 355), 355: (0, 356), 356: (0, 357), 357: (0, 358), 358: (0, 359), 359: (0, 360), 360: (0, 361), 361: (0, 362), 362: (0, 363), 363: (0, 364), 364: (0, 365), 365: (0, 366), 366: (0, 367), 367: (0, 368), 368: (0, 369), 369: (0, 370), 370: (0, 371), 371: (0, 372), 372: (0, 373), 373: (0, 374), 374: (0, 375), 375: (0, 376), 376: (0, 377), 377: (0, 378), 378: (0, 379), 379: (0, 380), 380: (0, 381), 381: (0, 382), 382: (0, 383), 383: (0, 384), 384: (0, 385), 385: (0, 386), 386: (0, 387), 387: (0, 388), 388: (0, 389), 389: (0, 390), 390: (0, 391), 391: (0, 392), 392: (0, 393), 393: (0, 394), 394: (0, 395), 395: (0, 396), 396: (0, 397), 397: (0, 398), 398: (0, 399), 399: (0, 400), 400: (0, 401), 401: (0, 402), 402: (0, 403), 403: (0, 404), 404: (0, 405), 405: (0, 406), 406: (0, 407), 407: (0, 408), 408: (0, 409), 409: (0, 410), 410: (0, 411), 411: (0, 412), 412: (0, 413), 413: (0, 414), 414: (0, 415), 415: (0, 416), 416: (0, 417), 417: (0, 418), 418: (0, 419), 419: (0, 420), 420: (0, 421), 421: (0, 422), 422: (0, 423), 423: (0, 424), 424: (0, 425), 425: (0, 426), 426: (0, 427), 427: (0, 428), 428: (0, 429), 429: (0, 430), 430: (0, 431), 431: (0, 432), 432: (0, 433), 433: (0, 434), 434: (0, 435), 435: (0, 436), 436: (0, 437), 437: (0, 438), 438: (0, 439), 439: (0, 440), 440: (0, 441), 441: (0, 442), 442: (0, 443), 443: (0, 444), 444: (0, 445), 445: (0, 446), 446: (0, 447), 447: (0, 448), 448: (0, 449), 449: (0, 450), 450: (0, 451), 451: (0, 452), 452: (0, 453), 453: (0, 454), 454: (0, 455), 455: (0, 456), 456: (0, 457), 457: (0, 458), 458: (0, 459), 459: (0, 460), 460: (0, 461), 461: (0, 462), 462: (0, 463), 463: (0, 464), 464: (0, 465), 465: (0, 466), 466: (0, 467), 467: (0, 468), 468: (0, 469), 469: (0, 470), 470: (0, 471), 471: (0, 472), 472: (0, 473), 473: (0, 474), 474: (0, 475), 475: (0, 476), 476: (0, 477), 477: (0, 478), 478: (0, 479), 479: (0, 480), 480: (0, 481), 481: (0, 482), 482: (0, 483), 483: (0, 484), 484: (0, 485), 485: (0, 486), 486: (0, 487), 487: (0, 488), 488: (0, 489), 489: (0, 490), 490: (0, 491), 491: (0, 492), 492: (0, 493), 493: (0, 494), 494: (0, 495), 495: (0, 496), 496: (0, 497), 497: (0, 498), 498: (0, 499), 499: (0, 500), 500: (0, 501), 501: (0, 502), 502: (0, 503), 503: (0, 504), 504: (0, 505), 505: (0, 506), 506: (0, 507), 507: (0, 508), 508: (0, 509), 509: (0, 510), 510: (0, 511), 511: (0, 512), 512: (0, 513), 513: (0, 514), 514: (0, 515), 515: (0, 516), 516: (0, 517), 517: (0, 518), 518: (0, 519), 519: (0, 520), 520: (0, 521), 521: (0, 522), 522: (0, 523), 523: (0, 524), 524: (0, 525), 525: (0, 526), 526: (0, 527), 527: (0, 528), 528: (0, 529), 529: (0, 530), 530: (0, 531), 531: (0, 532), 532: (0, 533), 533: (0, 534), 534: (0, 535), 535: (0, 536), 536: (0, 537), 537: (0, 538), 538: (0, 539), 539: (0, 540), 540: (0, 541), 541: (0, 542), 542: (0, 543), 543: (0, 544), 544: (0, 545), 545: (0, 546), 546: (0, 547), 547: (0, 548), 548: (0, 549), 549: (0, 550), 550: (0, 551), 551: (0, 552), 552: (0, 553), 553: (0, 554), 554: (0, 555), 555: (0, 556), 556: (0, 557), 557: (0, 558), 558: (0, 559), 559: (0, 560), 560: (0, 561), 561: (0, 562), 562: (0, 563), 563: (0, 564), 564: (0, 565), 565: (0, 566), 566: (0, 567), 567: (0, 568), 568: (0, 569), 569: (0, 570), 570: (0, 571), 571: (0, 572), 572: (0, 573), 573: (0, 574), 574: (0, 575), 575: (0, 576), 576: (0, 577), 577: (0, 578), 578: (0, 579), 579: (0, 580), 580: (0, 581), 581: (0, 582), 582: (0, 583), 583: (0, 584), 584: (0, 585), 585: (0, 586), 586: (0, 587), 587: (0, 588), 588: (0, 589), 589: (0, 590), 590: (0, 591), 591: (0, 592), 592: (0, 593), 593: (0, 594), 594: (0, 595), 595: (0, 596), 596: (0, 597), 597: (0, 598), 598: (0, 599), 599: (0, 600), 600: (0, 601), 601: (0, 602), 602: (0, 603), 603: (0, 604), 604: (0, 605), 605: (0, 606), 606: (0, 607), 607: (0, 608), 608: (0, 609), 609: (0, 610), 610: (0, 611), 611: (0, 612), 612: (0, 613), 613: (0, 614), 614: (0, 615), 615: (0, 616), 616: (0, 617), 617: (0, 618), 618: (0, 619), 619: (0, 620), 620: (0, 621), 621: (0, 622), 622: (0, 623), 623: (0, 624), 624: (0, 625), 625: (0, 626), 626: (0, 627), 627: (0, 628), 628: (0, 629), 629: (0, 630), 630: (0, 631), 631: (0, 632), 632: (0, 633), 633: (0, 634), 634: (0, 635), 635: (0, 636), 636: (0, 637), 637: (0, 638), 638: (0, 639), 639: (0, 640), 640: (0, 641), 641: (0, 642), 642: (0, 643), 643: (0, 644), 644: (0, 645), 645: (0, 646), 646: (0, 647), 647: (0, 648), 648: (0, 649), 649: (0, 650), 650: (0, 651), 651: (0, 652), 652: (0, 653), 653: (0, 654), 654: (0, 655), 655: (0, 656), 656: (0, 657), 657: (0, 658), 658: (0, 659), 659: (0, 660), 660: (0, 661), 661: (0, 662), 662: (0, 663), 663: (0, 664), 664: (0, 665), 665: (0, 666), 666: (0, 667), 667: (0, 668), 668: (0, 669), 669: (0, 670), 670: (0, 671), 671: (0, 672), 672: (0, 673), 673: (0, 674), 674: (0, 675), 675: (0, 676), 676: (0, 677), 677: (0, 678), 678: (0, 679), 679: (0, 680), 680: (0, 681), 681: (0, 682), 682: (0, 683), 683: (0, 684), 684: (0, 685), 685: (0, 686), 686: (0, 687), 687: (0, 688), 688: (0, 689), 689: (0, 690), 690: (0, 691), 691: (0, 692), 692: (0, 693), 693: (0, 694), 694: (0, 695), 695: (0, 696), 696: (0, 697), 697: (0, 698), 698: (0, 699), 699: (0, 700), 700: (0, 701), 701: (0, 702), 702: (0, 703), 703: (0, 704), 704: (0, 705), 705: (0, 706), 706: (0, 707), 707: (0, 708), 708: (0, 709), 709: (0, 710), 710: (0, 711), 711: (0, 712), 712: (0, 713), 713: (0, 714), 714: (0, 715), 715: (0, 716), 716: (0, 717), 717: (0, 718), 718: (0, 719), 719: (0, 720), 720: (0, 721), 721: (0, 722), 722: (0, 723), 723: (0, 724), 724: (0, 725), 725: (0, 726), 726: (0, 727), 727: (0, 728), 728: (0, 729), 729: (0, 730), 730: (0, 731), 731: (0, 732), 732: (0, 733), 733: (0, 734), 734: (0, 735), 735: (0, 736), 736: (0, 737), 737: (0, 738), 738: (0, 739), 739: (0, 740), 740: (0, 741), 741: (0, 742), 742: (0, 743), 743: (0, 744), 744: (0, 745), 745: (0, 746), 746: (0, 747), 747: (0, 748), 748: (0, 749), 749: (0, 750), 750: (0, 751), 751: (0, 752), 752: (0, 753), 753: (0, 754), 754: (0, 755), 755: (0, 756), 756: (0, 757), 757: (0, 758), 758: (0, 759), 759: (0, 760), 760: (0, 761), 761: (0, 762), 762: (0, 763), 763: (0, 764), 764: (0, 765), 765: (0, 766), 766: (0, 767), 767: (0, 768), 768: (0, 769), 769: (0, 770), 770: (0, 771), 771: (0, 772), 772: (0, 773), 773: (0, 774), 774: (0, 775), 775: (0, 776), 776: (0, 777), 777: (0, 778), 778: (0, 779), 779: (0, 780), 780: (0, 781), 781: (0, 782), 782: (0, 783), 783: (0, 784), 784: (0, 785), 785: (0, 786), 786: (0, 787), 787: (0, 788), 788: (0, 789), 789: (0, 790), 790: (0, 791), 791: (0, 792), 792: (0, 793), 793: (0, 794), 794: (0, 795), 795: (0, 796), 796: (0, 797), 797: (0, 798), 798: (0, 799), 799: (0, 800), 800: (0, 801), 801: (0, 802), 802: (0, 803), 803: (0, 804), 804: (0, 805), 805: (0, 806), 806: (0, 807), 807: (0, 808), 808: (0, 809), 809: (0, 810), 810: (0, 811), 811: (0, 812), 812: (0, 813), 813: (0, 814), 814: (0, 815), 815: (0, 816), 816: (0, 817), 817: (0, 818), 818: (0, 819), 819: (0, 820), 820: (0, 821), 821: (0, 822), 822: (0, 823), 823: (0, 824), 824: (0, 825), 825: (0, 826), 826: (0, 827), 827: (0, 828), 828: (0, 829), 829: (0, 830), 830: (0, 831), 831: (0, 832), 832: (0, 833), 833: (0, 834), 834: (0, 835), 835: (0, 836), 836: (0, 837), 837: (0, 838), 838: (0, 839), 839: (0, 840), 840: (0, 841), 841: (0, 842), 842: (0, 843), 843: (0, 844), 844: (0, 845), 845: (0, 846), 846: (0, 847), 847: (0, 848), 848: (0, 849), 849: (0, 850), 850: (0, 851), 851: (0, 852), 852: (0, 853), 853: (0, 854), 854: (0, 855), 855: (0, 856), 856: (0, 857), 857: (0, 858), 858: (0, 859), 859: (0, 860), 860: (0, 861), 861: (0, 862), 862: (0, 863), 863: (0, 864), 864: (0, 865), 865: (0, 866), 866: (0, 867), 867: (0, 868), 868: (0, 869), 869: (0, 870), 870: (0, 871), 871: (0, 872), 872: (0, 873), 873: (0, 874), 874: (0, 875), 875: (0, 876), 876: (0, 877), 877: (0, 878), 878: (0, 879), 879: (0, 880), 880: (0, 881), 881: (0, 882), 882: (0, 883), 883: (0, 884), 884: (0, 885), 885: (0, 886), 886: (0, 887), 887: (0, 888), 888: (0, 889), 889: (0, 890), 890: (0, 891), 891: (0, 892), 892: (0, 893), 893: (0, 894)}
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/Trials.pkl
This many vals across loaded session
0 : 2918407
Assigning to SP.Params this item:
{'which_level': 'trial', '_list_events': ['fixcue', 'fix_touch', 'rulecue2', 'samp', 'go_cue', 'first_raise', 'on_strokeidx_0', 'off_stroke_last', 'doneb', 'post', 'reward_all'], 'list_events_uniqnames': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_features_extraction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_features_get_conjunction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_pre_dur': [-0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75], 'list_post_dur': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75], 'map_var_to_othervars': None, 'strokes_only_keep_single': False, 'tasks_only_keep_these': None, 'prune_feature_levels_min_n_trials': 1, 'fr_which_version': 'sqrt', 'map_var_to_levels': None}
Assigning to SP.ParamsGlobals this item:
{'n_min_trials_per_level': 5, 'lenient_allow_data_if_has_n_levels': 2, 'PRE_DUR_CALC': -0.75, 'POST_DUR_CALC': 0.75, 'list_events': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_pre_dur': [-0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75], 'list_post_dur': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]}
stored in self.Dat[BehClass]
0
200
400
600
800
Running D.behclass_tokens_extract_datsegs
0
200
400
600
800
TODO!!! Merge this with other learning-related code
stored in self.Dat[BehClass]
0
200
400
600
800
Running D.behclass_tokens_extract_datsegs
0
200
400
600
800
trial # 0
trial # 100
trial # 200
trial # 300
trial # 400
trial # 500
trial # 600
trial # 700
trial # 800
Generated column called 'agent', which connects agent_kind-rule
n samples for conjunctions of score_name, agent_rule, agent_kind:
('binsucc', 'L', 'model') :     453
('binsucc', 'R', 'model') :     409
TODO! _preprocess_sanity_check
Resulting taskgroup/probe combo, after taskgroup_reassign_simple_neural...
('I', 0) :     762
('I', 1) :     100
.. Appended new column 'char_seq', version: task_matlab
Done!, new len of dataset 862
stored in self.Dat[BehClass]
0
200
400
600
800
Running D.behclass_tokens_extract_datsegs
0
200
400
600
800
Appended columns gridsize!
Defined new column: epochset
... value_counts:
(L,)    453
(R,)    409
Name: epochset, dtype: int64
... merge_sets_with_only_single_epoch... 
('L',) only has one epoch!:  ['L']
('R',) only has one epoch!:  ['R']
Mergin these epochset's .. 
[('L',), ('R',)]
Into this new epochset: ('LEFTOVER',)
Final epochsets:
(LEFTOVER,)    862
Name: epochset, dtype: int64
Updating this column of SP.DfScalar with Dataset beh:
epoch
Updating this column of SP.DfScalar with Dataset beh:
epochset
Updating this column of SP.DfScalar with Dataset beh:
seqc_0_loc
Updating this column of SP.DfScalar with Dataset beh:
seqc_0_shape
Updating this column of SP.DfScalar with Dataset beh:
seqc_nstrokes_beh
Updating this column of SP.DfScalar with Dataset beh:
character
Updating this column of SP.DfScalar with Dataset beh:
seqc_0_loc_shape
Updating this column of SP.DfScalar with Dataset beh:
seqc_1_loc_shape
Starting length of D.Dat: 862
self.Dat modified!!
Len, after remove aborts: 683
############ TAKING ONLY NO SUPERVISION TRIALS
--BEFORE REMOVE; existing supervision_stage_concise:
off|1|solid|0     612
mask|1|solid|0     71
Name: supervision_stage_concise, dtype: int64
self.Dat modified!!
--AFTER REMOVE; existing supervision_stage_concise:
off|1|solid|0    612
Name: supervision_stage_concise, dtype: int64
Dataset final len: 612
-- Len of D, before applying this param: remove_repeated_trials, ... 612
appended col to self.Dat:
dummy
self.Dat starting legnth:  604
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  604
after: 604
-- Len of D, before applying this param: correct_sequencing_binary_score, ... 604
self.Dat starting legnth:  589
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  589
after: 589
-- Len of D, before applying this param: one_to_one_beh_task_strokes, ... 589
after: 589
-- Len of D, before applying this param: beh_strokes_at_least_one, ... 589
after: 589
Saving to: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff
starting sites:  325
starting sites:  [2, 3, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 21, 24, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 68, 69, 71, 72, 73, 74, 76, 77, 78, 80, 85, 86, 88, 92, 97, 98, 99, 100, 101, 102, 104, 105, 108, 113, 114, 116, 118, 119, 121, 122, 123, 126, 127, 129, 130, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 148, 150, 152, 154, 156, 158, 160, 161, 162, 163, 164, 165, 167, 170, 171, 173, 178, 179, 181, 184, 187, 189, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 205, 206, 210, 213, 215, 217, 218, 219, 223, 224, 225, 226, 227, 229, 233, 235, 237, 243, 245, 247, 248, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 291, 294, 298, 299, 300, 301, 302, 304, 306, 307, 310, 312, 316, 318, 320, 323, 325, 328, 329, 331, 333, 334, 341, 342, 343, 344, 346, 348, 349, 351, 352, 353, 360, 366, 368, 369, 371, 373, 374, 375, 376, 378, 379, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 421, 422, 423, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 443, 445, 447, 449, 450, 453, 454, 455, 457, 458, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 477, 478, 480, 481, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 500, 501, 502, 503, 504, 505, 508, 509, 510, 512]
For percentile 10, using this threshold: 11.896788906562474
sites_good:  292
sites_bad:  33
Updates self.Sites
ending sites:  292
ending sites:  [2, 3, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 21, 24, 27, 29, 30, 31, 32, 33, 38, 39, 40, 41, 42, 43, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 68, 69, 71, 72, 74, 77, 78, 80, 88, 92, 97, 98, 99, 100, 101, 102, 104, 108, 113, 114, 116, 118, 119, 121, 122, 123, 126, 127, 130, 131, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 148, 150, 152, 154, 156, 158, 160, 161, 162, 164, 165, 167, 170, 171, 173, 178, 179, 181, 184, 189, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 205, 206, 210, 213, 215, 217, 218, 219, 224, 226, 227, 229, 233, 235, 237, 243, 248, 252, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 276, 277, 278, 279, 280, 281, 282, 284, 285, 286, 288, 290, 294, 298, 299, 300, 301, 302, 304, 310, 312, 316, 318, 320, 323, 328, 329, 331, 333, 334, 341, 343, 346, 348, 349, 351, 352, 353, 366, 368, 369, 371, 373, 374, 375, 376, 379, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 401, 402, 403, 404, 405, 406, 407, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 421, 422, 423, 429, 430, 433, 434, 435, 436, 437, 438, 439, 441, 443, 445, 447, 449, 450, 453, 454, 455, 457, 458, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 470, 471, 472, 473, 474, 475, 477, 478, 480, 481, 483, 484, 485, 486, 487, 488, 489, 490, 492, 493, 494, 495, 497, 498, 500, 501, 502, 503, 504, 505, 508, 509, 510]
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.75
POST_DUR_CALC  =  0.75
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables
var -- vars_others:  epoch  ---  ['epochset']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-epoch-vs-varothers-levothers-levvar.txt
var -- vars_others:  epochset  ---  ['epoch']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-epochset-vs-varothers-levothers-levvar.txt
TODO: do fr scalar computation only once! takes too much time.
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/df_var.pkl
Searching for already-done df_var at this path:
df_var doesnt exist...!
COMPUTING df_var!!!
Running grouping_print_n_samples...
DOing these! ...
list_events ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
WILL SKIP THESE EVENTS...
[]
GOOD!, enough data, max n per grouping conjunction (nmin, nmax)  0 316
 
Updated ParamsGlobals for event 02_rulecue2 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  02_rulecue2_-600_to_-50
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 02_rulecue2 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.04
POST_DUR_CALC  =  0.24
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  02_rulecue2_40_to_240
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 02_rulecue2 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.26
POST_DUR_CALC  =  0.6
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  02_rulecue2_260_to_600
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.04
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_-600_to_-40
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.04
POST_DUR_CALC  =  0.24
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_40_to_240
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.26
POST_DUR_CALC  =  0.6
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_260_to_600
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 04_go_cue to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.04
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  04_go_cue_-600_to_-40
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 05_first_raise to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  05_first_raise_-600_to_-50
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 06_on_strokeidx_0 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.25
POST_DUR_CALC  =  0.35
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  06_on_strokeidx_0_-250_to_350
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 08_doneb to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.5
POST_DUR_CALC  =  0.3
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  08_doneb_-500_to_300
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 09_post to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  09_post_50_to_600
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
 
Updated ParamsGlobals for event 10_reward_all to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  7
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['02_rulecue2', '02_rulecue2', '02_rulecue2', '03_samp', '03_samp', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.04, 0.26, -0.6, 0.04, 0.26, -0.6, -0.6, -0.25, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.24, 0.6, -0.04, 0.24, 0.6, -0.04, -0.05, 0.35, 0.3, 0.6, 0.6]
DOING THIS EVENT:  10_reward_all_50_to_600
site : 40
site : 60
site : 80
site : 100
site : 140
site : 160
site : 200
site : 260
site : 280
site : 300
site : 320
site : 460
site : 480
site : 500
SAving:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/df_var.pkl
SAving:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/list_eventwindow_event.pkl
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation
** Plotting summarystats
Saving at: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation
Found this var:  epoch
Found this var_others:  ('epochset',)
Aggregating dataframe over all othervars ...
Plotting ...
** Plotting heatmaps
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation_heatmap
Saving to:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation_heatmap/brainschem-event-val-modulation_subgroups.pdf
Saving to:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/modulation_heatmap/brainschem-event-val-modulation_subgroups-NOMOTOR.pdf
** Plotting example strokes
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-221107-sess_0/Trials.pkl
Plotting ..  (('LEFTOVER',),)
** Making plots for this event_window: 
02_rulecue2_40_to_240
Saving this event, 02_rulecue2_40_to_240, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/02_rulecue2_40_to_240
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/02_rulecue2_40_to_240/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/rasters/02_rulecue2
** Making plots for this event_window: 
05_first_raise_-600_to_-50
Saving this event, 05_first_raise_-600_to_-50, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/05_first_raise_-600_to_-50
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/05_first_raise_-600_to_-50/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/rasters/05_first_raise
** Making plots for this event_window: 
06_on_strokeidx_0_-250_to_350
Saving this event, 06_on_strokeidx_0_-250_to_350, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-221107-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/EACH_EVENT/06_on_strokeidx_0_-250_to_350
./_analy_anova_script.sh: line 4: 17682 Killed                  python analy_anova_plot.py $@ n
