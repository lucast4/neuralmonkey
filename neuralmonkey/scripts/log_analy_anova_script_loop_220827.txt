Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220827*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
session:  0
1
Beh Sessions that exist on this date:  {220827: [(1, 'shapedirsequence1b')]}
taking this beh session: 1
Loading these beh expts: ['shapedirsequence1b']
Loading these beh sessions: [1]
Loading this neural session: 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220827*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
{'filename_components_hyphened': ['Pancho', '220827', '144815'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/220827'], 'basedirs_filenames': ['220827', 'Pancho-220827-144815'], 'filename_final_ext': 'Pancho-220827-144815', 'filename_final_noext': 'Pancho-220827-144815'}
FOund this path for spikes:  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/spikes_tdt_quick-4.5
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/Pancho-220827-144815
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/spikes_tdt_quick-4.5
final_dir_name  --  Pancho-220827-144815
time  --  144815
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/220827.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
o  1 78.24063331702274
o  2 91.65475607109548
o  3 82.6858934310034
o  4 76.50389594045909
o  5 93.06556964733463
o  6 85.77488834318065
o  7 117.77782036707654
o  8 78.05888096954084
o  9 109.60370006863914
o  10 99.82946428939067
o  11 276.6104192586103
o  12 108.15722115669996
o  13 285.13363360205676
o  14 90.30669870466514
o  15 132.67867053406184
o  16 113.45661807202906
o  17 76.53774701172297
o  18 111.44903177387316
o  19 141.84158967134718
o  20 110.13212114248236
o  21 129.662608026441
o  22 131.23411560740223
-  23 59.019189375055134
o  24 76.59424845272005
-  25 59.61587735340458
o  26 449.6442160824401
o  27 159.52470640838584
o  28 76.31703145042641
o  29 197.23512744366343
o  30 86.2226963159088
o  31 179.29690465294863
o  32 114.01467544168808
o  33 147.2482314495093
o  34 107.83939901177655
-  35 53.5722646354342
o  36 351.68574218703435
o  37 81.16013785333853
o  38 300.64280750323087
o  39 122.45653359738769
o  40 291.7908413211175
o  41 89.61758391747517
o  42 88.62039595152291
o  43 223.51818381375605
o  44 218.14961311392835
o  45 960.4380442964606
-  46 63.427138259270826
o  47 209.22238123500338
-  48 49.19629739198463
o  49 100.20637080793422
o  50 78.08808358760434
o  51 229.91293315040278
o  52 86.59389239157704
o  53 136.92010574976447
o  54 88.04685659665424
o  55 1161.5874274524708
-  56 66.85814513077185
o  57 127.5940355398292
o  58 145.13313070871556
o  59 131.1436064945172
o  60 97.9764248043306
o  61 119.83668572853166
o  62 118.29832202463653
o  63 177.05015741763614
o  64 120.72088924577793
-  65 69.18030037526087
o  66 137.26794206077102
o  67 179.83542731331931
o  68 149.42521172986508
o  69 108.12000675175952
-  70 60.40395984436054
o  71 107.65460603834595
o  72 84.4199989778339
o  73 101.72301188651554
o  74 81.41570684329454
o  75 74.34173357101886
-  76 58.891878384788285
o  77 74.678992562234
o  78 150.66634513173693
o  79 73.33806606942481
o  80 78.30361075157283
o  81 79.06644795032847
o  82 75.7683431215709
o  83 73.76499057700349
-  84 69.37295150228653
-  85 64.57617426329416
o  86 86.4076906384444
o  87 70.19142920086685
-  88 62.05785790926666
o  89 124.46045233767163
o  90 95.14329841133495
o  91 80.75461054633274
o  92 73.16916687450211
o  93 79.2151442272132
o  94 76.27990029466346
o  95 92.5095145058036
o  96 71.13301954733629
o  97 221.28915242686472
o  98 187.73568047239343
o  99 121.00600919866702
o  100 114.42264976903388
o  101 100.53021771311033
o  102 194.79702493608713
-  103 64.75408519222074
o  104 72.83572328137586
o  105 390.0394692928647
o  106 86.62428282689726
o  107 77.45786944103929
-  108 69.88647777195239
-  109 52.14264016166853
-  110 55.74328313839451
o  111 71.0074113856272
o  112 250.13274927715784
o  113 80.91012616843018
o  114 83.45716980102748
o  115 164.5748501861207
o  116 144.6149733359973
o  117 161.11974930025278
o  118 72.06022181530989
o  119 152.4364820143961
o  120 110.63360889973374
o  121 80.93098306812523
o  122 115.51832888454192
o  123 103.78977998692372
o  124 118.87837124143971
-  125 57.61461179043381
o  126 73.3532874037594
o  127 85.818007928726
o  128 71.57612224856915
-  129 46.969044067670985
o  130 121.84364324057238
o  131 81.50701830911808
o  132 471.50058929896784
o  133 77.68082681382458
o  134 188.4764477753988
o  135 73.53891551260612
o  136 107.0645058236936
o  137 76.76730135392572
o  138 298.14228831190485
o  139 102.25526271698973
o  140 89.21331766175281
o  141 105.71112559908885
o  142 101.99452967262296
o  143 97.37816078433853
o  144 132.3532955776167
o  145 112.4569761859304
o  146 130.25609610591346
o  147 113.42665465202784
o  148 73.40804209231011
-  149 63.9114868211178
o  150 106.16762525039394
o  151 100.26164124205661
-  152 69.15281509031615
o  153 92.27497824143393
o  154 178.4116346960367
o  155 70.28013495950873
-  156 57.150434458238486
o  157 80.95500355430886
o  158 87.5735891852688
o  159 107.62639064783275
o  160 131.1970850420795
o  161 104.29268531709623
o  162 148.91718098866204
o  163 136.98079886388783
o  164 71.04307455935304
o  165 133.99026378791189
o  166 92.86510339432229
o  167 124.1210188752242
-  168 50.187662851958976
o  169 73.980644389814
o  170 95.14945558761762
o  171 135.06008780379312
o  172 101.50355139772103
o  173 276.6840457738475
o  174 92.23142948828485
o  175 84.95520161025192
-  176 67.96174034140827
o  177 187.87227112083747
o  178 104.64204601327548
o  179 155.68895593478356
o  180 71.91814782574605
o  181 162.13119850583098
o  182 165.41369458910586
-  183 63.47108168883206
o  184 316.61490376015064
-  185 31.9347557764743
o  186 99.34602357338986
o  187 119.24801144857493
o  188 76.78364477697411
o  189 79.40763415196379
o  190 78.45860271445865
o  191 116.89705538202979
-  192 66.21701692197902
o  193 101.98281789507917
o  194 133.4077692751238
o  195 76.68121663003339
-  196 57.7896457265475
-  197 68.32829407303298
o  198 77.39698839521516
o  199 72.55616241658875
o  200 151.36900932626548
o  201 120.83240035737727
o  202 95.82046539926243
o  203 118.89577751629041
o  204 82.07194466277397
o  205 101.09086475448267
o  206 256.23440184101474
o  207 151.34154276470736
o  208 99.22259911949004
o  209 70.41931658911145
o  210 94.17534131527263
o  211 100.95047729482421
-  212 55.34953019202737
o  213 119.2466771260316
-  214 61.837644725181505
o  215 80.85453073218578
-  216 65.42982044525006
o  217 102.73856374995985
o  218 97.31723791812603
o  219 78.7511332916617
o  220 92.95790457731091
o  221 89.93188602438795
o  222 94.15558291923972
o  223 78.64139548473577
o  224 86.37484214283648
o  225 80.33455445423735
o  226 84.74069539605561
o  227 208.16971130820392
o  228 90.58060074724953
-  229 53.304728587198404
o  230 82.94731558888016
o  231 109.55009213173135
-  232 43.24571765029687
o  233 92.27763873098938
o  234 81.98620077614589
o  235 144.96753204217302
-  236 62.68523471717409
o  237 100.30362795724888
-  238 67.19066919611718
o  239 83.16444859033741
-  240 65.0246325103204
o  241 80.63933939079939
o  242 108.19568088869619
o  243 74.45855178942415
o  244 79.12666934661615
o  245 77.27341349339676
o  246 129.5802943845346
o  247 110.14279811497344
o  248 127.36810749930956
o  249 131.93994524965805
o  250 76.42251696032181
o  251 94.83765644234737
o  252 108.11330584707666
o  253 150.66731113827674
o  254 102.45195380477999
o  255 152.52895332477377
o  256 117.49187346690708
o  257 183.15227892913683
o  258 145.45448008506318
o  259 84.45882742892518
o  260 190.92844787804114
o  261 110.73674706205347
o  262 107.10661740531336
o  263 81.42073424630321
o  264 141.62358602829698
o  265 163.7454755013793
o  266 71.35631357947078
o  267 478.24666512678925
o  268 71.40588865747767
o  269 90.4837238360232
o  270 288.6734126447294
o  271 135.68707156891563
o  272 267.97481931510845
o  273 151.19160988452197
o  274 91.00963559141165
o  275 105.90103862816977
o  276 91.51387888511918
o  277 121.89207262399859
o  278 206.79918683641765
o  279 133.60921042611727
o  280 80.17549184621699
o  281 103.8289549611646
o  282 90.37812715391075
o  283 85.70758988586164
o  284 87.05752088144067
-  285 67.91261432606788
o  286 85.58854549354919
o  287 71.3486935951809
o  288 88.30475663685483
-  289 69.33176511394132
o  290 82.96549831941812
-  291 67.15347010590013
-  292 42.75824507229686
-  293 59.0752657117632
o  294 133.72995015398357
-  295 63.405517145131334
o  296 125.83808176728945
o  297 77.04825743229686
-  298 64.32087819166718
-  299 54.191602005741515
-  300 61.70697064488995
o  301 94.10195694528664
o  302 82.03076876386461
o  303 182.82464745684405
o  304 116.80392346000373
-  305 64.5468582718571
o  306 73.33176272312075
-  307 65.89037201308763
-  308 66.36249294843495
-  309 67.79026299622865
o  310 86.30312974142619
-  311 67.76190409284582
o  312 112.84216725517402
o  313 77.74818272120793
o  314 140.07171179055604
-  315 65.42598659278882
o  316 84.32388260632946
o  317 82.23505818925888
o  318 86.61272408539936
-  319 67.11593908942022
o  320 118.5383411715159
-  321 68.30099323894439
-  322 56.89960700869506
o  323 110.03719006430347
o  324 94.24183377608915
o  325 78.66410364948665
o  326 75.98459412676384
o  327 118.00160185530804
-  328 54.27339459617557
o  329 70.68850026235783
o  330 81.10232936426928
o  331 109.93189395762238
o  332 77.62480475327175
o  333 97.08224664961745
o  334 94.83684086627036
-  335 59.274073683191276
-  336 68.96147814664305
-  337 56.28382680979121
o  338 76.32501589614377
-  339 65.20131491652755
-  340 61.75857107844968
-  341 67.75073007161419
-  342 60.552224151619484
o  343 73.61720587939163
-  344 51.08567927458971
o  345 114.25884846077278
o  346 94.41924398620692
o  347 70.08694711240969
o  348 129.0458571516705
o  349 79.47204498306492
-  350 61.123530975286485
o  351 130.55494270636046
o  352 107.29811379050881
o  353 90.71019897088591
-  354 66.76676995715891
o  355 77.58323392794064
-  356 69.18787058571198
-  357 44.15532015336466
o  358 87.99657587848928
-  359 55.34754383346959
o  360 70.05876691938457
-  361 61.951045559710906
o  362 81.37170817238983
-  363 66.52298277795654
o  364 84.37027559891672
-  365 50.57404678228184
o  366 82.90965944032492
-  367 48.17163122880793
o  368 74.24298177858736
o  369 80.80229863472385
-  370 65.20572865896483
o  371 94.27931514796873
o  372 89.03832927771005
o  373 81.34695330174614
o  374 85.46318321550866
o  375 79.52434999314684
-  376 69.6613595847901
-  377 61.21075921170375
-  378 60.360699859520786
-  379 55.173891222677774
o  380 88.17121848802962
-  381 53.450151438557086
o  382 76.89892757742673
-  383 61.9306935479186
o  384 80.06298638868593
o  385 318.7617705931003
o  386 190.42624327586108
o  387 216.25346973672967
o  388 95.58238523941182
o  389 236.7866380978763
o  390 162.62761687065233
-  391 48.13818484165222
-  392 65.4077771086455
o  393 91.74794046807402
o  394 200.82897763266308
o  395 106.94082451282539
o  396 165.81672418960906
o  397 85.88091108799945
o  398 89.15134242396498
o  399 89.40510655841766
o  400 124.10633698585626
o  401 178.61973462687212
o  402 171.6692901375936
o  403 209.2891763356477
o  404 175.39085402565578
o  405 753.4067549257433
o  406 91.15599210501175
o  407 112.02876163895152
o  408 181.98749732987855
-  409 51.96860062485098
o  410 517.2650792782459
-  411 67.81834743579776
-  412 68.32869870381992
o  413 256.9357267743892
o  414 239.0228780285057
o  415 137.32342262851216
o  416 152.98473880575773
o  417 105.35408833370579
o  418 80.51888647685405
o  419 80.68910529818268
o  420 87.73824307387541
o  421 71.2557075087756
o  422 97.87757549591379
o  423 84.2629963500589
o  424 70.1796018626779
o  425 85.9310413883969
-  426 65.217224377204
-  427 64.92883725943166
-  428 29.41281740772429
o  429 94.94943891710356
o  430 89.42593765483417
-  431 69.67697721883556
-  432 49.548049012380766
o  433 205.29931062995783
o  434 109.84309017619353
o  435 135.5734286684782
o  436 176.57430627853427
o  437 120.35241502549353
o  438 119.59115072618124
o  439 132.20225354451446
o  440 79.54364416645808
o  441 322.2335220942295
o  442 82.148775369314
o  443 582.0270579166296
-  444 36.8269711608511
o  445 79.13064873931012
-  446 35.55283780314941
o  447 119.93644538092704
-  448 32.34644927125375
o  449 98.27939773782892
o  450 174.2833322602906
o  451 79.16331295190098
o  452 139.46968425837707
o  453 109.82339141362802
o  454 111.67980902676493
o  455 87.23318178110883
-  456 69.96676700987841
o  457 163.31040996996612
o  458 71.93719945961539
o  459 177.35246961816173
o  460 124.0717640833066
o  461 210.2038031796403
o  462 215.9689246197291
o  463 179.28644451426413
o  464 144.52284792220635
o  465 131.16452480981425
-  466 54.80607583645288
o  467 159.48366397460254
o  468 129.00872477158075
o  469 106.43573930171108
-  470 68.94193801493921
o  471 211.30332562918548
o  472 439.8942305749391
o  473 242.4171156458134
o  474 84.73898327288883
o  475 119.69523767173851
-  476 55.37006272698848
o  477 159.60150866138696
o  478 110.70553624375907
o  479 97.74692322886254
o  480 85.26464615588102
o  481 103.48604821952902
-  482 36.038702291305626
o  483 125.71091752287077
o  484 115.95919654926263
o  485 156.82626972499335
-  486 61.796567547348914
-  487 58.47883248165085
o  488 89.23812508316287
o  489 113.01230771877846
o  490 252.38942301570626
o  491 100.96516202115673
o  492 232.19379701333025
o  493 208.3783298800812
o  494 94.7273184425464
o  495 130.67445136685862
-  496 66.62208984708377
o  497 129.19695080108892
o  498 92.19606354402313
-  499 68.51373318213246
o  500 244.2474894877714
o  501 110.32029240423206
o  502 128.01795911290745
o  503 99.74778388744036
o  504 114.65771334177721
o  505 99.51138180679382
o  506 117.96246474390264
-  507 35.221439935774654
o  508 92.75557015819122
o  509 96.80716328741025
o  510 87.29584539063985
-  511 65.53660725867462
o  512 104.67071733503501
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Trials.pkl
** SKIPPING EXTRACTION, since was able to load snippets, for: 
(animal, DATE, which_level, ANALY_VER, session)
Pancho 220827 trial rulesw 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220827*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
session:  0
1
Beh Sessions that exist on this date:  {220827: [(1, 'shapedirsequence1b')]}
taking this beh session: 1
Loading these beh expts: ['shapedirsequence1b']
Loading these beh sessions: [1]
Loading this neural session: 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220827*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
{'filename_components_hyphened': ['Pancho', '220827', '144815'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/220827'], 'basedirs_filenames': ['220827', 'Pancho-220827-144815'], 'filename_final_ext': 'Pancho-220827-144815', 'filename_final_noext': 'Pancho-220827-144815'}
FOund this path for spikes:  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/spikes_tdt_quick-4.5
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/Pancho-220827-144815
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/spikes_tdt_quick-4.5
final_dir_name  --  Pancho-220827-144815
time  --  144815
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/220827.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
o  1 78.24063331702274
o  2 91.65475607109548
o  3 82.6858934310034
o  4 76.50389594045909
o  5 93.06556964733463
o  6 85.77488834318065
o  7 117.77782036707654
o  8 78.05888096954084
o  9 109.60370006863914
o  10 99.82946428939067
o  11 276.6104192586103
o  12 108.15722115669996
o  13 285.13363360205676
o  14 90.30669870466514
o  15 132.67867053406184
o  16 113.45661807202906
o  17 76.53774701172297
o  18 111.44903177387316
o  19 141.84158967134718
o  20 110.13212114248236
o  21 129.662608026441
o  22 131.23411560740223
-  23 59.019189375055134
o  24 76.59424845272005
-  25 59.61587735340458
o  26 449.6442160824401
o  27 159.52470640838584
o  28 76.31703145042641
o  29 197.23512744366343
o  30 86.2226963159088
o  31 179.29690465294863
o  32 114.01467544168808
o  33 147.2482314495093
o  34 107.83939901177655
-  35 53.5722646354342
o  36 351.68574218703435
o  37 81.16013785333853
o  38 300.64280750323087
o  39 122.45653359738769
o  40 291.7908413211175
o  41 89.61758391747517
o  42 88.62039595152291
o  43 223.51818381375605
o  44 218.14961311392835
o  45 960.4380442964606
-  46 63.427138259270826
o  47 209.22238123500338
-  48 49.19629739198463
o  49 100.20637080793422
o  50 78.08808358760434
o  51 229.91293315040278
o  52 86.59389239157704
o  53 136.92010574976447
o  54 88.04685659665424
o  55 1161.5874274524708
-  56 66.85814513077185
o  57 127.5940355398292
o  58 145.13313070871556
o  59 131.1436064945172
o  60 97.9764248043306
o  61 119.83668572853166
o  62 118.29832202463653
o  63 177.05015741763614
o  64 120.72088924577793
-  65 69.18030037526087
o  66 137.26794206077102
o  67 179.83542731331931
o  68 149.42521172986508
o  69 108.12000675175952
-  70 60.40395984436054
o  71 107.65460603834595
o  72 84.4199989778339
o  73 101.72301188651554
o  74 81.41570684329454
o  75 74.34173357101886
-  76 58.891878384788285
o  77 74.678992562234
o  78 150.66634513173693
o  79 73.33806606942481
o  80 78.30361075157283
o  81 79.06644795032847
o  82 75.7683431215709
o  83 73.76499057700349
-  84 69.37295150228653
-  85 64.57617426329416
o  86 86.4076906384444
o  87 70.19142920086685
-  88 62.05785790926666
o  89 124.46045233767163
o  90 95.14329841133495
o  91 80.75461054633274
o  92 73.16916687450211
o  93 79.2151442272132
o  94 76.27990029466346
o  95 92.5095145058036
o  96 71.13301954733629
o  97 221.28915242686472
o  98 187.73568047239343
o  99 121.00600919866702
o  100 114.42264976903388
o  101 100.53021771311033
o  102 194.79702493608713
-  103 64.75408519222074
o  104 72.83572328137586
o  105 390.0394692928647
o  106 86.62428282689726
o  107 77.45786944103929
-  108 69.88647777195239
-  109 52.14264016166853
-  110 55.74328313839451
o  111 71.0074113856272
o  112 250.13274927715784
o  113 80.91012616843018
o  114 83.45716980102748
o  115 164.5748501861207
o  116 144.6149733359973
o  117 161.11974930025278
o  118 72.06022181530989
o  119 152.4364820143961
o  120 110.63360889973374
o  121 80.93098306812523
o  122 115.51832888454192
o  123 103.78977998692372
o  124 118.87837124143971
-  125 57.61461179043381
o  126 73.3532874037594
o  127 85.818007928726
o  128 71.57612224856915
-  129 46.969044067670985
o  130 121.84364324057238
o  131 81.50701830911808
o  132 471.50058929896784
o  133 77.68082681382458
o  134 188.4764477753988
o  135 73.53891551260612
o  136 107.0645058236936
o  137 76.76730135392572
o  138 298.14228831190485
o  139 102.25526271698973
o  140 89.21331766175281
o  141 105.71112559908885
o  142 101.99452967262296
o  143 97.37816078433853
o  144 132.3532955776167
o  145 112.4569761859304
o  146 130.25609610591346
o  147 113.42665465202784
o  148 73.40804209231011
-  149 63.9114868211178
o  150 106.16762525039394
o  151 100.26164124205661
-  152 69.15281509031615
o  153 92.27497824143393
o  154 178.4116346960367
o  155 70.28013495950873
-  156 57.150434458238486
o  157 80.95500355430886
o  158 87.5735891852688
o  159 107.62639064783275
o  160 131.1970850420795
o  161 104.29268531709623
o  162 148.91718098866204
o  163 136.98079886388783
o  164 71.04307455935304
o  165 133.99026378791189
o  166 92.86510339432229
o  167 124.1210188752242
-  168 50.187662851958976
o  169 73.980644389814
o  170 95.14945558761762
o  171 135.06008780379312
o  172 101.50355139772103
o  173 276.6840457738475
o  174 92.23142948828485
o  175 84.95520161025192
-  176 67.96174034140827
o  177 187.87227112083747
o  178 104.64204601327548
o  179 155.68895593478356
o  180 71.91814782574605
o  181 162.13119850583098
o  182 165.41369458910586
-  183 63.47108168883206
o  184 316.61490376015064
-  185 31.9347557764743
o  186 99.34602357338986
o  187 119.24801144857493
o  188 76.78364477697411
o  189 79.40763415196379
o  190 78.45860271445865
o  191 116.89705538202979
-  192 66.21701692197902
o  193 101.98281789507917
o  194 133.4077692751238
o  195 76.68121663003339
-  196 57.7896457265475
-  197 68.32829407303298
o  198 77.39698839521516
o  199 72.55616241658875
o  200 151.36900932626548
o  201 120.83240035737727
o  202 95.82046539926243
o  203 118.89577751629041
o  204 82.07194466277397
o  205 101.09086475448267
o  206 256.23440184101474
o  207 151.34154276470736
o  208 99.22259911949004
o  209 70.41931658911145
o  210 94.17534131527263
o  211 100.95047729482421
-  212 55.34953019202737
o  213 119.2466771260316
-  214 61.837644725181505
o  215 80.85453073218578
-  216 65.42982044525006
o  217 102.73856374995985
o  218 97.31723791812603
o  219 78.7511332916617
o  220 92.95790457731091
o  221 89.93188602438795
o  222 94.15558291923972
o  223 78.64139548473577
o  224 86.37484214283648
o  225 80.33455445423735
o  226 84.74069539605561
o  227 208.16971130820392
o  228 90.58060074724953
-  229 53.304728587198404
o  230 82.94731558888016
o  231 109.55009213173135
-  232 43.24571765029687
o  233 92.27763873098938
o  234 81.98620077614589
o  235 144.96753204217302
-  236 62.68523471717409
o  237 100.30362795724888
-  238 67.19066919611718
o  239 83.16444859033741
-  240 65.0246325103204
o  241 80.63933939079939
o  242 108.19568088869619
o  243 74.45855178942415
o  244 79.12666934661615
o  245 77.27341349339676
o  246 129.5802943845346
o  247 110.14279811497344
o  248 127.36810749930956
o  249 131.93994524965805
o  250 76.42251696032181
o  251 94.83765644234737
o  252 108.11330584707666
o  253 150.66731113827674
o  254 102.45195380477999
o  255 152.52895332477377
o  256 117.49187346690708
o  257 183.15227892913683
o  258 145.45448008506318
o  259 84.45882742892518
o  260 190.92844787804114
o  261 110.73674706205347
o  262 107.10661740531336
o  263 81.42073424630321
o  264 141.62358602829698
o  265 163.7454755013793
o  266 71.35631357947078
o  267 478.24666512678925
o  268 71.40588865747767
o  269 90.4837238360232
o  270 288.6734126447294
o  271 135.68707156891563
o  272 267.97481931510845
o  273 151.19160988452197
o  274 91.00963559141165
o  275 105.90103862816977
o  276 91.51387888511918
o  277 121.89207262399859
o  278 206.79918683641765
o  279 133.60921042611727
o  280 80.17549184621699
o  281 103.8289549611646
o  282 90.37812715391075
o  283 85.70758988586164
o  284 87.05752088144067
-  285 67.91261432606788
o  286 85.58854549354919
o  287 71.3486935951809
o  288 88.30475663685483
-  289 69.33176511394132
o  290 82.96549831941812
-  291 67.15347010590013
-  292 42.75824507229686
-  293 59.0752657117632
o  294 133.72995015398357
-  295 63.405517145131334
o  296 125.83808176728945
o  297 77.04825743229686
-  298 64.32087819166718
-  299 54.191602005741515
-  300 61.70697064488995
o  301 94.10195694528664
o  302 82.03076876386461
o  303 182.82464745684405
o  304 116.80392346000373
-  305 64.5468582718571
o  306 73.33176272312075
-  307 65.89037201308763
-  308 66.36249294843495
-  309 67.79026299622865
o  310 86.30312974142619
-  311 67.76190409284582
o  312 112.84216725517402
o  313 77.74818272120793
o  314 140.07171179055604
-  315 65.42598659278882
o  316 84.32388260632946
o  317 82.23505818925888
o  318 86.61272408539936
-  319 67.11593908942022
o  320 118.5383411715159
-  321 68.30099323894439
-  322 56.89960700869506
o  323 110.03719006430347
o  324 94.24183377608915
o  325 78.66410364948665
o  326 75.98459412676384
o  327 118.00160185530804
-  328 54.27339459617557
o  329 70.68850026235783
o  330 81.10232936426928
o  331 109.93189395762238
o  332 77.62480475327175
o  333 97.08224664961745
o  334 94.83684086627036
-  335 59.274073683191276
-  336 68.96147814664305
-  337 56.28382680979121
o  338 76.32501589614377
-  339 65.20131491652755
-  340 61.75857107844968
-  341 67.75073007161419
-  342 60.552224151619484
o  343 73.61720587939163
-  344 51.08567927458971
o  345 114.25884846077278
o  346 94.41924398620692
o  347 70.08694711240969
o  348 129.0458571516705
o  349 79.47204498306492
-  350 61.123530975286485
o  351 130.55494270636046
o  352 107.29811379050881
o  353 90.71019897088591
-  354 66.76676995715891
o  355 77.58323392794064
-  356 69.18787058571198
-  357 44.15532015336466
o  358 87.99657587848928
-  359 55.34754383346959
o  360 70.05876691938457
-  361 61.951045559710906
o  362 81.37170817238983
-  363 66.52298277795654
o  364 84.37027559891672
-  365 50.57404678228184
o  366 82.90965944032492
-  367 48.17163122880793
o  368 74.24298177858736
o  369 80.80229863472385
-  370 65.20572865896483
o  371 94.27931514796873
o  372 89.03832927771005
o  373 81.34695330174614
o  374 85.46318321550866
o  375 79.52434999314684
-  376 69.6613595847901
-  377 61.21075921170375
-  378 60.360699859520786
-  379 55.173891222677774
o  380 88.17121848802962
-  381 53.450151438557086
o  382 76.89892757742673
-  383 61.9306935479186
o  384 80.06298638868593
o  385 318.7617705931003
o  386 190.42624327586108
o  387 216.25346973672967
o  388 95.58238523941182
o  389 236.7866380978763
o  390 162.62761687065233
-  391 48.13818484165222
-  392 65.4077771086455
o  393 91.74794046807402
o  394 200.82897763266308
o  395 106.94082451282539
o  396 165.81672418960906
o  397 85.88091108799945
o  398 89.15134242396498
o  399 89.40510655841766
o  400 124.10633698585626
o  401 178.61973462687212
o  402 171.6692901375936
o  403 209.2891763356477
o  404 175.39085402565578
o  405 753.4067549257433
o  406 91.15599210501175
o  407 112.02876163895152
o  408 181.98749732987855
-  409 51.96860062485098
o  410 517.2650792782459
-  411 67.81834743579776
-  412 68.32869870381992
o  413 256.9357267743892
o  414 239.0228780285057
o  415 137.32342262851216
o  416 152.98473880575773
o  417 105.35408833370579
o  418 80.51888647685405
o  419 80.68910529818268
o  420 87.73824307387541
o  421 71.2557075087756
o  422 97.87757549591379
o  423 84.2629963500589
o  424 70.1796018626779
o  425 85.9310413883969
-  426 65.217224377204
-  427 64.92883725943166
-  428 29.41281740772429
o  429 94.94943891710356
o  430 89.42593765483417
-  431 69.67697721883556
-  432 49.548049012380766
o  433 205.29931062995783
o  434 109.84309017619353
o  435 135.5734286684782
o  436 176.57430627853427
o  437 120.35241502549353
o  438 119.59115072618124
o  439 132.20225354451446
o  440 79.54364416645808
o  441 322.2335220942295
o  442 82.148775369314
o  443 582.0270579166296
-  444 36.8269711608511
o  445 79.13064873931012
-  446 35.55283780314941
o  447 119.93644538092704
-  448 32.34644927125375
o  449 98.27939773782892
o  450 174.2833322602906
o  451 79.16331295190098
o  452 139.46968425837707
o  453 109.82339141362802
o  454 111.67980902676493
o  455 87.23318178110883
-  456 69.96676700987841
o  457 163.31040996996612
o  458 71.93719945961539
o  459 177.35246961816173
o  460 124.0717640833066
o  461 210.2038031796403
o  462 215.9689246197291
o  463 179.28644451426413
o  464 144.52284792220635
o  465 131.16452480981425
-  466 54.80607583645288
o  467 159.48366397460254
o  468 129.00872477158075
o  469 106.43573930171108
-  470 68.94193801493921
o  471 211.30332562918548
o  472 439.8942305749391
o  473 242.4171156458134
o  474 84.73898327288883
o  475 119.69523767173851
-  476 55.37006272698848
o  477 159.60150866138696
o  478 110.70553624375907
o  479 97.74692322886254
o  480 85.26464615588102
o  481 103.48604821952902
-  482 36.038702291305626
o  483 125.71091752287077
o  484 115.95919654926263
o  485 156.82626972499335
-  486 61.796567547348914
-  487 58.47883248165085
o  488 89.23812508316287
o  489 113.01230771877846
o  490 252.38942301570626
o  491 100.96516202115673
o  492 232.19379701333025
o  493 208.3783298800812
o  494 94.7273184425464
o  495 130.67445136685862
-  496 66.62208984708377
o  497 129.19695080108892
o  498 92.19606354402313
-  499 68.51373318213246
o  500 244.2474894877714
o  501 110.32029240423206
o  502 128.01795911290745
o  503 99.74778388744036
o  504 114.65771334177721
o  505 99.51138180679382
o  506 117.96246474390264
-  507 35.221439935774654
o  508 92.75557015819122
o  509 96.80716328741025
o  510 87.29584539063985
-  511 65.53660725867462
o  512 104.67071733503501
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Trials.pkl
This many vals across loaded session
0 : 2778663
Assigning to SP.Params this item:
{'which_level': 'trial', '_list_events': ['fixcue', 'fix_touch', 'rulecue2', 'samp', 'go_cue', 'first_raise', 'on_strokeidx_0', 'off_stroke_last', 'doneb', 'post', 'reward_all'], 'list_events_uniqnames': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_features_extraction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_features_get_conjunction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_pre_dur': [-0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75], 'list_post_dur': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75], 'map_var_to_othervars': None, 'strokes_only_keep_single': False, 'tasks_only_keep_these': None, 'prune_feature_levels_min_n_trials': 1, 'fr_which_version': 'sqrt', 'map_var_to_levels': None}
Assigning to SP.ParamsGlobals this item:
{'n_min_trials_per_level': 5, 'lenient_allow_data_if_has_n_levels': 2, 'PRE_DUR_CALC': -0.75, 'POST_DUR_CALC': 0.75, 'list_events': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_pre_dur': [-0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75], 'list_post_dur': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]}
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
TODO!!! Merge this with other learning-related code
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
trial # 0
trial # 100
trial # 200
trial # 300
trial # 400
trial # 500
trial # 600
trial # 700
Generated column called 'agent', which connects agent_kind-rule
n samples for conjunctions of score_name, agent_rule, agent_kind:
('binsucc', 'R', 'model') :     368
('binsucc', 'VlL1', 'model') :     378
TODO! _preprocess_sanity_check
Starting length of D.Dat: 746
self.Dat modified!!
Len, after remove aborts: 553
############ TAKING ONLY NO SUPERVISION TRIALS
--BEFORE REMOVE; existing supervision_stage_concise:
off|0||0     412
mask|0||0    141
Name: supervision_stage_concise, dtype: int64
self.Dat modified!!
--AFTER REMOVE; existing supervision_stage_concise:
off|0||0    412
Name: supervision_stage_concise, dtype: int64
Dataset final len: 412
-- Len of D, before applying this param: remove_repeated_trials, ... 412
appended col to self.Dat:
dummy
self.Dat starting legnth:  409
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  409
after: 409
-- Len of D, before applying this param: correct_sequencing_binary_score, ... 409
self.Dat starting legnth:  404
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  404
after: 404
-- Len of D, before applying this param: one_to_one_beh_task_strokes, ... 404
after: 404
Done!, new len of dataset 404
Saving to: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_taskgroup_probe/SV_r2_maxtime_1way_mshuff
starting sites:  395
starting sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104, 106, 107, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 233, 234, 235, 237, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 290, 294, 296, 297, 301, 302, 303, 304, 306, 310, 312, 313, 314, 316, 317, 318, 320, 324, 326, 327, 329, 330, 331, 332, 333, 334, 338, 343, 345, 346, 347, 349, 351, 352, 353, 355, 360, 362, 364, 366, 368, 369, 371, 372, 373, 374, 375, 380, 382, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 471, 472, 473, 474, 475, 477, 478, 479, 480, 481, 483, 484, 485, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512]
For percentile 10, using this threshold: 3.333271041101069
sites_good:  355
sites_bad:  40
Updates self.Sites
ending sites:  355
ending sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 24, 27, 29, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 71, 73, 74, 77, 78, 79, 80, 81, 82, 87, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 104, 107, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 130, 131, 132, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 213, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 233, 235, 237, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 288, 290, 294, 296, 297, 301, 302, 303, 304, 310, 312, 314, 316, 318, 320, 324, 327, 331, 332, 333, 334, 338, 345, 346, 347, 349, 351, 352, 353, 355, 366, 369, 371, 372, 373, 374, 375, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 471, 472, 473, 474, 475, 477, 478, 479, 481, 483, 484, 485, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512]
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.75
POST_DUR_CALC  =  0.75
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
TODO: do fr scalar computation only once! takes too much time.
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_taskgroup_probe/SV_r2_maxtime_1way_mshuff/df_var.pkl
Searching for already-done df_var at this path:
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_taskgroup_probe/SV_r2_maxtime_1way_mshuff/df_var.pkl
RELOADED df_var!!!
... from: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_taskgroup_probe/SV_r2_maxtime_1way_mshuff/df_var.pkl
Events already done: (will skip these when recomputing)...
['03_samp_-600_to_-50', '03_samp_50_to_600', '05_first_raise_-600_to_-50', '06_on_strokeidx_0_-100_to_600', '08_doneb_-500_to_300', '09_post_50_to_600', '10_reward_all_50_to_600']
COMPUTING df_var!!!
DOing these! ...
list_events ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
WILL SKIP THESE EVENTS...
['03_samp_-600_to_-50', '03_samp_50_to_600', '05_first_raise_-600_to_-50', '06_on_strokeidx_0_-100_to_600', '08_doneb_-500_to_300', '09_post_50_to_600', '10_reward_all_50_to_600']
Running grouping_print_n_samples...
GOOD!, enough data, max n per grouping conjunction (nmin, nmax)  0 107
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_-600_to_-50
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
03_samp_-600_to_-50
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_50_to_600
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
03_samp_50_to_600
 
Updated ParamsGlobals for event 05_first_raise to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  05_first_raise_-600_to_-50
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
05_first_raise_-600_to_-50
 
Updated ParamsGlobals for event 06_on_strokeidx_0 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.1
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  06_on_strokeidx_0_-100_to_600
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
06_on_strokeidx_0_-100_to_600
 
Updated ParamsGlobals for event 08_doneb to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.5
POST_DUR_CALC  =  0.3
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  08_doneb_-500_to_300
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
08_doneb_-500_to_300
 
Updated ParamsGlobals for event 09_post to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  09_post_50_to_600
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
09_post_50_to_600
 
Updated ParamsGlobals for event 10_reward_all to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  10_reward_all_50_to_600
!!!! SKIPPING this event, since it is in events_windowed_skip that you entered:
10_reward_all_50_to_600
SKIPPING, extracted df_var is empty. Probably you have not enough data for this conjunctions, try setting DEBUG_CONJUNCTIONS=True and reading the low-level data it prints.
!! SKIPPING:  epoch ['taskgroup', 'probe']
Saving to: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff
starting sites:  355
starting sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 24, 27, 29, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 71, 73, 74, 77, 78, 79, 80, 81, 82, 87, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 104, 107, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 130, 131, 132, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 213, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 233, 235, 237, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 288, 290, 294, 296, 297, 301, 302, 303, 304, 310, 312, 314, 316, 318, 320, 324, 327, 331, 332, 333, 334, 338, 345, 346, 347, 349, 351, 352, 353, 355, 366, 369, 371, 372, 373, 374, 375, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 471, 472, 473, 474, 475, 477, 478, 479, 481, 483, 484, 485, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512]
For percentile 10, using this threshold: 3.333271041101069
sites_good:  355
sites_bad:  40
Updates self.Sites
ending sites:  355
ending sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 24, 27, 29, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 71, 73, 74, 77, 78, 79, 80, 81, 82, 87, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 104, 107, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 130, 131, 132, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 213, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 233, 235, 237, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 288, 290, 294, 296, 297, 301, 302, 303, 304, 310, 312, 314, 316, 318, 320, 324, 327, 331, 332, 333, 334, 338, 345, 346, 347, 349, 351, 352, 353, 355, 366, 369, 371, 372, 373, 374, 375, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 471, 472, 473, 474, 475, 477, 478, 479, 481, 483, 484, 485, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512]
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.75
POST_DUR_CALC  =  0.75
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
TODO: do fr scalar computation only once! takes too much time.
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/df_var.pkl
Searching for already-done df_var at this path:
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/df_var.pkl
df_var doesnt exist...!
COMPUTING df_var!!!
DOing these! ...
list_events ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
WILL SKIP THESE EVENTS...
[]
Running grouping_print_n_samples...
GOOD!, enough data, max n per grouping conjunction (nmin, nmax)  0 40
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_-600_to_-50
site : 20
site : 60
site : 80
site : 120
site : 140
site : 160
site : 180
site : 200
site : 220
site : 260
site : 320
site : 400
site : 420
site : 440
site : 460
site : 500
 
Updated ParamsGlobals for event 03_samp to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  03_samp_50_to_600
site : 20
site : 60
site : 80
site : 120
site : 140
site : 160
site : 180
site : 200
site : 220
site : 260
site : 320
site : 400
site : 420
site : 440
site : 460
site : 500
 
Updated ParamsGlobals for event 05_first_raise to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.6
POST_DUR_CALC  =  -0.05
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  05_first_raise_-600_to_-50
site : 20
site : 60
site : 80
site : 120
site : 140
site : 160
site : 180
site : 200
site : 220
site : 260
site : 320
site : 400
site : 420
site : 440
site : 460
site : 500
 
Updated ParamsGlobals for event 06_on_strokeidx_0 to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.1
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  06_on_strokeidx_0_-100_to_600
site : 20
site : 60
site : 80
site : 120
site : 140
site : 160
site : 180
site : 200
site : 220
site : 260
site : 320
site : 400
site : 420
site : 440
site : 460
site : 500
 
Updated ParamsGlobals for event 08_doneb to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.5
POST_DUR_CALC  =  0.3
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  08_doneb_-500_to_300
site : 20
site : 60
site : 80
site : 120
site : 140
site : 160
site : 180
site : 200
site : 220
site : 260
site : 320
site : 400
site : 420
site : 440
site : 460
site : 500
 
Updated ParamsGlobals for event 09_post to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  09_post_50_to_600
site : 20
site : 60
site : 80
site : 120
site : 140
site : 160
site : 180
site : 200
site : 220
site : 260
site : 320
site : 400
site : 420
site : 440
site : 460
site : 500
 
Updated ParamsGlobals for event 10_reward_all to:
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  0.05
POST_DUR_CALC  =  0.6
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
DOING THIS EVENT:  10_reward_all_50_to_600
site : 20
site : 60
site : 80
site : 120
site : 140
site : 160
site : 180
site : 200
site : 220
site : 260
site : 320
site : 400
site : 420
site : 440
site : 460
site : 500
SAving:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/df_var.pkl
SAving:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/list_eventwindow_event.pkl
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables
var -- vars_others:  epoch  ---  ['seqc_0_loc']
var -- vars_others:  epoch  ---  ['seqc_0_shape']
var -- vars_others:  epoch  ---  ['seqc_nstrokes_beh']
var -- vars_others:  epoch  ---  ['seqc_0_loc', 'seqc_0_shape']
var -- vars_others:  epoch  ---  ['seqc_0_loc', 'seqc_nstrokes_beh']
var -- vars_others:  epoch  ---  ['seqc_0_shape', 'seqc_nstrokes_beh']
var -- vars_others:  epoch  ---  ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-epoch-vs-varothers-levothers-levvar.txt
var -- vars_others:  seqc_0_loc  ---  ['epoch']
var -- vars_others:  seqc_0_loc  ---  ['seqc_0_shape']
var -- vars_others:  seqc_0_loc  ---  ['seqc_nstrokes_beh']
var -- vars_others:  seqc_0_loc  ---  ['epoch', 'seqc_0_shape']
var -- vars_others:  seqc_0_loc  ---  ['epoch', 'seqc_nstrokes_beh']
var -- vars_others:  seqc_0_loc  ---  ['seqc_0_shape', 'seqc_nstrokes_beh']
var -- vars_others:  seqc_0_loc  ---  ['epoch', 'seqc_0_shape', 'seqc_nstrokes_beh']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-seqc_0_loc-vs-varothers-levothers-levvar.txt
var -- vars_others:  seqc_0_shape  ---  ['epoch']
var -- vars_others:  seqc_0_shape  ---  ['seqc_0_loc']
var -- vars_others:  seqc_0_shape  ---  ['seqc_nstrokes_beh']
var -- vars_others:  seqc_0_shape  ---  ['epoch', 'seqc_0_loc']
var -- vars_others:  seqc_0_shape  ---  ['epoch', 'seqc_nstrokes_beh']
var -- vars_others:  seqc_0_shape  ---  ['seqc_0_loc', 'seqc_nstrokes_beh']
var -- vars_others:  seqc_0_shape  ---  ['epoch', 'seqc_0_loc', 'seqc_nstrokes_beh']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-seqc_0_shape-vs-varothers-levothers-levvar.txt
var -- vars_others:  seqc_nstrokes_beh  ---  ['epoch']
var -- vars_others:  seqc_nstrokes_beh  ---  ['seqc_0_loc']
var -- vars_others:  seqc_nstrokes_beh  ---  ['seqc_0_shape']
var -- vars_others:  seqc_nstrokes_beh  ---  ['epoch', 'seqc_0_loc']
var -- vars_others:  seqc_nstrokes_beh  ---  ['epoch', 'seqc_0_shape']
var -- vars_others:  seqc_nstrokes_beh  ---  ['seqc_0_loc', 'seqc_0_shape']
var -- vars_others:  seqc_nstrokes_beh  ---  ['epoch', 'seqc_0_loc', 'seqc_0_shape']
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/snippets_check_conjunctions_variables/ncounts-seqc_nstrokes_beh-vs-varothers-levothers-levvar.txt
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation
** Plotting summarystats
Saving at: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation
Found this var:  epoch
Found this var_others:  ('seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh')
Aggregating dataframe over all othervars ...
Plotting ...
Plotting for specific single other var: seqc_0_loc...
Plotting for specific single other var: seqc_0_shape...
Plotting for specific single other var: seqc_nstrokes_beh...
** Plotting heatmaps
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation_heatmap
Saving to:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation_heatmap/brainschem-event-val-modulation_subgroups.pdf
Saving to:  /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/modulation_heatmap/brainschem-event-val-modulation_subgroups-NOMOTOR.pdf
** Plotting example strokes
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Trials.pkl
Plotting ..  ((-1, -1), 'V-2-4-0', 3)
Plotting ..  ((-1, 1), 'V-2-4-0', 3)
Plotting ..  ((-1, 0), 'V-2-4-0', 3)
** Making plots for this event_window: 
09_post_50_to_600
Saving this event, 09_post_50_to_600, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/09_post_50_to_600
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/09_post_50_to_600/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/09_post
** Making plots for this event_window: 
05_first_raise_-600_to_-50
Saving this event, 05_first_raise_-600_to_-50, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/05_first_raise_-600_to_-50
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/05_first_raise_-600_to_-50/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/05_first_raise
** Making plots for this event_window: 
08_doneb_-500_to_300
Saving this event, 08_doneb_-500_to_300, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/08_doneb_-500_to_300
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/08_doneb_-500_to_300/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/08_doneb
** Making plots for this event_window: 
03_samp_-600_to_-50
Saving this event, 03_samp_-600_to_-50, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/03_samp_-600_to_-50
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/03_samp_-600_to_-50/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.2, the latest is 0.5.3.
Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.
  return warn(
/gorilla1/code/pythonlib/pythonlib/tools/snstools.py:12: UserWarning: FixedFormatter should only be used together with FixedLocator
  a.set_xticklabels(a.get_xticklabels(), rotation=rotation,
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/03_samp
** Making plots for this event_window: 
03_samp_50_to_600
Saving this event, 03_samp_50_to_600, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/03_samp_50_to_600
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/03_samp_50_to_600/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/03_samp
** Making plots for this event_window: 
06_on_strokeidx_0_-100_to_600
Saving this event, 06_on_strokeidx_0_-100_to_600, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/06_on_strokeidx_0_-100_to_600
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/06_on_strokeidx_0_-100_to_600/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/06_on_strokeidx_0
** Making plots for this event_window: 
10_reward_all_50_to_600
Saving this event, 10_reward_all_50_to_600, to /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/10_reward_all_50_to_600
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/SV_r2_maxtime_1way_mshuff/EACH_EVENT/10_reward_all_50_to_600/modulation_v2
** Plotting summarystats
** Plotting raster + sm fr: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_seqc_0_loc_seqc_0_shape_seqc_nstrokes_beh/rasters/10_reward_all
Saving to: /gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff
starting sites:  355
starting sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 24, 27, 29, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 71, 73, 74, 77, 78, 79, 80, 81, 82, 87, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 104, 107, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 130, 131, 132, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 213, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 233, 235, 237, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 288, 290, 294, 296, 297, 301, 302, 303, 304, 310, 312, 314, 316, 318, 320, 324, 327, 331, 332, 333, 334, 338, 345, 346, 347, 349, 351, 352, 353, 355, 366, 369, 371, 372, 373, 374, 375, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 471, 472, 473, 474, 475, 477, 478, 479, 481, 483, 484, 485, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512]
For percentile 10, using this threshold: 3.333271041101069
sites_good:  355
sites_bad:  40
Updates self.Sites
ending sites:  355
ending sites:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 24, 27, 29, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 71, 73, 74, 77, 78, 79, 80, 81, 82, 87, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 104, 107, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 130, 131, 132, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 198, 199, 200, 201, 202, 203, 205, 206, 207, 209, 210, 211, 213, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 233, 235, 237, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 288, 290, 294, 296, 297, 301, 302, 303, 304, 310, 312, 314, 316, 318, 320, 324, 327, 331, 332, 333, 334, 338, 345, 346, 347, 349, 351, 352, 353, 355, 366, 369, 371, 372, 373, 374, 375, 384, 385, 386, 387, 388, 389, 390, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 410, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 425, 429, 430, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 445, 447, 449, 450, 451, 452, 453, 454, 457, 459, 460, 461, 462, 463, 464, 465, 467, 468, 469, 471, 472, 473, 474, 475, 477, 478, 479, 481, 483, 484, 485, 488, 489, 490, 491, 492, 493, 494, 495, 497, 498, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512]
Updated self.ParamsGlobals:
n_min_trials_per_level  =  8
lenient_allow_data_if_has_n_levels  =  2
PRE_DUR_CALC  =  -0.75
POST_DUR_CALC  =  0.75
list_events  =  ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur  =  [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur  =  [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
TODO: do fr scalar computation only once! takes too much time.
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/df_var.pkl
Searching for already-done df_var at this path:
/gorilla1/analyses/recordings/main/anova/bytrial/MULT_SESS/Pancho-220827-0/rulesw/var_by_varsother/VAR_epoch-OV_epochset/SV_r2_maxtime_1way_mshuff/df_var.pkl
df_var doesnt exist...!
COMPUTING df_var!!!
DOing these! ...
list_events ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all']
list_pre_dur [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05]
list_post_dur [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6]
WILL SKIP THESE EVENTS...
[]
Running grouping_print_n_samples...
These are the existing columns
Index(['trialcode', 'chan', 'event_aligned', '_event_aligned', 'spike_times',
       'trial_neural', 'event_time', 'fr_sm', 'probe', 'taskgroup',
       'character', 'epoch', 'task_kind', 'supervision_stage_concise',
       'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc',
       'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc',
       'seqc_3_shape', 'seqc_3_loc', 'gridsize', 'event', 'fr_sm_times',
       'fr_sm_sqrt', 'session_idx', 'fr_scalar_raw'],
      dtype='object')
failed searchign for these columns:
['chan', 'event', 'epoch', 'epochset']
Traceback (most recent call last):
  File "analy_anova_plot.py", line 115, in <module>
    SP.modulationgood_compute_plot_ALL(var, vars_conjuction, 
  File "/gorilla1/code/neuralmonkey/neuralmonkey/classes/snippets.py", line 1412, in modulationgood_compute_plot_ALL
    df_var, list_eventwindow_event = self.modulationgood_compute_wrapper(var, 
  File "/gorilla1/code/neuralmonkey/neuralmonkey/classes/snippets.py", line 1756, in modulationgood_compute_wrapper
    raise err
  File "/gorilla1/code/neuralmonkey/neuralmonkey/classes/snippets.py", line 1750, in modulationgood_compute_wrapper
    n_min, n_max = grouping_count_n_samples_quick(self.DfScalar, list_grp)
  File "/gorilla1/code/pythonlib/pythonlib/tools/pandastools.py", line 1315, in grouping_count_n_samples_quick
    dftmp = df.groupby(list_groupouter_grouping_vars).count()
  File "/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/core/frame.py", line 7718, in groupby
    return DataFrameGroupBy(
  File "/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/core/groupby/groupby.py", line 882, in __init__
    grouper, exclusions, obj = get_grouper(
  File "/home/lucast4/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/core/groupby/grouper.py", line 882, in get_grouper
    raise KeyError(gpr)
KeyError: 'epochset'
./_analy_anova_script.sh: line 6: syntax error: unexpected end of file
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220827*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
session:  0
1
Beh Sessions that exist on this date:  {220827: [(1, 'shapedirsequence1b')]}
taking this beh session: 1
Loading these beh expts: ['shapedirsequence1b']
Loading these beh sessions: [1]
Loading this neural session: 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220827*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
{'filename_components_hyphened': ['Pancho', '220827', '144815'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/220827'], 'basedirs_filenames': ['220827', 'Pancho-220827-144815'], 'filename_final_ext': 'Pancho-220827-144815', 'filename_final_noext': 'Pancho-220827-144815'}
FOund this path for spikes:  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/spikes_tdt_quick-4.5
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/Pancho-220827-144815
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/spikes_tdt_quick-4.5
final_dir_name  --  Pancho-220827-144815
time  --  144815
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/220827.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
o  1 78.24063331702274
o  2 91.65475607109548
o  3 82.6858934310034
o  4 76.50389594045909
o  5 93.06556964733463
o  6 85.77488834318065
o  7 117.77782036707654
o  8 78.05888096954084
o  9 109.60370006863914
o  10 99.82946428939067
o  11 276.6104192586103
o  12 108.15722115669996
o  13 285.13363360205676
o  14 90.30669870466514
o  15 132.67867053406184
o  16 113.45661807202906
o  17 76.53774701172297
o  18 111.44903177387316
o  19 141.84158967134718
o  20 110.13212114248236
o  21 129.662608026441
o  22 131.23411560740223
-  23 59.019189375055134
o  24 76.59424845272005
-  25 59.61587735340458
o  26 449.6442160824401
o  27 159.52470640838584
o  28 76.31703145042641
o  29 197.23512744366343
o  30 86.2226963159088
o  31 179.29690465294863
o  32 114.01467544168808
o  33 147.2482314495093
o  34 107.83939901177655
-  35 53.5722646354342
o  36 351.68574218703435
o  37 81.16013785333853
o  38 300.64280750323087
o  39 122.45653359738769
o  40 291.7908413211175
o  41 89.61758391747517
o  42 88.62039595152291
o  43 223.51818381375605
o  44 218.14961311392835
o  45 960.4380442964606
-  46 63.427138259270826
o  47 209.22238123500338
-  48 49.19629739198463
o  49 100.20637080793422
o  50 78.08808358760434
o  51 229.91293315040278
o  52 86.59389239157704
o  53 136.92010574976447
o  54 88.04685659665424
o  55 1161.5874274524708
-  56 66.85814513077185
o  57 127.5940355398292
o  58 145.13313070871556
o  59 131.1436064945172
o  60 97.9764248043306
o  61 119.83668572853166
o  62 118.29832202463653
o  63 177.05015741763614
o  64 120.72088924577793
-  65 69.18030037526087
o  66 137.26794206077102
o  67 179.83542731331931
o  68 149.42521172986508
o  69 108.12000675175952
-  70 60.40395984436054
o  71 107.65460603834595
o  72 84.4199989778339
o  73 101.72301188651554
o  74 81.41570684329454
o  75 74.34173357101886
-  76 58.891878384788285
o  77 74.678992562234
o  78 150.66634513173693
o  79 73.33806606942481
o  80 78.30361075157283
o  81 79.06644795032847
o  82 75.7683431215709
o  83 73.76499057700349
-  84 69.37295150228653
-  85 64.57617426329416
o  86 86.4076906384444
o  87 70.19142920086685
-  88 62.05785790926666
o  89 124.46045233767163
o  90 95.14329841133495
o  91 80.75461054633274
o  92 73.16916687450211
o  93 79.2151442272132
o  94 76.27990029466346
o  95 92.5095145058036
o  96 71.13301954733629
o  97 221.28915242686472
o  98 187.73568047239343
o  99 121.00600919866702
o  100 114.42264976903388
o  101 100.53021771311033
o  102 194.79702493608713
-  103 64.75408519222074
o  104 72.83572328137586
o  105 390.0394692928647
o  106 86.62428282689726
o  107 77.45786944103929
-  108 69.88647777195239
-  109 52.14264016166853
-  110 55.74328313839451
o  111 71.0074113856272
o  112 250.13274927715784
o  113 80.91012616843018
o  114 83.45716980102748
o  115 164.5748501861207
o  116 144.6149733359973
o  117 161.11974930025278
o  118 72.06022181530989
o  119 152.4364820143961
o  120 110.63360889973374
o  121 80.93098306812523
o  122 115.51832888454192
o  123 103.78977998692372
o  124 118.87837124143971
-  125 57.61461179043381
o  126 73.3532874037594
o  127 85.818007928726
o  128 71.57612224856915
-  129 46.969044067670985
o  130 121.84364324057238
o  131 81.50701830911808
o  132 471.50058929896784
o  133 77.68082681382458
o  134 188.4764477753988
o  135 73.53891551260612
o  136 107.0645058236936
o  137 76.76730135392572
o  138 298.14228831190485
o  139 102.25526271698973
o  140 89.21331766175281
o  141 105.71112559908885
o  142 101.99452967262296
o  143 97.37816078433853
o  144 132.3532955776167
o  145 112.4569761859304
o  146 130.25609610591346
o  147 113.42665465202784
o  148 73.40804209231011
-  149 63.9114868211178
o  150 106.16762525039394
o  151 100.26164124205661
-  152 69.15281509031615
o  153 92.27497824143393
o  154 178.4116346960367
o  155 70.28013495950873
-  156 57.150434458238486
o  157 80.95500355430886
o  158 87.5735891852688
o  159 107.62639064783275
o  160 131.1970850420795
o  161 104.29268531709623
o  162 148.91718098866204
o  163 136.98079886388783
o  164 71.04307455935304
o  165 133.99026378791189
o  166 92.86510339432229
o  167 124.1210188752242
-  168 50.187662851958976
o  169 73.980644389814
o  170 95.14945558761762
o  171 135.06008780379312
o  172 101.50355139772103
o  173 276.6840457738475
o  174 92.23142948828485
o  175 84.95520161025192
-  176 67.96174034140827
o  177 187.87227112083747
o  178 104.64204601327548
o  179 155.68895593478356
o  180 71.91814782574605
o  181 162.13119850583098
o  182 165.41369458910586
-  183 63.47108168883206
o  184 316.61490376015064
-  185 31.9347557764743
o  186 99.34602357338986
o  187 119.24801144857493
o  188 76.78364477697411
o  189 79.40763415196379
o  190 78.45860271445865
o  191 116.89705538202979
-  192 66.21701692197902
o  193 101.98281789507917
o  194 133.4077692751238
o  195 76.68121663003339
-  196 57.7896457265475
-  197 68.32829407303298
o  198 77.39698839521516
o  199 72.55616241658875
o  200 151.36900932626548
o  201 120.83240035737727
o  202 95.82046539926243
o  203 118.89577751629041
o  204 82.07194466277397
o  205 101.09086475448267
o  206 256.23440184101474
o  207 151.34154276470736
o  208 99.22259911949004
o  209 70.41931658911145
o  210 94.17534131527263
o  211 100.95047729482421
-  212 55.34953019202737
o  213 119.2466771260316
-  214 61.837644725181505
o  215 80.85453073218578
-  216 65.42982044525006
o  217 102.73856374995985
o  218 97.31723791812603
o  219 78.7511332916617
o  220 92.95790457731091
o  221 89.93188602438795
o  222 94.15558291923972
o  223 78.64139548473577
o  224 86.37484214283648
o  225 80.33455445423735
o  226 84.74069539605561
o  227 208.16971130820392
o  228 90.58060074724953
-  229 53.304728587198404
o  230 82.94731558888016
o  231 109.55009213173135
-  232 43.24571765029687
o  233 92.27763873098938
o  234 81.98620077614589
o  235 144.96753204217302
-  236 62.68523471717409
o  237 100.30362795724888
-  238 67.19066919611718
o  239 83.16444859033741
-  240 65.0246325103204
o  241 80.63933939079939
o  242 108.19568088869619
o  243 74.45855178942415
o  244 79.12666934661615
o  245 77.27341349339676
o  246 129.5802943845346
o  247 110.14279811497344
o  248 127.36810749930956
o  249 131.93994524965805
o  250 76.42251696032181
o  251 94.83765644234737
o  252 108.11330584707666
o  253 150.66731113827674
o  254 102.45195380477999
o  255 152.52895332477377
o  256 117.49187346690708
o  257 183.15227892913683
o  258 145.45448008506318
o  259 84.45882742892518
o  260 190.92844787804114
o  261 110.73674706205347
o  262 107.10661740531336
o  263 81.42073424630321
o  264 141.62358602829698
o  265 163.7454755013793
o  266 71.35631357947078
o  267 478.24666512678925
o  268 71.40588865747767
o  269 90.4837238360232
o  270 288.6734126447294
o  271 135.68707156891563
o  272 267.97481931510845
o  273 151.19160988452197
o  274 91.00963559141165
o  275 105.90103862816977
o  276 91.51387888511918
o  277 121.89207262399859
o  278 206.79918683641765
o  279 133.60921042611727
o  280 80.17549184621699
o  281 103.8289549611646
o  282 90.37812715391075
o  283 85.70758988586164
o  284 87.05752088144067
-  285 67.91261432606788
o  286 85.58854549354919
o  287 71.3486935951809
o  288 88.30475663685483
-  289 69.33176511394132
o  290 82.96549831941812
-  291 67.15347010590013
-  292 42.75824507229686
-  293 59.0752657117632
o  294 133.72995015398357
-  295 63.405517145131334
o  296 125.83808176728945
o  297 77.04825743229686
-  298 64.32087819166718
-  299 54.191602005741515
-  300 61.70697064488995
o  301 94.10195694528664
o  302 82.03076876386461
o  303 182.82464745684405
o  304 116.80392346000373
-  305 64.5468582718571
o  306 73.33176272312075
-  307 65.89037201308763
-  308 66.36249294843495
-  309 67.79026299622865
o  310 86.30312974142619
-  311 67.76190409284582
o  312 112.84216725517402
o  313 77.74818272120793
o  314 140.07171179055604
-  315 65.42598659278882
o  316 84.32388260632946
o  317 82.23505818925888
o  318 86.61272408539936
-  319 67.11593908942022
o  320 118.5383411715159
-  321 68.30099323894439
-  322 56.89960700869506
o  323 110.03719006430347
o  324 94.24183377608915
o  325 78.66410364948665
o  326 75.98459412676384
o  327 118.00160185530804
-  328 54.27339459617557
o  329 70.68850026235783
o  330 81.10232936426928
o  331 109.93189395762238
o  332 77.62480475327175
o  333 97.08224664961745
o  334 94.83684086627036
-  335 59.274073683191276
-  336 68.96147814664305
-  337 56.28382680979121
o  338 76.32501589614377
-  339 65.20131491652755
-  340 61.75857107844968
-  341 67.75073007161419
-  342 60.552224151619484
o  343 73.61720587939163
-  344 51.08567927458971
o  345 114.25884846077278
o  346 94.41924398620692
o  347 70.08694711240969
o  348 129.0458571516705
o  349 79.47204498306492
-  350 61.123530975286485
o  351 130.55494270636046
o  352 107.29811379050881
o  353 90.71019897088591
-  354 66.76676995715891
o  355 77.58323392794064
-  356 69.18787058571198
-  357 44.15532015336466
o  358 87.99657587848928
-  359 55.34754383346959
o  360 70.05876691938457
-  361 61.951045559710906
o  362 81.37170817238983
-  363 66.52298277795654
o  364 84.37027559891672
-  365 50.57404678228184
o  366 82.90965944032492
-  367 48.17163122880793
o  368 74.24298177858736
o  369 80.80229863472385
-  370 65.20572865896483
o  371 94.27931514796873
o  372 89.03832927771005
o  373 81.34695330174614
o  374 85.46318321550866
o  375 79.52434999314684
-  376 69.6613595847901
-  377 61.21075921170375
-  378 60.360699859520786
-  379 55.173891222677774
o  380 88.17121848802962
-  381 53.450151438557086
o  382 76.89892757742673
-  383 61.9306935479186
o  384 80.06298638868593
o  385 318.7617705931003
o  386 190.42624327586108
o  387 216.25346973672967
o  388 95.58238523941182
o  389 236.7866380978763
o  390 162.62761687065233
-  391 48.13818484165222
-  392 65.4077771086455
o  393 91.74794046807402
o  394 200.82897763266308
o  395 106.94082451282539
o  396 165.81672418960906
o  397 85.88091108799945
o  398 89.15134242396498
o  399 89.40510655841766
o  400 124.10633698585626
o  401 178.61973462687212
o  402 171.6692901375936
o  403 209.2891763356477
o  404 175.39085402565578
o  405 753.4067549257433
o  406 91.15599210501175
o  407 112.02876163895152
o  408 181.98749732987855
-  409 51.96860062485098
o  410 517.2650792782459
-  411 67.81834743579776
-  412 68.32869870381992
o  413 256.9357267743892
o  414 239.0228780285057
o  415 137.32342262851216
o  416 152.98473880575773
o  417 105.35408833370579
o  418 80.51888647685405
o  419 80.68910529818268
o  420 87.73824307387541
o  421 71.2557075087756
o  422 97.87757549591379
o  423 84.2629963500589
o  424 70.1796018626779
o  425 85.9310413883969
-  426 65.217224377204
-  427 64.92883725943166
-  428 29.41281740772429
o  429 94.94943891710356
o  430 89.42593765483417
-  431 69.67697721883556
-  432 49.548049012380766
o  433 205.29931062995783
o  434 109.84309017619353
o  435 135.5734286684782
o  436 176.57430627853427
o  437 120.35241502549353
o  438 119.59115072618124
o  439 132.20225354451446
o  440 79.54364416645808
o  441 322.2335220942295
o  442 82.148775369314
o  443 582.0270579166296
-  444 36.8269711608511
o  445 79.13064873931012
-  446 35.55283780314941
o  447 119.93644538092704
-  448 32.34644927125375
o  449 98.27939773782892
o  450 174.2833322602906
o  451 79.16331295190098
o  452 139.46968425837707
o  453 109.82339141362802
o  454 111.67980902676493
o  455 87.23318178110883
-  456 69.96676700987841
o  457 163.31040996996612
o  458 71.93719945961539
o  459 177.35246961816173
o  460 124.0717640833066
o  461 210.2038031796403
o  462 215.9689246197291
o  463 179.28644451426413
o  464 144.52284792220635
o  465 131.16452480981425
-  466 54.80607583645288
o  467 159.48366397460254
o  468 129.00872477158075
o  469 106.43573930171108
-  470 68.94193801493921
o  471 211.30332562918548
o  472 439.8942305749391
o  473 242.4171156458134
o  474 84.73898327288883
o  475 119.69523767173851
-  476 55.37006272698848
o  477 159.60150866138696
o  478 110.70553624375907
o  479 97.74692322886254
o  480 85.26464615588102
o  481 103.48604821952902
-  482 36.038702291305626
o  483 125.71091752287077
o  484 115.95919654926263
o  485 156.82626972499335
-  486 61.796567547348914
-  487 58.47883248165085
o  488 89.23812508316287
o  489 113.01230771877846
o  490 252.38942301570626
o  491 100.96516202115673
o  492 232.19379701333025
o  493 208.3783298800812
o  494 94.7273184425464
o  495 130.67445136685862
-  496 66.62208984708377
o  497 129.19695080108892
o  498 92.19606354402313
-  499 68.51373318213246
o  500 244.2474894877714
o  501 110.32029240423206
o  502 128.01795911290745
o  503 99.74778388744036
o  504 114.65771334177721
o  505 99.51138180679382
o  506 117.96246474390264
-  507 35.221439935774654
o  508 92.75557015819122
o  509 96.80716328741025
o  510 87.29584539063985
-  511 65.53660725867462
o  512 104.67071733503501
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Trials.pkl
** SKIPPING EXTRACTION, since was able to load snippets, for: 
(animal, DATE, which_level, ANALY_VER, session)
Pancho 220827 trial ruleswERROR 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220827*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
session:  0
1
Beh Sessions that exist on this date:  {220827: [(1, 'shapedirsequence1b')]}
taking this beh session: 1
Loading these beh expts: ['shapedirsequence1b']
Loading these beh sessions: [1]
Loading this neural session: 0
Searching using this string:
/mnt/hopfield_data01/ltian/recordings/*Pancho*/*220827*/**
Found this many paths:
1
---
/mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
{'filename_components_hyphened': ['Pancho', '220827', '144815'], 'basedirs': ['/mnt/hopfield_data01/ltian/recordings/Pancho', '/mnt/hopfield_data01/ltian/recordings/Pancho/220827'], 'basedirs_filenames': ['220827', 'Pancho-220827-144815'], 'filename_final_ext': 'Pancho-220827-144815', 'filename_final_noext': 'Pancho-220827-144815'}
FOund this path for spikes:  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/spikes_tdt_quick-4.5
== PATHS for this expt: 
raws  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815
tank  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/Pancho-220827-144815
spikes  --  /mnt/hopfield_data01/ltian/recordings/Pancho/220827/Pancho-220827-144815/spikes_tdt_quick-4.5
final_dir_name  --  Pancho-220827-144815
time  --  144815
pathbase_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815
tank_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_tank.pkl
spikes_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_spikes.pkl
datall_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/data_datall.pkl
events_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/events_photodiode.pkl
mapper_st2dat_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/mapper_st2dat.pkl
figs_local  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/figs
metadata_units  --  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units
cached_dir  --  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/cached
Found! metada path :  /home/lucast4/code/neuralmonkey/neuralmonkey/metadat/units/220827.yaml
updating self.SitesDirty with:  ('sites_garbage', 'sites_error_spikes', 'sites_low_spk_magn')
[_sitesdirty_update] skipping! since did not find:  sites_error_spikes
Printing whether spikes gotten (o) or not (-) because of spike peak to trough
o  1 78.24063331702274
o  2 91.65475607109548
o  3 82.6858934310034
o  4 76.50389594045909
o  5 93.06556964733463
o  6 85.77488834318065
o  7 117.77782036707654
o  8 78.05888096954084
o  9 109.60370006863914
o  10 99.82946428939067
o  11 276.6104192586103
o  12 108.15722115669996
o  13 285.13363360205676
o  14 90.30669870466514
o  15 132.67867053406184
o  16 113.45661807202906
o  17 76.53774701172297
o  18 111.44903177387316
o  19 141.84158967134718
o  20 110.13212114248236
o  21 129.662608026441
o  22 131.23411560740223
-  23 59.019189375055134
o  24 76.59424845272005
-  25 59.61587735340458
o  26 449.6442160824401
o  27 159.52470640838584
o  28 76.31703145042641
o  29 197.23512744366343
o  30 86.2226963159088
o  31 179.29690465294863
o  32 114.01467544168808
o  33 147.2482314495093
o  34 107.83939901177655
-  35 53.5722646354342
o  36 351.68574218703435
o  37 81.16013785333853
o  38 300.64280750323087
o  39 122.45653359738769
o  40 291.7908413211175
o  41 89.61758391747517
o  42 88.62039595152291
o  43 223.51818381375605
o  44 218.14961311392835
o  45 960.4380442964606
-  46 63.427138259270826
o  47 209.22238123500338
-  48 49.19629739198463
o  49 100.20637080793422
o  50 78.08808358760434
o  51 229.91293315040278
o  52 86.59389239157704
o  53 136.92010574976447
o  54 88.04685659665424
o  55 1161.5874274524708
-  56 66.85814513077185
o  57 127.5940355398292
o  58 145.13313070871556
o  59 131.1436064945172
o  60 97.9764248043306
o  61 119.83668572853166
o  62 118.29832202463653
o  63 177.05015741763614
o  64 120.72088924577793
-  65 69.18030037526087
o  66 137.26794206077102
o  67 179.83542731331931
o  68 149.42521172986508
o  69 108.12000675175952
-  70 60.40395984436054
o  71 107.65460603834595
o  72 84.4199989778339
o  73 101.72301188651554
o  74 81.41570684329454
o  75 74.34173357101886
-  76 58.891878384788285
o  77 74.678992562234
o  78 150.66634513173693
o  79 73.33806606942481
o  80 78.30361075157283
o  81 79.06644795032847
o  82 75.7683431215709
o  83 73.76499057700349
-  84 69.37295150228653
-  85 64.57617426329416
o  86 86.4076906384444
o  87 70.19142920086685
-  88 62.05785790926666
o  89 124.46045233767163
o  90 95.14329841133495
o  91 80.75461054633274
o  92 73.16916687450211
o  93 79.2151442272132
o  94 76.27990029466346
o  95 92.5095145058036
o  96 71.13301954733629
o  97 221.28915242686472
o  98 187.73568047239343
o  99 121.00600919866702
o  100 114.42264976903388
o  101 100.53021771311033
o  102 194.79702493608713
-  103 64.75408519222074
o  104 72.83572328137586
o  105 390.0394692928647
o  106 86.62428282689726
o  107 77.45786944103929
-  108 69.88647777195239
-  109 52.14264016166853
-  110 55.74328313839451
o  111 71.0074113856272
o  112 250.13274927715784
o  113 80.91012616843018
o  114 83.45716980102748
o  115 164.5748501861207
o  116 144.6149733359973
o  117 161.11974930025278
o  118 72.06022181530989
o  119 152.4364820143961
o  120 110.63360889973374
o  121 80.93098306812523
o  122 115.51832888454192
o  123 103.78977998692372
o  124 118.87837124143971
-  125 57.61461179043381
o  126 73.3532874037594
o  127 85.818007928726
o  128 71.57612224856915
-  129 46.969044067670985
o  130 121.84364324057238
o  131 81.50701830911808
o  132 471.50058929896784
o  133 77.68082681382458
o  134 188.4764477753988
o  135 73.53891551260612
o  136 107.0645058236936
o  137 76.76730135392572
o  138 298.14228831190485
o  139 102.25526271698973
o  140 89.21331766175281
o  141 105.71112559908885
o  142 101.99452967262296
o  143 97.37816078433853
o  144 132.3532955776167
o  145 112.4569761859304
o  146 130.25609610591346
o  147 113.42665465202784
o  148 73.40804209231011
-  149 63.9114868211178
o  150 106.16762525039394
o  151 100.26164124205661
-  152 69.15281509031615
o  153 92.27497824143393
o  154 178.4116346960367
o  155 70.28013495950873
-  156 57.150434458238486
o  157 80.95500355430886
o  158 87.5735891852688
o  159 107.62639064783275
o  160 131.1970850420795
o  161 104.29268531709623
o  162 148.91718098866204
o  163 136.98079886388783
o  164 71.04307455935304
o  165 133.99026378791189
o  166 92.86510339432229
o  167 124.1210188752242
-  168 50.187662851958976
o  169 73.980644389814
o  170 95.14945558761762
o  171 135.06008780379312
o  172 101.50355139772103
o  173 276.6840457738475
o  174 92.23142948828485
o  175 84.95520161025192
-  176 67.96174034140827
o  177 187.87227112083747
o  178 104.64204601327548
o  179 155.68895593478356
o  180 71.91814782574605
o  181 162.13119850583098
o  182 165.41369458910586
-  183 63.47108168883206
o  184 316.61490376015064
-  185 31.9347557764743
o  186 99.34602357338986
o  187 119.24801144857493
o  188 76.78364477697411
o  189 79.40763415196379
o  190 78.45860271445865
o  191 116.89705538202979
-  192 66.21701692197902
o  193 101.98281789507917
o  194 133.4077692751238
o  195 76.68121663003339
-  196 57.7896457265475
-  197 68.32829407303298
o  198 77.39698839521516
o  199 72.55616241658875
o  200 151.36900932626548
o  201 120.83240035737727
o  202 95.82046539926243
o  203 118.89577751629041
o  204 82.07194466277397
o  205 101.09086475448267
o  206 256.23440184101474
o  207 151.34154276470736
o  208 99.22259911949004
o  209 70.41931658911145
o  210 94.17534131527263
o  211 100.95047729482421
-  212 55.34953019202737
o  213 119.2466771260316
-  214 61.837644725181505
o  215 80.85453073218578
-  216 65.42982044525006
o  217 102.73856374995985
o  218 97.31723791812603
o  219 78.7511332916617
o  220 92.95790457731091
o  221 89.93188602438795
o  222 94.15558291923972
o  223 78.64139548473577
o  224 86.37484214283648
o  225 80.33455445423735
o  226 84.74069539605561
o  227 208.16971130820392
o  228 90.58060074724953
-  229 53.304728587198404
o  230 82.94731558888016
o  231 109.55009213173135
-  232 43.24571765029687
o  233 92.27763873098938
o  234 81.98620077614589
o  235 144.96753204217302
-  236 62.68523471717409
o  237 100.30362795724888
-  238 67.19066919611718
o  239 83.16444859033741
-  240 65.0246325103204
o  241 80.63933939079939
o  242 108.19568088869619
o  243 74.45855178942415
o  244 79.12666934661615
o  245 77.27341349339676
o  246 129.5802943845346
o  247 110.14279811497344
o  248 127.36810749930956
o  249 131.93994524965805
o  250 76.42251696032181
o  251 94.83765644234737
o  252 108.11330584707666
o  253 150.66731113827674
o  254 102.45195380477999
o  255 152.52895332477377
o  256 117.49187346690708
o  257 183.15227892913683
o  258 145.45448008506318
o  259 84.45882742892518
o  260 190.92844787804114
o  261 110.73674706205347
o  262 107.10661740531336
o  263 81.42073424630321
o  264 141.62358602829698
o  265 163.7454755013793
o  266 71.35631357947078
o  267 478.24666512678925
o  268 71.40588865747767
o  269 90.4837238360232
o  270 288.6734126447294
o  271 135.68707156891563
o  272 267.97481931510845
o  273 151.19160988452197
o  274 91.00963559141165
o  275 105.90103862816977
o  276 91.51387888511918
o  277 121.89207262399859
o  278 206.79918683641765
o  279 133.60921042611727
o  280 80.17549184621699
o  281 103.8289549611646
o  282 90.37812715391075
o  283 85.70758988586164
o  284 87.05752088144067
-  285 67.91261432606788
o  286 85.58854549354919
o  287 71.3486935951809
o  288 88.30475663685483
-  289 69.33176511394132
o  290 82.96549831941812
-  291 67.15347010590013
-  292 42.75824507229686
-  293 59.0752657117632
o  294 133.72995015398357
-  295 63.405517145131334
o  296 125.83808176728945
o  297 77.04825743229686
-  298 64.32087819166718
-  299 54.191602005741515
-  300 61.70697064488995
o  301 94.10195694528664
o  302 82.03076876386461
o  303 182.82464745684405
o  304 116.80392346000373
-  305 64.5468582718571
o  306 73.33176272312075
-  307 65.89037201308763
-  308 66.36249294843495
-  309 67.79026299622865
o  310 86.30312974142619
-  311 67.76190409284582
o  312 112.84216725517402
o  313 77.74818272120793
o  314 140.07171179055604
-  315 65.42598659278882
o  316 84.32388260632946
o  317 82.23505818925888
o  318 86.61272408539936
-  319 67.11593908942022
o  320 118.5383411715159
-  321 68.30099323894439
-  322 56.89960700869506
o  323 110.03719006430347
o  324 94.24183377608915
o  325 78.66410364948665
o  326 75.98459412676384
o  327 118.00160185530804
-  328 54.27339459617557
o  329 70.68850026235783
o  330 81.10232936426928
o  331 109.93189395762238
o  332 77.62480475327175
o  333 97.08224664961745
o  334 94.83684086627036
-  335 59.274073683191276
-  336 68.96147814664305
-  337 56.28382680979121
o  338 76.32501589614377
-  339 65.20131491652755
-  340 61.75857107844968
-  341 67.75073007161419
-  342 60.552224151619484
o  343 73.61720587939163
-  344 51.08567927458971
o  345 114.25884846077278
o  346 94.41924398620692
o  347 70.08694711240969
o  348 129.0458571516705
o  349 79.47204498306492
-  350 61.123530975286485
o  351 130.55494270636046
o  352 107.29811379050881
o  353 90.71019897088591
-  354 66.76676995715891
o  355 77.58323392794064
-  356 69.18787058571198
-  357 44.15532015336466
o  358 87.99657587848928
-  359 55.34754383346959
o  360 70.05876691938457
-  361 61.951045559710906
o  362 81.37170817238983
-  363 66.52298277795654
o  364 84.37027559891672
-  365 50.57404678228184
o  366 82.90965944032492
-  367 48.17163122880793
o  368 74.24298177858736
o  369 80.80229863472385
-  370 65.20572865896483
o  371 94.27931514796873
o  372 89.03832927771005
o  373 81.34695330174614
o  374 85.46318321550866
o  375 79.52434999314684
-  376 69.6613595847901
-  377 61.21075921170375
-  378 60.360699859520786
-  379 55.173891222677774
o  380 88.17121848802962
-  381 53.450151438557086
o  382 76.89892757742673
-  383 61.9306935479186
o  384 80.06298638868593
o  385 318.7617705931003
o  386 190.42624327586108
o  387 216.25346973672967
o  388 95.58238523941182
o  389 236.7866380978763
o  390 162.62761687065233
-  391 48.13818484165222
-  392 65.4077771086455
o  393 91.74794046807402
o  394 200.82897763266308
o  395 106.94082451282539
o  396 165.81672418960906
o  397 85.88091108799945
o  398 89.15134242396498
o  399 89.40510655841766
o  400 124.10633698585626
o  401 178.61973462687212
o  402 171.6692901375936
o  403 209.2891763356477
o  404 175.39085402565578
o  405 753.4067549257433
o  406 91.15599210501175
o  407 112.02876163895152
o  408 181.98749732987855
-  409 51.96860062485098
o  410 517.2650792782459
-  411 67.81834743579776
-  412 68.32869870381992
o  413 256.9357267743892
o  414 239.0228780285057
o  415 137.32342262851216
o  416 152.98473880575773
o  417 105.35408833370579
o  418 80.51888647685405
o  419 80.68910529818268
o  420 87.73824307387541
o  421 71.2557075087756
o  422 97.87757549591379
o  423 84.2629963500589
o  424 70.1796018626779
o  425 85.9310413883969
-  426 65.217224377204
-  427 64.92883725943166
-  428 29.41281740772429
o  429 94.94943891710356
o  430 89.42593765483417
-  431 69.67697721883556
-  432 49.548049012380766
o  433 205.29931062995783
o  434 109.84309017619353
o  435 135.5734286684782
o  436 176.57430627853427
o  437 120.35241502549353
o  438 119.59115072618124
o  439 132.20225354451446
o  440 79.54364416645808
o  441 322.2335220942295
o  442 82.148775369314
o  443 582.0270579166296
-  444 36.8269711608511
o  445 79.13064873931012
-  446 35.55283780314941
o  447 119.93644538092704
-  448 32.34644927125375
o  449 98.27939773782892
o  450 174.2833322602906
o  451 79.16331295190098
o  452 139.46968425837707
o  453 109.82339141362802
o  454 111.67980902676493
o  455 87.23318178110883
-  456 69.96676700987841
o  457 163.31040996996612
o  458 71.93719945961539
o  459 177.35246961816173
o  460 124.0717640833066
o  461 210.2038031796403
o  462 215.9689246197291
o  463 179.28644451426413
o  464 144.52284792220635
o  465 131.16452480981425
-  466 54.80607583645288
o  467 159.48366397460254
o  468 129.00872477158075
o  469 106.43573930171108
-  470 68.94193801493921
o  471 211.30332562918548
o  472 439.8942305749391
o  473 242.4171156458134
o  474 84.73898327288883
o  475 119.69523767173851
-  476 55.37006272698848
o  477 159.60150866138696
o  478 110.70553624375907
o  479 97.74692322886254
o  480 85.26464615588102
o  481 103.48604821952902
-  482 36.038702291305626
o  483 125.71091752287077
o  484 115.95919654926263
o  485 156.82626972499335
-  486 61.796567547348914
-  487 58.47883248165085
o  488 89.23812508316287
o  489 113.01230771877846
o  490 252.38942301570626
o  491 100.96516202115673
o  492 232.19379701333025
o  493 208.3783298800812
o  494 94.7273184425464
o  495 130.67445136685862
-  496 66.62208984708377
o  497 129.19695080108892
o  498 92.19606354402313
-  499 68.51373318213246
o  500 244.2474894877714
o  501 110.32029240423206
o  502 128.01795911290745
o  503 99.74778388744036
o  504 114.65771334177721
o  505 99.51138180679382
o  506 117.96246474390264
-  507 35.221439935774654
o  508 92.75557015819122
o  509 96.80716328741025
o  510 87.29584539063985
-  511 65.53660725867462
o  512 104.67071733503501
== Loading TDT tank
** Loading tank data from local (previusly cached)
== Done
== Trying to load events data
Loading this events (pd) locally to:  /gorilla1/neural_preprocess/recordings/Pancho/220827/Pancho-220827-144815/events_photodiode.pkl
== Done
** MINIMAL_LOADING, therefore loading previuosly cached data
Generated self._MapperTrialcode2TrialToTrial!
Extracted into self.Dat[epoch_orig]
Extracted successfully for session:  0
Generated index mappers!
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DfScalar.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/fr_sm_times.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/DS.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Params.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/ParamsGlobals.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Sites.pkl
Loading:  /gorilla1/analyses/recordings/main/anova/bytrial/Pancho-220827-sess_0/Trials.pkl
This many vals across loaded session
0 : 2778663
Assigning to SP.Params this item:
{'which_level': 'trial', '_list_events': ['fixcue', 'fix_touch', 'rulecue2', 'samp', 'go_cue', 'first_raise', 'on_strokeidx_0', 'off_stroke_last', 'doneb', 'post', 'reward_all'], 'list_events_uniqnames': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_features_extraction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_features_get_conjunction': ['probe', 'taskgroup', 'character', 'trialcode', 'epoch', 'task_kind', 'supervision_stage_concise', 'seqc_nstrokes_beh', 'seqc_nstrokes_task', 'seqc_0_shape', 'seqc_0_loc', 'seqc_1_shape', 'seqc_1_loc', 'seqc_2_shape', 'seqc_2_loc', 'seqc_3_shape', 'seqc_3_loc', 'gridsize'], 'list_pre_dur': [-0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75], 'list_post_dur': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75], 'map_var_to_othervars': None, 'strokes_only_keep_single': False, 'tasks_only_keep_these': None, 'prune_feature_levels_min_n_trials': 1, 'fr_which_version': 'sqrt', 'map_var_to_levels': None}
Assigning to SP.ParamsGlobals this item:
{'n_min_trials_per_level': 5, 'lenient_allow_data_if_has_n_levels': 2, 'PRE_DUR_CALC': -0.75, 'POST_DUR_CALC': 0.75, 'list_events': ['00_fixcue', '01_fix_touch', '02_rulecue2', '03_samp', '04_go_cue', '05_first_raise', '06_on_strokeidx_0', '07_off_stroke_last', '08_doneb', '09_post', '10_reward_all'], 'list_pre_dur': [-0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75], 'list_post_dur': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]}
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
TODO!!! Merge this with other learning-related code
stored in self.Dat[BehClass]
0
200
400
600
Running D.behclass_tokens_extract_datsegs
0
200
400
600
trial # 0
trial # 100
trial # 200
trial # 300
trial # 400
trial # 500
trial # 600
trial # 700
Generated column called 'agent', which connects agent_kind-rule
n samples for conjunctions of score_name, agent_rule, agent_kind:
('binsucc', 'R', 'model') :     368
('binsucc', 'VlL1', 'model') :     378
TODO! _preprocess_sanity_check
Starting length of D.Dat: 746
############ TAKING ONLY NO SUPERVISION TRIALS
--BEFORE REMOVE; existing supervision_stage_concise:
off|0||0     546
mask|0||0    200
Name: supervision_stage_concise, dtype: int64
self.Dat modified!!
--AFTER REMOVE; existing supervision_stage_concise:
off|0||0    546
Name: supervision_stage_concise, dtype: int64
Dataset final len: 546
-- Len of D, before applying this param: remove_repeated_trials, ... 546
appended col to self.Dat:
dummy
self.Dat starting legnth:  525
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  525
after: 525
-- Len of D, before applying this param: wrong_sequencing_binary_score, ... 525
self.Dat starting legnth:  90
Modified self.Dat, keeping only the inputted inds
self.Dat final legnth:  90
after: 90
{'LIST_VAR': ['epoch', 'epoch'], 'LIST_VARS_CONJUNCTION': [['taskgroup', 'probe'], ['seqc_0_loc', 'seqc_0_shape', 'seqc_nstrokes_beh']], 'PRE_DUR_CALC': None, 'POST_DUR_CALC': None, 'globals_nmin': 8, 'globals_lenient_allow_data_if_has_n_levels': 2, 'score_ver': 'r2_maxtime_1way_mshuff', 'list_events': ['03_samp', '03_samp', '05_first_raise', '06_on_strokeidx_0', '08_doneb', '09_post', '10_reward_all'], 'list_pre_dur': [-0.6, 0.05, -0.6, -0.1, -0.5, 0.05, 0.05], 'list_post_dur': [-0.05, 0.6, -0.05, 0.6, 0.3, 0.6, 0.6], 'ANALY_VER': 'ruleswERROR', 'which_level': 'trial', 'DATE': 220827, 'animal': 'Pancho', 'get_z_score': True, 'list_superv_keep': None, 'preprocess_steps_append': ['remove_repeated_trials', 'wrong_sequencing_binary_score'], 'remove_aborts': False, 'DO_SCORE_SEQUENCE_VER': 'matlab', 'list_superv_keep_full': None}
Traceback (most recent call last):
  File "analy_anova_plot.py", line 102, in <module>
    assert False, "dataset pruning removed >0.75 of data. Are you sure correct? Maybe removing a supervisiuon stage that is actually important?"
AssertionError: dataset pruning removed >0.75 of data. Are you sure correct? Maybe removing a supervisiuon stage that is actually important?
