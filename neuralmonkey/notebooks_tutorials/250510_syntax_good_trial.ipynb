{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7125966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOrganizing good plots for syntax, fo|cusing on activity before trial onset.\\n- euclidian dist\\n- state space\\n\\nSee structured representation?\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Organizing good plots for syntax, fo|cusing on activity before trial onset.\n",
    "- euclidian dist\n",
    "- state space\n",
    "\n",
    "See structured representation?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b248d33aff307a2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralmonkey.scripts.analy_dfallpa_extract import extract_dfallpa_helper\n",
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_match_chans_across_pa_each_bregion\n",
    "from neuralmonkey.classes.population_mult import extract_single_pa\n",
    "from neuralmonkey.metadat.analy.anova_params import params_getter_euclidian_vars\n",
    "from neuralmonkey.classes.population_mult import dfpa_concatbregion_preprocess_clean_bad_channels, dfpa_concat_bregion_to_combined_bregion, dfpa_concatbregion_preprocess_wrapper\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "import seaborn as sns\n",
    "import os\n",
    "from neuralmonkey.classes.population_mult import extract_single_pa\n",
    "from neuralmonkey.analyses.state_space_good import euclidian_distance_compute_trajectories_single, euclidian_distance_compute_trajectories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d20c8",
   "metadata": {},
   "source": [
    "# Load DFallPa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4252ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"trial\"\n",
    "combine = False\n",
    "question = \"RULE_BASE_trial\"\n",
    "\n",
    "animal = \"Diego\"\n",
    "# date = 230915\n",
    "# date = 230913\n",
    "date = 230726\n",
    "\n",
    "# animal = \"Pancho\"\n",
    "# # date = 230829\n",
    "# date = 220908\n",
    "\n",
    "# Load a single DFallPA\n",
    "DFallpa = load_handsaved_wrapper(animal, date, version=version, combine_areas=combine, \n",
    "                                    question=question)\n",
    "\n",
    "events_keep = [\"03_samp\"]\n",
    "DFallpa = DFallpa[DFallpa[\"event\"].isin(events_keep)].reset_index(drop=True)\n",
    "\n",
    "DFallpa = dfpa_concat_bregion_to_combined_bregion(DFallpa)\n",
    "\n",
    "\n",
    "# Make a copy of all PA before normalization\n",
    "dfpa_concatbregion_preprocess_wrapper(DFallpa, animal, date)\n",
    "\n",
    "### Preprocessing\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import preprocess_dfallpa_basic_quick\n",
    "preprocess_dfallpa_basic_quick(DFallpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e071ea4",
   "metadata": {},
   "source": [
    "### Subspace projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62464778",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = \"/tmp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2946320",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa = DFallpa[:15].reset_index(drop=True)\n",
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2be5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import preprocess_dfallpa\n",
    "list_subspace_projection = [\"epch_sytxcncr\"]\n",
    "tbin_dur = \"default\"\n",
    "tbin_slide = None\n",
    "\n",
    "LIST_VAR_VAROTHERS = [\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "    # (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_0\"]),\n",
    "    # (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_shape\", \"seqc_0_loc\"]),\n",
    "    (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "    # (\"FEAT_num_strokes_beh\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"epoch\", [\"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "]\n",
    "\n",
    "for subspace_projection in list_subspace_projection:\n",
    "\n",
    "    SAVEDIR_ANALYSIS = f\"{SAVEDIR}/statespace_and_regression/{animal}-{date}-comb={combine}-q={question}-ssproj={subspace_projection}\"            \n",
    "    os.makedirs(SAVEDIR_ANALYSIS, exist_ok=True)\n",
    "\n",
    "    ### Preprocessing\n",
    "    LIST_DIMS = preprocess_dfallpa(DFallpa, subspace_projection, tbin_slide, tbin_dur, SAVEDIR_ANALYSIS, HACK=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e42b40b",
   "metadata": {},
   "source": [
    "### State space plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa61722",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_VAR_VAROTHERS = [\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_1\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "    (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_0\"]),\n",
    "    (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_shape\", \"seqc_0_loc\"]),\n",
    "    (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "]\n",
    "NPCS_KEEP = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import preprocess_dfallpa\n",
    "\n",
    "list_subspace_projection = [\"epch_sytxcncr\"]\n",
    "tbin_dur = \"default\"\n",
    "tbin_slide = None\n",
    "\n",
    "for subspace_projection in list_subspace_projection:\n",
    "\n",
    "    ### Preprocessing\n",
    "    savedir = f\"{SAVEDIR}/ssproj={subspace_projection}\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    LIST_DIMS = preprocess_dfallpa(DFallpa, subspace_projection, tbin_slide, tbin_dur, savedir, HACK=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60836302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import state_space_plot_scalar_wrapper\n",
    "\n",
    "# extract new variable, the number of items for each of the chunk ranks\n",
    "SAVEDIR = f\"/tmp/SYNTAX_TRIAL/{animal}-{date}\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "state_space_plot_scalar_wrapper(DFallpa, SAVEDIR, LIST_VAR_VAROTHERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de56085b",
   "metadata": {},
   "source": [
    "### Linear regression to find encoding axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9221a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR_BASE = f\"/tmp/SYNTAX_REGRE/{animal}-{date}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import regression_fit_and_score_single, regression_wrapper\n",
    "var_effect = \"syntax_slot_0\"\n",
    "vars_others = [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_shape\", \"seqc_0_loc\", \"syntax_slot_1\"]\n",
    "# vars_others = [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_1\"]\n",
    "# vars_others = [\"FEAT_num_strokes_beh\", \"epoch\", \"syntax_slot_1\"]\n",
    "\n",
    "DFRES_ALL, DFDISTCOS_ALL, SAVEDIR = regression_wrapper(DFallpa, var_effect, vars_others, SAVEDIR_BASE, \n",
    "                                              ndims = 4, PLOT_SCATTER_PRED_VS_ACTUAL = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For pruning\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import regression_wrapper_prune\n",
    "\n",
    "min_levs = 3\n",
    "# min_r2_test = 0.1\n",
    "min_r2_test = None\n",
    "min_ntot = 15\n",
    "min_nmin = 4\n",
    "\n",
    "DFRES_ALL_PRUNED, DFDISTCOS_ALL_PRUNED = regression_wrapper_prune(DFRES_ALL, DFDISTCOS_ALL, min_levs, min_r2_test, \n",
    "                                                                  min_ntot, min_nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42011cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each bregion/event, \n",
    "# Plot:\n",
    "# - distribution of R2\n",
    "# - how many R2 are significant\n",
    "# - cosine between R2\n",
    "# --- both with and without significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822a276d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = f\"{SAVEDIR}/MULT_PLOTS\"\n",
    "os.makedirs(savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import regression_wrapper_plot_each_grp, regression_wrapper_plot_cosine_sim\n",
    "\n",
    "\n",
    "# Prune, based on data quality (not on r2)\n",
    "min_levs = 3\n",
    "min_r2_test = None\n",
    "min_ntot = 20\n",
    "min_nmin = 5\n",
    "\n",
    "DFRES_ALL_PRUNED, DFDISTCOS_ALL_PRUNED = regression_wrapper_prune(DFRES_ALL, DFDISTCOS_ALL, min_levs, min_r2_test, \n",
    "                                                                  min_ntot, min_nmin)\n",
    "\n",
    "# dfthis = DFRES_ALL[DFRES_ALL[\"same_grp\"] == True].reset_index(drop=True)\n",
    "for savesuff, dfthis in zip(\n",
    "    [\"all\", \"pruned\"],\n",
    "    [DFRES_ALL, DFRES_ALL_PRUNED]):\n",
    "\n",
    "    savedirthis = f\"{savedir}/plot_each_grp-{savesuff}\"\n",
    "    os.makedirs(savedirthis, exist_ok=True)\n",
    "    regression_wrapper_plot_each_grp(dfthis, savedirthis)\n",
    "\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c76241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune, based on good regression\n",
    "min_levs = 3\n",
    "min_r2_test = 0.1\n",
    "min_ntot = 20\n",
    "min_nmin = 5\n",
    "\n",
    "DFRES_ALL_PRUNED, DFDISTCOS_ALL_PRUNED = regression_wrapper_prune(DFRES_ALL, DFDISTCOS_ALL, min_levs, min_r2_test, \n",
    "                                                                  min_ntot, min_nmin)\n",
    "\n",
    "for savesuff, dfthis in zip(\n",
    "    [\"all\", \"pruned\"],\n",
    "    [DFDISTCOS_ALL, DFDISTCOS_ALL_PRUNED]):\n",
    "\n",
    "    savedirthis = f\"{savedir}/plot_cosine_sim-{savesuff}\"\n",
    "    os.makedirs(savedirthis, exist_ok=True)\n",
    "\n",
    "    # dfthis = DFDISTCOS_ALL[DFDISTCOS_ALL[\"same_grp\"] == False].reset_index(drop=True)\n",
    "    regression_wrapper_plot_cosine_sim(dfthis, savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0964dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17934c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Plot state space scatter\n",
    "from neuralmonkey.analyses.state_space_good import trajgood_plot_colorby_splotby_scalar_WRAPPER\n",
    "savedir_this = \"/tmp\"\n",
    "LIST_DIMS = [(0,1), (2,3), (4,5), (5,6)]\n",
    "dflab = PAredu.Xlabels[\"trials\"]\n",
    "trajgood_plot_colorby_splotby_scalar_WRAPPER(X, dflab, var_effect, savedir_this,\n",
    "                                                vars_subplot=vars_others, list_dims=LIST_DIMS,\n",
    "                                                overlay_mean_orig=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IN PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Project neural data onto the axis.\n",
    "\n",
    "# - get predicted neural for min and max y\n",
    "from pythonlib.tools.vectools import projection_onto_axis_subspace\n",
    "\n",
    "grp_axis = (5, \"llCV2\", \"line-6-2-0\", (2, 0), 2)\n",
    "grp_data = (5, \"llCV2\", \"line-6-2-0\", (0, 0), 2)\n",
    "\n",
    "_, _, _, _, reg, _, _ = _extract_data(X, Y, grp_axis, grp_axis)\n",
    "X_train, labels_train, _, _, _, _, _ = _extract_data(X, Y, grp_data, grp_data)\n",
    "\n",
    "reg.coef_\n",
    "\n",
    "x1 = -reg.coef_\n",
    "x2 = reg.coef_\n",
    "\n",
    "projection_onto_axis_subspace(x1, x2, X_train, True, plot_color_labels=labels_train)\n",
    "projection_onto_axis_subspace(x1, x2, X_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a8cbd7",
   "metadata": {},
   "source": [
    "### Score euclidian distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d410eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2befdf73",
   "metadata": {},
   "source": [
    "### [Good] project to submspace spanned by two axes, each identified using regression (targeted PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463201a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "- read papers that do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ad068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ways to get factoriztaion:\n",
    "# 1. average over other variables (problem if they are correlated)\n",
    "# 2. condition on other variables (problem if limited data)\n",
    "# 3. first use multiple (or partial) regression model \n",
    "# -- Liping \n",
    "\n",
    "# Ways to identify subspace\n",
    "# 1. PCA, after factorization.\n",
    "# 2. Regression (without necessarily factorizing).\n",
    "\n",
    "# TO read:\n",
    "# -  machens.\n",
    "# - churchland 2012\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# Like in Mante 2013\n",
    "# - get denoising matrix.\n",
    "# - compute regression \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59361e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For each neuron/dim, get regression coefficients (task coeff)\n",
    "# Method 1: Full data, multple regression\n",
    "\n",
    "# Method 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "### method: regression\n",
    "\n",
    "# variables = [\"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\", \"syntax_slot_2\"]\n",
    "# variables_is_cat = [True, True, False, False]\n",
    "\n",
    "# variables = [\"seqc_0_shape\"]\n",
    "# variables_is_cat = [True]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ff8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92fc52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA = DFallpa[\"pa\"].values[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars_helper\n",
    "\n",
    "extract_with_levels_of_conjunction_vars_helper(dflab, var=var_effect, vars_others=vars_others, \n",
    "                                               n_min_per_lev=prune_levs_min_n_trials, lenient_allow_data_if_has_n_levels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde71e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = DFallpa[\"pa\"].values[0]\n",
    "dflab = pa.Xlabels[\"trials\"]\n",
    "\n",
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars_helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab[\"syntax_concrete\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab[\"syntax_slot_2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print levels for the varialbes\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "dflab = PA.Xlabels[\"trials\"]\n",
    "grouping_print_n_samples(dflab, variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac7dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab = PAredu.Xlabels[\"trials\"]\n",
    "dfout, _ = extract_with_levels_of_conjunction_vars_helper(dflab, var=var_effect, vars_others=[\"syntax_slot_1\"], \n",
    "                                        n_min_per_lev=3, \n",
    "                                        lenient_allow_data_if_has_n_levels=2)        \n",
    "len(dfout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ede1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_effect, vars_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75190197",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa, vars_others = PAredu.slice_prune_dflab_and_vars_others(var_effect, vars_others,\n",
    "                                                prune_levs_min_n_trials, min_levs_per_levother)\n",
    "vars_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# During samp\n",
    "DFallpa = DFallpa[:16]\n",
    "\n",
    "from pythonlib.tools.vectools import average_vectors_wrapper, get_vector_from_angle\n",
    "\n",
    "twind_scal = (0.2, 1.4)\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import state_space_targeted_pca_scalar_single, targeted_pca_euclidian_dist_angles\n",
    "\n",
    "variables = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"syntax_slot_1\", \"syntax_slot_2\"]\n",
    "variables_is_cat = [True, True, True, True, False, False, False]\n",
    "\n",
    "list_subspaces = [\n",
    "    (\"syntax_slot_0\", \"syntax_slot_1\"),\n",
    "    # (\"syntax_slot_1\", \"syntax_slot_2\"),   \n",
    "    # (\"syntax_slot_0\", \"syntax_slot_2\"),   \n",
    "]\n",
    "\n",
    "LIST_VAR_VAROTHERS_SS = [\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"shapes_n_unique\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]),\n",
    "    # (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_0\"]),\n",
    "    (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]),\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"FEAT_num_strokes_beh\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"epoch\", [\"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"seqc_0_shape\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "]\n",
    "\n",
    "LIST_DIMS = [(0,1), (1,2)]\n",
    "\n",
    "LIST_VAR_VAROTHERS_REGR = [\n",
    "    (\"syntax_slot_0\", [\"syntax_slot_1\", \"seqc_0_loc\", \"seqc_0_shape\", \"epoch\", \"FEAT_num_strokes_beh\"]),\n",
    "    (\"syntax_slot_1\", [\"syntax_slot_0\", \"seqc_0_loc\", \"seqc_0_shape\", \"epoch\", \"FEAT_num_strokes_beh\"]),\n",
    "    # (\"FEAT_num_strokes_beh\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "]\n",
    "# else:\n",
    "#     # TODO: find the most constrainig params givne this expt\n",
    "#     LIST_VAR_VAROTHERS_REGR = [\n",
    "#         (\"syntax_slot_0\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "#         (\"syntax_slot_1\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]),\n",
    "#         # (\"FEAT_num_strokes_beh\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "#     ]\n",
    "\n",
    "\n",
    "subspace_tuple = ('syntax_slot_0', 'syntax_slot_1')\n",
    "\n",
    "SAVEDIR_ANALYSIS = f\"/tmp/TERGET_PCA_EUCL/{animal}-{date}\"\n",
    "os.makedirs(SAVEDIR_ANALYSIS, exist_ok=True)\n",
    "DFANGLE = targeted_pca_euclidian_dist_angles(DFallpa, SAVEDIR_ANALYSIS, twind_scal,\n",
    "                                       variables, variables_is_cat, list_subspaces, LIST_VAR_VAROTHERS_SS, # For dim reduction and plotting state space\n",
    "                                       subspace_tuple, LIST_VAR_VAROTHERS_REGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dcacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import targeted_pca_euclidian_dist_angles_plots\n",
    "\n",
    "# var_vector_length = \"dist_norm\"\n",
    "var_vector_length = \"dist_yue_diff\"\n",
    "# length_method = \"dot\"\n",
    "length_method = \"sum\"\n",
    "min_levs_exist = 3\n",
    "SAVEDIR = f\"{SAVEDIR_ANALYSIS}/PLOTS/varlength={var_vector_length}-lengthmeth={length_method}-minlevs={min_levs_exist}\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "targeted_pca_euclidian_dist_angles_plots(DFANGLE, var_vector_length, length_method, min_levs_exist, SAVEDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0be86",
   "metadata": {},
   "source": [
    "##### Other methods for doing targeted PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285561ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_red_method = \"pca\"\n",
    "\n",
    "# Compute PCA projection matrix\n",
    "scalar_or_traj = \"scal\"\n",
    "savedir = \"/tmp\"\n",
    "twind_pca = twind_scal\n",
    "tbin_dur = \"default\"\n",
    "tbin_slide = \"default\"\n",
    "NPCS_KEEP = 20\n",
    "\n",
    "dpca_var = \"var_all_conditions\"\n",
    "dpca_vars_group = None\n",
    "\n",
    "_, _, pca = PA.dataextract_dimred_wrapper(scalar_or_traj, dim_red_method, savedir, \n",
    "                                   twind_pca, tbin_dur, tbin_slide, \n",
    "                                   NPCS_KEEP, dpca_var, dpca_vars_group = dpca_vars_group, dpca_filtdict=None, dpca_proj_twind = None, \n",
    "                                   raw_subtract_mean_each_timepoint=False,\n",
    "                                   n_min_per_lev_lev_others = 2, return_pca_components=True)\n",
    "\n",
    "print(pca[\"components\"].shape) # (ndim_reduced, ndim_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4110eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-noise the coefficients using pca\n",
    "\n",
    "# Project \n",
    "p = pca[\"components\"] # (ndims_pc, nchans)\n",
    "\n",
    "ndims_keep = 20\n",
    "p = p[:ndims_keep, :]\n",
    "\n",
    "D = p.T @ p # (nchans, nchans)\n",
    "values_denoised = D @ dfcoeff.values # (nchans, nfeatures\n",
    "\n",
    "dfcoeff = pd.DataFrame(values_denoised, columns=dfcoeff.columns)\n",
    "\n",
    "# Replot coefficiens\n",
    "from pythonlib.tools.snstools import heatmap\n",
    "heatmap(dfcoeff, annotate_heatmap=False, diverge=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd258553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional] do regression by controlling for specific values of the other variables\n",
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars_helper\n",
    "\n",
    "# variables = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"syntax_slot_1\"]\n",
    "# variables = [\"seqc_0_loc\", \"seqc_0_shape\"]\n",
    "\n",
    "list_var_varothers = [\n",
    "    [\"syntax_slot_0\", (\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\")],\n",
    "    [\"syntax_slot_1\", (\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\")],\n",
    "]\n",
    "list_vars_is_cat = [False, False]\n",
    "\n",
    "n_min_per_lev = 4\n",
    "dflab = pa.Xlabels[\"trials\"]\n",
    "\n",
    "print(\"TODO: Test that all variables are cat or ordinal\")\n",
    "map_vareffect_to_dfcoeff = {}\n",
    "# for i in range(len(variables)):\n",
    "#     var_effect = variables[i]\n",
    "#     vars_others = variables[:i] + variables[i+1:]\n",
    "#     var_effect_is_cat = variables_is_cat[i]\n",
    "#     dfout, dict_dfthis = extract_with_levels_of_conjunction_vars_helper(dflab, var_effect, vars_others, n_min_per_lev, lenient_allow_data_if_has_n_levels=2)\n",
    "\n",
    "for (var_effect, vars_others), var_effect_is_cat in zip(list_var_varothers, list_vars_is_cat):\n",
    "    dfout, dict_dfthis = extract_with_levels_of_conjunction_vars_helper(dflab, var_effect, vars_others, \n",
    "                                                                        n_min_per_lev, lenient_allow_data_if_has_n_levels=2)\n",
    "\n",
    "    print(var_effect)\n",
    "    print(var_effect_is_cat)\n",
    "    print(vars_others)\n",
    "    print(len(dfout))\n",
    "\n",
    "    if len(dfout)>0:\n",
    "        # for each level of var_other, do regression\n",
    "        # map_varlevel_to_dfcoeff = {}\n",
    "        list_dfcoeff = []\n",
    "        PLOT_COEFF_HEATMAP = False\n",
    "        columns_take = None\n",
    "        for grp, dfthis in dict_dfthis.items():\n",
    "            print(grp, len(dfthis))\n",
    "\n",
    "            # Sanity check indices are correct, even globally.\n",
    "            inds = dfthis[\"_index\"]\n",
    "            dflab.iloc[inds][\"trialcode\"].tolist() == dfthis[\"trialcode\"].tolist()\n",
    "        \n",
    "            pasub = pa.slice_by_dim_indices_wrapper(\"trials\", inds, reset_trial_indices=True)\n",
    "            dfcoeff, res_all = pasub.regress_neuron_task_variables_all_chans([var_effect], [var_effect_is_cat], \n",
    "                                                                            PLOT_COEFF_HEATMAP=PLOT_COEFF_HEATMAP, PRINT=False)\n",
    "            \n",
    "            # save the coefficients\n",
    "            _columns_take = [k for k,v in res_all[0][\"original_feature_mapping\"].items() if v==var_effect]\n",
    "            if columns_take is not None:\n",
    "                assert columns_take == _columns_take, \"to ensure that concatting at end is correct\"\n",
    "            else:\n",
    "                columns_take = _columns_take\n",
    "\n",
    "            if len(columns_take)>1:\n",
    "                print(columns_take)\n",
    "                print(var_effect)\n",
    "                print(\"var_effect_is_cat:\", var_effect_is_cat)\n",
    "                assert False, \"not yet coded for categorical variables with >2 categories. TO do so, need to solve problem of diff var_other levesl having ptoentialyl different levesl of var_effect, and how to agg that over var_others\"\n",
    "\n",
    "            dfcoeff_nointercept = dfcoeff.loc[:, columns_take]\n",
    "\n",
    "            list_dfcoeff.append(dfcoeff_nointercept)\n",
    "            \n",
    "        # Get mean coefficients over all runs\n",
    "        dfcoeff_mean = np.concatenate(list_dfcoeff, axis=1).mean(axis=1, keepdims=True) # (ndims, ncoeff)\n",
    "\n",
    "        if PLOT_COEFF_HEATMAP:\n",
    "            print(columns_take)\n",
    "            print(dfcoeff_mean.shape)\n",
    "            assert False\n",
    "        map_vareffect_to_dfcoeff[var_effect] = dfcoeff_mean\n",
    "    \n",
    "dfcoeff_all_var = np.concatenate(list(map_vareffect_to_dfcoeff.values()), axis=1)\n",
    "dfcoeff_all_var = pd.DataFrame(dfcoeff_all_var, columns=[x[0] for x in list_var_varothers])\n",
    "\n",
    "# Hacky, for plotting\n",
    "dfcoeff = dfcoeff_all_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ea793",
   "metadata": {},
   "source": [
    "### Compare to my previous DPCA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bbdc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_or_traj = \"scal\"\n",
    "dim_red_method = \"dpca\"\n",
    "savedir = \"/tmp\"\n",
    "twind_pca = twind_scal\n",
    "tbin_dur = \"default\"\n",
    "tbin_slide = \"default\"\n",
    "NPCS_KEEP = 20\n",
    "\n",
    "# dpca_var = \"seqc_0_shape\"\n",
    "# dpca_vars_group = None\n",
    "\n",
    "\n",
    "list_var_varothers = [\n",
    "    [\"syntax_slot_0\", (\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\")],\n",
    "    [\"syntax_slot_1\", (\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\")],\n",
    "]\n",
    "list_vars_is_cat = [False, False]\n",
    "\n",
    "# dpca_var = \"syntax_slot_0\"\n",
    "# dpca_vars_group = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]\n",
    "dpca_var = \"syntax_slot_1\"\n",
    "dpca_vars_group = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]\n",
    "\n",
    "Xredu, PAredu, pca = PA.dataextract_dimred_wrapper(scalar_or_traj, dim_red_method, savedir, \n",
    "                                   twind_pca, tbin_dur, tbin_slide, \n",
    "                                   NPCS_KEEP, dpca_var, dpca_vars_group = dpca_vars_group, dpca_filtdict=None, dpca_proj_twind = None, \n",
    "                                   raw_subtract_mean_each_timepoint=False,\n",
    "                                   umap_n_components=2, umap_n_neighbors=40,\n",
    "                                   inds_pa_fit=None, inds_pa_final=None,\n",
    "                                   n_min_per_lev_lev_others = 2, return_pca_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca[\"X_before_dimred\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7988de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca[\"components\"].shape # (ndims, ntrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abbc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot state space\n",
    "savedir = \"/tmp/TARGETED_DPCA/original\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "LIST_VAR_VAROTHERS_SS = [\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"shapes_n_unique\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_1\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]),\n",
    "    (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_0\"]),\n",
    "\n",
    "    # (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"FEAT_num_strokes_beh\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"epoch\", [\"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"seqc_0_shape\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    # (\"seqc_0_loc\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_shape\"]),\n",
    "]\n",
    "\n",
    "LIST_VAR = [x[0] for x in LIST_VAR_VAROTHERS_SS]\n",
    "LIST_VARS_OTHERS = [x[1] for x in LIST_VAR_VAROTHERS_SS]\n",
    "PAredu.plot_state_space_good_wrapper(savedir, LIST_VAR, LIST_VARS_OTHERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a66a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - instead of multiple regression, do controlled regression\n",
    "# - do regression in neural space\n",
    "# - do dPCA, controlling for each variable, and then concatenate the top PC\n",
    "# - do PCA after regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d396cbe",
   "metadata": {},
   "source": [
    "##### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cba0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot showing that the order doesnt matter, first \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n_neurons = 100\n",
    "n_trials = 500\n",
    "n_signal_neurons = 5\n",
    "noise_level = 10.0  # High noise\n",
    "signal_strength = 1.0\n",
    "k = 2\n",
    "\n",
    "# Simulate task variable (binary)\n",
    "task = np.random.choice([0, 1], size=n_trials)\n",
    "\n",
    "# Simulate neural data\n",
    "X = np.random.randn(n_neurons, n_trials) * noise_level  # Pure noise\n",
    "\n",
    "# Add task-related signal to a few neurons\n",
    "for i in range(n_signal_neurons):\n",
    "    X[i, :] += task * signal_strength\n",
    "\n",
    "# Center data\n",
    "X_centered = X - X.mean(axis=1, keepdims=True)\n",
    "\n",
    "# --- Option A: Regress first, then denoise ---\n",
    "\n",
    "# Step 1: Regress each neuron on task\n",
    "beta = np.zeros(n_neurons)\n",
    "for i in range(n_neurons):\n",
    "    model = LinearRegression().fit(task.reshape(-1, 1), X_centered[i, :])\n",
    "    beta[i] = model.coef_[0]\n",
    "\n",
    "# Step 2: PCA denoising (keep top k PCs)\n",
    "pca = PCA(n_components=k)\n",
    "pca.fit(X_centered.T)\n",
    "P = pca.components_.T @ pca.components_\n",
    "beta_denoised = P @ beta\n",
    "\n",
    "# --- Option B: Denoise first, then regress ---\n",
    "\n",
    "# Step 1: Denoise data\n",
    "X_denoised = P @ X_centered\n",
    "\n",
    "# Step 2: Regress each neuron in denoised data on task\n",
    "beta_denoised_first = np.zeros(n_neurons)\n",
    "for i in range(n_neurons):\n",
    "    model = LinearRegression().fit(task.reshape(-1, 1), X_denoised[i, :])\n",
    "    beta_denoised_first[i] = model.coef_[0]\n",
    "\n",
    "# Plot results\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# True task neurons\n",
    "axs[0].scatter(range(n_neurons), beta, color='gray')\n",
    "axs[0].scatter(range(n_signal_neurons), beta[:n_signal_neurons], color='red')\n",
    "axs[0].set_title('Original Beta (regress first)')\n",
    "axs[0].axhline(0, color='black', linestyle='--')\n",
    "\n",
    "# After denoising betas\n",
    "axs[1].scatter(range(n_neurons), beta_denoised, color='gray')\n",
    "axs[1].scatter(range(n_signal_neurons), beta_denoised[:n_signal_neurons], color='red')\n",
    "axs[1].set_title('Beta after denoising (regress first)')\n",
    "axs[1].axhline(0, color='black', linestyle='--')\n",
    "\n",
    "# After denoising data first\n",
    "axs[2].scatter(range(n_neurons), beta_denoised_first, color='gray')\n",
    "axs[2].scatter(range(n_signal_neurons), beta_denoised_first[:n_signal_neurons], color='red')\n",
    "axs[2].set_title('Beta after denoising data first')\n",
    "axs[2].axhline(0, color='black', linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52113102",
   "metadata": {},
   "source": [
    "### [Load mult dates] [Old method, angles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is obsolete, but can run this to plot, and it works. For updated version\n",
    "# see below (### [MULT] [NEW] Load and plot all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505986ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good\n",
    "from pythonlib.tools.vectools import get_vector_from_angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list_dates = [230728, 231118, 240822, 230723, 230724, 230726, 230727, 230730, 230815, 230816, 230817, 230913, 230914, 230915, 231116, 240827, 250319, 250321]\n",
    "# list_dates = [230728, 231118, 240822, 230723, 230724, 230726, 230727, 230815, 230816, 230817, 230913, 230914, 230915, 231116, 250321]\n",
    "# list_dates = [230728, 230723, 230724, 230726, 230727, 230815, 230816, 230817, 230913, 230914, 230915]\n",
    "# animal = \"Diego\"\n",
    "\n",
    "# list_dates = [230810, 230811, 230824, 230826, 230829, 231114, 231116, 240830, 220831, 220901, 250321, 250322, 220902, 220906, 220907, 220908, 220909]\n",
    "# list_dates = [230810, 230811, 230824, 230826, 230829, 231114, 231116, 240830, 220901, 250321, 250322, 220902, 220906, 220907, 220908, 220909]\n",
    "list_dates = [220901, 250321, 220902, 220906, 220907, 220908, 220909]\n",
    "animal = \"Pancho\"\n",
    "\n",
    "SAVEDIR = \"/lemur2/lucas/analyses/recordings/main/syntax_good_trial/targeted_dim_redu_angles\"\n",
    "# Diego-230723-comb=False-q=RULE_BASE_trial\n",
    "\n",
    "var_vector_length = \"dist_yue_diff\"\n",
    "# var_vector_length = \"dist_norm\"\n",
    "# length_method = \"sum\"\n",
    "length_method = \"dot\"\n",
    "min_levs_exist = 3\n",
    "\n",
    "\n",
    "list_dfangle = []\n",
    "list_dfdot = []\n",
    "for date in list_dates:\n",
    "    path = f\"{SAVEDIR}/{animal}-{date}-comb=False-q=RULE_BASE_trial/DFANGLE.pkl\"\n",
    "        \n",
    "        # import pickle\n",
    "        # with open(path, \"rb\") as f:\n",
    "        \n",
    "    dfangle = pd.read_pickle(path)\n",
    "    dfangle[\"animal\"] = animal\n",
    "    dfangle[\"date\"] = date\n",
    "    dfangle[\"levs_exist_n\"] = [len(levs_exist) for levs_exist in dfangle[\"levs_exist\"]]\n",
    "\n",
    "    dfangle = dfangle[\n",
    "        (dfangle[\"var_vector_length\"] == var_vector_length) & \n",
    "        (dfangle[\"length_method\"] == length_method) &\n",
    "        (dfangle[\"levs_exist_n\"] >= min_levs_exist)].reset_index(drop=True)\n",
    "\n",
    "    if len(dfangle)==0:\n",
    "        print(\"skipping, dfangle 0: \", dfangle)\n",
    "        continue\n",
    "\n",
    "    list_dfangle.append(dfangle)\n",
    "\n",
    "    ##############\n",
    "    from neuralmonkey.scripts.analy_syntax_good_eucl_trial import targeted_pca_euclidian_dist_angles_compute_dfdot\n",
    "    df_dot = targeted_pca_euclidian_dist_angles_compute_dfdot(dfangle, var_vector_length, \n",
    "                                                            length_method, min_levs_exist)\n",
    "    if df_dot is not None:\n",
    "        df_dot[\"animal\"] = animal\n",
    "        df_dot[\"date\"] = date\n",
    "        list_dfdot.append(df_dot)\n",
    "    \n",
    "    # assert np.all(_dfdot[\"dot_product\"] == df_dot[\"dot_product\"])\n",
    "    # # assert np.all(_dfdot[\"var_effect_12\"] == df_dot[\"var_effect_12\"])\n",
    "    # assert np.all(_dfdot[\"var_effect_1\"] == df_dot[\"var_effect_1\"])\n",
    "    # assert np.all(_dfdot[\"var_effect_2\"] == df_dot[\"var_effect_2\"])\n",
    "    # assert np.all(_dfdot[\"var_other_1\"] == df_dot[\"var_other_1\"])\n",
    "    # assert np.all(_dfdot[\"var_other_2\"] == df_dot[\"var_other_2\"])\n",
    "\n",
    "\n",
    "    # dfangle[\"vector_mean\"] = [l * get_vector_from_angle(a) for a, l in zip(dfangle[\"angle_mean\"], dfangle[\"norm_mean\"])]\n",
    "\n",
    "    # res_dot = []\n",
    "    # grpdict = grouping_append_and_return_inner_items_good(dfangle, [\"bregion\", \"event\", \"var_effect\", \"var_other\"])\n",
    "    # for i, (grp1, inds1) in enumerate(grpdict.items()):\n",
    "    #     for j, (grp2, inds2) in enumerate(grpdict.items()):\n",
    "    #         if grp1[0]==grp2[0]: # same bregion\n",
    "    #             bregion =grp1[0]\n",
    "    #             if grp1[1]==grp2[1]: # same event\n",
    "    #                 event = grp1[1]\n",
    "    #                 if j>i:\n",
    "    #                     tmp1 = dfangle.iloc[inds1]\n",
    "    #                     tmp2 = dfangle.iloc[inds2]\n",
    "    #                     assert len(tmp1)==1\n",
    "    #                     assert len(tmp2)==1\n",
    "\n",
    "    #                     vec1 = tmp1[\"vector_mean\"].values[0]\n",
    "    #                     vec2 = tmp2[\"vector_mean\"].values[0]\n",
    "                        \n",
    "    #                     # Get dot product\n",
    "    #                     res_dot.append({\n",
    "    #                         # \"dot_product_mean\":np.mean(dot_products),\n",
    "    #                         \"var_effect_1\":grp1[2],\n",
    "    #                         \"var_effect_2\":grp2[2],\n",
    "    #                         \"var_other_1\":grp1[3],\n",
    "    #                         \"var_other_2\":grp2[3],\n",
    "    #                         \"dot_product\":np.dot(vec1, vec2),\n",
    "    #                         \"bregion\":bregion,\n",
    "    #                         \"event\":event,\n",
    "    #                     })\n",
    "    # if len(res_dot)>0:\n",
    "    #     df_dot = pd.DataFrame(res_dot)\n",
    "        # df_dot = append_col_with_grp_index(df_dot, [\"var_effect_1\", \"var_effect_2\"], \"var_effect_12\")\n",
    "        # df_dot[\"animal\"] = animal\n",
    "        # df_dot[\"date\"] = date\n",
    "        # list_dfdot.append(df_dot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import aggregGeneral\n",
    "DFANGLE= pd.concat(list_dfangle).reset_index(drop=True)\n",
    "DF_DOT = pd.concat(list_dfdot).reset_index(drop=True)\n",
    "print(len(DFANGLE))\n",
    "print(len(DF_DOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFANGLE_AGG = aggregGeneral(DFANGLE, [\"var_effect\", \"vars_others\", \"bregion\", \"event\", \"animal\", \"date\"], [\"angle_mean\", \"norm_mean\"])\n",
    "DF_DOT = aggregGeneral(DF_DOT, [\"var_effect_1\", \"var_effect_2\", \"bregion\", \"event\", \"var_effect_12\", \"animal\", \"date\"], [\"dot_product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\" from neuralmonkey.scripts.analy_syntax_good_eucl_trial import targeted_pca_euclidian_dist_angles_plots\n",
    "# SAVEDIR_ANALYSIS = \"/tmp/SYNTAX_TRIAL_MULT\"\n",
    "# for var_vector_length in [\"dist_yue_diff\", \"dist_norm\"]:\n",
    "#     for length_method in [\"sum\", \"dot\"]:\n",
    "#         for min_levs_exist in [3, 2]:\n",
    "\n",
    "#             savedir = f\"{SAVEDIR_ANALYSIS}/PLOTS/varlength={var_vector_length}-lengthmeth={length_method}-minlevs={min_levs_exist}\"\n",
    "#             os.makedirs(savedir, exist_ok=True)\n",
    "#             targeted_pca_euclidian_dist_angles_plots(DFANGLE_ALL, var_vector_length, length_method, min_levs_exist, savedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.session import MAP_REGION_TO_COMBINED_REGION\n",
    "MAP_REGION_TO_COMBINED_REGION\n",
    "DF_DOT[\"bregion\"] = [MAP_REGION_TO_COMBINED_REGION[r] for r in DF_DOT[\"bregion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61cd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.snstools import rotateLabel\n",
    "\n",
    "fig = sns.catplot(data=DFANGLE_AGG, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect\", jitter=True, alpha=0.7, aspect=1.5)\n",
    "rotateLabel(fig)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR}/allvectors-catplot-1.pdf\")\n",
    "\n",
    "fig = sns.catplot(data=DFANGLE_AGG, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect\", kind=\"point\", aspect=1.5)\n",
    "rotateLabel(fig)\n",
    "# savefig(fig, f\"{SAVEDIR}/allvectors-catplot-2.pdf\")\n",
    "# plt.close(\"all\")\n",
    "\n",
    "\n",
    "fig = sns.catplot(data=DFANGLE_AGG, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect\", jitter=True, alpha=0.7, aspect=1.5, col=\"date\", col_wrap=4)\n",
    "rotateLabel(fig)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR}/allvectors-catplot-1.pdf\")\n",
    "\n",
    "fig = sns.catplot(data=DFANGLE_AGG, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect\", kind=\"bar\", aspect=1.5, col=\"date\", col_wrap=4)\n",
    "rotateLabel(fig)\n",
    "# savefig(fig, f\"{SAVEDIR}/allvectors-catplot-2.pdf\")\n",
    "# plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8361f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.catplot(data=DF_DOT, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", jitter=True, \n",
    "                  alpha=0.25, aspect=1.5)\n",
    "rotateLabel(fig)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR}/dot_across_ovar-catplot-1.pdf\")\n",
    "\n",
    "fig = sns.catplot(data=DF_DOT, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"bar\", aspect=1.5, errorbar=\"se\")\n",
    "rotateLabel(fig)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR}/dot_across_ovar-catplot-2.pdf\")\n",
    "\n",
    "fig = sns.catplot(data=DF_DOT, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"point\", aspect=1.5, errorbar=\"se\")\n",
    "rotateLabel(fig)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR}/dot_across_ovar-catplot-2.pdf\")\n",
    "\n",
    "fig = sns.catplot(data=DF_DOT, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"violin\", aspect=1.5)\n",
    "rotateLabel(fig)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR}/dot_across_ovar-catplot-2.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ddba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.catplot(data=DF_DOT, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", jitter=True, \n",
    "                  alpha=0.25, aspect=1.5, col=\"date\", col_wrap=4, sharey=False)\n",
    "rotateLabel(fig)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR}/dot_across_ovar-catplot-1.pdf\")\n",
    "\n",
    "fig = sns.catplot(data=DF_DOT, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"bar\", aspect=1.5,\n",
    "                  col=\"date\", col_wrap=4, sharey=False)\n",
    "rotateLabel(fig)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR}/dot_across_ovar-catplot-2.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1851c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75caab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.plottools import savefig\n",
    "from pythonlib.tools.snstools import rotateLabel\n",
    "from pythonlib.tools.pandastools import aggregGeneral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR_PLOT = \"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05460f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### (2) Angles (e.g,, dot product)\n",
    "savedir = f\"{SAVEDIR_PLOT}/angles\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "DFANGLE = pd.concat(list_dfangle).reset_index(drop=True)\n",
    "DFDOT = pd.concat(list_dfdot).reset_index(drop=True)\n",
    "DFDOT[:2]\n",
    "# Remove cases that are 2 levs and dot products. They are not defined.\n",
    "a = DFANGLE[\"levs_exist_n\"] == 2\n",
    "b = DFANGLE[\"length_method\"] == \"dot\"\n",
    "DFANGLE = DFANGLE[~(a & b)]\n",
    "assert sum(DFANGLE[\"norm_mean\"].isna())==0\n",
    "DFANGLE = append_col_with_grp_index(DFANGLE, [\"length_method\", \"var_vector_length\"], \"length_method_var\")\n",
    "DFDOT = append_col_with_grp_index(DFDOT, [\"length_method\", \"var_vector_length\"], \"length_method_var\")\n",
    "\n",
    "DFANGLE = append_col_with_grp_index(DFANGLE, [\"var_effect\", \"vars_others\"], \"var_effect_others\")\n",
    "\n",
    "# Agg over (var_effect\", \"vars_others)\n",
    "DFANGLE_AGG = aggregGeneral(DFANGLE, [\"var_effect_others\", \"length_method_var\", \"var_effect\", \"vars_others\", \"bregion\", \"event\", \"animal\", \"date\", \"var_vector_length\", \"length_method\", \"levs_exist_n\"], [\"angle_mean\", \"norm_mean\"])\n",
    "# Agg over <var_other>\n",
    "DFDOT_AGG = aggregGeneral(DFDOT, [\"length_method_var\", \"var_effect_1\", \"var_effect_2\", \"bregion\", \"event\", \"var_effect_12\", \"animal\", \"date\", \"var_vector_length\", \"length_method\", \"min_levs_exist\"], [\"dot_product\"])\n",
    "### (1) ANGLE: Plot each date (older, more detailed plots)\n",
    "if False: # TAkes too long\n",
    "    from neuralmonkey.scripts.analy_syntax_good_eucl_trial import targeted_pca_euclidian_dist_angles_plots\n",
    "    for date in DFANGLE[\"date\"].unique():\n",
    "        dfangle = DFANGLE[DFANGLE[\"date\"] ==date].reset_index(drop=True)\n",
    "        for var_vector_length in [\"dist_yue_diff\", \"dist_norm\"]:\n",
    "            for length_method in [\"sum\", \"dot\"]:\n",
    "                for min_levs_exist in [3, 2]:\n",
    "                    savedir_this = f\"{savedir}/angles_vectors/each_date/{date}-varlength={var_vector_length}-lengthmeth={length_method}-minlevs={min_levs_exist}\"\n",
    "                    os.makedirs(savedir_this, exist_ok=True)\n",
    "                    print(\"Saving to: \", savedir_this)\n",
    "                    targeted_pca_euclidian_dist_angles_plots(dfangle, var_vector_length, length_method, min_levs_exist, savedir_this)\n",
    "                    plt.close(\"all\")\n",
    "\n",
    "### (2) ANGLE: Plot agg\n",
    "fig = sns.catplot(data=DFANGLE_AGG, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect_others\", \n",
    "                row=\"length_method_var\", col=\"levs_exist_n\", kind=\"bar\", aspect=1.5, sharey=False)\n",
    "savefig(fig, f\"{savedir}/ANGLE_AGG-1.pdf\")\n",
    "\n",
    "### (3) ANGLE: Plot each date\n",
    "for levs_exist_n in DFANGLE[\"levs_exist_n\"].unique():\n",
    "    dfangle = DFANGLE[DFANGLE[\"levs_exist_n\"] == levs_exist_n].reset_index(drop=True)\n",
    "\n",
    "    fig = sns.catplot(data=dfangle, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect_others\", \n",
    "                    row=\"length_method_var\", col=\"date\", kind=\"bar\", aspect=1.5, sharey=False)\n",
    "    rotateLabel(fig)\n",
    "    for ax in fig.axes.flatten():\n",
    "        ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "    savefig(fig, f\"{savedir}/ANGLE_EACH-levs_exist_n={levs_exist_n}-catplot-1.pdf\")\n",
    "\n",
    "    fig = sns.catplot(data=dfangle, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect_others\", \n",
    "                    row=\"length_method_var\", col=\"date\", jitter=True, alpha=0.5, aspect=1.5, sharey=False)\n",
    "    rotateLabel(fig)\n",
    "    for ax in fig.axes.flatten():\n",
    "        ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "    savefig(fig, f\"{savedir}/ANGLE_EACH-{levs_exist_n}-catplot-2.pdf\")\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "### (4) DOT: Plot each date\n",
    "for date in DFDOT[\"date\"].unique():\n",
    "    dfdot = DFDOT[DFDOT[\"date\"] == date].reset_index(drop=True)\n",
    "    fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", jitter=True, \n",
    "                    row=\"min_levs_exist\", col=\"length_method_var\", alpha=0.25, aspect=1.5)\n",
    "    for ax in fig.axes.flatten():\n",
    "        ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "    savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-1.pdf\")\n",
    "\n",
    "    fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"boxen\",\n",
    "                    row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "    savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-2.pdf\")\n",
    "\n",
    "    fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"bar\", errorbar=\"se\", \n",
    "                    row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "    savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-3.pdf\")\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "### (5) DOT: Plot agg\n",
    "fig = sns.catplot(data=DFDOT_AGG, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", jitter=True, \n",
    "                row=\"min_levs_exist\", col=\"length_method_var\", alpha=0.25, aspect=1.5)\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "savefig(fig, f\"{savedir}/DOT_AGG-catplot-1.pdf\")\n",
    "    \n",
    "fig = sns.catplot(data=DFDOT_AGG, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"boxen\",\n",
    "                row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "savefig(fig, f\"{savedir}/DOT_AGG-catplot-2.pdf\")\n",
    "\n",
    "fig = sns.catplot(data=DFDOT_AGG, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"bar\", errorbar=\"se\", \n",
    "                row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "savefig(fig, f\"{savedir}/DOT_AGG-catplot-3.pdf\")\n",
    "\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "for date in DFDOT[\"date\"].unique():\n",
    "    dfdot = DFDOT[DFDOT[\"date\"] == date].reset_index(drop=True)\n",
    "    fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", jitter=True, \n",
    "                    row=\"min_levs_exist\", col=\"length_method_var\", alpha=0.25, aspect=1.5)\n",
    "    for ax in fig.axes.flatten():\n",
    "        ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "    savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-1.pdf\")\n",
    "\n",
    "    fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"boxen\",\n",
    "                    row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "    savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-2.pdf\")\n",
    "\n",
    "    fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"bar\", errorbar=\"se\", \n",
    "                    row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "    savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-3.pdf\")\n",
    "\n",
    "    plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e19cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998735a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDOT_AGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.catplot(data=DFDOT, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"bar\", errorbar=\"se\", \n",
    "                row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "rotateLabel(fig)\n",
    "# savefig(fig, f\"{savedir}/DOT_AGG-catplot-3.pdf\")\n",
    "fig = sns.catplot(data=DFDOT, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"boxen\",\n",
    "                row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "rotateLabel(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c36cc",
   "metadata": {},
   "source": [
    "# [Updated] Targeted PCA mult axes (coming back here after syntax state space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d50b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same procedure as there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d92491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# During samp\n",
    "DFallpa = DFallpa[:16]\n",
    "\n",
    "from pythonlib.tools.vectools import average_vectors_wrapper, get_vector_from_angle\n",
    "\n",
    "twind_scal = (0.2, 1.4)\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import state_space_targeted_pca_scalar_single_one_axis_per_var, state_space_targeted_pca_scalar_single_one_var_mult_axes, targeted_pca_euclidian_dist_angles\n",
    "\n",
    "variables = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"syntax_slot_1\", \"syntax_slot_2\"]\n",
    "variables_is_cat = [True, True, True, True, False, False, False]\n",
    "\n",
    "list_subspaces = [\n",
    "    (\"syntax_slot_0\", \"syntax_slot_1\"),\n",
    "    # (\"syntax_slot_1\", \"syntax_slot_2\"),   \n",
    "    # (\"syntax_slot_0\", \"syntax_slot_2\"),   \n",
    "]\n",
    "\n",
    "LIST_VAR_VAROTHERS_SS = [\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"shapes_n_unique\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]),\n",
    "    # (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"syntax_slot_0\"]),\n",
    "    (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]),\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"FEAT_num_strokes_beh\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"epoch\", [\"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"seqc_0_shape\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "]\n",
    "\n",
    "LIST_DIMS = [(0,1), (1,2)]\n",
    "\n",
    "LIST_VAR_VAROTHERS_REGR = [\n",
    "    (\"syntax_slot_0\", [\"syntax_slot_1\", \"seqc_0_loc\", \"seqc_0_shape\", \"epoch\", \"FEAT_num_strokes_beh\"]),\n",
    "    (\"syntax_slot_1\", [\"syntax_slot_0\", \"seqc_0_loc\", \"seqc_0_shape\", \"epoch\", \"FEAT_num_strokes_beh\"]),\n",
    "    # (\"FEAT_num_strokes_beh\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "]\n",
    "# else:\n",
    "#     # TODO: find the most constrainig params givne this expt\n",
    "#     LIST_VAR_VAROTHERS_REGR = [\n",
    "#         (\"syntax_slot_0\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "#         (\"syntax_slot_1\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]),\n",
    "#         # (\"FEAT_num_strokes_beh\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "#     ]\n",
    "\n",
    "\n",
    "subspace_tuple = ('syntax_slot_0', 'syntax_slot_1')\n",
    "\n",
    "SAVEDIR_ANALYSIS = f\"/tmp/TERGET_PCA_EUCL/{animal}-{date}\"\n",
    "os.makedirs(SAVEDIR_ANALYSIS, exist_ok=True)\n",
    "DFANGLE = state_space_targeted_pca_scalar_single_one_axis_per_var(DFallpa, SAVEDIR_ANALYSIS, twind_scal,\n",
    "                                       variables, variables_is_cat, list_subspaces, LIST_VAR_VAROTHERS_SS, # For dim reduction and plotting state space\n",
    "                                       subspace_tuple, LIST_VAR_VAROTHERS_REGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac170af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "twind_scal = (0.2, 1.4)\n",
    "\n",
    "for _, row in DFallpa.iterrows():\n",
    "    PA = row[\"pa\"].copy()\n",
    "    bregion = row[\"bregion\"]\n",
    "    event = row[\"event\"]\n",
    "    \n",
    "    SAVEDIR = f\"{SAVEDIR_ANALYSIS}/{event}-{bregion}\"\n",
    "    os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "    ### Dim reductions, AND scalar state space plots\n",
    "    # if subspace_filtdict:\n",
    "    #     # Then take subset of data for computing the state space \n",
    "    just_extract_paredu = False\n",
    "    LIST_DIMS = [(0,1)]\n",
    "    # dict_subspace_pa, _, _, _, _ = state_space_targeted_pca_scalar_single(\n",
    "    #                         PA, twind_scal, variables, variables_is_cat, list_subspaces, \n",
    "    #                         LIST_VAR_VAROTHERS_SS, LIST_DIMS, SAVEDIR, just_extract_paredu=just_extract_paredu)\n",
    "    dict_subspace_pa, _, _, _, _ = state_space_targeted_pca_scalar_single_one_axis_per_var(\n",
    "                            PA, twind_scal, variables, variables_is_cat, list_subspaces, \n",
    "                            LIST_VAR_VAROTHERS_SS, LIST_DIMS, SAVEDIR, just_extract_paredu=just_extract_paredu)\n",
    "\n",
    "    asdda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.plottools import savefig\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR_ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e30dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bregion = [\"vlPFC\"]\n",
    "for _, row in DFallpa.iterrows():\n",
    "\n",
    "    PA = row[\"pa\"]\n",
    "    bregion = row[\"bregion\"]\n",
    "    if bregion not in list_bregion:\n",
    "        continue\n",
    "    SAVEDIR = f\"{SAVEDIR_ANALYSIS}/good/{bregion}\"\n",
    "    os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "    ##### Update dim reduction\n",
    "    variables_cont = []\n",
    "    variables_cat = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"syntax_slot_1\", \"syntax_slot_2\"]\n",
    "    # var_subspace = \"syntax_slot_0\"\n",
    "    var_subspace = variables_cat\n",
    "    # variables_cat = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\"]\n",
    "    # var_subspace = \"seqc_0_loc\"\n",
    "    npcs_keep = 6\n",
    "    tbin_dur = 0.2\n",
    "    tbin_slide = 0.1\n",
    "    LIST_DIMS = [(0,1), (2,3)]\n",
    "    pa_subspace, subspace_axes_orig, subspace_axes_normed, dfcoeff, PAscalTest = state_space_targeted_pca_scalar_single_one_var_mult_axes(\n",
    "                            PA, twind_scal, variables_cont, variables_cat, \n",
    "                            var_subspace, npcs_keep, \n",
    "                            LIST_VAR_VAROTHERS_SS, LIST_DIMS, SAVEDIR, \n",
    "                            savedir_pca_subspaces=SAVEDIR, \n",
    "                            tbin_dur = tbin_dur, tbin_slide = tbin_slide)\n",
    "\n",
    "    if False:\n",
    "        # Also plot using UMAP\n",
    "        scalar_or_traj = \"scal\"\n",
    "        dim_red_method = \"umap\"\n",
    "        savedir = f\"{SAVEDIR}/umap\"\n",
    "        os.makedirs(savedir, exist_ok=True)\n",
    "        twind_pca = [-1, 1]\n",
    "\n",
    "        Xredu, PAredu = pa_subspace.dataextract_dimred_wrapper(scalar_or_traj, dim_red_method, savedir, \n",
    "                                        twind_pca, umap_n_components=2, umap_n_neighbors=40,\n",
    "                                        n_min_per_lev_lev_others = 2,\n",
    "                                        return_pca_components=False)\n",
    "        LIST_VAR_VAROTHERS_SS\n",
    "        LIST_VAR = [x[0] for x in LIST_VAR_VAROTHERS_SS]\n",
    "        LIST_VARS_OTHERS = [x[1] for x in LIST_VAR_VAROTHERS_SS]\n",
    "        PAredu.plot_state_space_good_wrapper(savedir, LIST_VAR, LIST_VARS_OTHERS, \n",
    "                                            PLOT_CLEAN_VERSION = True,  \n",
    "                                            nmin_trials_per_lev=None, \n",
    "                                            list_dim_timecourse=None, list_dims=None, \n",
    "                                            also_plot_heatmaps=False)\n",
    "    ### Compute metrics\n",
    "\n",
    "    ##### TODO: euclidean distance\n",
    "\n",
    "    ##### Ordinal regression (including generalization)\n",
    "    from neuralmonkey.scripts.analy_syntax_good_eucl_trial import ordinalregress_1_compute\n",
    "    pa_subspace_this = pa_subspace.slice_by_dim_indices_wrapper(\"chans\", list(range(npcs_keep)))\n",
    "    DFCROSS, DFWITHIN = ordinalregress_1_compute(pa_subspace, LIST_VAR_VAROTHERS_REGR, SAVEDIR, nsplits=4,\n",
    "                             apply_kernel = False, plot_regr=False)\n",
    "\n",
    "    assert False\n",
    "    \n",
    "    # list_dfcross = []\n",
    "    # list_dfwithin = []\n",
    "    # for yvar, vars_grp in LIST_VAR_VAROTHERS_REGR:\n",
    "    #     # yvar = \"syntax_slot_0\"\n",
    "    #     # vars_grp = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]\n",
    "    #     # yvar = \"syntax_slot_1\"\n",
    "    #     # vars_grp = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]\n",
    "    #     savedir = f\"{SAVEDIR}/ordinal_regress-yvar={yvar}=varsgrp={vars_grp}\"\n",
    "    #     apply_kernel = False\n",
    "    #     os.makedirs(savedir, exist_ok=True)\n",
    "    #     npcs_keep = 6\n",
    "    #     list_do_grid_search = [False]\n",
    "    #     dfcross, dfwithin = kernel_ordinal_logistic_regression_wrapper(pa_subspace_this, yvar, vars_grp, savedir, \n",
    "    #                                             plot_test_data_projected=False, nsplits=4, PLOT=True, do_rezero=False,\n",
    "    #                                             apply_kernel=apply_kernel, list_do_grid_search=list_do_grid_search)\n",
    "    #     dfcross[\"yvar\"] = yvar\n",
    "    #     dfcross[\"vars_grp\"] = [tuple(vars_grp) for _ in range(len(dfcross))]\n",
    "\n",
    "    #     dfwithin[\"yvar\"] = yvar\n",
    "    #     dfwithin[\"vars_grp\"] = [tuple(vars_grp) for _ in range(len(dfwithin))]\n",
    "\n",
    "    #     list_dfcross.append(dfcross)\n",
    "    #     list_dfwithin.append(dfwithin)\n",
    "\n",
    "    # DFCROSS = pd.concat(list_dfcross).reset_index(drop=True)\n",
    "    # DFWITHIN = pd.concat(list_dfwithin).reset_index(drop=True)\n",
    "\n",
    "    # # Compare the angles of the regression axes.\n",
    "    # list_coeff = []\n",
    "    # for _, row in DFWITHIN.iterrows():\n",
    "    #     coeff = row[\"res\"][\"coeff\"]\n",
    "    #     list_coeff.append(coeff)\n",
    "    # DFWITHIN[\"coeff\"] = list_coeff\n",
    "    # coeff_mat = np.stack(DFWITHIN[\"coeff\"])\n",
    "\n",
    "    # labels_row = DFWITHIN[\"grp\"].tolist()\n",
    "    # labels_row = [tuple(x) for x in DFWITHIN.loc[:, [\"yvar\", \"grp\"]].values.tolist()]\n",
    "    \n",
    "    # from pythonlib.tools.snstools import heatmap_mat\n",
    "    # fig, ax, rgba_values = heatmap_mat(coeff_mat, diverge=True, labels_row=labels_row, annotate_heatmap=False)\n",
    "    # savefig(fig, f\"{SAVEDIR}/ordinal_regress-coefficients_heatmap.pdf\")\n",
    "\n",
    "    # pd.to_pickle(DFCROSS, f\"{SAVEDIR}/DFCROSS.pkl\")\n",
    "    # pd.to_pickle(DFWITHIN, f\"{SAVEDIR}/DFWITHIN.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compare angles of regression coefficients across all conditions.\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import ordinalregress_2_regr_coeff_pairs\n",
    "savedir = f\"{SAVEDIR}/pairwise_regr_coeffs\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "ordinalregress_2_regr_coeff_pairs(DFWITHIN, savedir=savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4fc095",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_effect = LIST_VAR_VAROTHERS_REGR[0][0]\n",
    "vars_others = LIST_VAR_VAROTHERS_REGR[0][1]\n",
    "### (2) Compute euclidian distances\n",
    "from neuralmonkey.analyses.euclidian_distance import timevarying_compute_fast_to_scalar\n",
    "savedir = \"/tmp\"\n",
    "prune_levs_min_n_trials = 2\n",
    "dfdist, _ = timevarying_compute_fast_to_scalar(pa_subspace, [var_effect] + vars_others, \n",
    "                                                plot_conjunctions_savedir=savedir,\n",
    "                                                prune_levs_min_n_trials=prune_levs_min_n_trials,\n",
    "                                                get_only_one_direction=False)\n",
    "\n",
    "### (3) Get angles between all conditions\n",
    "from neuralmonkey.analyses.euclidian_distance import compute_angle_between_conditions\n",
    "dfangle = compute_angle_between_conditions(pa_subspace, dfdist, var_effect, vars_others)\n",
    "assert np.all(dfangle[\"labels_1\"] == dfdist[\"labels_1\"])\n",
    "assert np.all(dfangle[\"labels_2\"] == dfdist[\"labels_2\"])\n",
    "dfdist[\"theta\"] = dfangle[\"theta\"]\n",
    "dfdist[\"norm\"] = dfangle[\"norm\"]\n",
    "# dfdist[\"vector\"] = dfangle[\"vector\"]  \n",
    "\n",
    "from neuralmonkey.analyses.euclidian_distance import dfdist_variables_generate_constrast_strings, dfdist_variables_generate_var_same\n",
    "var_same = dfdist_variables_generate_var_same([var_effect] + vars_others)\n",
    "var_same_val = dfdist_variables_generate_constrast_strings([var_effect] + vars_others, contrasts_diff=[var_effect], contrasts_either=[])[0]\n",
    "from neuralmonkey.analyses.euclidian_distance import compute_average_angle_between_pairs_of_levels_of_vareffect\n",
    "dfanglemean = compute_average_angle_between_pairs_of_levels_of_vareffect(dfdist, var_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71b5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f83a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Cleaning up DFWITHIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdce1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merging dfwithin and dfcross \n",
    "# [ignore?]\n",
    "DFCROSS = DFCROSS[DFCROSS[\"grp_train\"] != DFCROSS[\"grp_test\"]].reset_index(drop=True)\n",
    "DFWITHIN[\"grp_train\"] = DFWITHIN[\"grp\"]\n",
    "DFWITHIN[\"grp_test\"] = DFWITHIN[\"grp\"] \n",
    "\n",
    "DFWITHIN[\"var_effect\"] = DFWITHIN[\"yvar\"] \n",
    "DFWITHIN[\"vars_others\"] = DFWITHIN[\"vars_grp\"] \n",
    "DFCROSS[\"var_effect\"] = DFCROSS[\"yvar\"] \n",
    "DFCROSS[\"vars_others\"] = DFCROSS[\"vars_grp\"] \n",
    "\n",
    "DFWITHIN[\"res\"] = \"none\"\n",
    "\n",
    "DFRES = pd.concat([DFWITHIN, DFCROSS], axis=0).reset_index(drop=True)\n",
    "DFRES = DFRES.drop([\"grp\"], axis=1)\n",
    "from pythonlib.cluster.clustclass import generate_clustclass_from_flat_df_rectangle\n",
    "\n",
    "# This fails -- it requires square data\n",
    "Cl = generate_clustclass_from_flat_df_rectangle(DFRES, \"grp_train\", \"grp_test\", var_value=\"balanced_accuracy_adjusted\", \n",
    "                                      var_labels=vars_grp)\n",
    "fig, _ = Cl.rsa_plot_heatmap()\n",
    "savefig(fig, f\"{plot_savedir}/heatmap-r2_test.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b8d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### dot product of vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58747ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load all regression results and summarize across regions\n",
    "path = \"/tmp/TERGET_PCA_EUCL/Diego-230913/good/vlPFC/DFWITHIN.pkl\"\n",
    "# path = \"/tmp/TERGET_PCA_EUCL/Diego-230913/good/M1/DFWITHIN.pkl\"\n",
    "\n",
    "# path = \"/tmp/TERGET_PCA_EUCL/Diego-230726/good/M1/DFWITHIN.pkl\"\n",
    "path = \"/tmp/TERGET_PCA_EUCL/Diego-230726/good/vlPFC/DFWITHIN.pkl\"\n",
    "dfwithin = pd.read_pickle(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First get dim reduced data\n",
    "list_bregion = [\"M1\", \"vlPFC\"]\n",
    "list_pa_redu = []\n",
    "for _, row in DFallpa.iterrows():\n",
    "\n",
    "    PA = row[\"pa\"]\n",
    "    bregion = row[\"bregion\"]\n",
    "\n",
    "    print(\"Getting this bregion: \", bregion)\n",
    "    \n",
    "    ##### Update dim reduction\n",
    "    variables_cont = []\n",
    "    variables_cat = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"syntax_slot_1\", \"syntax_slot_2\"]\n",
    "    # var_subspace = \"syntax_slot_0\"\n",
    "    var_subspace = variables_cat\n",
    "    # variables_cat = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\"]\n",
    "    # var_subspace = \"seqc_0_loc\"\n",
    "    npcs_keep = 6\n",
    "    tbin_dur = 0.2\n",
    "    tbin_slide = 0.1\n",
    "    LIST_DIMS = [(0,1), (2,3)]\n",
    "    pa_subspace, subspace_axes_orig, subspace_axes_normed, dfcoeff, PAscalTest = state_space_targeted_pca_scalar_single_one_var_mult_axes(\n",
    "                            PA, twind_scal, variables_cont, variables_cat, \n",
    "                            var_subspace, npcs_keep, \n",
    "                            LIST_VAR_VAROTHERS_SS, LIST_DIMS, SAVEDIR, \n",
    "                            just_extract_paredu=True,\n",
    "                            savedir_pca_subspaces=SAVEDIR, \n",
    "                            tbin_dur = tbin_dur, tbin_slide = tbin_slide)\n",
    "\n",
    "    list_pa_redu.append(pa_subspace)\n",
    "\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11706182",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa[\"pa_redu\"] = list_pa_redu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd70c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69822968",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_effect = LIST_VAR_VAROTHERS_REGR[0][0]\n",
    "vars_others = LIST_VAR_VAROTHERS_REGR[0][1]\n",
    "ndims = 4\n",
    "N_MIN_TRIALS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba631ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFWITHIN[\"grp_train\"] = DFWITHIN[\"grp\"]\n",
    "DFWITHIN[\"grp_test\"] = DFWITHIN[\"grp\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import regression_fit_and_score_single_ordinal\n",
    "bregion = \"preSMA\"\n",
    "event = \"03_samp\"\n",
    "\n",
    "plot_savedir = \"/tmp/TEST\"\n",
    "os.makedirs(plot_savedir, exist_ok=True)\n",
    "\n",
    "# list_dfcross = []\n",
    "# list_dfwithin = []\n",
    "# for yvar, vars_grp in LIST_VAR_VAROTHERS_REGR:\n",
    "#     # yvar = \"syntax_slot_0\"\n",
    "#     # vars_grp = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]\n",
    "#     # yvar = \"syntax_slot_1\"\n",
    "#     # vars_grp = [\"epoch\", \"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]\n",
    "#     savedir = f\"{SAVEDIR}/ordinal_regress-yvar={yvar}=varsgrp={vars_grp}\"\n",
    "#     apply_kernel = False\n",
    "#     os.makedirs(savedir, exist_ok=True)\n",
    "#     npcs_keep = 6\n",
    "#     list_do_grid_search = [False]\n",
    "#     pa_subspace_this = pa_subspace.slice_by_dim_indices_wrapper(\"chans\", list(range(npcs_keep)))\n",
    "\n",
    "regression_fit_and_score_single_ordinal(DFallpa, bregion, event, var_effect, \n",
    "                                        vars_others, ndims, N_MIN_TRIALS, plot_savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d6263c",
   "metadata": {},
   "source": [
    "### [GOOD CODE] wraps everything above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bdba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR_ANALYSIS = f\"/tmp/SYNTAX_TRIAL/{animal}-{date}\"\n",
    "os.makedirs(SAVEDIR_ANALYSIS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba584db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import targeted_pca_combined_v2_good\n",
    "LIST_VAR_VAROTHERS_SS = [\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "    # (\"syntax_slot_ratio\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"shapes_n_unique\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "\n",
    "    (\"syntax_slot_0\", [\"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\", \"epoch\", \"FEAT_num_strokes_beh\"]),\n",
    "    (\"syntax_slot_0\", [\"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\", \"epoch\"]),\n",
    "    (\"syntax_slot_0\", [\"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "    (\"syntax_slot_0\", [\"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"syntax_slot_0\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    (\"syntax_slot_1\", [\"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"epoch\", \"FEAT_num_strokes_beh\"]),\n",
    "    (\"syntax_slot_1\", [\"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"epoch\"]),\n",
    "    (\"syntax_slot_1\", [\"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]),\n",
    "    (\"syntax_slot_1\", [\"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"syntax_slot_1\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_0\"]),\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\", \"syntax_slot_1\"]),\n",
    "    # (\"syntax_slot_2\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    # (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"syntax_concrete\", [\"FEAT_num_strokes_beh\", \"epoch\"]),\n",
    "\n",
    "    (\"FEAT_num_strokes_beh\", [\"epoch\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    # (\"epoch\", [\"FEAT_num_strokes_beh\", \"seqc_0_loc\", \"seqc_0_shape\"]),\n",
    "    (\"seqc_0_shape\", [\"FEAT_num_strokes_beh\", \"epoch\", \"seqc_0_loc\"]),\n",
    "]\n",
    "targeted_pca_combined_v2_good(DFallpa, SAVEDIR_ANALYSIS, LIST_VAR_VAROTHERS_SS, DEBUG=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0222e",
   "metadata": {},
   "source": [
    "### [MULT] [NEW] Load and plot all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897137b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plots related to angles (dot product) see above\n",
    "# For other plots, see below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719e603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.session import _REGIONS_IN_ORDER_COMBINED\n",
    "\n",
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good\n",
    "from pythonlib.tools.vectools import get_vector_from_angle\n",
    "from pythonlib.tools.plottools import savefig\n",
    "from pythonlib.tools.snstools import rotateLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6464b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making copy and replacing None with 'none', for:  balanced_accuracy\n",
      "* This adds compute time!!!!\n",
      "Making copy and replacing None with 'none', for:  balanced_accuracy_adjusted\n",
      "* This adds compute time!!!!\n",
      "Making copy and replacing None with 'none', for:  balanced_accuracy\n",
      "* This adds compute time!!!!\n",
      "Making copy and replacing None with 'none', for:  balanced_accuracy_adjusted\n",
      "* This adds compute time!!!!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuralmonkey\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manaly_syntax_good_eucl_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kernel_ordinal_logistic_regression_wrapper_postprocess_mult_varsgrp\n\u001b[1;32m     49\u001b[0m dfcross, dfwithin \u001b[38;5;241m=\u001b[39m kernel_ordinal_logistic_regression_wrapper_postprocess_mult_varsgrp(dfcross, dfwithin)\n\u001b[0;32m---> 51\u001b[0m \u001b[43masd\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Also load dfdist to extract the name of the subspace\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvar_conj\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dfdist:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asd' is not defined"
     ]
    }
   ],
   "source": [
    "SAVEDIR = \"/lemur2/lucas/analyses/recordings/main/syntax_good_trial/targeted_pca_v2\"\n",
    "list_regions = _REGIONS_IN_ORDER_COMBINED\n",
    "event =\"03_samp\"\n",
    "\n",
    "### Collect all data\n",
    "for animal in [\"Diego\", \"Pancho\"]:\n",
    "    if animal==\"Diego\":\n",
    "        list_dates = [230728, 231118, 240822, 230723, 230724, 230726, 230727, 230815, 230816, 230817, 230913, 230914, 230915, 231116, 250321]\n",
    "        # list_dates = [230728, 230723, 230724, 230726, 230727, 230815, 230816, 230817, 230913, 230914, 230915]\n",
    "        # list_dates = [230728, 230723, 230724, 230726, 230727]\n",
    "        # animal = \"Diego\"\n",
    "    elif animal==\"Pancho\":\n",
    "        list_dates = [230810, 230811, 230824, 230826, 230829, 231114, 231116, 240830, 220831, 220901, 250321, 250322, 220902, 220906, 220907, 220908, 220909]\n",
    "        # list_dates = [230810, 230811, 230824, 230826, 230829, 231114, 231116, 240830, 220901, 250321, 250322, 220902, 220906, 220907, 220908, 220909]\n",
    "        # list_dates = [220901, 250321, 220902, 220906, 220907, 220908, 220909]\n",
    "        # list_dates = [220901, 250321, 220902, 220906, 220907, 220908, 220909]\n",
    "        # animal = \"Pancho\"\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    list_dfangle = []\n",
    "    list_dfdot = []\n",
    "    list_dfdist = []\n",
    "    LIST_DFWITHIN = []\n",
    "    LIST_DFCROSS = []\n",
    "    for date in list_dates:\n",
    "        for bregion in list_regions:\n",
    "            # EUCLIDEAN\n",
    "            path = f\"{SAVEDIR}/{animal}-{date}-q=RULE_BASE_trial/{event}-{bregion}/DFDIST.pkl\"\n",
    "            if os.path.exists(path):\n",
    "                dfdist = pd.read_pickle(path)\n",
    "                dfdist[\"var_subspace\"] = [tuple(x) if isinstance(x, list) else x for x in dfdist[\"var_subspace\"]]\n",
    "                if \"i_proj\" not in dfdist:\n",
    "                    dfdist[\"i_proj\"] = 0\n",
    "                for _df in [dfdist]:\n",
    "                    _df[\"date\"] = date\n",
    "                    _df[\"bregion\"] = bregion\n",
    "                list_dfdist.append(dfdist)\n",
    "\n",
    "                # REGRESSION\n",
    "                path = f\"{SAVEDIR}/{animal}-{date}-q=RULE_BASE_trial/{event}-{bregion}/DFWITHIN.pkl\"\n",
    "                dfwithin = pd.read_pickle(path)\n",
    "                \n",
    "                path = f\"{SAVEDIR}/{animal}-{date}-q=RULE_BASE_trial/{event}-{bregion}/DFCROSS.pkl\"\n",
    "                dfcross = pd.read_pickle(path)\n",
    "\n",
    "\n",
    "                from neuralmonkey.scripts.analy_syntax_good_eucl_state import kernel_ordinal_logistic_regression_wrapper_postprocess_mult_varsgrp\n",
    "                dfcross, dfwithin = kernel_ordinal_logistic_regression_wrapper_postprocess_mult_varsgrp(dfcross, dfwithin)\n",
    "\n",
    "                # Also load dfdist to extract the name of the subspace\n",
    "                if \"var_conj\" not in dfdist:\n",
    "                    dfdist[\"var_conj\"] = \"none\"\n",
    "                    dfdist[\"var_conj_lev\"] = \"none\"\n",
    "                # - confirm there's only one subspace\n",
    "                subspace_tuple = list(set([tuple(x) for x in dfdist.loc[:, [\"var_subspace\", \"var_conj\", \"var_conj_lev\"]].values.tolist()]))\n",
    "                assert len(subspace_tuple)==1\n",
    "                # - then prune dfdist to make the following faster\n",
    "                dfdist = dfdist.iloc[:1].reset_index(drop=True)\n",
    "                dfdist[\"var_subspace\"] = [tuple(x)  if isinstance(x, list) else x for x in dfdist[\"var_subspace\"]]  \n",
    "                dfdist = append_col_with_grp_index(dfdist, [\"var_subspace\", \"var_conj\", \"var_conj_lev\"], \"subspace\")\n",
    "                \n",
    "                tmp = dfdist[\"subspace\"].unique().tolist()\n",
    "                subspace = tmp[0]\n",
    "\n",
    "                tmp = dfdist[\"i_proj\"].unique().tolist()\n",
    "                i_proj = tmp[0]\n",
    "\n",
    "                for _df in [dfcross, dfwithin]:\n",
    "                    _df[\"bregion\"] = bregion\n",
    "                    _df[\"date\"] = date\n",
    "                    _df[\"subspace\"] = subspace\n",
    "                    _df[\"i_proj\"] = i_proj\n",
    "\n",
    "\n",
    "                for _df in [dfwithin, dfcross]:\n",
    "                    _df[\"date\"] = date\n",
    "                    _df[\"bregion\"] = bregion\n",
    "\n",
    "                LIST_DFWITHIN.append(dfwithin)\n",
    "                LIST_DFCROSS.append(dfcross)\n",
    "\n",
    "                # ANGLES\n",
    "                path = f\"{SAVEDIR}/{animal}-{date}-q=RULE_BASE_trial/{event}-{bregion}/DFANGLE.pkl\"\n",
    "                dfangle = pd.read_pickle(path)\n",
    "                dfangle[\"animal\"] = animal\n",
    "                dfangle[\"date\"] = date\n",
    "                dfangle[\"bregion\"] = bregion\n",
    "\n",
    "                # Also compute dfdot (consistency across vars_others)\n",
    "                from neuralmonkey.scripts.analy_syntax_good_eucl_trial import targeted_pca_euclidian_dist_angles_compute_dfdot\n",
    "                for var_vector_length in [\"dist_yue_diff\"]:\n",
    "                    for length_method in [\"sum\", \"dot\"]:\n",
    "                        for min_levs_exist in [2, 3]:\n",
    "                            \n",
    "                            if min_levs_exist==2 and length_method==\"dot\": \n",
    "                                # This doestn exist\n",
    "                                continue\n",
    "                            \n",
    "                            dfdot = targeted_pca_euclidian_dist_angles_compute_dfdot(dfangle, var_vector_length, \n",
    "                                                                                    length_method, min_levs_exist)\n",
    "                            if dfdot is None:\n",
    "                                print(\"skipping: \", var_vector_length, length_method, min_levs_exist)\n",
    "                            else:\n",
    "                                dfdot[\"animal\"] = animal\n",
    "                                dfdot[\"date\"] = date\n",
    "                                dfdot[\"bregion\"] = bregion\n",
    "                                list_dfdot.append(dfdot)\n",
    "                            \n",
    "                list_dfangle.append(dfangle)\n",
    "            \n",
    "    SAVEDIR_PLOT = f\"{SAVEDIR}/MULT/{animal}\"\n",
    "    os.makedirs(SAVEDIR_PLOT, exist_ok=True)\n",
    "\n",
    "    #####################################################\n",
    "    ### (1) Plot euclidean distance\n",
    "    savedir = f\"{SAVEDIR_PLOT}/euclidean\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good\n",
    "    from pythonlib.tools.pandastools import aggregGeneral\n",
    "    from neuralmonkey.analyses.euclidian_distance import dfdist_variables_generate_var_same\n",
    "    from neuralmonkey.analyses.euclidian_distance import dfdist_variables_generate_var_same\n",
    "    from neuralmonkey.neuralplots.brainschematic import datamod_reorder_by_bregion\n",
    "\n",
    "    # Collect data\n",
    "    DFDIST = pd.concat(list_dfdist).reset_index(drop=True)\n",
    "\n",
    "    # Split into different varsets (makes it easier to analyse)\n",
    "    grpdict = grouping_append_and_return_inner_items_good(DFDIST, [\"var_idx\", \"var_effect\", \"vars_others\"])\n",
    "    MAP_VARSET_TO_DFDIST = {}\n",
    "    for grp, inds in grpdict.items():\n",
    "        MAP_VARSET_TO_DFDIST[grp] = DFDIST.iloc[inds].reset_index(drop=True)\n",
    "    # one datapt per each (date, varsame)\n",
    "    MAP_VARSET_TO_DFDISTAGG = {}\n",
    "    for varset, dfdist in MAP_VARSET_TO_DFDIST.items():\n",
    "        var_effect = varset[1]\n",
    "        vars_others = list(varset[2])\n",
    "        varsame = dfdist_variables_generate_var_same([var_effect] + vars_others)\n",
    "        dfdistagg = aggregGeneral(dfdist, [varsame, \"bregion\", \"date\"], [\"dist_yue_diff\"])\n",
    "        dfdistagg = datamod_reorder_by_bregion(dfdistagg)\n",
    "        MAP_VARSET_TO_DFDISTAGG[varset] = dfdistagg\n",
    "\n",
    "    for varset, dfdist in MAP_VARSET_TO_DFDIST.items():\n",
    "        print(varset)\n",
    "\n",
    "        var_effect = varset[1]\n",
    "        vars_others = list(varset[2])\n",
    "        varsame = dfdist_variables_generate_var_same([var_effect] + vars_others)\n",
    "\n",
    "        # Split by dates\n",
    "        # sns.catplot(data=dfdist, x=\"bregion\", y=\"dist_yue_diff\", col=\"date\", col_wrap=6, hue=varsame, height=8,\n",
    "        #             jitter=True, alpha=0.3)    \n",
    "        fig = sns.catplot(data=dfdist, x=\"bregion\", y=\"dist_yue_diff\", col=\"date\", col_wrap=6, hue=varsame, height=8,\n",
    "                    kind=\"boxen\")\n",
    "        savefig(fig, f\"{savedir}/vareffect={var_effect}-varsother={vars_others}-catplot-1.pdf\")\n",
    "        \n",
    "        fig = sns.catplot(data=dfdist, x=\"bregion\", y=\"dist_yue_diff\", col=\"date\", col_wrap=6, hue=varsame, height=8,\n",
    "                    kind=\"bar\", errorbar=\"se\")\n",
    "        savefig(fig, f\"{savedir}/vareffect={var_effect}-varsother={vars_others}-catplot-2.pdf\")\n",
    "        \n",
    "        # agg, datapt= (date, varsame)\n",
    "        dfdistagg = MAP_VARSET_TO_DFDISTAGG[varset]\n",
    "        fig = sns.catplot(data=dfdistagg, x=\"bregion\", y=\"dist_yue_diff\", hue=varsame, height=8, kind=\"boxen\")\n",
    "        savefig(fig, f\"{savedir}/vareffect={var_effect}-varsother={vars_others}-catplot-agg-1.pdf\")\n",
    "\n",
    "        fig = sns.catplot(data=dfdistagg, x=\"bregion\", y=\"dist_yue_diff\", hue=varsame, height=8,\n",
    "                    kind=\"bar\", errorbar=\"se\")\n",
    "        savefig(fig, f\"{savedir}/vareffect={var_effect}-varsother={vars_others}-catplot-agg-2.pdf\")\n",
    "\n",
    "        plt.close(\"all\")\n",
    "\n",
    "    ##########################################################\n",
    "    ### (2) Angles (e.g,, dot product)\n",
    "    savedir = f\"{SAVEDIR_PLOT}/angles\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    DFANGLE = pd.concat(list_dfangle).reset_index(drop=True)\n",
    "    DFDOT = pd.concat(list_dfdot).reset_index(drop=True)\n",
    "    DFDOT[:2]\n",
    "    # Remove cases that are 2 levs and dot products. They are not defined.\n",
    "    a = DFANGLE[\"levs_exist_n\"] == 2\n",
    "    b = DFANGLE[\"length_method\"] == \"dot\"\n",
    "    DFANGLE = DFANGLE[~(a & b)]\n",
    "    assert sum(DFANGLE[\"norm_mean\"].isna())==0\n",
    "    DFANGLE = append_col_with_grp_index(DFANGLE, [\"length_method\", \"var_vector_length\"], \"length_method_var\")\n",
    "    DFDOT = append_col_with_grp_index(DFDOT, [\"length_method\", \"var_vector_length\"], \"length_method_var\")\n",
    "\n",
    "    DFANGLE = append_col_with_grp_index(DFANGLE, [\"var_effect\", \"vars_others\"], \"var_effect_others\")\n",
    "\n",
    "    # Agg over (var_effect\", \"vars_others)\n",
    "    DFANGLE_AGG = aggregGeneral(DFANGLE, [\"var_effect_others\", \"length_method_var\", \"var_effect\", \"vars_others\", \"bregion\", \"event\", \"animal\", \"date\", \"var_vector_length\", \"length_method\", \"levs_exist_n\"], [\"angle_mean\", \"norm_mean\"])\n",
    "    # Agg over <var_other>\n",
    "    DFDOT_AGG = aggregGeneral(DFDOT, [\"length_method_var\", \"var_effect_1\", \"var_effect_2\", \"bregion\", \"event\", \"var_effect_12\", \"animal\", \"date\", \"var_vector_length\", \"length_method\", \"min_levs_exist\"], [\"dot_product\"])\n",
    "    ### (1) ANGLE: Plot each date (older, more detailed plots)\n",
    "    if False: # TAkes too long\n",
    "        from neuralmonkey.scripts.analy_syntax_good_eucl_trial import targeted_pca_euclidian_dist_angles_plots\n",
    "        for date in DFANGLE[\"date\"].unique():\n",
    "            dfangle = DFANGLE[DFANGLE[\"date\"] ==date].reset_index(drop=True)\n",
    "            for var_vector_length in [\"dist_yue_diff\", \"dist_norm\"]:\n",
    "                for length_method in [\"sum\", \"dot\"]:\n",
    "                    for min_levs_exist in [3, 2]:\n",
    "                        savedir_this = f\"{savedir}/angles_vectors/each_date/{date}-varlength={var_vector_length}-lengthmeth={length_method}-minlevs={min_levs_exist}\"\n",
    "                        os.makedirs(savedir_this, exist_ok=True)\n",
    "                        print(\"Saving to: \", savedir_this)\n",
    "                        targeted_pca_euclidian_dist_angles_plots(dfangle, var_vector_length, length_method, min_levs_exist, savedir_this)\n",
    "                        plt.close(\"all\")\n",
    "\n",
    "    ### (2) ANGLE: Plot agg\n",
    "    fig = sns.catplot(data=DFANGLE_AGG, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect_others\", \n",
    "                    row=\"length_method_var\", col=\"levs_exist_n\", kind=\"bar\", aspect=1.5, sharey=False)\n",
    "    savefig(fig, f\"{savedir}/ANGLE_AGG-1.pdf\")\n",
    "\n",
    "    ### (3) ANGLE: Plot each date\n",
    "    for levs_exist_n in DFANGLE[\"levs_exist_n\"].unique():\n",
    "        dfangle = DFANGLE[DFANGLE[\"levs_exist_n\"] == levs_exist_n].reset_index(drop=True)\n",
    "\n",
    "        fig = sns.catplot(data=dfangle, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect_others\", \n",
    "                        row=\"length_method_var\", col=\"date\", kind=\"bar\", aspect=1.5, sharey=False)\n",
    "        rotateLabel(fig)\n",
    "        for ax in fig.axes.flatten():\n",
    "            ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "        savefig(fig, f\"{savedir}/ANGLE_EACH-levs_exist_n={levs_exist_n}-catplot-1.pdf\")\n",
    "\n",
    "        fig = sns.catplot(data=dfangle, x=\"bregion\", y=\"norm_mean\", hue=\"var_effect_others\", \n",
    "                        row=\"length_method_var\", col=\"date\", jitter=True, alpha=0.5, aspect=1.5, sharey=False)\n",
    "        rotateLabel(fig)\n",
    "        for ax in fig.axes.flatten():\n",
    "            ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "        savefig(fig, f\"{savedir}/ANGLE_EACH-{levs_exist_n}-catplot-2.pdf\")\n",
    "\n",
    "        plt.close(\"all\")\n",
    "\n",
    "    ### (4) DOT: Plot each date\n",
    "    for date in DFDOT[\"date\"].unique():\n",
    "        dfdot = DFDOT[DFDOT[\"date\"] == date].reset_index(drop=True)\n",
    "        fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", jitter=True, \n",
    "                        row=\"min_levs_exist\", col=\"length_method_var\", alpha=0.25, aspect=1.5)\n",
    "        for ax in fig.axes.flatten():\n",
    "            ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "        savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-1.pdf\")\n",
    "\n",
    "        fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"boxen\",\n",
    "                        row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "        savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-2.pdf\")\n",
    "\n",
    "        fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"bar\", errorbar=\"se\", \n",
    "                        row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "        savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-3.pdf\")\n",
    "\n",
    "        plt.close(\"all\")\n",
    "\n",
    "    ### (5) DOT: Plot agg\n",
    "    fig = sns.catplot(data=DFDOT_AGG, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", jitter=True, \n",
    "                    row=\"min_levs_exist\", col=\"length_method_var\", alpha=0.25, aspect=1.5)\n",
    "    for ax in fig.axes.flatten():\n",
    "        ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "    savefig(fig, f\"{savedir}/DOT_AGG-catplot-1.pdf\")\n",
    "        \n",
    "    fig = sns.catplot(data=DFDOT_AGG, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"boxen\",\n",
    "                    row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "    savefig(fig, f\"{savedir}/DOT_AGG-catplot-2.pdf\")\n",
    "\n",
    "    fig = sns.catplot(data=DFDOT_AGG, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"bar\", errorbar=\"se\", \n",
    "                    row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "    savefig(fig, f\"{savedir}/DOT_AGG-catplot-3.pdf\")\n",
    "\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    for date in DFDOT[\"date\"].unique():\n",
    "        dfdot = DFDOT[DFDOT[\"date\"] == date].reset_index(drop=True)\n",
    "        fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", jitter=True, \n",
    "                        row=\"min_levs_exist\", col=\"length_method_var\", alpha=0.25, aspect=1.5)\n",
    "        for ax in fig.axes.flatten():\n",
    "            ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "        savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-1.pdf\")\n",
    "\n",
    "        fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"boxen\",\n",
    "                        row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "        savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-2.pdf\")\n",
    "\n",
    "        fig = sns.catplot(data=dfdot, x=\"bregion\", y=\"dot_product\", hue=\"var_effect_12\", kind=\"bar\", errorbar=\"se\", \n",
    "                        row=\"min_levs_exist\", col=\"length_method_var\", aspect=1.5, sharey=False)\n",
    "        savefig(fig, f\"{savedir}/DOT_EACH-{date}-catplot-3.pdf\")\n",
    "\n",
    "        plt.close(\"all\")\n",
    "\n",
    "    ############################################\n",
    "    ### Regression\n",
    "    savedir = f\"{SAVEDIR_PLOT}/regression\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    DFWITHIN = pd.concat(LIST_DFWITHIN).reset_index(drop=True)\n",
    "    DFCROSS = pd.concat(LIST_DFCROSS).reset_index(drop=True)\n",
    "    ############################################\n",
    "    ### Postprocess        \n",
    "    from neuralmonkey.scripts.analy_syntax_good_eucl_state import kernel_ordinal_logistic_regression_wrapper_CONCATED_postprocess, kernel_ordinal_logistic_regression_wrapper_CONCATED_plot_all\n",
    "    vars_datapt = [\"epoch\", \"FEAT_num_strokes_beh\", \"syntax_slot_0\", \"syntax_slot_1\", \"seqc_0_loc\", \"seqc_0_shape\"]\n",
    "    DFCROSS, DFWITHIN, DFWITHIN_AGG_SHP, DFWITHIN_AGG_DATE = kernel_ordinal_logistic_regression_wrapper_CONCATED_postprocess(DFCROSS, DFWITHIN, vars_datapt)\n",
    "\n",
    "    # savedir = \"/tmp\"\n",
    "    kernel_ordinal_logistic_regression_wrapper_CONCATED_plot_all(DFCROSS, DFWITHIN, DFWITHIN_AGG_SHP, DFWITHIN_AGG_DATE, savedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1c27ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dfdist[\"var_effect\"] == \"syntax_slot_0\"\n",
    "b = dfdist[\"vars_others\"] == ('seqc_0_loc', 'seqc_0_shape', 'syntax_slot_1', 'epoch', 'FEAT_num_strokes_beh')\n",
    "dfdist = dfdist[a & b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97743869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['syntax_slot_0'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdist[\"var_effect\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63accd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('seqc_0_loc', 'seqc_0_shape', 'syntax_slot_1', 'epoch', 'FEAT_num_strokes_beh')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdist = dfdist.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56d0d022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_other</th>\n",
       "      <th>levs_exist</th>\n",
       "      <th>angles</th>\n",
       "      <th>weights</th>\n",
       "      <th>angle_mean</th>\n",
       "      <th>norm_mean</th>\n",
       "      <th>var_vector_length</th>\n",
       "      <th>length_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[4.832475415954616]</td>\n",
       "      <td>[0.5906494632238395]</td>\n",
       "      <td>4.832475</td>\n",
       "      <td>0.590649</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[4.832475415954616]</td>\n",
       "      <td>[0.5906494632238395]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[4.832475415954616]</td>\n",
       "      <td>[0.033720521171148654]</td>\n",
       "      <td>4.832475</td>\n",
       "      <td>0.033721</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[4.832475415954616]</td>\n",
       "      <td>[0.033720521171148654]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((-1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.7363294138416516]</td>\n",
       "      <td>[0.530802185762632]</td>\n",
       "      <td>3.736329</td>\n",
       "      <td>0.530802</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((-1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.7363294138416516]</td>\n",
       "      <td>[0.530802185762632]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((-1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.7363294138416516]</td>\n",
       "      <td>[-0.007550998155462896]</td>\n",
       "      <td>0.594737</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((-1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.7363294138416516]</td>\n",
       "      <td>[-0.007550998155462896]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((0, 0), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[5.821231741264794]</td>\n",
       "      <td>[0.5186904284585455]</td>\n",
       "      <td>5.821232</td>\n",
       "      <td>0.518690</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((0, 0), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[5.821231741264794]</td>\n",
       "      <td>[0.5186904284585455]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>((0, 0), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[5.821231741264794]</td>\n",
       "      <td>[-0.016462009007894518]</td>\n",
       "      <td>2.679639</td>\n",
       "      <td>0.016462</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>((0, 0), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[5.821231741264794]</td>\n",
       "      <td>[-0.016462009007894518]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>((0, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[2.19406036783109, 4.277099495013471]</td>\n",
       "      <td>[0.5836664065450927, 0.577959606035025]</td>\n",
       "      <td>3.227181</td>\n",
       "      <td>0.293268</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>((0, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[2.19406036783109, 4.277099495013471]</td>\n",
       "      <td>[0.5836664065450927, 0.577959606035025]</td>\n",
       "      <td>3.227181</td>\n",
       "      <td>-0.406620</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>((0, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[2.19406036783109, 4.277099495013471]</td>\n",
       "      <td>[0.01808606831173254, -0.005273211014596546]</td>\n",
       "      <td>1.975258</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>((0, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[2.19406036783109, 4.277099495013471]</td>\n",
       "      <td>[0.01808606831173254, -0.005273211014596546]</td>\n",
       "      <td>1.975258</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>((0, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[3.6342844700541534, 4.761871112779049]</td>\n",
       "      <td>[0.5295362714679248, 0.6316296135020099]</td>\n",
       "      <td>4.253610</td>\n",
       "      <td>0.491486</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>((0, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[3.6342844700541534, 4.761871112779049]</td>\n",
       "      <td>[0.5295362714679248, 0.6316296135020099]</td>\n",
       "      <td>4.253610</td>\n",
       "      <td>0.378728</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>((0, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[3.6342844700541534, 4.761871112779049]</td>\n",
       "      <td>[0.02087890540742554, -0.007501841975837031]</td>\n",
       "      <td>3.267900</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>((0, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[3.6342844700541534, 4.761871112779049]</td>\n",
       "      <td>[0.02087890540742554, -0.007501841975837031]</td>\n",
       "      <td>3.267900</td>\n",
       "      <td>-0.008196</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>((0, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.177524569083286]</td>\n",
       "      <td>[0.48476327656425344]</td>\n",
       "      <td>3.177525</td>\n",
       "      <td>0.484763</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>((0, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.177524569083286]</td>\n",
       "      <td>[0.48476327656425344]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>((0, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.177524569083286]</td>\n",
       "      <td>[0.03211039903858448]</td>\n",
       "      <td>3.177525</td>\n",
       "      <td>0.032110</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>((0, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.177524569083286]</td>\n",
       "      <td>[0.03211039903858448]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>((1, 1), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[3.466850138155289]</td>\n",
       "      <td>[0.517708828854528]</td>\n",
       "      <td>3.466850</td>\n",
       "      <td>0.517709</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>((1, 1), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[3.466850138155289]</td>\n",
       "      <td>[0.517708828854528]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>((1, 1), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[3.466850138155289]</td>\n",
       "      <td>[0.013572115333491452]</td>\n",
       "      <td>3.466850</td>\n",
       "      <td>0.013572</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>((1, 1), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[3.466850138155289]</td>\n",
       "      <td>[0.013572115333491452]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>((1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[2.480647246257943, 4.460766493969676]</td>\n",
       "      <td>[0.6245054717842959, 0.5410661327627175]</td>\n",
       "      <td>3.362047</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>((1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[2.480647246257943, 4.460766493969676]</td>\n",
       "      <td>[0.6245054717842959, 0.5410661327627175]</td>\n",
       "      <td>3.362047</td>\n",
       "      <td>-0.366715</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>((1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[2.480647246257943, 4.460766493969676]</td>\n",
       "      <td>[0.03660176581944585, -0.007633540663955829]</td>\n",
       "      <td>2.305787</td>\n",
       "      <td>0.020127</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>((1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[2.480647246257943, 4.460766493969676]</td>\n",
       "      <td>[0.03660176581944585, -0.007633540663955829]</td>\n",
       "      <td>2.305787</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>((1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1.6076412743667774, 4.341039751899087]</td>\n",
       "      <td>[0.5260028129105109, 0.6170325019945262]</td>\n",
       "      <td>3.341646</td>\n",
       "      <td>0.124116</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>((1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1.6076412743667774, 4.341039751899087]</td>\n",
       "      <td>[0.5260028129105109, 0.6170325019945262]</td>\n",
       "      <td>3.341646</td>\n",
       "      <td>-0.545797</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>((1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1.6076412743667774, 4.341039751899087]</td>\n",
       "      <td>[-0.000803785628594178, 0.03861673439674518]</td>\n",
       "      <td>4.349147</td>\n",
       "      <td>0.019678</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>((1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1.6076412743667774, 4.341039751899087]</td>\n",
       "      <td>[-0.000803785628594178, 0.03861673439674518]</td>\n",
       "      <td>4.349147</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>((1, 1), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.5532950114907047]</td>\n",
       "      <td>[0.5502838504122606]</td>\n",
       "      <td>3.553295</td>\n",
       "      <td>0.550284</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>((1, 1), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.5532950114907047]</td>\n",
       "      <td>[0.5502838504122606]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>((1, 1), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.5532950114907047]</td>\n",
       "      <td>[0.006524340521067207]</td>\n",
       "      <td>3.553295</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>((1, 1), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[3.5532950114907047]</td>\n",
       "      <td>[0.006524340521067207]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>((2, 0), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[4.258693459880285]</td>\n",
       "      <td>[0.573639164751913]</td>\n",
       "      <td>4.258693</td>\n",
       "      <td>0.573639</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>((2, 0), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[4.258693459880285]</td>\n",
       "      <td>[0.573639164751913]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>((2, 0), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[4.258693459880285]</td>\n",
       "      <td>[0.018883348924492394]</td>\n",
       "      <td>4.258693</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>((2, 0), line-6-2-0, 0, llCV2, 5)</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[4.258693459880285]</td>\n",
       "      <td>[0.018883348924492394]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>((2, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[3.1027479500559374, 1.068055666060047]</td>\n",
       "      <td>[0.5208118851107146, 0.5576309189705897]</td>\n",
       "      <td>2.030201</td>\n",
       "      <td>0.283861</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>((2, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[3.1027479500559374, 1.068055666060047]</td>\n",
       "      <td>[0.5208118851107146, 0.5576309189705897]</td>\n",
       "      <td>2.030201</td>\n",
       "      <td>-0.360478</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>((2, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[3.1027479500559374, 1.068055666060047]</td>\n",
       "      <td>[-0.00042023435476501447, 0.007078984866336402]</td>\n",
       "      <td>1.016385</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>((2, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[3.1027479500559374, 1.068055666060047]</td>\n",
       "      <td>[-0.00042023435476501447, 0.007078984866336402]</td>\n",
       "      <td>1.016385</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[4.29909647022179, 4.769091695866414]</td>\n",
       "      <td>[0.5834303339391587, 0.5706314178214175]</td>\n",
       "      <td>4.531439</td>\n",
       "      <td>0.561173</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[4.29909647022179, 4.769091695866414]</td>\n",
       "      <td>[0.5834303339391587, 0.5706314178214175]</td>\n",
       "      <td>4.531439</td>\n",
       "      <td>0.544816</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[4.29909647022179, 4.769091695866414]</td>\n",
       "      <td>[-0.0031964393020138537, 0.013700121918603814]</td>\n",
       "      <td>4.901725</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[4.29909647022179, 4.769091695866414]</td>\n",
       "      <td>[-0.0031964393020138537, 0.013700121918603814]</td>\n",
       "      <td>4.901725</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>((2, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[4.345948543525283]</td>\n",
       "      <td>[0.5573564051009982]</td>\n",
       "      <td>4.345949</td>\n",
       "      <td>0.557356</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>((2, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[4.345948543525283]</td>\n",
       "      <td>[0.5573564051009982]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_norm</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>((2, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[4.345948543525283]</td>\n",
       "      <td>[0.05048697484329567]</td>\n",
       "      <td>4.345949</td>\n",
       "      <td>0.050487</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>((2, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[4.345948543525283]</td>\n",
       "      <td>[0.05048697484329567]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dist_yue_diff</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             var_other levs_exist  \\\n",
       "0   ((-1, 1), line-6-2-0, 1, llCV2, 5)     [1, 2]   \n",
       "1   ((-1, 1), line-6-2-0, 1, llCV2, 5)     [1, 2]   \n",
       "2   ((-1, 1), line-6-2-0, 1, llCV2, 5)     [1, 2]   \n",
       "3   ((-1, 1), line-6-2-0, 1, llCV2, 5)     [1, 2]   \n",
       "4   ((-1, 1), line-6-2-0, 2, llCV2, 5)     [1, 2]   \n",
       "5   ((-1, 1), line-6-2-0, 2, llCV2, 5)     [1, 2]   \n",
       "6   ((-1, 1), line-6-2-0, 2, llCV2, 5)     [1, 2]   \n",
       "7   ((-1, 1), line-6-2-0, 2, llCV2, 5)     [1, 2]   \n",
       "8    ((0, 0), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "9    ((0, 0), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "10   ((0, 0), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "11   ((0, 0), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "12   ((0, 0), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "13   ((0, 0), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "14   ((0, 0), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "15   ((0, 0), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "16   ((0, 0), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "17   ((0, 0), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "18   ((0, 0), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "19   ((0, 0), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "20   ((0, 0), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "21   ((0, 0), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "22   ((0, 0), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "23   ((0, 0), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "24   ((1, 1), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "25   ((1, 1), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "26   ((1, 1), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "27   ((1, 1), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "28   ((1, 1), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "29   ((1, 1), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "30   ((1, 1), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "31   ((1, 1), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "32   ((1, 1), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "33   ((1, 1), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "34   ((1, 1), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "35   ((1, 1), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "36   ((1, 1), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "37   ((1, 1), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "38   ((1, 1), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "39   ((1, 1), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "40   ((2, 0), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "41   ((2, 0), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "42   ((2, 0), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "43   ((2, 0), line-6-2-0, 0, llCV2, 5)     [2, 3]   \n",
       "44   ((2, 0), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "45   ((2, 0), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "46   ((2, 0), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "47   ((2, 0), line-6-2-0, 1, llCV2, 5)  [1, 2, 3]   \n",
       "48   ((2, 0), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "49   ((2, 0), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "50   ((2, 0), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "51   ((2, 0), line-6-2-0, 2, llCV2, 5)  [1, 2, 3]   \n",
       "52   ((2, 0), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "53   ((2, 0), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "54   ((2, 0), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "55   ((2, 0), line-6-2-0, 3, llCV2, 5)     [1, 2]   \n",
       "\n",
       "                                     angles  \\\n",
       "0                       [4.832475415954616]   \n",
       "1                       [4.832475415954616]   \n",
       "2                       [4.832475415954616]   \n",
       "3                       [4.832475415954616]   \n",
       "4                      [3.7363294138416516]   \n",
       "5                      [3.7363294138416516]   \n",
       "6                      [3.7363294138416516]   \n",
       "7                      [3.7363294138416516]   \n",
       "8                       [5.821231741264794]   \n",
       "9                       [5.821231741264794]   \n",
       "10                      [5.821231741264794]   \n",
       "11                      [5.821231741264794]   \n",
       "12    [2.19406036783109, 4.277099495013471]   \n",
       "13    [2.19406036783109, 4.277099495013471]   \n",
       "14    [2.19406036783109, 4.277099495013471]   \n",
       "15    [2.19406036783109, 4.277099495013471]   \n",
       "16  [3.6342844700541534, 4.761871112779049]   \n",
       "17  [3.6342844700541534, 4.761871112779049]   \n",
       "18  [3.6342844700541534, 4.761871112779049]   \n",
       "19  [3.6342844700541534, 4.761871112779049]   \n",
       "20                      [3.177524569083286]   \n",
       "21                      [3.177524569083286]   \n",
       "22                      [3.177524569083286]   \n",
       "23                      [3.177524569083286]   \n",
       "24                      [3.466850138155289]   \n",
       "25                      [3.466850138155289]   \n",
       "26                      [3.466850138155289]   \n",
       "27                      [3.466850138155289]   \n",
       "28   [2.480647246257943, 4.460766493969676]   \n",
       "29   [2.480647246257943, 4.460766493969676]   \n",
       "30   [2.480647246257943, 4.460766493969676]   \n",
       "31   [2.480647246257943, 4.460766493969676]   \n",
       "32  [1.6076412743667774, 4.341039751899087]   \n",
       "33  [1.6076412743667774, 4.341039751899087]   \n",
       "34  [1.6076412743667774, 4.341039751899087]   \n",
       "35  [1.6076412743667774, 4.341039751899087]   \n",
       "36                     [3.5532950114907047]   \n",
       "37                     [3.5532950114907047]   \n",
       "38                     [3.5532950114907047]   \n",
       "39                     [3.5532950114907047]   \n",
       "40                      [4.258693459880285]   \n",
       "41                      [4.258693459880285]   \n",
       "42                      [4.258693459880285]   \n",
       "43                      [4.258693459880285]   \n",
       "44  [3.1027479500559374, 1.068055666060047]   \n",
       "45  [3.1027479500559374, 1.068055666060047]   \n",
       "46  [3.1027479500559374, 1.068055666060047]   \n",
       "47  [3.1027479500559374, 1.068055666060047]   \n",
       "48    [4.29909647022179, 4.769091695866414]   \n",
       "49    [4.29909647022179, 4.769091695866414]   \n",
       "50    [4.29909647022179, 4.769091695866414]   \n",
       "51    [4.29909647022179, 4.769091695866414]   \n",
       "52                      [4.345948543525283]   \n",
       "53                      [4.345948543525283]   \n",
       "54                      [4.345948543525283]   \n",
       "55                      [4.345948543525283]   \n",
       "\n",
       "                                            weights  angle_mean  norm_mean  \\\n",
       "0                              [0.5906494632238395]    4.832475   0.590649   \n",
       "1                              [0.5906494632238395]         NaN        NaN   \n",
       "2                            [0.033720521171148654]    4.832475   0.033721   \n",
       "3                            [0.033720521171148654]         NaN        NaN   \n",
       "4                               [0.530802185762632]    3.736329   0.530802   \n",
       "5                               [0.530802185762632]         NaN        NaN   \n",
       "6                           [-0.007550998155462896]    0.594737   0.007551   \n",
       "7                           [-0.007550998155462896]         NaN        NaN   \n",
       "8                              [0.5186904284585455]    5.821232   0.518690   \n",
       "9                              [0.5186904284585455]         NaN        NaN   \n",
       "10                          [-0.016462009007894518]    2.679639   0.016462   \n",
       "11                          [-0.016462009007894518]         NaN        NaN   \n",
       "12          [0.5836664065450927, 0.577959606035025]    3.227181   0.293268   \n",
       "13          [0.5836664065450927, 0.577959606035025]    3.227181  -0.406620   \n",
       "14     [0.01808606831173254, -0.005273211014596546]    1.975258   0.010588   \n",
       "15     [0.01808606831173254, -0.005273211014596546]    1.975258   0.006837   \n",
       "16         [0.5295362714679248, 0.6316296135020099]    4.253610   0.491486   \n",
       "17         [0.5295362714679248, 0.6316296135020099]    4.253610   0.378728   \n",
       "18     [0.02087890540742554, -0.007501841975837031]    3.267900   0.009459   \n",
       "19     [0.02087890540742554, -0.007501841975837031]    3.267900  -0.008196   \n",
       "20                            [0.48476327656425344]    3.177525   0.484763   \n",
       "21                            [0.48476327656425344]         NaN        NaN   \n",
       "22                            [0.03211039903858448]    3.177525   0.032110   \n",
       "23                            [0.03211039903858448]         NaN        NaN   \n",
       "24                              [0.517708828854528]    3.466850   0.517709   \n",
       "25                              [0.517708828854528]         NaN        NaN   \n",
       "26                           [0.013572115333491452]    3.466850   0.013572   \n",
       "27                           [0.013572115333491452]         NaN        NaN   \n",
       "28         [0.6245054717842959, 0.5410661327627175]    3.362047   0.321637   \n",
       "29         [0.6245054717842959, 0.5410661327627175]    3.362047  -0.366715   \n",
       "30     [0.03660176581944585, -0.007633540663955829]    2.305787   0.020127   \n",
       "31     [0.03660176581944585, -0.007633540663955829]    2.305787   0.010545   \n",
       "32         [0.5260028129105109, 0.6170325019945262]    3.341646   0.124116   \n",
       "33         [0.5260028129105109, 0.6170325019945262]    3.341646  -0.545797   \n",
       "34     [-0.000803785628594178, 0.03861673439674518]    4.349147   0.019678   \n",
       "35     [-0.000803785628594178, 0.03861673439674518]    4.349147   0.005338   \n",
       "36                             [0.5502838504122606]    3.553295   0.550284   \n",
       "37                             [0.5502838504122606]         NaN        NaN   \n",
       "38                           [0.006524340521067207]    3.553295   0.006524   \n",
       "39                           [0.006524340521067207]         NaN        NaN   \n",
       "40                              [0.573639164751913]    4.258693   0.573639   \n",
       "41                              [0.573639164751913]         NaN        NaN   \n",
       "42                           [0.018883348924492394]    4.258693   0.018883   \n",
       "43                           [0.018883348924492394]         NaN        NaN   \n",
       "44         [0.5208118851107146, 0.5576309189705897]    2.030201   0.283861   \n",
       "45         [0.5208118851107146, 0.5576309189705897]    2.030201  -0.360478   \n",
       "46  [-0.00042023435476501447, 0.007078984866336402]    1.016385   0.003638   \n",
       "47  [-0.00042023435476501447, 0.007078984866336402]    1.016385   0.001154   \n",
       "48         [0.5834303339391587, 0.5706314178214175]    4.531439   0.561173   \n",
       "49         [0.5834303339391587, 0.5706314178214175]    4.531439   0.544816   \n",
       "50   [-0.0031964393020138537, 0.013700121918603814]    4.901725   0.005473   \n",
       "51   [-0.0031964393020138537, 0.013700121918603814]    4.901725  -0.006248   \n",
       "52                             [0.5573564051009982]    4.345949   0.557356   \n",
       "53                             [0.5573564051009982]         NaN        NaN   \n",
       "54                            [0.05048697484329567]    4.345949   0.050487   \n",
       "55                            [0.05048697484329567]         NaN        NaN   \n",
       "\n",
       "   var_vector_length length_method  \n",
       "0          dist_norm           sum  \n",
       "1          dist_norm           dot  \n",
       "2      dist_yue_diff           sum  \n",
       "3      dist_yue_diff           dot  \n",
       "4          dist_norm           sum  \n",
       "5          dist_norm           dot  \n",
       "6      dist_yue_diff           sum  \n",
       "7      dist_yue_diff           dot  \n",
       "8          dist_norm           sum  \n",
       "9          dist_norm           dot  \n",
       "10     dist_yue_diff           sum  \n",
       "11     dist_yue_diff           dot  \n",
       "12         dist_norm           sum  \n",
       "13         dist_norm           dot  \n",
       "14     dist_yue_diff           sum  \n",
       "15     dist_yue_diff           dot  \n",
       "16         dist_norm           sum  \n",
       "17         dist_norm           dot  \n",
       "18     dist_yue_diff           sum  \n",
       "19     dist_yue_diff           dot  \n",
       "20         dist_norm           sum  \n",
       "21         dist_norm           dot  \n",
       "22     dist_yue_diff           sum  \n",
       "23     dist_yue_diff           dot  \n",
       "24         dist_norm           sum  \n",
       "25         dist_norm           dot  \n",
       "26     dist_yue_diff           sum  \n",
       "27     dist_yue_diff           dot  \n",
       "28         dist_norm           sum  \n",
       "29         dist_norm           dot  \n",
       "30     dist_yue_diff           sum  \n",
       "31     dist_yue_diff           dot  \n",
       "32         dist_norm           sum  \n",
       "33         dist_norm           dot  \n",
       "34     dist_yue_diff           sum  \n",
       "35     dist_yue_diff           dot  \n",
       "36         dist_norm           sum  \n",
       "37         dist_norm           dot  \n",
       "38     dist_yue_diff           sum  \n",
       "39     dist_yue_diff           dot  \n",
       "40         dist_norm           sum  \n",
       "41         dist_norm           dot  \n",
       "42     dist_yue_diff           sum  \n",
       "43     dist_yue_diff           dot  \n",
       "44         dist_norm           sum  \n",
       "45         dist_norm           dot  \n",
       "46     dist_yue_diff           sum  \n",
       "47     dist_yue_diff           dot  \n",
       "48         dist_norm           sum  \n",
       "49         dist_norm           dot  \n",
       "50     dist_yue_diff           sum  \n",
       "51     dist_yue_diff           dot  \n",
       "52         dist_norm           sum  \n",
       "53         dist_norm           dot  \n",
       "54     dist_yue_diff           sum  \n",
       "55     dist_yue_diff           dot  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuralmonkey.analyses.euclidian_distance import compute_average_angle_between_pairs_of_levels_of_vareffect\n",
    "var_effect = \"syntax_slot_0\"\n",
    "vars_others = \"('seqc_0_loc', 'seqc_0_shape', 'syntax_slot_1', 'epoch', 'FEAT_num_strokes_beh')\"\n",
    "compute_average_angle_between_pairs_of_levels_of_vareffect(dfdist, var_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0d8c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels_1</th>\n",
       "      <th>labels_2</th>\n",
       "      <th>dist_mean</th>\n",
       "      <th>n_1_2</th>\n",
       "      <th>DIST_50</th>\n",
       "      <th>DIST_98</th>\n",
       "      <th>dist_norm</th>\n",
       "      <th>dist_yue_diff</th>\n",
       "      <th>dist_within_norm</th>\n",
       "      <th>syntax_slot_0_1</th>\n",
       "      <th>syntax_slot_0_2</th>\n",
       "      <th>syntax_slot_0_12</th>\n",
       "      <th>syntax_slot_0_same</th>\n",
       "      <th>seqc_0_loc_1</th>\n",
       "      <th>seqc_0_loc_2</th>\n",
       "      <th>seqc_0_loc_12</th>\n",
       "      <th>seqc_0_loc_same</th>\n",
       "      <th>seqc_0_shape_1</th>\n",
       "      <th>seqc_0_shape_2</th>\n",
       "      <th>seqc_0_shape_12</th>\n",
       "      <th>seqc_0_shape_same</th>\n",
       "      <th>syntax_slot_1_1</th>\n",
       "      <th>syntax_slot_1_2</th>\n",
       "      <th>syntax_slot_1_12</th>\n",
       "      <th>syntax_slot_1_same</th>\n",
       "      <th>epoch_1</th>\n",
       "      <th>epoch_2</th>\n",
       "      <th>epoch_12</th>\n",
       "      <th>epoch_same</th>\n",
       "      <th>FEAT_num_strokes_beh_1</th>\n",
       "      <th>FEAT_num_strokes_beh_2</th>\n",
       "      <th>FEAT_num_strokes_beh_12</th>\n",
       "      <th>FEAT_num_strokes_beh_same</th>\n",
       "      <th>same-syntax_slot_0|seqc_0_loc|seqc_0_shape|syntax_slot_1|epoch|FEAT_num_strokes_beh</th>\n",
       "      <th>data_dim</th>\n",
       "      <th>theta</th>\n",
       "      <th>norm</th>\n",
       "      <th>vars_others_1</th>\n",
       "      <th>vars_others_2</th>\n",
       "      <th>vars_others_same</th>\n",
       "      <th>bregion</th>\n",
       "      <th>event</th>\n",
       "      <th>var_subspace</th>\n",
       "      <th>var_idx</th>\n",
       "      <th>var_effect</th>\n",
       "      <th>vars_others</th>\n",
       "      <th>same-syntax_slot_1|seqc_0_loc|seqc_0_shape|syntax_slot_0|epoch|FEAT_num_strokes_beh</th>\n",
       "      <th>i_proj</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, (-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>(1, (-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>1.572092</td>\n",
       "      <td>(11, 11)</td>\n",
       "      <td>1.610711</td>\n",
       "      <td>2.772302</td>\n",
       "      <td>0.567071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567071</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1|1</td>\n",
       "      <td>True</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(-1, 1)|(-1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0|line-6-2-0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1|1</td>\n",
       "      <td>True</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>1|1|1|1|1|1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>0</td>\n",
       "      <td>syntax_slot_0</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, (-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>(1, (-1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>1.536839</td>\n",
       "      <td>(11, 15)</td>\n",
       "      <td>1.610711</td>\n",
       "      <td>2.772302</td>\n",
       "      <td>0.554355</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>0.544300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1|1</td>\n",
       "      <td>True</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(-1, 1)|(-1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0|line-6-2-0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1|2</td>\n",
       "      <td>False</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>1|1|1|0|1|1</td>\n",
       "      <td>6</td>\n",
       "      <td>5.158629</td>\n",
       "      <td>0.339171</td>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>((-1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>0</td>\n",
       "      <td>syntax_slot_0</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, (-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>(1, (0, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>1.639922</td>\n",
       "      <td>(11, 9)</td>\n",
       "      <td>1.610711</td>\n",
       "      <td>2.772302</td>\n",
       "      <td>0.591538</td>\n",
       "      <td>0.056407</td>\n",
       "      <td>0.535131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1|1</td>\n",
       "      <td>True</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(-1, 1)|(0, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0|line-6-2-0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1|1</td>\n",
       "      <td>True</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>1|0|1|1|1|1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>0.291536</td>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>((0, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>0</td>\n",
       "      <td>syntax_slot_0</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, (-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>(1, (0, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>1.778989</td>\n",
       "      <td>(11, 14)</td>\n",
       "      <td>1.610711</td>\n",
       "      <td>2.772302</td>\n",
       "      <td>0.641701</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.547001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1|1</td>\n",
       "      <td>True</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(-1, 1)|(0, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0|line-6-2-0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1|2</td>\n",
       "      <td>False</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>1|0|1|0|1|1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.119484</td>\n",
       "      <td>0.459285</td>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>((0, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>0</td>\n",
       "      <td>syntax_slot_0</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, (-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>(1, (0, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>1.689468</td>\n",
       "      <td>(11, 8)</td>\n",
       "      <td>1.610711</td>\n",
       "      <td>2.772302</td>\n",
       "      <td>0.609410</td>\n",
       "      <td>0.058021</td>\n",
       "      <td>0.551389</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1|1</td>\n",
       "      <td>True</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(-1, 1)|(0, 0)</td>\n",
       "      <td>False</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0|line-6-2-0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1|3</td>\n",
       "      <td>False</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>1|0|1|0|1|1</td>\n",
       "      <td>6</td>\n",
       "      <td>5.133569</td>\n",
       "      <td>0.303218</td>\n",
       "      <td>((-1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>((0, 0), line-6-2-0, 3, llCV2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>0</td>\n",
       "      <td>syntax_slot_0</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>(3, (2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>(3, (1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>1.516768</td>\n",
       "      <td>(6, 12)</td>\n",
       "      <td>1.618778</td>\n",
       "      <td>2.790980</td>\n",
       "      <td>0.543454</td>\n",
       "      <td>0.005695</td>\n",
       "      <td>0.537758</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2|1</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 0)|(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0|line-6-2-0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3|3</td>\n",
       "      <td>True</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>3.140453</td>\n",
       "      <td>0.332917</td>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>((1, 1), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>1</td>\n",
       "      <td>syntax_slot_1</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...</td>\n",
       "      <td>1|0|1|0|1|1</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>(3, (2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>(3, (1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>1.506922</td>\n",
       "      <td>(6, 8)</td>\n",
       "      <td>1.618778</td>\n",
       "      <td>2.790980</td>\n",
       "      <td>0.539926</td>\n",
       "      <td>0.047823</td>\n",
       "      <td>0.492103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2|2</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 0)|(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0|line-6-2-0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3|3</td>\n",
       "      <td>True</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>3.346745</td>\n",
       "      <td>0.651298</td>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>((1, 1), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>1</td>\n",
       "      <td>syntax_slot_1</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...</td>\n",
       "      <td>1|0|1|1|1|1</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>(3, (2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>(3, (2, 0), line-6-1-0, 0, llCV2, 5)</td>\n",
       "      <td>1.620661</td>\n",
       "      <td>(6, 16)</td>\n",
       "      <td>1.618778</td>\n",
       "      <td>2.790980</td>\n",
       "      <td>0.580678</td>\n",
       "      <td>0.063139</td>\n",
       "      <td>0.517539</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2|0</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>(2, 0)|(2, 0)</td>\n",
       "      <td>True</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-1-0</td>\n",
       "      <td>line-6-2-0|line-6-1-0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3|3</td>\n",
       "      <td>True</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2.624797</td>\n",
       "      <td>0.623603</td>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>((2, 0), line-6-1-0, 0, llCV2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>1</td>\n",
       "      <td>syntax_slot_1</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...</td>\n",
       "      <td>1|1|0|0|1|1</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>(3, (2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>(3, (2, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>1.545160</td>\n",
       "      <td>(6, 9)</td>\n",
       "      <td>1.618778</td>\n",
       "      <td>2.790980</td>\n",
       "      <td>0.553626</td>\n",
       "      <td>0.050149</td>\n",
       "      <td>0.503477</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2|1</td>\n",
       "      <td>False</td>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>(2, 0)|(2, 0)</td>\n",
       "      <td>True</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0|line-6-2-0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3|3</td>\n",
       "      <td>True</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1.204356</td>\n",
       "      <td>0.737589</td>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>((2, 0), line-6-2-0, 1, llCV2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>1</td>\n",
       "      <td>syntax_slot_1</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...</td>\n",
       "      <td>1|1|1|0|1|1</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>(3, (2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>(3, (2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>1.366856</td>\n",
       "      <td>(6, 6)</td>\n",
       "      <td>1.618778</td>\n",
       "      <td>2.790980</td>\n",
       "      <td>0.489740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489740</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2|2</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>(2, 0)|(2, 0)</td>\n",
       "      <td>True</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0</td>\n",
       "      <td>line-6-2-0|line-6-2-0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3|3</td>\n",
       "      <td>True</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2</td>\n",
       "      <td>llCV2|llCV2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5|5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>((2, 0), line-6-2-0, 2, llCV2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>M1</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>(epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...</td>\n",
       "      <td>1</td>\n",
       "      <td>syntax_slot_1</td>\n",
       "      <td>(seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...</td>\n",
       "      <td>1|1|1|1|1|1</td>\n",
       "      <td>0</td>\n",
       "      <td>230728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3005 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   labels_1  \\\n",
       "0     (1, (-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "1     (1, (-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "2     (1, (-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "3     (1, (-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "4     (1, (-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "...                                     ...   \n",
       "3000   (3, (2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "3001   (3, (2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "3002   (3, (2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "3003   (3, (2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "3004   (3, (2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "\n",
       "                                   labels_2  dist_mean     n_1_2   DIST_50  \\\n",
       "0     (1, (-1, 1), line-6-2-0, 1, llCV2, 5)   1.572092  (11, 11)  1.610711   \n",
       "1     (1, (-1, 1), line-6-2-0, 2, llCV2, 5)   1.536839  (11, 15)  1.610711   \n",
       "2      (1, (0, 0), line-6-2-0, 1, llCV2, 5)   1.639922   (11, 9)  1.610711   \n",
       "3      (1, (0, 0), line-6-2-0, 2, llCV2, 5)   1.778989  (11, 14)  1.610711   \n",
       "4      (1, (0, 0), line-6-2-0, 3, llCV2, 5)   1.689468   (11, 8)  1.610711   \n",
       "...                                     ...        ...       ...       ...   \n",
       "3000   (3, (1, 1), line-6-2-0, 1, llCV2, 5)   1.516768   (6, 12)  1.618778   \n",
       "3001   (3, (1, 1), line-6-2-0, 2, llCV2, 5)   1.506922    (6, 8)  1.618778   \n",
       "3002   (3, (2, 0), line-6-1-0, 0, llCV2, 5)   1.620661   (6, 16)  1.618778   \n",
       "3003   (3, (2, 0), line-6-2-0, 1, llCV2, 5)   1.545160    (6, 9)  1.618778   \n",
       "3004   (3, (2, 0), line-6-2-0, 2, llCV2, 5)   1.366856    (6, 6)  1.618778   \n",
       "\n",
       "       DIST_98  dist_norm  dist_yue_diff  dist_within_norm  syntax_slot_0_1  \\\n",
       "0     2.772302   0.567071       0.000000          0.567071                1   \n",
       "1     2.772302   0.554355       0.010055          0.544300                1   \n",
       "2     2.772302   0.591538       0.056407          0.535131                1   \n",
       "3     2.772302   0.641701       0.094700          0.547001                1   \n",
       "4     2.772302   0.609410       0.058021          0.551389                1   \n",
       "...        ...        ...            ...               ...              ...   \n",
       "3000  2.790980   0.543454       0.005695          0.537758                2   \n",
       "3001  2.790980   0.539926       0.047823          0.492103                2   \n",
       "3002  2.790980   0.580678       0.063139          0.517539                2   \n",
       "3003  2.790980   0.553626       0.050149          0.503477                2   \n",
       "3004  2.790980   0.489740       0.000000          0.489740                2   \n",
       "\n",
       "      syntax_slot_0_2 syntax_slot_0_12  syntax_slot_0_same seqc_0_loc_1  \\\n",
       "0                   1              1|1                True      (-1, 1)   \n",
       "1                   1              1|1                True      (-1, 1)   \n",
       "2                   1              1|1                True      (-1, 1)   \n",
       "3                   1              1|1                True      (-1, 1)   \n",
       "4                   1              1|1                True      (-1, 1)   \n",
       "...               ...              ...                 ...          ...   \n",
       "3000                1              2|1               False       (2, 0)   \n",
       "3001                2              2|2                True       (2, 0)   \n",
       "3002                0              2|0               False       (2, 0)   \n",
       "3003                1              2|1               False       (2, 0)   \n",
       "3004                2              2|2                True       (2, 0)   \n",
       "\n",
       "     seqc_0_loc_2    seqc_0_loc_12  seqc_0_loc_same seqc_0_shape_1  \\\n",
       "0         (-1, 1)  (-1, 1)|(-1, 1)             True     line-6-2-0   \n",
       "1         (-1, 1)  (-1, 1)|(-1, 1)             True     line-6-2-0   \n",
       "2          (0, 0)   (-1, 1)|(0, 0)            False     line-6-2-0   \n",
       "3          (0, 0)   (-1, 1)|(0, 0)            False     line-6-2-0   \n",
       "4          (0, 0)   (-1, 1)|(0, 0)            False     line-6-2-0   \n",
       "...           ...              ...              ...            ...   \n",
       "3000       (1, 1)    (2, 0)|(1, 1)            False     line-6-2-0   \n",
       "3001       (1, 1)    (2, 0)|(1, 1)            False     line-6-2-0   \n",
       "3002       (2, 0)    (2, 0)|(2, 0)             True     line-6-2-0   \n",
       "3003       (2, 0)    (2, 0)|(2, 0)             True     line-6-2-0   \n",
       "3004       (2, 0)    (2, 0)|(2, 0)             True     line-6-2-0   \n",
       "\n",
       "     seqc_0_shape_2        seqc_0_shape_12  seqc_0_shape_same  \\\n",
       "0        line-6-2-0  line-6-2-0|line-6-2-0               True   \n",
       "1        line-6-2-0  line-6-2-0|line-6-2-0               True   \n",
       "2        line-6-2-0  line-6-2-0|line-6-2-0               True   \n",
       "3        line-6-2-0  line-6-2-0|line-6-2-0               True   \n",
       "4        line-6-2-0  line-6-2-0|line-6-2-0               True   \n",
       "...             ...                    ...                ...   \n",
       "3000     line-6-2-0  line-6-2-0|line-6-2-0               True   \n",
       "3001     line-6-2-0  line-6-2-0|line-6-2-0               True   \n",
       "3002     line-6-1-0  line-6-2-0|line-6-1-0              False   \n",
       "3003     line-6-2-0  line-6-2-0|line-6-2-0               True   \n",
       "3004     line-6-2-0  line-6-2-0|line-6-2-0               True   \n",
       "\n",
       "      syntax_slot_1_1  syntax_slot_1_2 syntax_slot_1_12  syntax_slot_1_same  \\\n",
       "0                   1                1              1|1                True   \n",
       "1                   1                2              1|2               False   \n",
       "2                   1                1              1|1                True   \n",
       "3                   1                2              1|2               False   \n",
       "4                   1                3              1|3               False   \n",
       "...               ...              ...              ...                 ...   \n",
       "3000                3                3              3|3                True   \n",
       "3001                3                3              3|3                True   \n",
       "3002                3                3              3|3                True   \n",
       "3003                3                3              3|3                True   \n",
       "3004                3                3              3|3                True   \n",
       "\n",
       "     epoch_1 epoch_2     epoch_12  epoch_same  FEAT_num_strokes_beh_1  \\\n",
       "0      llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "1      llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "2      llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "3      llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "4      llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "...      ...     ...          ...         ...                     ...   \n",
       "3000   llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "3001   llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "3002   llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "3003   llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "3004   llCV2   llCV2  llCV2|llCV2        True                       5   \n",
       "\n",
       "      FEAT_num_strokes_beh_2 FEAT_num_strokes_beh_12  \\\n",
       "0                          5                     5|5   \n",
       "1                          5                     5|5   \n",
       "2                          5                     5|5   \n",
       "3                          5                     5|5   \n",
       "4                          5                     5|5   \n",
       "...                      ...                     ...   \n",
       "3000                       5                     5|5   \n",
       "3001                       5                     5|5   \n",
       "3002                       5                     5|5   \n",
       "3003                       5                     5|5   \n",
       "3004                       5                     5|5   \n",
       "\n",
       "      FEAT_num_strokes_beh_same  \\\n",
       "0                          True   \n",
       "1                          True   \n",
       "2                          True   \n",
       "3                          True   \n",
       "4                          True   \n",
       "...                         ...   \n",
       "3000                       True   \n",
       "3001                       True   \n",
       "3002                       True   \n",
       "3003                       True   \n",
       "3004                       True   \n",
       "\n",
       "     same-syntax_slot_0|seqc_0_loc|seqc_0_shape|syntax_slot_1|epoch|FEAT_num_strokes_beh  \\\n",
       "0                                           1|1|1|1|1|1                                    \n",
       "1                                           1|1|1|0|1|1                                    \n",
       "2                                           1|0|1|1|1|1                                    \n",
       "3                                           1|0|1|0|1|1                                    \n",
       "4                                           1|0|1|0|1|1                                    \n",
       "...                                                 ...                                    \n",
       "3000                                                NaN                                    \n",
       "3001                                                NaN                                    \n",
       "3002                                                NaN                                    \n",
       "3003                                                NaN                                    \n",
       "3004                                                NaN                                    \n",
       "\n",
       "      data_dim     theta      norm                       vars_others_1  \\\n",
       "0            6  0.000000  0.000000  ((-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "1            6  5.158629  0.339171  ((-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "2            6  0.011681  0.291536  ((-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "3            6  0.119484  0.459285  ((-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "4            6  5.133569  0.303218  ((-1, 1), line-6-2-0, 1, llCV2, 5)   \n",
       "...        ...       ...       ...                                 ...   \n",
       "3000         6  3.140453  0.332917   ((2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "3001         6  3.346745  0.651298   ((2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "3002         6  2.624797  0.623603   ((2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "3003         6  1.204356  0.737589   ((2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "3004         6  0.000000  0.000000   ((2, 0), line-6-2-0, 2, llCV2, 5)   \n",
       "\n",
       "                           vars_others_2  vars_others_same bregion    event  \\\n",
       "0     ((-1, 1), line-6-2-0, 1, llCV2, 5)              True      M1  03_samp   \n",
       "1     ((-1, 1), line-6-2-0, 2, llCV2, 5)             False      M1  03_samp   \n",
       "2      ((0, 0), line-6-2-0, 1, llCV2, 5)             False      M1  03_samp   \n",
       "3      ((0, 0), line-6-2-0, 2, llCV2, 5)             False      M1  03_samp   \n",
       "4      ((0, 0), line-6-2-0, 3, llCV2, 5)             False      M1  03_samp   \n",
       "...                                  ...               ...     ...      ...   \n",
       "3000   ((1, 1), line-6-2-0, 1, llCV2, 5)             False      M1  03_samp   \n",
       "3001   ((1, 1), line-6-2-0, 2, llCV2, 5)             False      M1  03_samp   \n",
       "3002   ((2, 0), line-6-1-0, 0, llCV2, 5)             False      M1  03_samp   \n",
       "3003   ((2, 0), line-6-2-0, 1, llCV2, 5)             False      M1  03_samp   \n",
       "3004   ((2, 0), line-6-2-0, 2, llCV2, 5)              True      M1  03_samp   \n",
       "\n",
       "                                           var_subspace  var_idx  \\\n",
       "0     (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        0   \n",
       "1     (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        0   \n",
       "2     (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        0   \n",
       "3     (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        0   \n",
       "4     (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        0   \n",
       "...                                                 ...      ...   \n",
       "3000  (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        1   \n",
       "3001  (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        1   \n",
       "3002  (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        1   \n",
       "3003  (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        1   \n",
       "3004  (epoch, FEAT_num_strokes_beh, seqc_0_loc, seqc...        1   \n",
       "\n",
       "         var_effect                                        vars_others  \\\n",
       "0     syntax_slot_0  (seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...   \n",
       "1     syntax_slot_0  (seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...   \n",
       "2     syntax_slot_0  (seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...   \n",
       "3     syntax_slot_0  (seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...   \n",
       "4     syntax_slot_0  (seqc_0_loc, seqc_0_shape, syntax_slot_1, epoc...   \n",
       "...             ...                                                ...   \n",
       "3000  syntax_slot_1  (seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...   \n",
       "3001  syntax_slot_1  (seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...   \n",
       "3002  syntax_slot_1  (seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...   \n",
       "3003  syntax_slot_1  (seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...   \n",
       "3004  syntax_slot_1  (seqc_0_loc, seqc_0_shape, syntax_slot_0, epoc...   \n",
       "\n",
       "     same-syntax_slot_1|seqc_0_loc|seqc_0_shape|syntax_slot_0|epoch|FEAT_num_strokes_beh  \\\n",
       "0                                                   NaN                                    \n",
       "1                                                   NaN                                    \n",
       "2                                                   NaN                                    \n",
       "3                                                   NaN                                    \n",
       "4                                                   NaN                                    \n",
       "...                                                 ...                                    \n",
       "3000                                        1|0|1|0|1|1                                    \n",
       "3001                                        1|0|1|1|1|1                                    \n",
       "3002                                        1|1|0|0|1|1                                    \n",
       "3003                                        1|1|1|0|1|1                                    \n",
       "3004                                        1|1|1|1|1|1                                    \n",
       "\n",
       "      i_proj    date  \n",
       "0          0  230728  \n",
       "1          0  230728  \n",
       "2          0  230728  \n",
       "3          0  230728  \n",
       "4          0  230728  \n",
       "...      ...     ...  \n",
       "3000       0  230728  \n",
       "3001       0  230728  \n",
       "3002       0  230728  \n",
       "3003       0  230728  \n",
       "3004       0  230728  \n",
       "\n",
       "[3005 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e4efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84430b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD: compare angles of regression coefficients\n",
    "##### Compare angles of regression coefficients across all conditions.\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import ordinalregress_2_regr_coeff_pairs\n",
    "savedir = f\"{SAVEDIR}/pairwise_regr_coeffs\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "ordinalregress_2_regr_coeff_pairs(DFWITHIN, savedir=savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d19162",
   "metadata": {},
   "source": [
    "##### [DEbugging].. failure in agging..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c44792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Solved -- now agging within each (var, vars_others) instead of after combining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/tmp/df.pkl\"\n",
    "df = pd.read_pickle(path)\n",
    "np.stack(df[\"coeff\"])\n",
    "from pythonlib.tools.pandastools import pad_tuple_values_to_same_length\n",
    "for col in [\"grp\", \"vars_grp\"]:\n",
    "    pad_tuple_values_to_same_length(df, col, col)\n",
    "\n",
    "def F(x):\n",
    "    X = np.stack(x)\n",
    "    return np.mean(X, axis=0)\n",
    "# group = ['grp', 'vars_grp', 'yvar']\n",
    "group = ['grp']\n",
    "# agg = {'coeff': F, 'balanced_accuracy': ['mean'], 'balanced_accuracy_adjusted': ['mean'], 'accuracy': ['mean'], 'score_train': ['mean'], 'n_labels_train': ['mean']}\n",
    "# agg = {'balanced_accuracy': ['mean'], 'balanced_accuracy_adjusted': ['mean'], 'accuracy': ['mean'], 'score_train': ['mean'], 'n_labels_train': ['mean']}\n",
    "agg = {'accuracy': ['mean']}\n",
    "from pythonlib.tools.pandastools import stringify_values\n",
    "# tmp = df[\"\"]\n",
    "df = stringify_values(df)\n",
    "dfagg = df[1240:].groupby(group).agg(agg).reset_index()\n",
    "df.loc[1230:1240, :]\n",
    "df[\"grp\"].value_counts()\n",
    "from pythonlib.tools.pandastools import pad_tuple_values_to_same_length\n",
    "pad_tuple_values_to_same_length(df, \"grp\", \"grp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a184c",
   "metadata": {},
   "source": [
    "##### [Debugging] Comparing old and new results for angle scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdcf949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: solved. Recent run was wrong becuase it was taking angle using just first 2 dims, even though the space is 6d. Code updated to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfangle_old = pd.read_pickle(\"/lemur2/lucas/analyses/recordings/main/syntax_good_trial/targeted_dim_redu_angles/Diego-230726-comb=False-q=RULE_BASE_trial/DFANGLE.pkl\")\n",
    "dfangle_new = pd.read_pickle(\"/lemur2/lucas/analyses/recordings/main/syntax_good_trial/targeted_pca_v2/Diego-230726-q=RULE_BASE_trial/03_samp-vlPFC/DFANGLE.pkl\")\n",
    "# dfangle_old = dfangle_old[dfangle_old[\"bregion\"].isin([\"preSMA_p\", \"preSMA_a\"])].reset_index(drop=True)\n",
    "dfangle_old = dfangle_old[dfangle_old[\"bregion\"].isin([\"vlPFC_p\"])].reset_index(drop=True)\n",
    "\n",
    "dfangle_old[\"n_levs\"] = dfangle_old[\"levs_exist\"].map(len)\n",
    "dfangle_new[\"n_levs\"] = dfangle_new[\"levs_exist\"].map(len)\n",
    "# dfangle_new = stringify_values(dfangle_new)\n",
    "dfangle_new\n",
    "dfangle_old\n",
    "len(dfangle_old), len(dfangle_new)\n",
    "dfangle_old[(dfangle_old[\"var_vector_length\"]==\"dist_yue_diff\") & (dfangle_old[\"length_method\"]==\"dot\") & (dfangle_old[\"n_levs\"]==3)]\n",
    "\n",
    "dfangle_new[(dfangle_new[\"var_vector_length\"]==\"dist_yue_diff\") & (dfangle_new[\"length_method\"]==\"dot\") & (dfangle_new[\"n_levs\"]==3)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drag2_matlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
