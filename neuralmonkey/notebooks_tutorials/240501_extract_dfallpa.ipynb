{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e3fd17c4f13ba43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:19:17.870857780Z",
     "start_time": "2024-04-26T04:19:17.840623783Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nFor extracting and saving DFallpa objects\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\"\"\n",
    "For extracting and saving DFallpa objects\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e1e23ec6b587",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load a DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea6f5073b3909f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T04:26:53.950560389Z",
     "start_time": "2024-04-26T04:22:47.458873356Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Char, \n",
    "# animal = \"Pancho\"\n",
    "# date = 230623\n",
    "# do_combine = True\n",
    "\n",
    "# Single prim, novels\n",
    "animal = \"Diego\"\n",
    "# date = 231211\n",
    "# date = 240619\n",
    "# animal = \"Diego\"\n",
    "date = 231211\n",
    "# date = 240605\n",
    "# date = 230615\n",
    "do_combine = False\n",
    "\n",
    "if do_combine:\n",
    "    # COMBINE trial and stroke\n",
    "    dir_suffix = \"test\"\n",
    "    question = None\n",
    "    # q_params = None\n",
    "    which_level = None\n",
    "    q_params = {\n",
    "        \"effect_vars\": [\"seqc_0_shape\", \"seqc_0_loc\"]\n",
    "    }\n",
    "    \n",
    "    combine_trial_and_stroke = True\n",
    "    \n",
    "    # PIG\n",
    "    # question_trial = \"PIG_BASE_trial\"\n",
    "    # question_stroke = \"PIG_BASE_stroke\"\n",
    "    # check_that_locs_match = True\n",
    "    \n",
    "    # CHAR\n",
    "    question_trial = \"PIG_BASE_trial\"\n",
    "    question_stroke = \"PIG_BASE_stroke\"\n",
    "    check_that_locs_match = False\n",
    "    check_that_shapes_match = False\n",
    "\n",
    "    HACK_RENAME_SHAPES = \"CHAR\" in question_trial\n",
    "    \n",
    "    events_keep_trials = [\"03_samp\", \"05_first_raise\"]\n",
    "\n",
    "else:\n",
    "    # DONT COMBINE, use questions.\n",
    "    # question = \"SS_shape\"\n",
    "    question = \"CHAR_BASE_stroke\"\n",
    "    # question = \"CHAR_BASE_trial\"\n",
    "    # question = \"SP_shape_loc\"\n",
    "    # question = \"SP_BASE_stroke\"\n",
    "    # question = \"SP_BASE_trial\"\n",
    "    # question = \"PIG_BASE_trial\"\n",
    "    # question = \"RULE_BASE_trial\"\n",
    "    # question = \"PIG_BASE_stroke\"\n",
    "    # question = \"RULE_ANBMCK_STROKE\"\n",
    "    \n",
    "    # which_level = \"trial\" # Doesnt matter\n",
    "    which_level = \"stroke\" # Doesnt matter\n",
    "    # which_level = \"substroke\" # Doesnt matter\n",
    "\n",
    "    dir_suffix = question\n",
    "    combine_trial_and_stroke = False\n",
    "    # Load q_params\n",
    "    from neuralmonkey.analyses.rsa import rsagood_questions_dict, rsagood_questions_params\n",
    "    q_params = rsagood_questions_dict(animal, date, question)[question]\n",
    "\n",
    "    HACK_RENAME_SHAPES = \"CHAR\" in question\n",
    "    events_keep = [\"00_stroke\"]\n",
    "    # events_keep = [\"03_samp\", \"05_first_raise\", \"06_on_strokeidx_0\"]\n",
    "\n",
    "\n",
    "############### PARAMS\n",
    "exclude_bad_areas = True\n",
    "SPIKES_VERSION = \"kilosort_if_exists\" # since Snippets not yet extracted for ks\n",
    "# SPIKES_VERSION = \"tdt\" # since Snippets not yet extracted for ks\n",
    "combine_into_larger_areas = True\n",
    "\n",
    "\n",
    "list_time_windows = [(-0.8, 1.2)]\n",
    "# list_time_windows = [(-0.8, 1.4)]\n",
    "# list_time_windows = [(-0.8, 1.25)]\n",
    "# list_time_windows = [(-1., 1.6)]\n",
    "# events_keep = None\n",
    "# events_keep = [\"03_samp\", \"05_first_raise\", \"06_on_strokeidx_0\"]\n",
    "# events_keep = [\"03_samp\", \"05_first_raise\", \"06_on_strokeidx_0\"]\n",
    "fr_normalization_method = None\n",
    "# fr_normalization_method = \"across_time_bins\"\n",
    "\n",
    "########################################## RUN\n",
    "\n",
    "if combine_trial_and_stroke:\n",
    "    from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper_combine_trial_strokes\n",
    "    DFallpa = dfallpa_extraction_load_wrapper_combine_trial_strokes(animal, date, question_trial,\n",
    "                                                                       question_stroke,\n",
    "                                                list_time_windows, events_keep_trials=events_keep_trials,\n",
    "                                               combine_into_larger_areas = combine_into_larger_areas,\n",
    "                                               exclude_bad_areas=exclude_bad_areas,\n",
    "                                                SPIKES_VERSION=SPIKES_VERSION,\n",
    "                                                HACK_RENAME_SHAPES = HACK_RENAME_SHAPES,\n",
    "                                               fr_normalization_method=fr_normalization_method,\n",
    "                                                    check_that_shapes_match=check_that_shapes_match,\n",
    "                                                check_that_locs_match=check_that_locs_match)\n",
    "else:\n",
    "    from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper\n",
    "    DFallpa = dfallpa_extraction_load_wrapper(animal, date, question, list_time_windows,\n",
    "                                              which_level=which_level, events_keep=events_keep,\n",
    "                                              combine_into_larger_areas = combine_into_larger_areas,\n",
    "                                              exclude_bad_areas = exclude_bad_areas,\n",
    "                                              SPIKES_VERSION = SPIKES_VERSION,\n",
    "                                              HACK_RENAME_SHAPES = HACK_RENAME_SHAPES,\n",
    "                                              fr_normalization_method=fr_normalization_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = DFallpa[\"pa\"].values[0]\n",
    "dflab = pa.Xlabels[\"trials\"]\n",
    "pa.Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d588f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab[\"shape_semantic_grp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8322d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab[\"shape_semantic_grp\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897523ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(dflab.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pa.Xlabels[\"trials\"]:\n",
    "    print(col, \"   ====   \", type(pa.Xlabels[\"trials\"][col].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(pa.Xlabels[\"trials\"][\"seqc_0_shape\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6769cb",
   "metadata": {},
   "source": [
    "# Eye tracking (Kedar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.session import load_mult_session_helper\n",
    "from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper\n",
    "from neuralmonkey.classes.snippets import load_and_concat_mult_snippets\n",
    "from neuralmonkey.analyses.rsa import rsagood_questions_dict\n",
    "import pythonlib\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get session object\n",
    "animal = \"Diego\"\n",
    "date_list = [230630]\n",
    "RUN_CLUSTERFIX = False\n",
    "\n",
    "question = \"PIG_BASE_saccade_fix_on\" # holds variety of prepropoessing steps to clean data, specificalyl for PIG data.\n",
    "list_time_windows = [(-0.4, 0.4)] # to slice data including just within this time window (realtive to events)\n",
    "##### note: fine for preparation period, but may want to change if diff period^\n",
    "events_keep = [\"00_fixon_preparation\"]\n",
    "combine_into_larger_areas = False\n",
    "which_level = \"saccade_fix_on\"\n",
    "SPIKES_VERSION = \"kilosort_if_exists\"\n",
    "\n",
    "for date in date_list:\n",
    "    MS = load_mult_session_helper(date, animal, spikes_version=SPIKES_VERSION)\n",
    "    # sn = MS.SessionsList[session]\n",
    "\n",
    "    if RUN_CLUSTERFIX==True:\n",
    "        for sn in MS.SessionsList:\n",
    "            session = sn.RecSession\n",
    "            print(\"doing session: \", session)\n",
    "            savedir = f\"/home/kgg/Desktop/eyetracking_analyses/{animal}-{date}-{session}\"\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            sn.extract_and_save_clusterfix_results()\n",
    "        \n",
    "    DFallpa = dfallpa_extraction_load_wrapper(animal, date, question, list_time_windows,\n",
    "                                        which_level=which_level,\n",
    "                                        events_keep = events_keep,\n",
    "                                        combine_into_larger_areas=combine_into_larger_areas,\n",
    "                                        HACK_RENAME_SHAPES=False,\n",
    "                                        SPIKES_VERSION=SPIKES_VERSION)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    os.makedirs(savedir_pkl, exist_ok=True)    \n",
    "    savedir_pkl = f\"/home/kgg/Desktop/eyetracking_analyses/{animal}-{date}\"\n",
    "    DFallpa.to_pickle(savedir_pkl + \"/dfallpa.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23f4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddfeb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = DFallpa[\"pa\"].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d715a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.Chans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(pa.Xlabels[\"trials\"].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7dc437",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.plotwrapper_smoothed_fr_split_by_label_and_subplots(pa.Chans[23], \"shape-fixation\", (\"early-or-late-planning-period\", \"seqc_0_shape\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f47d540",
   "metadata": {},
   "source": [
    "# Saving DFallpa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25604cfd55e0753",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save DFallpa as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7b42e24ed9b46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T05:10:32.255719914Z",
     "start_time": "2024-04-26T05:10:32.137060753Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save it\n",
    "import pandas as pd\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/DFallpa.pkl\"\n",
    "# path = \"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Dolnik/DFallpa.pkl\"\n",
    "# path = \"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Dolnik/DFallpa_2.pkl\" # (tdt) (no norm)\n",
    "# path = \"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Dolnik/DFallpa_3.pkl\" # (no norm)\n",
    "# path = \"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Dolnik/DFallpa_4.pkl\" # (tdt)\n",
    "# path = \"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Dolnik/DFallpa_KS.pkl\" # (kilosort)\n",
    "# path = \"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Dolnik/DFallpa_KS_nonorm.pkl\" # (kilosort)\n",
    "\n",
    "# Dan: tough decoding, syntax stuff.\n",
    "# path = f\"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Dolnik/DFallpa-{animal}-{date}-{which_level}-tdt_nonorm.pkl\"\n",
    "\n",
    "# Xuan: Diego, char, good for testing tough shape decoding\n",
    "# path = f\"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Xuan/DFallpa-{animal}-{date}-{which_level}-ks_nonorm.pkl\"\n",
    "path = f\"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Xuan/DFallpa-{animal}-{date}-{which_level}-{SPIKES_VERSION}-norm={fr_normalization_method}-combine={combine_into_larger_areas}.pkl\"\n",
    "\n",
    "pd.to_pickle(DFallpa, path)\n",
    "print(\"Saved to:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d2d70",
   "metadata": {},
   "source": [
    "### Save raw data [Dolnik]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = \"Diego\"\n",
    "date = 240516\n",
    "which_level = \"trial\"\n",
    "SPIKES_VERSION = \"kilosort_if_exists\"\n",
    "fr_normalization_method = None\n",
    "combine_into_larger_areas = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcdaba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKES_VERSION = \"kilosort_if_exists\"\n",
    "fr_normalization_method = None\n",
    "combine_into_larger_areas = True\n",
    "which_level = \"trial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### To save DFallPA\n",
    "from neuralmonkey.classes.population_mult import data_extract_raw_and_save\n",
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper\n",
    "DFallpa, path = load_handsaved_wrapper(\"Diego\", 230615, \"trial\", question=\"SP_BASE_trial\", also_return_path=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b556a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = '/lemur2/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Xuan/DFallpa-Diego-230615-trial-kilosort_if_exists-norm=None-combine=True-t1=-1.0-t2=1.8-quest=SP_BASE_trial-RAW.pkl'\n",
    "data_extract_raw_and_save(DFallpa, savepath)\n",
    "# pd.to_pickle(DFallpa, savepath)gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070d412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff681c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RAW (Dan saved)\n",
    "import pandas as pd\n",
    "path = \"/home/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Xuan/DFallpa-Diego-240516-trial-kilosort_if_exists-norm=None-combine=True-RAW.pkl\" # Novel prims.\n",
    "DFallpa = pd.read_pickle(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e4d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab = DFallpa[\"labels\"].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(dflab[\"seqc_0_shape\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "s = \"asdfdasfdsafsadfsdafsaddf1- 123 130i23 .\"\n",
    "r = random.Random(s); \n",
    "\"\".join([str(r.randrange(10)) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965218c",
   "metadata": {},
   "source": [
    "# Load a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9499e9",
   "metadata": {},
   "source": [
    "To load and plot a dataset of neural activity across population, in a PopAnal class object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6120f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80bb91bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "to not run into error of loading old pa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m combine_areas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m load_spike_counts_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m DFallpa \u001b[38;5;241m=\u001b[39m \u001b[43mload_handsaved_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43manimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine_areas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_spike_counts_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/neuralmonkey/neuralmonkey/classes/population_mult.py:27\u001b[0m, in \u001b[0;36mload_handsaved_wrapper\u001b[0;34m(animal, date, version, combine_areas, return_none_if_no_exist, use_time, question, ignore_question, also_return_path, load_spike_counts_version, spike_counts_binsize)\u001b[0m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m     if not ignore_question:\n\u001b[0;32m---> 27\u001b[0m         assert question is not None, \"to not run into error of loading old pa\"\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m     if animal is not None:\n",
      "\u001b[0;31mAssertionError\u001b[0m: to not run into error of loading old pa"
     ]
    }
   ],
   "source": [
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper\n",
    "animal = \"Diego\"\n",
    "date = 230615\n",
    "version = \"trial\"\n",
    "combine_areas = True\n",
    "load_spike_counts_version = True\n",
    "DFallpa = load_handsaved_wrapper(animal, date, version, combine_areas, load_spike_counts_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149e048",
   "metadata": {},
   "source": [
    "##### [Optionally, merge across events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f04e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfpa_group_and_split\n",
    "\n",
    "DFallpa = dfpa_group_and_split(DFallpa, [\"event\"], concat_dim=\"trials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = DFallpa[\"pa\"].values[0]\n",
    "pa.Xlabels[\"trials\"][\"event\"].value_counts()\n",
    "pa.plotNeurHeat(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9995f0d",
   "metadata": {},
   "source": [
    "##### Preprocess fr normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c315129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfallpa_preprocess_fr_normalization\n",
    "dfallpa_preprocess_fr_normalization(DFallpa, \"across_time_bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765f0097",
   "metadata": {},
   "source": [
    "# [LFADS] Prep dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2515cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa52ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DFallpa from:  /lemur2/lucas/Dropbox/SCIENCE/FREIWALD_LAB/DATA/Xuan/DFallpa-Diego-230615-trial-kilosort_if_exists-norm=None-combine=True-t1=-1.0-t2=1.8-quest=SP_BASE_trial-spkcnts_binsz=0.01.pkl\n"
     ]
    }
   ],
   "source": [
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper\n",
    "animal = \"Diego\"\n",
    "date = 230615\n",
    "version = \"trial\"\n",
    "question = \"SP_BASE_trial\"\n",
    "combine_areas = True\n",
    "load_spike_counts_version = True\n",
    "DFallpa = load_handsaved_wrapper(animal, date, version, combine_areas, question=question, load_spike_counts_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeecc55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682d622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract data in this format\n",
    "\n",
    "# # Basic Walkthrough\n",
    "# ## DataModule Configuration\n",
    "# The first step in applying `lfads-torch` to your dataset is to prepare your preprocessed data files. Save your data as `n_samples x n_timesteps x n_channels` arrays in the HDF5 format using the following keys:\n",
    "# - `train_encod_data`: Data to be used as input when training the model.\n",
    "# - `train_recon_data`: Data to be used as a reconstruction target when training the model.\n",
    "# - `valid_encod_data`: Data to be used as input when validating the model.\n",
    "# - `valid_recon_data`: Data to be used as a reconstruction target when validating the model.\n",
    "\n",
    "# Note that for both training and validation data, `encod_data` may be the same as `recon_data`, but they can be different to allow prediction of held out neurons or time steps.\n",
    "\n",
    "# Create a new configuration file for your dataset (e.g. `configs/datamodule/my_datamodule.yaml`). For single-session runs, set `datafile_pattern` to the path to your data file. For multi-session runs, set `datafile_pattern` to a `glob`-style pattern that matches all of your data files.\n",
    "# ```\n",
    "# _target_: lfads_torch.datamodules.BasicDataModule\n",
    "# datafile_pattern: <PATH-TO-HDF5-FILE>\n",
    "# batch_size: <YOUR-BATCH-SIZE>\n",
    "# ```\n",
    "\n",
    "# We provide preprocessed example data files from the Neural Latents Benchmark in `datasets`. With [`nlb_tools`](https://github.com/neurallatents/nlb_tools) installed in your environment, you can additionally use the `NLBEvaluation` extension to monitor NLB metrics while training `lfads-torch` models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d053a4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>which_level</th>\n",
       "      <th>event</th>\n",
       "      <th>bregion</th>\n",
       "      <th>twind</th>\n",
       "      <th>pa</th>\n",
       "      <th>pa_x_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trial</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>M1</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(46, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trial</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>PMv</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(70, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trial</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>PMd</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(37, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trial</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>dlPFC</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(23, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trial</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>vlPFC</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(54, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trial</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>FP</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(35, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trial</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>SMA</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(53, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trial</td>\n",
       "      <td>03_samp</td>\n",
       "      <td>preSMA</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(68, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trial</td>\n",
       "      <td>05_first_raise</td>\n",
       "      <td>M1</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(46, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trial</td>\n",
       "      <td>05_first_raise</td>\n",
       "      <td>PMv</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(70, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trial</td>\n",
       "      <td>05_first_raise</td>\n",
       "      <td>PMd</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(37, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>trial</td>\n",
       "      <td>05_first_raise</td>\n",
       "      <td>dlPFC</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(23, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>trial</td>\n",
       "      <td>05_first_raise</td>\n",
       "      <td>vlPFC</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(54, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>trial</td>\n",
       "      <td>05_first_raise</td>\n",
       "      <td>FP</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(35, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>trial</td>\n",
       "      <td>05_first_raise</td>\n",
       "      <td>SMA</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(53, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>trial</td>\n",
       "      <td>05_first_raise</td>\n",
       "      <td>preSMA</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(68, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>trial</td>\n",
       "      <td>06_on_strokeidx_0</td>\n",
       "      <td>M1</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(46, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trial</td>\n",
       "      <td>06_on_strokeidx_0</td>\n",
       "      <td>PMv</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(70, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>trial</td>\n",
       "      <td>06_on_strokeidx_0</td>\n",
       "      <td>PMd</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(37, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>trial</td>\n",
       "      <td>06_on_strokeidx_0</td>\n",
       "      <td>dlPFC</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(23, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trial</td>\n",
       "      <td>06_on_strokeidx_0</td>\n",
       "      <td>vlPFC</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(54, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trial</td>\n",
       "      <td>06_on_strokeidx_0</td>\n",
       "      <td>FP</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(35, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>trial</td>\n",
       "      <td>06_on_strokeidx_0</td>\n",
       "      <td>SMA</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(53, 425, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>trial</td>\n",
       "      <td>06_on_strokeidx_0</td>\n",
       "      <td>preSMA</td>\n",
       "      <td>(-1.0, 1.8)</td>\n",
       "      <td>&lt;neuralmonkey.classes.population.PopAnal objec...</td>\n",
       "      <td>(68, 425, 280)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   which_level              event bregion        twind  \\\n",
       "0        trial            03_samp      M1  (-1.0, 1.8)   \n",
       "1        trial            03_samp     PMv  (-1.0, 1.8)   \n",
       "2        trial            03_samp     PMd  (-1.0, 1.8)   \n",
       "3        trial            03_samp   dlPFC  (-1.0, 1.8)   \n",
       "4        trial            03_samp   vlPFC  (-1.0, 1.8)   \n",
       "5        trial            03_samp      FP  (-1.0, 1.8)   \n",
       "6        trial            03_samp     SMA  (-1.0, 1.8)   \n",
       "7        trial            03_samp  preSMA  (-1.0, 1.8)   \n",
       "8        trial     05_first_raise      M1  (-1.0, 1.8)   \n",
       "9        trial     05_first_raise     PMv  (-1.0, 1.8)   \n",
       "10       trial     05_first_raise     PMd  (-1.0, 1.8)   \n",
       "11       trial     05_first_raise   dlPFC  (-1.0, 1.8)   \n",
       "12       trial     05_first_raise   vlPFC  (-1.0, 1.8)   \n",
       "13       trial     05_first_raise      FP  (-1.0, 1.8)   \n",
       "14       trial     05_first_raise     SMA  (-1.0, 1.8)   \n",
       "15       trial     05_first_raise  preSMA  (-1.0, 1.8)   \n",
       "16       trial  06_on_strokeidx_0      M1  (-1.0, 1.8)   \n",
       "17       trial  06_on_strokeidx_0     PMv  (-1.0, 1.8)   \n",
       "18       trial  06_on_strokeidx_0     PMd  (-1.0, 1.8)   \n",
       "19       trial  06_on_strokeidx_0   dlPFC  (-1.0, 1.8)   \n",
       "20       trial  06_on_strokeidx_0   vlPFC  (-1.0, 1.8)   \n",
       "21       trial  06_on_strokeidx_0      FP  (-1.0, 1.8)   \n",
       "22       trial  06_on_strokeidx_0     SMA  (-1.0, 1.8)   \n",
       "23       trial  06_on_strokeidx_0  preSMA  (-1.0, 1.8)   \n",
       "\n",
       "                                                   pa      pa_x_shape  \n",
       "0   <neuralmonkey.classes.population.PopAnal objec...  (46, 425, 280)  \n",
       "1   <neuralmonkey.classes.population.PopAnal objec...  (70, 425, 280)  \n",
       "2   <neuralmonkey.classes.population.PopAnal objec...  (37, 425, 280)  \n",
       "3   <neuralmonkey.classes.population.PopAnal objec...  (23, 425, 280)  \n",
       "4   <neuralmonkey.classes.population.PopAnal objec...  (54, 425, 280)  \n",
       "5   <neuralmonkey.classes.population.PopAnal objec...  (35, 425, 280)  \n",
       "6   <neuralmonkey.classes.population.PopAnal objec...  (53, 425, 280)  \n",
       "7   <neuralmonkey.classes.population.PopAnal objec...  (68, 425, 280)  \n",
       "8   <neuralmonkey.classes.population.PopAnal objec...  (46, 425, 280)  \n",
       "9   <neuralmonkey.classes.population.PopAnal objec...  (70, 425, 280)  \n",
       "10  <neuralmonkey.classes.population.PopAnal objec...  (37, 425, 280)  \n",
       "11  <neuralmonkey.classes.population.PopAnal objec...  (23, 425, 280)  \n",
       "12  <neuralmonkey.classes.population.PopAnal objec...  (54, 425, 280)  \n",
       "13  <neuralmonkey.classes.population.PopAnal objec...  (35, 425, 280)  \n",
       "14  <neuralmonkey.classes.population.PopAnal objec...  (53, 425, 280)  \n",
       "15  <neuralmonkey.classes.population.PopAnal objec...  (68, 425, 280)  \n",
       "16  <neuralmonkey.classes.population.PopAnal objec...  (46, 425, 280)  \n",
       "17  <neuralmonkey.classes.population.PopAnal objec...  (70, 425, 280)  \n",
       "18  <neuralmonkey.classes.population.PopAnal objec...  (37, 425, 280)  \n",
       "19  <neuralmonkey.classes.population.PopAnal objec...  (23, 425, 280)  \n",
       "20  <neuralmonkey.classes.population.PopAnal objec...  (54, 425, 280)  \n",
       "21  <neuralmonkey.classes.population.PopAnal objec...  (35, 425, 280)  \n",
       "22  <neuralmonkey.classes.population.PopAnal objec...  (53, 425, 280)  \n",
       "23  <neuralmonkey.classes.population.PopAnal objec...  (68, 425, 280)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed503edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Diego'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal = \"Diego\"\n",
    "date = 230615\n",
    "version = \"trial\"\n",
    "question = \"SP_BASE_trial\"\n",
    "combine_areas = True\n",
    "load_spike_counts_version = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e96c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = f\"/lemur2/lucas/neural_preprocess/LFADS/{animal}-{date}-{version}-{question}-combine={combine_areas}\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "import numpy as np\n",
    "\n",
    "for i, row in DFallpa.iterrows():\n",
    "    \n",
    "    bregion = row[\"bregion\"]\n",
    "    event = row[\"event\"]\n",
    "    PA = row[\"pa\"]\n",
    "    X = np.transpose(PA.X, axes=(1, 2, 0)) # n_samples(ntrials) x n_timesteps x n_channels\n",
    "    import h5py\n",
    "    # 'train_encod_data`: Data to be used as input when training the model.\n",
    "    # `train_recon_data`: Data to be used as a reconstruction target when training the model.\n",
    "    # `valid_encod_data`: Data to be used as input when validating the model.\n",
    "    # `valid_recon_data`: Data to be used as a reconstruction target when validating the model.\n",
    "\n",
    "    savepath = f\"{SAVEDIR}/{bregion}-{event}.h5\"\n",
    "    print(savepath)\n",
    "    with h5py.File(savepath, 'w') as hdf:\n",
    "        hdf.create_dataset('train_encod_data', data=X)\n",
    "        hdf.create_dataset('train_recon_data', data=X)\n",
    "        hdf.create_dataset('valid_encod_data', data=X)\n",
    "        hdf.create_dataset('valid_recon_data', data=X)\n",
    "        # hdf.create_dataset('train_labels', data=train_label_array)\n",
    "        # hdf.create_dataset('holdout_labels', data=holdout_label_array)\n",
    "        # hdf.create_dataset('test_data', data=reshaped_test)\n",
    "        # hdf.create_dataset('test_labels', data=test_label_array)\n",
    "\n",
    "    with h5py.File(savepath, 'r') as hdf:\n",
    "        data1 = hdf['train_encod_data']\n",
    "        data2 = hdf['valid_encod_data']\n",
    "        # data5 = hdf['test_data']\n",
    "        print(data1.shape)\n",
    "        print(data2.shape)\n",
    "        # print(data5.shape)\n",
    "    path = \"/home/lucas/code/lfads-torch-clean/datasets/mc_maze_small-05ms-val.h5\"\n",
    "    with h5py.File(path, \"r\") as hdf:\n",
    "        print(hdf.keys())\n",
    "        print(hdf[\"train_encod_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d433cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee97474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The spiking data were binned at 1 ms and smoothed by convolution with a Gaussian kernel (30 ms s.d.).\n",
    "\n",
    "# 700ms window.\n",
    "\n",
    "# Datasets of varying sizes were created for LFADS by randomly selecting trials with 20%, 10% and 5% of the original dataset using seven fixed seeds, and then splitting each of these into 80/20 training and validation sets for LFADS (22 total, including the full dataset).\n",
    "\n",
    "# Remove correlated neurons\n",
    "# We started with sorted units obtained from M1 and binned their spike times at 1 ms. To avoid artifacts in which the same spikes appeared on multiple channels, we computed cross-correlations between all pairs of neurons over the first 10 s and removed individual correlated neurons (n = 34) by highest firing rate until there were no pairs with correlation values above 0.0625, resulting in 181 uncorrelated neurons. We remove these neurons because correlated spike artifacts can cause overfitting issues, despite the protection afforded by CD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034fc8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial: https://snel-repo.github.io/autolfads/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drag2_matlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
