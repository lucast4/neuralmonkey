{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Organizing good plots for syntax, espeically:\n",
    "- euclidian dist\n",
    "- state space\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b248d33aff307a2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d20c8",
   "metadata": {},
   "source": [
    "# Load DFallPa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc90040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_dfallpa_extract import extract_dfallpa_helper\n",
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_match_chans_across_pa_each_bregion\n",
    "from neuralmonkey.classes.population_mult import extract_single_pa\n",
    "from neuralmonkey.metadat.analy.anova_params import params_getter_euclidian_vars\n",
    "from neuralmonkey.classes.population_mult import dfpa_concatbregion_preprocess_clean_bad_channels, dfpa_concatbregion_preprocess_wrapper\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "import seaborn as sns\n",
    "import os\n",
    "from neuralmonkey.classes.population_mult import extract_single_pa\n",
    "from neuralmonkey.analyses.state_space_good import euclidian_distance_compute_trajectories_single, euclidian_distance_compute_trajectories\n",
    "\n",
    "animal = \"Diego\"\n",
    "\n",
    "version = \"stroke\"\n",
    "combine = False\n",
    "\n",
    "date = 230913\n",
    "question = \"RULE_ANBMCK_STROKE\"\n",
    "\n",
    "# date = 230922\n",
    "# question = \"RULESW_ANY_SEQSUP_STROKE\"\n",
    "\n",
    "# Load a single DFallPA\n",
    "DFallpa = load_handsaved_wrapper(animal, date, version=version, combine_areas=combine, \n",
    "                                    question=question)\n",
    "\n",
    "dfpa_concatbregion_preprocess_wrapper(DFallpa, animal, date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1200ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load params\n",
    "from neuralmonkey.metadat.analy.anova_params import params_getter_euclidian_vars\n",
    "\n",
    "LIST_VAR, LIST_VARS_OTHERS, LIST_CONTEXT, LIST_PRUNE_MIN_N_LEVS, LIST_FILTDICT = params_getter_euclidian_vars(question, context_version=\"new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b3d89",
   "metadata": {},
   "source": [
    "##### Testing -- compute euclidian distance, using fast method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automaticlaly getting the contrast of interest\n",
    "\n",
    "list_contrast_idx = params_get_contrasts_of_interest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR_ANALYSIS = \"/tmp/SYNTAX_EUCL_2\"\n",
    "os.makedirs(SAVEDIR_ANALYSIS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7176d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import euclidian_time_resolved_fast_shuffled\n",
    "euclidian_time_resolved_fast_shuffled(DFallpa, SAVEDIR_ANALYSIS, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_euclidian_dist_pop_script import _get_list_twind_by_animal\n",
    "LIST_TWIND, LIST_TBIN_DUR, LIST_TBIN_SLIDE = _get_list_twind_by_animal(\"Pancho\", event, \"traj_to_scalar\")\n",
    "LIST_TWIND[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### [DEBUG] Run the old (classic) version.\n",
    "\n",
    "savedir = \"/tmp/SYNTAX_TEST\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "PLOT_STATE_SPACE = False\n",
    "PLOT_HEATMAPS = False\n",
    "nmin_trials_per_lev = 4\n",
    "dim_red_method = \"superv_dpca\"\n",
    "superv_dpca_params = {\n",
    "    \"superv_dpca_var\":\"epch_sytxrol\",\n",
    "    \"superv_dpca_vars_group\":None,\n",
    "    \"superv_dpca_filtdict\":None\n",
    "}\n",
    "COMPUTE_EUCLIDIAN = True\n",
    "PLOT_MASKS = False\n",
    "PAthisRedu = preprocess_pa(PA, var_effect, vars_others, prune_min_n_trials, prune_min_n_levs, filtdict,\n",
    "            savedir, \n",
    "            subspace_projection, subspace_projection_fitting_twind,\n",
    "            twind_analy, tbin_dur, tbin_slide)\n",
    "\n",
    "dfres = euclidian_distance_compute_trajectories(PAthisRedu, LIST_VAR[16:17], LIST_VARS_OTHERS[16:17], twind_analy, tbin_dur,\n",
    "                        tbin_slide, savedir, PLOT_TRAJS=PLOT_STATE_SPACE, PLOT_HEATMAPS=PLOT_HEATMAPS,\n",
    "                        nmin_trials_per_lev=nmin_trials_per_lev,\n",
    "                        LIST_CONTEXT=LIST_CONTEXT[16:17], LIST_FILTDICT=LIST_FILTDICT[16:17],\n",
    "                        LIST_PRUNE_MIN_N_LEVS=LIST_PRUNE_MIN_N_LEVS[16:17],\n",
    "                        NPCS_KEEP=NPCS_KEEP,\n",
    "                        dim_red_method = dim_red_method, superv_dpca_params=superv_dpca_params,\n",
    "                        COMPUTE_EUCLIDIAN = COMPUTE_EUCLIDIAN,\n",
    "                        PLOT_MASKS=PLOT_MASKS)\n",
    "\n",
    "# Postprocessing\n",
    "dfres = append_col_with_grp_index(dfres, [\"effect_samediff\", \"context_samediff\"], \"effect_context\")\n",
    "dfres[\"effect_context\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f634b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: chekc if this matches old plot.\n",
    "# Is NAN treated correcty? I think so, as it only adverses affects the ClAgg, which is not actually used.\n",
    "# Then run over all variable pairs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4491de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting \n",
    "DFDIST = pd.concat(list_dfdist).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa82378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import postprocess_dfdist_collected\n",
    "DFDIST = postprocess_dfdist_collected(DFDIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ec69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate, so that each label1 is given 4 datapoints (00, 01, 10, 11)\n",
    "from pythonlib.tools.pandastools import aggregGeneral, stringify_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61894c1a",
   "metadata": {},
   "source": [
    "## Load pre-saved data and make plots (eucl dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import mult_plot_all_wrapper\n",
    "\n",
    "mult_plot_all_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING\n",
    "import os\n",
    "\n",
    "animal = \"Diego\"\n",
    "save_suffix = \"sh_vs_seqsup\"\n",
    "# save_suffix = \"AnBmCk_general\"\n",
    "# save_suffix = \"two_shape_sets\"\n",
    "dates_skip_failed = [230817, 230913]\n",
    "\n",
    "# Params\n",
    "subspace_projection = \"epch_sytxrol\"\n",
    "subspace_projection_fitting_twind = (-0.8, 0.3)\n",
    "\n",
    "# Params for loading dataset\n",
    "question, dates, map_savesuffix_to_contrast_idx_pairs = get_params_this_save_suffix(animal, save_suffix)\n",
    "\n",
    "from neuralmonkey.metadat.analy.anova_params import params_getter_euclidian_vars\n",
    "LIST_VAR, LIST_VARS_OTHERS, LIST_CONTEXT, LIST_PRUNE_MIN_N_LEVS, LIST_FILTDICT = params_getter_euclidian_vars(question, \n",
    "                                                                                                                context_version=\"new\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e048700",
   "metadata": {},
   "source": [
    "##### seqsup -- effect of supervision, controlling for shape\n",
    "This doesnt work well -- even PMv shows it, due to not controlling for overall motor context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import postprocess_dfdist_collected\n",
    "DFDIST, DFDIST_AGG = postprocess_dfdist_collected(DFDIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2431736",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_savesuffix_to_contrast_idx_pairs = {\n",
    "    \"test\":[\n",
    "        (11, 5)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  neuralmonkey.scripts.analy_syntax_good_eucl_state import mult_plot_all\n",
    "\n",
    "### Summary plots\n",
    "SAVEDIR = \"/tmp/SYNTAX\"\n",
    "mult_plot_all(DFDIST_AGG, map_savesuffix_to_contrast_idx_pairs, SAVEDIR, question, skip_contrast_idx_pair_if_fail=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc9ead5",
   "metadata": {},
   "source": [
    "##### within chunk (did not finish)\n",
    "Too difficult, as the var others have differnet names... Need to recompute, writing code dedicated to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_idx = 15\n",
    "date = 230920\n",
    "dfdist = DFDIST[(DFDIST[\"date\"] == date) & (DFDIST[\"contrast_idx\"] == contrast_idx)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist[\"vars_others\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0caac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc387c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([x for x in dfdist[\"_vars_others_1\"] if x[-1]==\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da36981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([x for x in dfdist[\"_vars_others_1\"] if x[-1]==\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "grouping_print_n_samples(dfdist, [\"labels_1\", \"labels_2\"])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d169c9bc",
   "metadata": {},
   "source": [
    "### Debugging -- computing euclidian distance for a single PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_effect = \"chunk_within_rank_semantic\"\n",
    "# vars_others = [\"chunk_rank\"]\n",
    "# # vars_context_same = [\"gridloc\"]\n",
    "# # vars_context_diff = [\"stroke_index\"]\n",
    "# # context_dict = {\"same\":vars_context_same, \"diff\":vars_context_diff}\n",
    "# context_dict = {\"same\":[], \"diff\":[\"gridloc\"]}\n",
    "\n",
    "# var_effect = \"gridloc\"\n",
    "# vars_others = [\"chunk_rank\"]\n",
    "# # vars_context_same = [\"gridloc\"]\n",
    "# # vars_context_diff = [\"stroke_index\"]\n",
    "# # context_dict = {\"same\":vars_context_same, \"diff\":vars_context_diff}\n",
    "# context_dict = {\"same\":[], \"diff\":[\"chunk_within_rank_semantic\"]}\n",
    "# ### Testing, on simple thing\n",
    "\n",
    "var_effect = \"shape\"\n",
    "vars_others = [\"gridloc\"]\n",
    "# vars_context_same = [\"gridloc\"]\n",
    "# vars_context_diff = [\"stroke_index\"]\n",
    "# context_dict = {\"same\":vars_context_same, \"diff\":vars_context_diff}\n",
    "context_dict = {\"same\":[], \"diff\":[\"stroke_index\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2386cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate vars_others into a single variable\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "dflab = PA.Xlabels[\"trials\"]\n",
    "dflab = append_col_with_grp_index(dflab, vars_others, \"_vars_others\")\n",
    "PA.Xlabels[\"trials\"] = dflab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "grouping_print_n_samples(dflab, [var_effect] + vars_others + [\"gridloc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newer (fast) method\n",
    "from neuralmonkey.analyses.euclidian_distance import timevarying_compute_fast_to_scalar\n",
    "\n",
    "# (1) Data\n",
    "savedir = \"/tmp/SYNTAX\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "dfdist, Cldist = timevarying_compute_fast_to_scalar(PA, [var_effect, \"_vars_others\"], plot_conjunctions_savedir=savedir,\n",
    "                                                    context_dict = context_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92659108",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the output doesnt include context vriable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres, CldistAgg = Cldist.rsa_distmat_score_all_pairs_of_label_groups(get_only_one_direction=False, return_as_clustclass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ed137",
   "metadata": {},
   "outputs": [],
   "source": [
    "CldistAgg.rsa_plot_heatmap(sort_order=(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CldistAgg.rsa_labels_extract_label_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6047b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Testing out context helper.\n",
    "\n",
    "# Plot masks\n",
    "path_for_save_print_lab_each_mask = f\"/tmp/SYNTAX/mask.txt\"\n",
    "diffctxt_vars_same = [\"shape\", \"stroke_index\"]\n",
    "diffctxt_vars_diff = []\n",
    "# diffctxt_vars_diff = [\"_vars_others\", \"stroke_index\"]\n",
    "diff_context_ver = None\n",
    "\n",
    "PLOT = True\n",
    "path_for_save_print_lab_each_mask = f\"/tmp/SYNTAX/mask.txt\"\n",
    "ma_context, fig, axes = CldistAgg.rsa_mask_context_helper_simple(diffctxt_vars_same, diffctxt_vars_diff, \n",
    "                                                            diff_context_ver, only_upper_triangle=False,\n",
    "                                                            PLOT=PLOT, \n",
    "                                                            path_for_save_print_lab_each_mask=path_for_save_print_lab_each_mask)\n",
    "from pythonlib.tools.plottools import savefig\n",
    "savefig(fig, f\"/tmp/SYNTAX/masks.pdf\")\n",
    "plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b828fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE -- masking at level of trial, \n",
    "# PROBLEM -- some cases dont have within-group distance, and so fails above.\n",
    "# SOLUTION -- have exception to always have within-group scores collected.\n",
    "# DONE!!\n",
    "\n",
    "# TODO -- recompute the euclidian distance scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e5816",
   "metadata": {},
   "source": [
    "# Devo -- shape vs. seqsup, starting from scratch, good controlling of context, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = DFallpa[\"pa\"].values[14]\n",
    "dflab = PA.Xlabels[\"trials\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep pool of chars that are in both (no superv, and superv) epochs\n",
    "dflab = dflab[dflab[\"epochset_shape\"] == (\"llCV3\",)].reset_index(drop=True)\n",
    "\n",
    "# assert that each character has each syntax role existing in both epoch\n",
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars_helper\n",
    "dfout, dict_dfthis = extract_with_levels_of_conjunction_vars_helper(dflab, \"superv_is_seq_sup\", [\"character\", \"syntax_role\"], lenient_allow_data_if_has_n_levels=2, \n",
    "                                               levels_var=[False, True])\n",
    "assert len(dflab) == len(dfout), \"This means either (i) a char was not in both epochs or (ii) a char has diff syntax role across epochs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4362324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see what exists\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "\n",
    "# grouping_print_n_samples(dflab, [\"epochset_shape\", \"epoch_rand\", \"superv_is_seq_sup\", \"chunk_rank\", \"shape\", \"chunk_within_rank\"])\n",
    "grouping_print_n_samples(dflab, [\"epochset_shape\", \"character\", \"epoch_rand\", \"superv_is_seq_sup\", \"chunk_rank\", \"shape\", \"chunk_within_rank\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import preprocess_pa\n",
    "from neuralmonkey.analyses.euclidian_distance import timevarying_compute_fast_to_scalar\n",
    "\n",
    "\n",
    "prune_min_n_trials = 4\n",
    "subspace_projection = \"epch_sytxrol\"\n",
    "subspace_projection_fitting_twind = (-0.8, 0.3)\n",
    "twind_analy = (-1, 0.6)\n",
    "tbin_dur = 0.15 # Matching params in other analyses\n",
    "tbin_slide = 0.02\n",
    "\n",
    "# Compute eucl distance within each shape\n",
    "var_effect = \"chunk_within_rank_semantic_v2\"\n",
    "vars_others = [\"epochset_shape\", \"epoch_rand\", \"chunk_rank\", \"shape\", \"superv_is_seq_sup\"]\n",
    "context_dict = {\"same\":[\"epochset_shape\", \"epoch_rand\", \"chunk_rank\", \"shape\", \"superv_is_seq_sup\"], \"diff\":None}\n",
    "prune_min_n_levs = 2\n",
    "# filtdict = {\"stroke_index\": list(range(1, 10, 1))}\n",
    "filtdict = {\"epochset_shape\":[(\"llCV3\",)]}\n",
    "\n",
    "vars_group = [var_effect, \"_vars_others\"]\n",
    "\n",
    "SAVEDIR = \"/tmp/SYNTAX_RAW\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "print(\"SAVING AT ... \", SAVEDIR)\n",
    "\n",
    "# Make sure there is no \"diff\" in context\n",
    "if context_dict is not None:\n",
    "    assert (context_dict[\"diff\"] is None) or (len(context_dict[\"diff\"])==0), \"need to run the step above, removing diffs, or else will fail to get diff var_others eucliian\"\n",
    "\n",
    "print(\"These params: \", var_effect, vars_others, context_dict, filtdict)\n",
    "\n",
    "# Preprocess\n",
    "savedir = f\"{SAVEDIR}/preprocess\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "PAthisRedu = preprocess_pa(PA, var_effect, vars_others, prune_min_n_trials, prune_min_n_levs, filtdict,\n",
    "            savedir, \n",
    "            subspace_projection, subspace_projection_fitting_twind,\n",
    "            twind_analy, tbin_dur, tbin_slide, use_strings_for_vars_others=False)\n",
    "\n",
    "###################################### Running euclidian\n",
    "twind_scal = (-0.1, 0.3)\n",
    "\n",
    "# Prune to scalar window\n",
    "pathis = PAthisRedu.slice_by_dim_values_wrapper(\"times\", twind_scal)\n",
    "\n",
    "# \n",
    "rsa_savedir = f\"{SAVEDIR}/rsa-twind_scal={twind_scal}\"\n",
    "os.makedirs(rsa_savedir, exist_ok=True)\n",
    "\n",
    "# Run\n",
    "dfdist, _ = timevarying_compute_fast_to_scalar(pathis, label_vars=vars_group, rsa_heatmap_savedir=rsa_savedir,\n",
    "                                                prune_levs_min_n_trials=prune_min_n_trials, \n",
    "                                                context_dict=context_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Good, running all\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import euclidian_time_resolved_fast_shuffled\n",
    "question = \"RULESW_ANY_SEQSUP_STROKE\"\n",
    "SAVEDIR_ANALYSIS = f\"/tmp/SYNTAX_TEST-{question}\"\n",
    "os.makedirs(SAVEDIR_ANALYSIS, exist_ok=True)\n",
    "euclidian_time_resolved_fast_shuffled(DFallpa, animal, SAVEDIR_ANALYSIS, question, version_seqsup_good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954012ac",
   "metadata": {},
   "source": [
    "### [Load mult data] and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state_MULT import mult_plot_all_wrapper\n",
    "DFDIST = mult_plot_all_wrapper(just_return_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ecda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDIST[\"date\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4141cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDIST = DFDIST[DFDIST[\"date\"]!=250324].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import mult_plot_grammar_vs_seqsup_new\n",
    "contrast_version = \"shape_index\"\n",
    "mult_plot_grammar_vs_seqsup_new(DFDIST, SAVEDIR, contrast_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed88a20",
   "metadata": {},
   "source": [
    "# Single trial state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = \"/lemur2/lucas/neural_preprocess/PA_trialpop/Diego-230615/PA.pkl\"\n",
    "with open(path, \"rb\") as f:\n",
    "    PA = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA.Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313638f3",
   "metadata": {},
   "source": [
    "# Targeted PCA (good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867aca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape vs. chunk_rank_within_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e06bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_euclidian_dist_pop_script import _get_list_twind_by_animal\n",
    "_list_twind, _, _ = _get_list_twind_by_animal(animal, \"00_stroke\", \"traj_to_scalar\")\n",
    "twind_scal = _list_twind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables = ['chunk_within_rank_semantic_v2', 'epoch', 'chunk_rank', 'shape', \n",
    "#              'loc_on_clust', 'CTXT_locoffclust_prev', 'loc_off_clust', \n",
    "#              'CTXT_shape_prev']\n",
    "\n",
    "# variables = ['epoch', 'shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'loc_off_clust', \n",
    "#              'CTXT_shape_prev', 'chunk_within_rank', 'chunk_rank']\n",
    "# variables_is_cat = [True, True, True, True, True, True, False, False]\n",
    "\n",
    "variables = ['epoch', 'shape', 'gridloc', 'loc_on_clust', 'CTXT_locoffclust_prev', 'loc_off_clust', \n",
    "             'CTXT_shape_prev', 'chunk_within_rank']\n",
    "variables_is_cat = [True, True, True, True, True, True, True, False]\n",
    "\n",
    "assert len(variables)==len(variables_is_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = DFallpa[\"pa\"].values[3]\n",
    "twind_scal = (0, 1)\n",
    "PA = PA.slice_by_dim_values_wrapper(\"times\", twind_scal).agg_wrapper(\"times\")\n",
    "PA.dataextract_subspace_targeted_pca(variables, variables_is_cat, list_subspaces, demean=True, \n",
    "                                          normalization=None, plot_orthonormalization=False, \n",
    "                                          PLOT_COEFF_HEATMAP=False, savedir_coeff_heatmap=None, PRINT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = DFallpa[\"pa\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365756ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import state_space_targeted_pca_scalar_single\n",
    "\n",
    "dict_subspace_pa, _, _, _, _ = state_space_targeted_pca_scalar_single(\n",
    "                        PA, twind_scal, variables, variables_is_cat, list_subspaces, \n",
    "                        LIST_VAR_VAROTHERS_SS, LIST_DIMS, \"/tmp\", just_extract_paredu=False,\n",
    "                        subspace_filtdict = subspace_filtdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56451cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# During samp\n",
    "from pythonlib.tools.vectools import average_vectors_wrapper, get_vector_from_angle\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import state_space_targeted_pca_scalar_single\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import state_space_targeted_pca_scalar_single, targeted_pca_euclidian_dist_angles\n",
    "\n",
    "# list_subspaces = [\n",
    "#     (\"chunk_within_rank\", \"chunk_rank\"),\n",
    "# ]\n",
    "\n",
    "list_subspaces = [\n",
    "    (\"shape\", \"chunk_within_rank\"),\n",
    "]\n",
    "\n",
    "LIST_VAR_VAROTHERS_SS = [\n",
    "    (\"chunk_within_rank\", ['epoch', 'chunk_rank', 'shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev', 'loc_off_clust']),\n",
    "    (\"chunk_within_rank\", ['epoch', 'chunk_rank', 'shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev']),\n",
    "    (\"chunk_within_rank\", ['epoch', 'shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev']),\n",
    "    (\"chunk_within_rank\", ['epoch', 'shape']),\n",
    "    (\"chunk_within_rank\", ['epoch']),\n",
    "    (\"shape\", ['epoch', 'chunk_within_rank', 'chunk_rank', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev', 'loc_off_clust']),\n",
    "    (\"shape\", ['epoch', 'chunk_within_rank', 'chunk_rank', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev']),\n",
    "    (\"shape\", ['epoch', 'chunk_within_rank', 'chunk_rank']),\n",
    "    (\"shape\", ['epoch']),\n",
    "]\n",
    "\n",
    "LIST_DIMS = [(0,1), (1,2)]\n",
    "\n",
    "LIST_VAR_VAROTHERS_REGR = [\n",
    "    (\"chunk_within_rank\", ['epoch', 'shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev', 'loc_off_clust']),\n",
    "    (\"shape\", ['epoch', 'chunk_within_rank', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev', 'loc_off_clust']),\n",
    "]\n",
    "\n",
    "subspace_tuple = (\"shape\", \"chunk_within_rank\")\n",
    "\n",
    "min_levs_per_levother = 2\n",
    "prune_levs_min_n_trials = 4\n",
    "\n",
    "SAVEDIR_ANALYSIS = f\"/tmp/TERGET_PCA_EUCL_STATE/{animal}-{date}\"\n",
    "os.makedirs(SAVEDIR_ANALYSIS, exist_ok=True)\n",
    "DFANGLE = targeted_pca_euclidian_dist_angles(DFallpa, SAVEDIR_ANALYSIS, \n",
    "                                             variables, variables_is_cat, list_subspaces, LIST_VAR_VAROTHERS_SS, # For dim reduction and plotting state space\n",
    "                                            subspace_tuple, LIST_VAR_VAROTHERS_REGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13150309",
   "metadata": {},
   "outputs": [],
   "source": [
    "### (2) Make all plots\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import targeted_pca_euclidian_dist_angles_plots\n",
    "\n",
    "for var_vector_length in [\"dist_yue_diff\", \"dist_norm\"]:\n",
    "    for length_method in [\"sum\", \"dot\"]:\n",
    "        for min_levs_exist in [3, 2]:\n",
    "            savedir = f\"{SAVEDIR_ANALYSIS}/PLOTS/varlength={var_vector_length}-lengthmeth={length_method}-minlevs={min_levs_exist}\"\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            targeted_pca_euclidian_dist_angles_plots(DFANGLE, var_vector_length, length_method, min_levs_exist, savedir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32b2509",
   "metadata": {},
   "source": [
    "### [Devo] New method to get different subspaces each using subbset of data\n",
    "\n",
    "i.e., get separate axes for chunk_within_shape for each shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['epoch', 'chunk_shape', 'gridloc', 'loc_on_clust', 'CTXT_locoffclust_prev', 'loc_off_clust', \n",
    "            'CTXT_shape_prev', 'chunk_within_rank']\n",
    "variables_is_cat = [True, True, True, True, True, True, True, False]\n",
    "\n",
    "twind_scal_force = [-0.1, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc2618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import targeted_pca_state_space_split_over\n",
    "\n",
    "LIST_DIMS = [(0,1), (1,2)]\n",
    "SAVEDIR_ANALYSIS = \"/tmp/TARGETED_PCA_EUCL_STATE_2\"\n",
    "os.makedirs(SAVEDIR_ANALYSIS, exist_ok=True)\n",
    "\n",
    "LIST_VAR_VAROTHERS = [\n",
    "    (\"chunk_within_rank\", ['epoch', 'chunk_shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev', 'loc_off_clust']),\n",
    "    (\"chunk_within_rank\", ['epoch', 'chunk_shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev']),\n",
    "    (\"chunk_within_rank\", ['epoch', 'chunk_shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev']),\n",
    "    (\"chunk_within_rank\", ['epoch', 'chunk_shape']),\n",
    "    (\"chunk_within_rank\", ['epoch']),\n",
    "    (\"chunk_shape\", ['epoch', 'chunk_within_rank', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev', 'loc_off_clust']),\n",
    "    (\"chunk_shape\", ['epoch', 'chunk_within_rank', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev']),\n",
    "    (\"chunk_shape\", ['epoch', 'chunk_within_rank']),\n",
    "    (\"chunk_shape\", ['epoch']),\n",
    "]\n",
    "\n",
    "targeted_pca_state_space_split_over(DFallpa, SAVEDIR_ANALYSIS, \n",
    "                                    variables, variables_is_cat, LIST_VAR_VAROTHERS, # For dim reduction and plotting state space\n",
    "                                       twind_scal_force)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c0e39a",
   "metadata": {},
   "source": [
    "# [RSA] making version that controls for other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa\n",
    "PA = DFallpa[\"pa\"].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ed35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = f\"/tmp/RSAGOOD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "twind_analy = (-1, 0.6)\n",
    "tbin_dur = 0.15 # Matching params in other analyses\n",
    "tbin_slide = 0.02\n",
    "N_MIN_TRIALS = 4\n",
    "prune_min_n_trials = N_MIN_TRIALS\n",
    "\n",
    "list_fit_twind = [(-0.8, 0.3)]\n",
    "\n",
    "from neuralmonkey.scripts.analy_euclidian_dist_pop_script import _get_list_twind_by_animal\n",
    "_list_twind, _, _ = _get_list_twind_by_animal(animal, \"00_stroke\", \"traj_to_scalar\")\n",
    "assert len(_list_twind)==1, \"why mutliple?\"\n",
    "twind_ideal = _list_twind[0]\n",
    "\n",
    "# twind_scal = (-0.5, -0.05) # char_sp\n",
    "# list_twind_scal = [(-0.1, 0.3)] # syntax, previously\n",
    "if False:\n",
    "    list_twind_scal = [twind_ideal, (-0.3, -0.1)]\n",
    "else:\n",
    "    list_twind_scal = [twind_ideal]\n",
    "\n",
    "# ### Load params\n",
    "\n",
    "LIST_VAR = [\n",
    "    \"chunk_within_rank_semantic_v2\", \n",
    "    # \"chunk_within_rank\", \n",
    "    \"chunk_within_rank_fromlast\", \n",
    "    \"syntax_role\", # ------------- Using syntax_role instead of stroke_index\n",
    "    \"stroke_index\",\n",
    "    \"syntax_role\", # ------------- Using syntax_role instead of stroke_index\n",
    "    ]\n",
    "LIST_VARS_OTHERS = [\n",
    "    [\"epoch\", \"chunk_rank\", \"shape\"], \n",
    "    # [\"epoch\", \"chunk_rank\", \"shape\"], \n",
    "    [\"epoch\", \"chunk_rank\", \"shape\"], \n",
    "    [\"epoch\", \"chunk_rank\", \"shape\"], # ------------- Using syntax_role instead of stroke_index\n",
    "    [\"epoch\", \"FEAT_num_strokes_beh\"],\n",
    "    [\"epoch\"], # ------------- Using syntax_role instead of stroke_index\n",
    "    ]\n",
    "LIST_CONTEXT = [\n",
    "    None,\n",
    "    # None,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    ]\n",
    "\n",
    "LIST_PRUNE_MIN_N_LEVS = [2 for _ in range(len(LIST_VAR))]\n",
    "# filtdict = {\"stroke_index\": list(range(1, 10, 1))}\n",
    "# filtdict = {\"epochset_shape\":[(\"llCV3\",)]}\n",
    "LIST_FILTDICT = [None for _ in range(len(LIST_VAR))]\n",
    "use_strings_for_vars_others = False\n",
    "# list_subspace_projection = [\"sytx_all\", \"epch_sytxrol\", \"syntax_role\"]\n",
    "list_subspace_projection = [\"sytx_all\"]\n",
    "is_seqsup_version = False\n",
    "\n",
    "### Automaticlaly getting the contrast of interest\n",
    "# The inidices are not documneted. Therefore get all of them.\n",
    "list_contrast_idx = list(range(len(LIST_VAR)))\n",
    "\n",
    "# Map from index to variables and other params.\n",
    "contrasts_dict = {}\n",
    "for idx in sorted(list_contrast_idx):\n",
    "    contrasts_dict[idx] = [LIST_VAR[idx], LIST_VARS_OTHERS[idx], LIST_CONTEXT[idx], LIST_PRUNE_MIN_N_LEVS[idx], LIST_FILTDICT[idx]]\n",
    "\n",
    "# - for method\n",
    "from pythonlib.cluster.clustclass import Clusters\n",
    "cl = Clusters(None)\n",
    "\n",
    "# # Save some general params\n",
    "# from pythonlib.tools.expttools import writeDictToTxtFlattened\n",
    "# writeDictToTxtFlattened({\n",
    "#     \"list_subspace_projection\":list_subspace_projection,\n",
    "#     \"twind_analy\":twind_analy,\n",
    "#     \"tbin_dur\":tbin_dur,\n",
    "#     \"tbin_slide\":tbin_slide,\n",
    "#     \"prune_min_n_trials\":prune_min_n_trials,\n",
    "#     \"list_fit_twind\":list_fit_twind,\n",
    "#     \"list_twind_scal\":list_twind_scal,\n",
    "#     \"LIST_VAR\":LIST_VAR,\n",
    "#     \"LIST_VARS_OTHERS\":LIST_VARS_OTHERS,\n",
    "#     \"LIST_CONTEXT\":LIST_CONTEXT,\n",
    "#     \"LIST_PRUNE_MIN_N_LEVS\":LIST_PRUNE_MIN_N_LEVS,\n",
    "#     \"LIST_FILTDICT\":LIST_FILTDICT,\n",
    "#     \"list_contrast_idx\":list_contrast_idx}, path=f\"{SAVEDIR_ANALYSIS}/params.txt\")\n",
    "\n",
    "# from pythonlib.tools.expttools import writeDictToTxtFlattened\n",
    "# writeDictToTxtFlattened(contrasts_dict, path=f\"{SAVEDIR_ANALYSIS}/contrasts_dict.txt\", \n",
    "#                         header = \"contrast_idx: var, vars_others, context, prune_min_n_levs, filtdict\")\n",
    "\n",
    "### RUN\n",
    "subspace_projection = \"sytx_all\"\n",
    "subspace_projection_fitting_twind = (-0.8, 0.3)\n",
    "\n",
    "\n",
    "# Get variables for this contrast  \n",
    "var_effect = \"chunk_within_rank_semantic\"\n",
    "vars_others =  [\"epoch\", \"shape\"]\n",
    "context_dict = None\n",
    "prune_min_n_levs = 4\n",
    "filtdict = {}\n",
    "vars_group = [var_effect, \"_vars_others\"]\n",
    "\n",
    "# SAVEDIR = f\"{SAVEDIR_ANALYSIS}/{which_level}-{bregion}-{event}-ss={subspace_projection}-fit_twind={subspace_projection_fitting_twind}/contrast={contrast_idx}|{var_effect}\"\n",
    "# os.makedirs(SAVEDIR, exist_ok=True)\n",
    "# print(\"SAVING AT ... \", SAVEDIR)\n",
    "\n",
    "# Make sure there is no \"diff\" in context\n",
    "if context_dict is not None:\n",
    "    assert (context_dict[\"diff\"] is None) or (len(context_dict[\"diff\"])==0), \"need to run the step above, removing diffs, or else will fail to get diff var_others eucliian\"\n",
    "\n",
    "print(\"These params: \", var_effect, vars_others, context_dict, filtdict)\n",
    "\n",
    "# Preprocess\n",
    "savedir = f\"{SAVEDIR}/preprocess\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import preprocess_pa\n",
    "PAthisRedu = preprocess_pa(PA, var_effect, vars_others, prune_min_n_trials, prune_min_n_levs, filtdict,\n",
    "            savedir, \n",
    "            subspace_projection, subspace_projection_fitting_twind,\n",
    "            twind_analy, tbin_dur, tbin_slide, use_strings_for_vars_others=use_strings_for_vars_others,\n",
    "            is_seqsup_version=is_seqsup_version)\n",
    "\n",
    "\n",
    "###################################### Running euclidian\n",
    "context_dict = {\n",
    "    # \"same\":[\"shape\", \"loc_on_clust\", \"CTXT_locoffclust_prev\", \"loc_off_clust\", \"CTXT_shape_prev\", \"CTXT_loconclust_next\"],\n",
    "    \"same\":[\"shape\", \"gridloc\", \"CTXT_loc_prev\"],\n",
    "    # \"same\":[\"shape\", \"gridloc\", \"CTXT_gridloc_prev\", \"CTXT_shape_prev\", \"CTXT_gridloc_next\"],\n",
    "    # \"same\":[\"shape\", \"gridloc\", \"CTXT_gridloc_prev\", \"loc_on_clust\", \"CTXT_locoffclust_prev\", \"loc_off_clust\", \"CTXT_shape_prev\", \"CTXT_gridloc_next\", \"CTXT_loconclust_next\"],\n",
    "    \"diff\":[],\n",
    "    }\n",
    "# context_dict = None\n",
    "for twind_scal in list_twind_scal:\n",
    "\n",
    "    # Prune to scalar window\n",
    "    pathis = PAthisRedu.slice_by_dim_values_wrapper(\"times\", twind_scal)\n",
    "\n",
    "    # \n",
    "    rsa_savedir = f\"{SAVEDIR}/rsa-twind_scal={twind_scal}\"\n",
    "    os.makedirs(rsa_savedir, exist_ok=True)\n",
    "\n",
    "    # Run\n",
    "    from neuralmonkey.analyses.euclidian_distance import timevarying_compute_fast_to_scalar\n",
    "    dfdist, Cldist = timevarying_compute_fast_to_scalar(pathis, label_vars=vars_group, rsa_heatmap_savedir=rsa_savedir,\n",
    "                                                    context_dict=context_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cldist.Xinput<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ba0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RSA\n",
    "label_vars = [var_effect, \"_vars_others\"]\n",
    "context_dict = None\n",
    "# context_dict = {\n",
    "#     # \"same\":[\"shape\", \"loc_on_clust\", \"CTXT_locoffclust_prev\", \"loc_off_clust\", \"CTXT_shape_prev\", \"CTXT_loconclust_next\"],\n",
    "#     # \"same\":[\"loc_on_clust\"],\n",
    "#     # \"same\":[\"CTXT_loc_prev\", \"gridloc\"],\n",
    "#     \"same\":[\"gridloc\"],\n",
    "#     \"diff\":[],\n",
    "#     }\n",
    "_, CldistAgg = Cldist.rsa_distmat_score_all_pairs_of_label_groups(label_vars=label_vars, get_only_one_direction=False, \n",
    "                                                                return_as_clustclass=True,\n",
    "                                                                context_dict=context_dict,\n",
    "                                                                return_as_clustclass_which_var_score=\"dist_yue_diff\")\n",
    "\n",
    "sort_order = (1,0)\n",
    "fig, ax = CldistAgg.rsa_plot_heatmap(sort_order, zlims=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a936c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RSA\n",
    "label_vars = [var_effect, \"_vars_others\"]\n",
    "context_dict = None\n",
    "context_dict = {\n",
    "    # \"same\":[\"shape\", \"loc_on_clust\", \"CTXT_locoffclust_prev\", \"loc_off_clust\", \"CTXT_shape_prev\", \"CTXT_loconclust_next\"],\n",
    "    # \"same\":[\"loc_on_clust\"],\n",
    "    # \"same\":[\"CTXT_loc_prev\", \"gridloc\"],\n",
    "    \"same\":[\"gridloc\"],\n",
    "    \"diff\":[],\n",
    "    }\n",
    "_, CldistAgg = Cldist.rsa_distmat_score_all_pairs_of_label_groups(label_vars=label_vars, get_only_one_direction=False, \n",
    "                                                                return_as_clustclass=True,\n",
    "                                                                context_dict=context_dict,\n",
    "                                                                return_as_clustclass_which_var_score=\"dist_mean\")\n",
    "\n",
    "sort_order = (1,0)\n",
    "fig, ax = CldistAgg.rsa_plot_heatmap(sort_order, zlims=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76aeae7",
   "metadata": {},
   "source": [
    "# [Good] Targeted dim reduction, done carefully [250731]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5743767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Notes, prior code.\n",
    "\n",
    "# # For getting multi-axis subspace\n",
    "# PA.dataextract ...\n",
    "# (as done in char_sp...)\n",
    "\n",
    "# # For getting subspace separately for each othervar\n",
    "# PA.regress_neuron_task_variables_all_chans_data_splits\n",
    "# (as done in syntax state .py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1bc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_concatbregion_preprocess_wrapper, dfpa_concat_bregion_to_combined_bregion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_concatbregion_preprocess_wrapper, dfpa_concat_bregion_to_combined_bregion\n",
    "SAVEDIR = f\"/lemur2/lucas/analyses/recordings/main/syntax_good\"\n",
    "\n",
    "\n",
    "# animal = \"Diego\"\n",
    "# date = 250321\n",
    "\n",
    "animal = \"Pancho\"\n",
    "date = 230810\n",
    "\n",
    "version = \"stroke\"\n",
    "combine = False\n",
    "\n",
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_concat_bregion_to_combined_bregion\n",
    "\n",
    "### (1) load Grammar Dfallpa\n",
    "question = \"RULE_ANBMCK_STROKE\"\n",
    "DFallpa = load_handsaved_wrapper(animal, date, version=version, combine_areas=combine, \n",
    "                                    question=question)\n",
    "DFallpa = dfpa_concat_bregion_to_combined_bregion(DFallpa)\n",
    "\n",
    "try:\n",
    "    ### (2) Load SP data\n",
    "    question = \"SP_BASE_stroke\"\n",
    "    twind = [-0.5, 2.1]\n",
    "    DFallpaSP = load_handsaved_wrapper(animal, date, version=version, combine_areas=combine, \n",
    "                                        question=question, twind=twind)\n",
    "    DFallpaSP = dfpa_concat_bregion_to_combined_bregion(DFallpaSP)\n",
    "\n",
    "    # Merge SP and grammar along chan indices\n",
    "    from neuralmonkey.classes.population_mult import dfpa_concat_merge_pa_along_trials\n",
    "    DFallpa = dfpa_concat_merge_pa_along_trials(DFallpa, DFallpaSP)\n",
    "    del DFallpaSP\n",
    "\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "\n",
    "# Make a copy of all PA before normalization\n",
    "dfpa_concatbregion_preprocess_wrapper(DFallpa, animal, date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b81859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import targeted_pca_clean_plots_and_dfdist\n",
    "import os\n",
    "SAVEDIR_ALL = \"/tmp/SYNTAX_TARGETED_PCA_run4\" \n",
    "os.makedirs(SAVEDIR_ALL, exist_ok=True)\n",
    "targeted_pca_clean_plots_and_dfdist(DFallpa, animal, date, SAVEDIR_ALL, DEBUG=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab455b",
   "metadata": {},
   "source": [
    "##### Debugging, using single PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42957553",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = DFallpa[\"pa\"].values[0]\n",
    "dflab = PA.Xlabels[\"trials\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb5cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import preprocess_pa, preprocess_pa_syntax\n",
    "preprocess_pa_syntax(PA)\n",
    "prune_min_n_trials = 3\n",
    "filtdict = {}\n",
    "prune_min_n_levs = 2\n",
    "# use these regardless of what subspace, as they are good for pruning\n",
    "_var_effect = \"chunk_within_rank_semantic_v2\"\n",
    "_vars_others = [\"epoch\", \"chunk_shape\", \"syntax_concrete\", \"task_kind\"]\n",
    "PA = preprocess_pa(PA, _var_effect, _vars_others, prune_min_n_trials, prune_min_n_levs, filtdict,\n",
    "            SAVEDIR, \n",
    "            None, None, None, None, None, \n",
    "            skip_dimredu=True, prune_by_conj_var=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab = PA.Xlabels[\"trials\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffcbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "grouping_print_n_samples(dflab, [\"DIFF_gridloc\", \"CTXT_loc_prev\", \"gridloc\"])\n",
    "dflab[\"DIFF_gridloc\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34096cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_plot_n_samples_conjunction_heatmap, grouping_print_n_samples\n",
    "\n",
    "grouping_print_n_samples(dflab, [\"chunk_within_rank\", \"chunk_within_rank_fromlast\", \"chunk_rank\", \"shape\", \"gridloc\"])\n",
    "# grouping_print_n_samples(dflab, [\"chunk_within_rank_semantic_v2\", \"chunk_rank\", \"shape\", \"gridloc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_plot_n_samples_conjunction_heatmap, grouping_print_n_samples\n",
    "\n",
    "grouping_print_n_samples(dflab, [\"epoch\", \"chunk_within_rank\", \"syntax_concrete\", \"chunk_rank\", \"shape\", \"gridloc\", \"task_kind\"])\n",
    "grouping_print_n_samples(dflab, [\"task_kind\", \"shape\", \"gridloc\"])\n",
    "grouping_print_n_samples(dflab, [\"shape\", \"gridloc\", \"task_kind\", \"stroke_index\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b37eb0",
   "metadata": {},
   "source": [
    "### Subtracting single-shape activity, using SP files as control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593b12e",
   "metadata": {},
   "source": [
    "##### Quickly plot shape-related activity to visualize across SP and Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split trials into early and late day\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "for pa in DFallpa[\"pa\"]:\n",
    "    dflab = pa.Xlabels[\"trials\"]\n",
    "\n",
    "    # Make sure any nan are replaced\n",
    "    tmedian = np.median(dflab[dflab[\"task_kind\"] == \"prims_single\"][\"trialcode_scal\"])\n",
    "    dflab[\"early_vs_late\"] = dflab[\"trialcode_scal\"]>tmedian\n",
    "\n",
    "    if False:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        ts = dflab[\"trialcode_scal\"]\n",
    "        tk = dflab[\"task_kind\"]\n",
    "        ax.plot(ts, tk, \"ok\")\n",
    "\n",
    "\n",
    "    #### Append any new columns\n",
    "    dflab = append_col_with_grp_index(dflab, [\"epoch\", \"syntax_role\"], \"epch_sytxrol\")\n",
    "    dflab = append_col_with_grp_index(dflab, [\"epoch\", \"syntax_role\", \"shape\", \"gridloc\"], \"sytx_all\")\n",
    "    dflab = append_col_with_grp_index(dflab, [\"epoch_rand\", \"shape\", \"syntax_role\", \"superv_is_seq_sup\"], \"stxsuperv\")\n",
    "    dflab = append_col_with_grp_index(dflab, [\"chunk_rank\", \"shape\"], \"chunk_shape\")\n",
    "\n",
    "    # Also reach direction\n",
    "    tmp = []\n",
    "    for _, row in dflab.iterrows():\n",
    "        loc = row[\"gridloc\"]\n",
    "        loc_prev = row[\"CTXT_loc_prev\"]\n",
    "\n",
    "        if loc_prev[1] == \"START\":\n",
    "            loc_diff = (0, \"START\")\n",
    "        else:\n",
    "            loc_diff = (loc[0] - loc_prev[0], loc[1] - loc_prev[1])\n",
    "\n",
    "        tmp.append(loc_diff)\n",
    "    dflab[\"DIFF_gridloc\"] = tmp\n",
    "\n",
    "    # Also shape change\n",
    "    tmp = []\n",
    "    for _, row in dflab.iterrows():\n",
    "        shape = row[\"shape\"]\n",
    "        shape_prev = row[\"CTXT_shape_prev\"]\n",
    "\n",
    "        if shape_prev == \"START\":\n",
    "            shape_diff = \"START\"\n",
    "        else:\n",
    "            shape_diff = (shape_prev, shape)\n",
    "\n",
    "        tmp.append(shape_diff)\n",
    "    dflab[\"DIFF_shape\"] = tmp\n",
    "\n",
    "\n",
    "    pa.Xlabels[\"trials\"] = dflab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c995e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "grouping_print_n_samples(dflab, [\"task_kind\", \"trialcode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: ignore this -- it's incorporated into the main scritp.\n",
    "for ind in range(len(DFallpa)):\n",
    "    # ind = 1\n",
    "    bregion = DFallpa.iloc[ind][\"bregion\"]\n",
    "    PA = DFallpa.iloc[ind][\"pa\"]\n",
    "\n",
    "    if False:\n",
    "        savedir = f\"/tmp/PREPROCESS/{bregion}\"\n",
    "        os.makedirs(savedir, exist_ok=True)\n",
    "        # Dim reduction\n",
    "        twind_pca = (-0.1, 0.3)\n",
    "        dpca_filtdict = {\"task_kind\":[\"prims_single\"]}\n",
    "        _, PAredu = PA.dataextract_dimred_wrapper(\"scal\", \"dpca\", savedir, \n",
    "                                        twind_pca, tbin_dur=\"default\", tbin_slide=\"default\", \n",
    "                                        NPCS_KEEP = 10,\n",
    "                                        dpca_var = \"shape\", dpca_vars_group = None, dpca_filtdict=dpca_filtdict, dpca_proj_twind = None, \n",
    "                                        raw_subtract_mean_each_timepoint=False,\n",
    "                                        return_pca_components=False)\n",
    "\n",
    "        LIST_VAR = [\n",
    "            \"shape\",\n",
    "            \"task_kind\",\n",
    "            \"task_kind\",\n",
    "        ]\n",
    "        LIST_VARS_OTHERS = [\n",
    "            [\"task_kind\"],\n",
    "            [\"shape\"],\n",
    "            [\"shape\", \"stroke_index\"],\n",
    "        ]\n",
    "\n",
    "        PAredu.plot_state_space_good_wrapper(savedir, LIST_VAR, LIST_VARS_OTHERS)\n",
    "\n",
    "    else:\n",
    "        from neuralmonkey.scripts.analy_syntax_good_eucl_trial import state_space_targeted_pca_scalar_single_one_var_mult_axes\n",
    "        \n",
    "\n",
    "        if False:\n",
    "            # V1: fitting to SP (early part of day) and then plotting all\n",
    "            savedir = f\"/tmp/PREPROCESS_TPCA_v1_fit_on_SP/{bregion}\"\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "            variables = [\"shape\", \"gridloc\", \"CTXT_loc_prev\"]\n",
    "            var_subspace = \"shape\"\n",
    "            npcs_keep = 8\n",
    "            twind_scal = (-0.1, 0.3)\n",
    "\n",
    "            LIST_VAR_VAROTHERS = [\n",
    "                [\"shape\",[\"task_kind\", \"early_vs_late\"]],\n",
    "                [\"task_kind\",[\"shape\", \"early_vs_late\"]],\n",
    "                [\"task_kind\",[\"shape\", \"stroke_index\"]],\n",
    "            ]\n",
    "\n",
    "            dflab = PA.Xlabels[\"trials\"]\n",
    "            inds_trials_pa_train = dflab[\n",
    "                (dflab[\"task_kind\"] == \"prims_single\") & (dflab[\"early_vs_late\"] == False)\n",
    "                ].index.tolist()\n",
    "            inds_trials_pa_test = list(range(len(dflab)))\n",
    "        else:\n",
    "            # V2: fitting using grammar as before, then plotting SP\n",
    "            savedir = f\"/tmp/PREPROCESS_TPCA_v2_fit_on_grammar/{bregion}\"\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            \n",
    "            variables = ['epoch', 'gridloc', 'DIFF_gridloc', 'shape', 'chunk_rank', 'chunk_within_rank', 'chunk_within_rank_fromlast', 'chunk_n_in_chunk'] # Removing diff shape, it is too correlated with chunk rank?\n",
    "            var_subspace = \"shape\"\n",
    "            npcs_keep = 8\n",
    "            twind_scal = (-0.1, 0.3)\n",
    "\n",
    "            LIST_VAR_VAROTHERS = [\n",
    "                [\"shape\",[\"task_kind\", \"early_vs_late\"]],\n",
    "                [\"task_kind\",[\"shape\", \"early_vs_late\"]],\n",
    "                [\"task_kind\",[\"shape\", \"stroke_index\"]],\n",
    "            ]\n",
    "\n",
    "            # prune_min_n_trials = 3\n",
    "            # filtdict = {}\n",
    "            # prune_min_n_levs = 2\n",
    "            # # use these regardless of what subspace, as they are good for pruning\n",
    "            # _var_effect = \"chunk_within_rank_semantic_v2\"\n",
    "            # _vars_others = [\"epoch\", \"chunk_shape\", \"syntax_concrete\"]\n",
    "            # from neuralmonkey.scripts.analy_syntax_good_eucl_state import preprocess_pa\n",
    "            # PA = preprocess_pa(PA, _var_effect, _vars_others, prune_min_n_trials, prune_min_n_levs, filtdict,\n",
    "            #             SAVEDIR, \n",
    "            #             None, None, None, None, None, \n",
    "            #             skip_dimredu=True, prune_by_conj_var=False)\n",
    "\n",
    "\n",
    "            dflab = PA.Xlabels[\"trials\"]\n",
    "            inds_trials_pa_train = dflab[\n",
    "                (dflab[\"task_kind\"] == \"prims_on_grid\") & (dflab[\"early_vs_late\"] == False)\n",
    "                ].index.tolist()\n",
    "            inds_trials_pa_test = list(range(len(dflab)))\n",
    "\n",
    "            # keep only nonfitted\n",
    "            inds_trials_pa_test = [i for i in inds_trials_pa_test if i not in inds_trials_pa_train]\n",
    "\n",
    "        pa_subspace, subspace_axes_orig, subspace_axes_normed, dfcoeff, PAscalTest = state_space_targeted_pca_scalar_single_one_var_mult_axes(PA, twind_scal, variables, None, \n",
    "                                                                    var_subspace, npcs_keep, \n",
    "                                                                    LIST_VAR_VAROTHERS, None, savedir, \n",
    "                                                                    tbin_dur = 0.15, tbin_slide = 0.075,\n",
    "                                                                    inds_trials_pa_train=inds_trials_pa_train, inds_trials_pa_test=inds_trials_pa_test)        \n",
    "\n",
    "                \n",
    "        # Compute effect of shape after \"subtracting\" effect of shape in SP\n",
    "        from neuralmonkey.analyses.euclidian_distance import timevarying_compute_fast_to_scalar\n",
    "        from neuralmonkey.analyses.euclidian_distance import dfdist_extract_label_vars_specific\n",
    "        import seaborn as sns\n",
    "        from pythonlib.tools.snstools import rotateLabel\n",
    "        from pythonlib.tools.plottools import savefig\n",
    "\n",
    "        euclidean_label_vars = [\"shape\", \"gridloc\", \"task_kind\"]\n",
    "        dfdist, _ = timevarying_compute_fast_to_scalar(pa_subspace, label_vars=euclidean_label_vars, \n",
    "                                                rsa_heatmap_savedir=savedir, plot_conjunctions_savedir=savedir)\n",
    "\n",
    "        dfdist, colname_conj_same = dfdist_extract_label_vars_specific(dfdist, euclidean_label_vars, return_var_same=True)\n",
    "\n",
    "        order = sorted(dfdist[colname_conj_same].unique())\n",
    "        fig = sns.catplot(data=dfdist, x=colname_conj_same, y=\"dist_yue_diff\", order=order)\n",
    "        savefig(fig, f\"{savedir}/catplot-1.pdf\")\n",
    "\n",
    "        fig = sns.catplot(data=dfdist, x=colname_conj_same, y=\"dist_yue_diff\", order=order, kind=\"bar\", errorbar=\"se\")\n",
    "        savefig(fig, f\"{savedir}/catplot-2.pdf\")\n",
    "\n",
    "        fig = sns.catplot(data=dfdist, x=\"task_kind_12\", hue=colname_conj_same, y=\"dist_yue_diff\", kind=\"bar\", errorbar=\"se\")\n",
    "        rotateLabel(fig)\n",
    "        savefig(fig, f\"{savedir}/catplot-3.pdf\")\n",
    "\n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5678cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute effect of shape after \"subtracting\" effect of shape in SP\n",
    "from neuralmonkey.analyses.euclidian_distance import timevarying_compute_fast_to_scalar\n",
    "\n",
    "euclidean_label_vars = [\"shape\", \"gridloc\", \"task_kind\"]\n",
    "savedir = \"/tmp\"\n",
    "dfdist, _ = timevarying_compute_fast_to_scalar(pa_subspace, label_vars=euclidean_label_vars, \n",
    "                                        rsa_heatmap_savedir=savedir, plot_conjunctions_savedir=savedir)\n",
    "\n",
    "from neuralmonkey.analyses.euclidian_distance import dfdist_extract_label_vars_specific\n",
    "dfdist, colname_conj_same = dfdist_extract_label_vars_specific(dfdist, euclidean_label_vars, return_var_same=True)\n",
    "\n",
    "import seaborn as sns\n",
    "order = sorted(dfdist[colname_conj_same].unique())\n",
    "sns.catplot(data=dfdist, x=colname_conj_same, y=\"dist_yue_diff\", order=order)\n",
    "sns.catplot(data=dfdist, x=colname_conj_same, y=\"dist_yue_diff\", order=order, kind=\"bar\", errorbar=\"se\")\n",
    "\n",
    "fig = sns.catplot(data=dfdist, x=\"task_kind_12\", hue=colname_conj_same, y=\"dist_yue_diff\", kind=\"bar\", errorbar=\"se\")\n",
    "from pythonlib.tools.snstools import rotateLabel\n",
    "rotateLabel(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0cbeae",
   "metadata": {},
   "source": [
    "### Messing around with dfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51267c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "grouping_print_n_samples(dfdist, [\"chunk_rank_same\", \"shape_same\", \"chunk_within_rank_same\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.euclidian_distance import dfdist_extract_label_vars_specific\n",
    "dfdist = dfdist_extract_label_vars_specific(dfdist, label_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = sorted(dfdist[\"same-chunk_within_rank|chunk_rank|shape\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: also get effect for each variable conditioned on every level of every other variable -- plot all of them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd25b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.catplot(data=dfdist, x=\"same-chunk_within_rank|chunk_rank|shape\", y=\"dist_yue_diff\", order=order)\n",
    "sns.catplot(data=dfdist, x=\"same-chunk_within_rank|chunk_rank|shape\", y=\"dist_yue_diff\", order=order, kind=\"bar\", errorbar=\"se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.catplot(data=dfdist, x=\"same-chunk_within_rank|chunk_rank|shape\", y=\"dist_yue_diff\", order=order)\n",
    "sns.catplot(data=dfdist, x=\"same-chunk_within_rank|chunk_rank|shape\", y=\"dist_yue_diff\", order=order, kind=\"bar\", errorbar=\"se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.catplot(data=dfdist, x=\"same-chunk_within_rank|chunk_rank|shape\", y=\"dist_yue_diff\", order=order)\n",
    "sns.catplot(data=dfdist, x=\"same-chunk_within_rank|chunk_rank|shape\", y=\"dist_yue_diff\", order=order, kind=\"bar\", errorbar=\"se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.catplot(data=dfdist, x=\"same-chunk_within_rank|chunk_rank|shape\", y=\"dist_yue_diff\", order=order)\n",
    "sns.catplot(data=dfdist, x=\"same-chunk_within_rank|chunk_rank|shape\", y=\"dist_yue_diff\", order=order, kind=\"bar\", errorbar=\"se\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d87c8",
   "metadata": {},
   "source": [
    "### [MULT] Loading all dfdists and making summary plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f1dd7",
   "metadata": {},
   "source": [
    "##### First, load, compile, and then save, one for each (animal, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state_MULT import targeted_pca_MULT_load_and_save\n",
    "targeted_pca_MULT_load_and_save(animal, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/lemur2/lucas/analyses/recordings/main/syntax_good/targeted_dim_redu_v2/run11/MULT/DFDIST-Diego-230723.pkl\"\n",
    "# DFDIST = pd.read_pickle(path)\n",
    "# DFDIST[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import aggregGeneral, stringify_values\n",
    "DFDIST_TMP = aggregGeneral(DFDIST, [\"labels_1\", \"labels_2\", \"var_subspace\", \"bregion\", \"question\", \"subspace\", \"subspace_orig\", \n",
    "                        \"contrast_vars\", \"contrast_string\", \"effect\", \"task_kind_1\", \"task_kind_2\", \"task_kind_12\"], \n",
    "                        [\"dist_mean\", \"DIST_98\", \"dist_norm\", \"dist_yue_diff\", \"dist_yue_diff_unnorm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3441de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import aggregGeneral, stringify_values\n",
    "DFEFFECT_STR = stringify_values(DFEFFECT)\n",
    "DFEFFECT_STR = aggregGeneral(DFEFFECT_STR, [\"labels_1\", \"labels_2\", \"var_subspace\", \"bregion\", \"question\", \"subspace\", \"subspace_orig\", \n",
    "                        \"contrast_vars\", \"contrast_string\", \"effect\", \"task_kind_1\", \"task_kind_2\", \"task_kind_12\"], \n",
    "                        [\"dist_yue_diff\", \"dist_yue_diff_unnorm\"])\n",
    "DFEFFECT_STR[\"animal\"] = animal\n",
    "DFEFFECT_STR[\"date\"] = date\n",
    "LIST_DFEFFECT_ALL.append(DFEFFECT_STR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agg over replicates\n",
    "if False: # done above\n",
    "    from pythonlib.tools.pandastools import aggregGeneral\n",
    "    # DFDIST = aggregGeneral(DFDIST, [\"labels_1\", \"labels_2\", \"var_subspace\", \"var_conj\", \"var_conj_lev\", \"bregion\", \"question\"], [\"dist_mean\", \"DIST_98\", \"dist_norm\", \"dist_yue_diff\"], nonnumercols=\"all\")\n",
    "    DFDIST = aggregGeneral(DFDIST, [\"labels_1\", \"labels_2\", \"var_subspace\", \"var_conj\", \"var_conj_lev\", \"bregion\", \"question\"], [\"dist_mean\", \"DIST_98\", \"dist_norm\", \"dist_yue_diff\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556fdaf",
   "metadata": {},
   "source": [
    "##### Second, load each pre-compiled (animal, date) and make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bc62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.plottools import savefig\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVEDIR_MULT = \"/lemur2/lucas/analyses/recordings/main/syntax_good/targeted_dim_redu_v2/run{run}/MULT\"\n",
    "# import os\n",
    "# os.makedirs(SAVEDIR_MULT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 11\n",
    "SAVEDIR = f\"/tmp/SYNTAX_TARGETED_PCA_run{run}\"\n",
    "SAVEDIR_MULT = f\"/lemur2/lucas/analyses/recordings/main/syntax_good/targeted_dim_redu_v2/run{run}/MULT\"\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bacb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state_MULT import targeted_pca_MULT_2_plot_single\n",
    "\n",
    "for animal in [\"Diego\", \"Pancho\"]:\n",
    "    LIST_DFEFFECT_ALL = []\n",
    "    if animal == \"Diego\":\n",
    "        list_dates = [230728, 231118, 240822, 230723, 230724, 230726, 230727, 230730, 230815, 230816, 230817, 230913, 230914, 230915, 231116, 240827, 250319, 250321]\n",
    "        \n",
    "        # list_dates = [230726, 230913]        \n",
    "        # list_dates = [230915, 231116, 231118]        \n",
    "        # list_dates = [230726]        \n",
    "        # list_dates = [230728, 231118, 240822, 230723, 230724, 230726, 230727, 230730, 230815, 230816]        \n",
    "        # list_dates = [230816, 230817, 230913, 230914, 230915, 231116, 240827, 250319, 250321]        \n",
    "        # list_dates = []\n",
    "    elif animal == \"Pancho\":\n",
    "        list_dates = [231114, 231116, 230810, 230811, 230824, 230826, 230829, 240830, 220831, 220901, 250322, 220902, 220906, 220907, 220908, 220909, 230830]\n",
    "\n",
    "        # list_dates = [231114, 231116, 230826, 230829, 220906, 220907, 220908, 220909, 220902]\n",
    "        # list_dates = [230810, 230811, 230824, 240830, 220831, 220901, 250322, 230830]\n",
    "        # list_dates = [220909]\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    for date in list_dates:\n",
    "\n",
    "        run = 11\n",
    "        targeted_pca_MULT_2_plot_single(animal, date, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d03853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state_MULT import targeted_pca_MULT_2_plot_single\n",
    "animal = \"Diego\"\n",
    "date = 230913\n",
    "run = 11\n",
    "targeted_pca_MULT_2_plot_single(animal, date, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state_MULT import targeted_pca_MULT_3_combined_plots\n",
    "for animal in [\"Diego\", \"Pancho\"]:\n",
    "    targeted_pca_MULT_3_combined_plots(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    restrict_questions_based_on_subspace = {\n",
    "        \"shape\":[\"4_shape_vs_chunk\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14069a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(DFEFFECT_STR, \"/tmp/dfeffect.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f0ed6",
   "metadata": {},
   "source": [
    "##### [Devo] 2 shape sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same syntax, diff shape\n",
    "# Sha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afd498",
   "metadata": {},
   "source": [
    "##### [Debugging] Figuring out why not all rows have same DIST_98 for a given bregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solved -- is beucase agging over splits in original extraction, each may have diff DIST_98 and lose certain conjucntions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c8d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=DFDIST, x=\"bregion\", y=\"DIST_98\", hue=\"question\", col=\"subspace\", row=\"task_kind_12\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8dcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,10))\n",
    "ax.plot(dfdist[\"DIST_98\"], dfdist[\"labels_1\"], \"xk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good, stringify_values\n",
    "DFDIST_THIS = stringify_values(DFDIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba6a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grpdict = grouping_append_and_return_inner_items_good(DFDIST_THIS, [\"bregion\",\"question\", \"task_kind_12\"])\n",
    "for grp, inds in grpdict.items():\n",
    "\n",
    "    dfdist = DFDIST_THIS.iloc[inds].reset_index(drop=True)\n",
    "    # sns.catplot(data=dfdist, x=\"labels_1\", hue=\"labels_2\", y=\"DIST_98\", height=20)\n",
    "\n",
    "    from pythonlib.tools.pandastools import plot_subplots_heatmap\n",
    "    plot_subplots_heatmap(dfdist, \"labels_1\", \"labels_2\", \"DIST_98\", \"subspace\", W=8, share_zlim=True)\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec90d8e",
   "metadata": {},
   "source": [
    "##### [OLDER PLOTS] Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955132e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "if run==1:\n",
    "    order = ['0|0|0', '0|1|1', '1|0|1', '0|0|1', '1|1|0', '1|0|0', '1|1|1']\n",
    "elif run==3:\n",
    "    order = [\n",
    "    '0|0|1|1',\n",
    "    '0|0|1|0',\n",
    "    '0|1|1|1',\n",
    "    '0|1|1|0',\n",
    "    '1|0|1|1',\n",
    "    '1|0|1|0',\n",
    "    '1|1|0|1',\n",
    "    '1|1|0|0',\n",
    "    '1|1|1|0',\n",
    "    ]\n",
    "else:\n",
    "    order = sorted(DFDIST[colname_conj_same].unique())\n",
    "\n",
    "if False: # good, but takes  long time to plot all datapts\n",
    "    sns.catplot(data=DFDIST, x=\"bregion\", y=\"dist_yue_diff\", hue_order=order,\n",
    "                col=\"subspace\", row=colname_conj_same, jitter=True, alpha=0.5)\n",
    "\n",
    "sns.catplot(data=DFDIST, x=\"bregion\", hue=colname_conj_same, y=\"dist_yue_diff\", hue_order=order,\n",
    "            col=\"subspace\", kind=\"bar\", errorbar=\"se\")\n",
    "fig = sns.catplot(data=DFDIST, x=colname_conj_same, hue=\"subspace\", y=\"dist_yue_diff\", order=order,\n",
    "            col=\"bregion\", kind=\"bar\", errorbar=\"se\")\n",
    "from pythonlib.tools.snstools import rotateLabel\n",
    "rotateLabel(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f30d6",
   "metadata": {},
   "source": [
    "##### Plots of effects that are within-chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30633ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get effects for chunk_within_rank, separately for each chunk_shape\n",
    "DFDIST = append_col_with_grp_index(DFDIST, [\"chunk_rank_1\", \"shape_1\"], \"chunk_shape_1\")\n",
    "DFDIST = append_col_with_grp_index(DFDIST, [\"chunk_rank_2\", \"shape_2\"], \"chunk_shape_2\")\n",
    "\n",
    "# Keep only these\n",
    "dfdist = DFDIST[(DFDIST[\"shape_same\"] == True) & (DFDIST[\"chunk_rank_same\"] == True) & (DFDIST[\"same-chunk_within_rank|chunk_rank|shape\"] == \"0|1|1\")]\n",
    "assert all(dfdist[\"chunk_shape_1\"] == dfdist[\"chunk_shape_2\"])\n",
    "\n",
    "sns.catplot(data=dfdist, x=\"bregion\", hue=\"chunk_shape_1\", y=\"dist_yue_diff\", col=\"subspace\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8f674",
   "metadata": {},
   "source": [
    "### Testing kernel trick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d96e6",
   "metadata": {},
   "source": [
    "##### Testing oridnal regression for analyzing rank-within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05669d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e988232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import targeted_pca_clean_plots_and_dfdist_params, preprocess_pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR_ALL = \"/tmp/SYNTAX_ORDINAL_REGRESSION\"\n",
    "os.makedirs(SAVEDIR_ALL, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801bf185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.plottools import savefig\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import state_space_targeted_pca_scalar_single_one_var_mult_axes\n",
    "from neuralmonkey.analyses.euclidian_distance import timevarying_compute_fast_to_scalar\n",
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "### DEBUG -- quick testing\n",
    "if DEBUG:\n",
    "    bregions_get = [\"PMv\"]\n",
    "    n_splits = 1\n",
    "    do_subspaces_within_chunk = False\n",
    "else:\n",
    "    bregions_get = None\n",
    "    n_splits = 3 # make this high, since with splits you might lose certain low-n labels tuples.\n",
    "    # do_subspaces_within_chunk = True\n",
    "    do_subspaces_within_chunk = False\n",
    "\n",
    "# Stratified splits params\n",
    "# Better, more careful, ensuring enough data for euclidian distance.\n",
    "fraction_constrained_set=0.4\n",
    "n_constrained=2 # Ideally have more than 1 pair\n",
    "list_labels_need_n=None\n",
    "min_frac_datapts_unconstrained=None\n",
    "# min_n_datapts_unconstrained=len(PAscal.Xlabels[\"trials\"][_var_effect].unique())\n",
    "min_n_datapts_unconstrained=None\n",
    "plot_train_test_counts=True\n",
    "plot_indices=False\n",
    "\n",
    "# Scalar preprocessing\n",
    "from neuralmonkey.scripts.analy_euclidian_dist_pop_script import _get_list_twind_by_animal\n",
    "_list_twind, _, _ = _get_list_twind_by_animal(animal, \"00_stroke\", \"traj_to_scalar\")\n",
    "twind_scal = _list_twind[0]\n",
    "npcs_keep_force = 50\n",
    "\n",
    "# tbin_dur = 0.2\n",
    "# tbin_slide = 0.1\n",
    "tbin_dur = 0.15\n",
    "tbin_slide = 0.075\n",
    "\n",
    "# Regression variables (and also, variables that are candidates for subspaces)\n",
    "# Run 1 (7/31/25)\n",
    "# variables = ['epoch', 'chunk_rank', 'shape', 'gridloc', 'CTXT_loc_prev', 'CTXT_shape_prev', 'chunk_within_rank', 'stroke_index_is_first']\n",
    "\n",
    "# Run 2 (8/1/25)\n",
    "# variables = ['epoch', 'gridloc', 'DIFF_gridloc', 'shape', 'chunk_rank', 'chunk_within_rank']\n",
    "# variables = ['epoch', 'gridloc', 'DIFF_gridloc', 'shape', 'DIFF_shape', 'chunk_rank', 'chunk_within_rank', 'chunk_within_rank_fromlast', 'chunk_n_in_chunk']\n",
    "variables = ['epoch', 'gridloc', 'DIFF_gridloc', 'shape', 'chunk_rank', 'chunk_within_rank', 'chunk_within_rank_fromlast', 'chunk_n_in_chunk'] # Removing diff shape, it is too correlated with chunk rank?\n",
    "variables_is_cat = [True for _ in range(len(variables))]\n",
    "\n",
    "### Subspace params\n",
    "# list_var_subspace = [\"chunk_within_rank\", \"chunk_rank\", \"chunk_within_rank_fromlast\", \"chunk_n_in_chunk\", \"shape\", \"gridloc\"]\n",
    "list_var_subspace = [\"chunk_within_rank_fromlast\"]\n",
    "\n",
    "### State space plots params\n",
    "LIST_VAR_VAROTHERS = [\n",
    "    # (\"chunk_within_rank\", ['epoch', 'chunk_shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev', 'loc_off_clust']),\n",
    "    # (\"chunk_within_rank\", ['epoch', 'chunk_shape', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev']),\n",
    "    # (\"chunk_shape\", ['epoch', 'chunk_within_rank', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev', 'loc_off_clust']),\n",
    "    # (\"chunk_shape\", ['epoch', 'chunk_within_rank', 'loc_on_clust', 'CTXT_locoffclust_prev', 'CTXT_shape_prev']),\n",
    "\n",
    "    ## N in chunk\n",
    "    (\"chunk_n_in_chunk\", ['task_kind', 'epoch', 'chunk_shape', 'chunk_within_rank']),\n",
    "    (\"chunk_n_in_chunk\", ['task_kind', 'epoch', 'chunk_shape']),\n",
    "    (\"chunk_n_in_chunk\", ['task_kind', 'epoch']),\n",
    "\n",
    "    ## Rank within\n",
    "    (\"chunk_within_rank\", ['task_kind', 'epoch', 'chunk_shape', 'chunk_within_rank_fromlast']),\n",
    "    (\"chunk_within_rank\", ['task_kind', 'epoch', 'chunk_shape', 'chunk_n_in_chunk']),\n",
    "    (\"chunk_within_rank\", ['task_kind', 'epoch', 'chunk_shape']),\n",
    "    (\"chunk_within_rank\", ['task_kind', 'epoch']),\n",
    "\n",
    "    (\"chunk_within_rank_fromlast\", ['task_kind', 'epoch', 'chunk_shape', 'chunk_within_rank']),\n",
    "    (\"chunk_within_rank_fromlast\", ['task_kind', 'epoch', 'chunk_shape', 'chunk_n_in_chunk']),\n",
    "    (\"chunk_within_rank_fromlast\", ['task_kind', 'epoch', 'chunk_shape']),\n",
    "    (\"chunk_within_rank_fromlast\", ['task_kind', 'epoch']),\n",
    "\n",
    "    ## Stroke index (generic)\n",
    "    (\"stroke_index\", ['task_kind', 'epoch', 'syntax_concrete']),\n",
    "    # (\"stroke_index\", ['epoch', 'chunk_shape']),\n",
    "    (\"stroke_index\", ['task_kind', 'epoch']),\n",
    "\n",
    "    ## Location\n",
    "    (\"gridloc_x\", ['task_kind', 'epoch', 'chunk_shape', 'chunk_within_rank_v2']),\n",
    "    # (\"gridloc_x\", ['epoch', 'syntax_concrete']),\n",
    "    # (\"gridloc_x\", ['epoch', 'chunk_shape']),\n",
    "    (\"gridloc_x\", ['task_kind', 'epoch']),\n",
    "\n",
    "    ## Chunk rank and shape\n",
    "    # (\"chunk_shape\", ['epoch', 'chunk_within_rank', 'syntax_concrete']),\n",
    "    # (\"chunk_shape\", ['epoch', 'chunk_within_rank']),\n",
    "    # (\"chunk_shape\", ['epoch']),\n",
    "\n",
    "    # (\"chunk_rank\", ['epoch', 'shape', 'chunk_within_rank']),\n",
    "    (\"chunk_rank\", ['task_kind', 'epoch', 'shape']),\n",
    "    (\"chunk_rank\", ['task_kind', 'epoch']),\n",
    "\n",
    "    # (\"shape\", ['epoch', 'chunk_rank', 'chunk_within_rank']),\n",
    "    (\"shape\", ['epoch', 'task_kind', 'chunk_rank']),\n",
    "    (\"shape\", ['epoch', 'task_kind']),\n",
    "\n",
    "    (\"task_kind\", [\"epoch\", \"shape\"]),\n",
    "]\n",
    "LIST_DIMS = [(0,1), (1,2)]\n",
    "\n",
    "### Euclidean dist params (ie one set for each \"question\")\n",
    "# 1: Two things: (1) rank within an dsimple within vs. chunk vs. motor (shape, gridloc)\n",
    "# TODO: possibly also exclude gridloc. Note that this leads to larger effects of grammar stuff even in M1. Is cleaner this way.\n",
    "# TODO: possibly also include DIFF_gridloc. But problem is that then there is not much data..\n",
    "map_question_to_euclideanvars = targeted_pca_clean_plots_and_dfdist_params()[\"map_question_to_euclideanvars\"]\n",
    "euclidean_npcs_keep = 8\n",
    "\n",
    "for _, row in DFallpa.iterrows():\n",
    "    bregion = row[\"bregion\"]\n",
    "    PA = row[\"pa\"]\n",
    "\n",
    "    if (bregions_get is not None) and (bregion not in bregions_get):\n",
    "        continue\n",
    "    \n",
    "    SAVEDIR = f\"{SAVEDIR_ALL}/bregion={bregion}\"\n",
    "    os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "    prune_min_n_trials = 3\n",
    "    filtdict = {}\n",
    "    prune_min_n_levs = 2\n",
    "    # use these regardless of what subspace, as they are good for pruning\n",
    "    _var_effect = \"chunk_within_rank_semantic_v2\"\n",
    "    _vars_others = [\"epoch\", \"chunk_shape\", \"syntax_concrete\", \"task_kind\"]\n",
    "    PA = preprocess_pa(PA, _var_effect, _vars_others, prune_min_n_trials, prune_min_n_levs, filtdict,\n",
    "                SAVEDIR, \n",
    "                None, None, None, None, None, \n",
    "                skip_dimredu=True, prune_by_conj_var=False)\n",
    "\n",
    "    # Do dim reduction of PA up here, to be able to skip it below (quicker)\n",
    "    savedir_pca = f\"{SAVEDIR}/pca\"\n",
    "    os.makedirs(savedir_pca, exist_ok=True)\n",
    "    _, PAscal = PA.dataextract_dimred_wrapper(\"scal\", \"pca\", savedir_pca, twind_scal, tbin_dur, tbin_slide,\n",
    "                                npcs_keep_force)            \n",
    "\n",
    "    assert False\n",
    "    ### Method 1: Use entire data for fitting and projecting (with cross-validation)\n",
    "    # Now split into train (fitting targeted PCA) and testing (projection).\n",
    "\n",
    "    ### Get subsamples\n",
    "    vars_stratification = [\"epoch\", \"chunk_within_rank_semantic_v2\", \"chunk_shape\", \"syntax_concrete\", \"task_kind\"]\n",
    "    folds_dflab, fig_unc, fig_con = PAscal.split_stratified_constrained_grp_var(n_splits, vars_stratification, \n",
    "                                                    fraction_constrained_set, n_constrained, \n",
    "                                                    list_labels_need_n, min_frac_datapts_unconstrained,  \n",
    "                                                    min_n_datapts_unconstrained, plot_train_test_counts, plot_indices)\n",
    "    savefig(fig_con, f\"{SAVEDIR}/after_split_constrained_fold_0.pdf\") # TEST\n",
    "    savefig(fig_unc, f\"{SAVEDIR}/after_split_unconstrained_fold_0.pdf\") # TRIAN\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "    # Save some params\n",
    "    from pythonlib.tools.expttools import writeDictToYaml, writeDictToTxtFlattened\n",
    "    writeDictToYaml({\n",
    "        \"vars_stratification\":vars_stratification,\n",
    "        \"map_question_to_euclideanvars\":map_question_to_euclideanvars,\n",
    "        \"euclidean_npcs_keep\":euclidean_npcs_keep,\n",
    "        \"LIST_VAR_VAROTHERS\":LIST_VAR_VAROTHERS,\n",
    "        \"list_var_subspace\":list_var_subspace,\n",
    "        \"variables\":variables,\n",
    "        \"variables_is_cat\":variables_is_cat,\n",
    "        \"twind_scal\":twind_scal,\n",
    "    }, f\"{SAVEDIR}/params.yaml\")\n",
    "    writeDictToTxtFlattened({\n",
    "        \"vars_stratification\":vars_stratification,\n",
    "        \"map_question_to_euclideanvars\":map_question_to_euclideanvars,\n",
    "        \"euclidean_npcs_keep\":euclidean_npcs_keep,\n",
    "        \"LIST_VAR_VAROTHERS\":LIST_VAR_VAROTHERS,\n",
    "        \"list_var_subspace\":list_var_subspace,\n",
    "        \"variables\":variables,\n",
    "        \"variables_is_cat\":variables_is_cat,\n",
    "        \"twind_scal\":twind_scal,\n",
    "    }, f\"{SAVEDIR}/params.txt\")\n",
    "\n",
    "    for i_proj, (train_inds, test_inds) in enumerate(folds_dflab):\n",
    "        \n",
    "        # train_inds has FEWER inds than test_inds\n",
    "        train_inds = [int(i) for i in train_inds]\n",
    "        test_inds = [int(i) for i in test_inds]\n",
    "        print(\"n_train, n_test:\", len(train_inds), len(test_inds))\n",
    "\n",
    "        # HACK: Single prims trials should always be in test inds, not train inds.\n",
    "        dflab = PAscal.Xlabels[\"trials\"]\n",
    "        inds_sp = dflab[dflab[\"task_kind\"]==\"prims_single\"].index.tolist()\n",
    "        test_inds = test_inds + [i for i in train_inds if i in inds_sp]\n",
    "        train_inds = [i for i in train_inds if i not in inds_sp]\n",
    "\n",
    "        # Then run this: state_space_targeted_pca_scalar_single_one_var_mult_axes\n",
    "        # TODO: split the training and testing\n",
    "        for var_subspace in list_var_subspace:\n",
    "\n",
    "            savedir = f\"{SAVEDIR}/FITTING_subspc={var_subspace}-iter={i_proj}\"\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "            pa_subspace, _, _, dfcoeff, _ = state_space_targeted_pca_scalar_single_one_var_mult_axes(\n",
    "                    PAscal, None, variables, variables_is_cat, var_subspace, npcs_keep_force, \n",
    "                    LIST_VAR_VAROTHERS, LIST_DIMS, savedir, just_extract_paredu=False,\n",
    "                    savedir_pca_subspaces=savedir, tbin_dur=tbin_dur, tbin_slide=tbin_slide,\n",
    "                    inds_trials_pa_train=train_inds, inds_trials_pa_test=test_inds,\n",
    "                    skip_dim_redu=True)\n",
    "\n",
    "            assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d317d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont do subspace projection, just use all data\n",
    "pa_subspace = PAscal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa950832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune to top two dimesinos\n",
    "assert False, \"do this correctly\"\n",
    "pa_subspace.X = pa_subspace.X[:2, :, :]\n",
    "pa_subspace.Chans = pa_subspace.Chans[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_subspace.X.shape, PAscal.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d54341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.regression_good import kernel_ordinal_logistic_regression, _kernel_ordinal_logistic_regression_example\n",
    "# kernel_ordinal_logistic_regression()\n",
    "res = _kernel_ordinal_logistic_regression_example(rescale_std=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = f\"{SAVEDIR}/kernel_ordinal_regress\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "pa_subspace = pa_subspace.slice_by_labels_filtdict({\"task_kind\":[\"prims_on_grid\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = f\"{SAVEDIR}/kernel_ordinal_regress\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "pa_subspace = pa_subspace.slice_by_labels_filtdict({\"task_kind\":[\"prims_on_grid\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep classes with at least this many items\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Example array\n",
    "arr = np.array([1, 1, 1, 2, 2, 3, 3, 3, 4, 5, 5])\n",
    "from pythonlib.tools.nptools import filter_array_to_include_minimum_n_items\n",
    "filter_array_to_include_minimum_n_items(arr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d82c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do testing on held-out data\n",
    "if False:\n",
    "\n",
    "    from pythonlib.tools.statstools import split_stratified_constrained_multiple\n",
    "    nsplits = 10\n",
    "    fraction_constrained_set = 0.75\n",
    "    n_constrained = 2\n",
    "\n",
    "    # each fold (unconstrainted, constrainted), ie (test, train)\n",
    "    folds = split_stratified_constrained_multiple(Y, nsplits, fraction_constrained_set, n_constrained, PLOT=False)\n",
    "\n",
    "    for inds_test, inds_train in folds:\n",
    "        print(len(inds_test), len(inds_train))\n",
    "\n",
    "    from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "    y_actual = [1,1,2,2,2, 2, 0]\n",
    "    y_pred = [1, 1, 1, 2, 2, 2, 0]\n",
    "    balanced_accuracy_score(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar = \"chunk_within_rank_fromlast\"\n",
    "\n",
    "# dflab = pa_subspace.Xlabels[\"trials\"]\n",
    "# Y = dflab[yvar].values\n",
    "# Y = Y - min(Y)\n",
    "# Y = Y.astype(np.int64)\n",
    "\n",
    "# dflab[f\"{yvar}-ord\"] = Y\n",
    "# pa_subspace.Xlabels[\"trials\"] = dflab\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import kernel_ordinal_logistic_regression_wrapper\n",
    "vars_grp = [\"task_kind\", \"epoch\", \"chunk_shape\", \"chunk_n_in_chunk\"]\n",
    "# yvar_ord = f\"{yvar}-ord\"\n",
    "dfcross, dfwithin = kernel_ordinal_logistic_regression_wrapper(pa_subspace, yvar, vars_grp, savedir, plot_test_data_projected=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82ea5c",
   "metadata": {},
   "source": [
    "##### Loading pre-saved pa_subspace, and then run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from pythonlib.tools.pandastools import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = \"Diego\"\n",
    "date = 230913\n",
    "nsplits = 10\n",
    "for bregion in [\"M1\", \"PMv\", \"preSMA\", \"PMd\"]:\n",
    "\n",
    "    savedir = f\"/tmp/LOGISTIC/{animal}-{date}/{bregion}\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "    path = f\"/lemur2/lucas/analyses/recordings/main/syntax_good/targeted_dim_redu_v2/run12/{animal}-{date}-q=RULE_ANBMCK_STROKE/bregion={bregion}/FITTING_subspc=('epoch', 'gridloc', 'DIFF_gridloc', 'chunk_rank', 'shape', 'rank_conj')-iter=0/pa_subspace.pkl\"\n",
    "    import pickle\n",
    "    with open(path, \"rb\") as f:\n",
    "        pa_subspace = pickle.load(f)\n",
    "    euclidean_npcs_keep = 6\n",
    "    _npcs_keep_euclidean = min([euclidean_npcs_keep, pa_subspace.X.shape[0]])\n",
    "    pa_subspace_this = pa_subspace.slice_by_dim_indices_wrapper(\"chans\", list(range(_npcs_keep_euclidean)))\n",
    "\n",
    "    from neuralmonkey.scripts.analy_syntax_good_eucl_state import kernel_ordinal_logistic_regression_wrapper\n",
    "    yvar = \"chunk_within_rank_fromlast\"\n",
    "    vars_grp = [\"task_kind\", \"epoch\", \"chunk_rank\", \"shape\", \"gridloc\", \"CTXT_loc_prev\", \"chunk_n_in_chunk\"]\n",
    "\n",
    "    # vars_grp = [\"epoch\", \"chunk_within_rank\", \"chunk_rank\", \"shape\", \"gridloc\", \"CTXT_loc_prev\", \"chunk_n_in_chunk\", \"task_kind\"]\n",
    "\n",
    "    savedir_this = f\"{savedir}/kernel_ordinal_regress-yvar={yvar}\"\n",
    "    os.makedirs(savedir_this, exist_ok=True)\n",
    "\n",
    "    # Exclude single prims\n",
    "    pa_subspace_this_PIG = pa_subspace_this.slice_by_labels_filtdict({\"task_kind\":[\"prims_on_grid\"]})\n",
    "\n",
    "\n",
    "    dfcross, dfwithin = kernel_ordinal_logistic_regression_wrapper(pa_subspace_this_PIG, yvar, vars_grp, \n",
    "                                                                savedir_this, plot_test_data_projected=False, \n",
    "                                                                nsplits=nsplits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339dc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_plot_n_samples_conjunction_heatmap, append_col_with_grp_index\n",
    "dflab = pa_subspace_this_PIG.Xlabels[\"trials\"]\n",
    "dflab = append_col_with_grp_index(dflab, [\"epoch\", \"chunk_rank\", \"gridloc\", \"CTXT_loc_prev\", \"chunk_n_in_chunk\", \"task_kind\", \"shape\"], \"_vars_others\")\n",
    "grouping_plot_n_samples_conjunction_heatmap(dflab, \"_vars_others\", yvar, FIGSIZE=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06a248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fcc9da3",
   "metadata": {},
   "source": [
    "### Improving targeted PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all motor params\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import preprocess_dfallpa_motor_features\n",
    "preprocess_dfallpa_motor_features(DFallpa, plot_motor_values=True, do_zscore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HEre, load a PAscal using the code from above (under ##### Testing oridnal regression for analyzing rank-within)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9bf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do projection\n",
    "variables_cont = (\"motor_onsetx\", \"motor_onsety\", \"gap_from_prev_x\", \"gap_from_prev_y\", \"velmean_x\", \"velmean_y\")\n",
    "variables_cat = (\"gridloc\", \"DIFF_gridloc\", \"stroke_index_is_first\", \"chunk_rank\", \"shape\", \"rank_conj\")\n",
    "vars_remove = [\"motor_onsetx\", \"motor_onsety\", \"gap_from_prev_x\", \"gap_from_prev_y\", \n",
    "            \"velmean_x\", \"velmean_y\", \"gridloc\", \"DIFF_gridloc\", \"stroke_index_is_first\"]\n",
    "\n",
    "# var_subspace = \"rank_conj\"\n",
    "var_subspace = [\"rank_conj\"]\n",
    "\n",
    "pa_subspace, subspace_axes_orig, subspace_axes_normed, dfcoeff, pa_test, PAresid, original_feature_mapping = PAscal.dataextract_subspace_targeted_pca_subtract_confounds(variables_cont, variables_cat, vars_remove,\n",
    "                                                             var_subspace, npcs_keep, normalization=\"orthonormal\",\n",
    "                                                             PLOT_COEFF_HEATMAP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_this_subspace = [\"motor_onsetx\", \"motor_onsety\", \"gap_from_prev_x\", \"gap_from_prev_y\", \n",
    "            \"velmean_x\", \"velmean_y\", \"gridloc\", \"DIFF_gridloc\"]\n",
    "dfbases = PAscal.regress_neuron_task_variables_convert_coeff_to_basis(dfcoeff, vars_this_subspace, original_feature_mapping,\n",
    "                                                             savedir_pca_subspaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edacb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_trial import state_space_targeted_pca_scalar_single_plot_\n",
    "savedir = f\"{SAVEDIR}/FITTING_subspc={var_subspace}-v5_good\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "LIST_DIMS = [(0, 1), (2, 3), (4, 5)]\n",
    "state_space_targeted_pca_scalar_single_plot_(pa_subspace, LIST_VAR_VAROTHERS, LIST_DIMS, savedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e82994",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Logging all the different methods\n",
    "\n",
    "# Method 1(original): Project original data, not residuals\n",
    "savedir = f\"{SAVEDIR}/FITTING_subspc={var_subspace}-v6_final\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "print(savedir)\n",
    "train_inds=None\n",
    "test_inds = None\n",
    "pa_subspace, _, _, dfcoeff, _ = state_space_targeted_pca_scalar_single_one_var_mult_axes(\n",
    "        PAscal, None, variables_cont, variables_cat, var_subspace, npcs_keep_force, \n",
    "        LIST_VAR_VAROTHERS, LIST_DIMS, savedir, just_extract_paredu=False,\n",
    "        savedir_pca_subspaces=savedir, tbin_dur=tbin_dur, tbin_slide=tbin_slide,\n",
    "        inds_trials_pa_train=train_inds, inds_trials_pa_test=test_inds,\n",
    "        skip_dim_redu=True,\n",
    "        do_vars_remove=True, vars_remove=vars_remove)\n",
    "\n",
    "# Then, project PAresid to a subspace\n",
    "\n",
    "\n",
    "# Method 1(original): Project original data, not residuals\n",
    "savedir = f\"{SAVEDIR}/FITTING_subspc={var_subspace}-iter={i_proj}-v1_noresid\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "print(savedir)\n",
    "pa_subspace, _, _, dfcoeff, _ = state_space_targeted_pca_scalar_single_one_var_mult_axes(\n",
    "        PAscal, None, variables, None, var_subspace, npcs_keep_force, \n",
    "        LIST_VAR_VAROTHERS, LIST_DIMS, savedir, just_extract_paredu=False,\n",
    "        savedir_pca_subspaces=savedir, tbin_dur=tbin_dur, tbin_slide=tbin_slide,\n",
    "        inds_trials_pa_train=train_inds, inds_trials_pa_test=test_inds,\n",
    "        skip_dim_redu=True)\n",
    "\n",
    "# Method 2 (new): First get residuals, then project to subspace\n",
    "savedir = f\"{SAVEDIR}/FITTING_subspc={var_subspace}-iter={i_proj}-v2_resid\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "print(savedir)\n",
    "pa_subspace, _, _, dfcoeff, _ = state_space_targeted_pca_scalar_single_one_var_mult_axes(\n",
    "        PAresid, None, [var_subspace], None, var_subspace, npcs_keep_force, \n",
    "        LIST_VAR_VAROTHERS, LIST_DIMS, savedir, just_extract_paredu=False,\n",
    "        savedir_pca_subspaces=savedir, tbin_dur=tbin_dur, tbin_slide=tbin_slide,\n",
    "        inds_trials_pa_train=train_inds, inds_trials_pa_test=test_inds,\n",
    "        skip_dim_redu=True)\n",
    "\n",
    "# Method 3 (new): First get residuals, then project to subspace (but as sanity check, use all variables)\n",
    "savedir = f\"{SAVEDIR}/FITTING_subspc={var_subspace}-iter={i_proj}-v3_resid\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "print(savedir)\n",
    "pa_subspace, _, _, dfcoeff, _ = state_space_targeted_pca_scalar_single_one_var_mult_axes(\n",
    "        PAresid, None, variables, None, var_subspace, npcs_keep_force, \n",
    "        LIST_VAR_VAROTHERS, LIST_DIMS, savedir, just_extract_paredu=False,\n",
    "        savedir_pca_subspaces=savedir, tbin_dur=tbin_dur, tbin_slide=tbin_slide,\n",
    "        inds_trials_pa_train=train_inds, inds_trials_pa_test=test_inds,\n",
    "        skip_dim_redu=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626723d1",
   "metadata": {},
   "source": [
    "### Devo -- new kind of pipeline for euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ie. see run7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453370a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = \"/tmp/NEW_PIPELINE\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f94dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = f\"{SAVEDIR}/{bregion}\"\n",
    "os.makedirs(savedir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project to a single generic space (capturing both syntax and motor effects)\n",
    "\n",
    "\n",
    "# First, PCA to convert window to vector\n",
    "savedir_pca = f\"{SAVEDIR}/pca\"\n",
    "os.makedirs(savedir_pca, exist_ok=True)\n",
    "\n",
    "from neuralmonkey.scripts.analy_euclidian_dist_pop_script import _get_list_twind_by_animal\n",
    "_list_twind, _, _ = _get_list_twind_by_animal(animal, \"00_stroke\", \"traj_to_scalar\")\n",
    "twind_scal = _list_twind[0]\n",
    "npcs_keep_force = 50\n",
    "tbin_dur = 0.15\n",
    "tbin_slide = 0.075\n",
    "_, PAscal = PA.dataextract_dimred_wrapper(\"scal\", \"pca\", savedir_pca, twind_scal, tbin_dur, tbin_slide,\n",
    "                            npcs_keep_force)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Remove effect of first stroke.\n",
    "    _savedir = f\"{SAVEDIR}/remove_effect_first_stroke-coeff\"\n",
    "    os.makedirs(_savedir, exist_ok=True)\n",
    "    _, _, _, _, _, PAscal, _ = PAscal.dataextract_subspace_targeted_pca_subtract_confounds(\n",
    "                                                variables_cont_global, variables_cat_global, vars_remove_global,\n",
    "                                                None, None, None,\n",
    "                                                True, False,\n",
    "                                                savedir_coeff_heatmap=_savedir,\n",
    "                                                savedir_pca_subspaces=_savedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fa312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep just PIG\n",
    "PAscal = PAscal.slice_by_labels_filtdict({\"task_kind\":[\"prims_on_grid\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, then targeted PCA to get signal\n",
    "# - don't control for motor\n",
    "\n",
    "variables_cont = []\n",
    "variables_cat = [\"epoch\", \"gridloc\", \"DIFF_gridloc\", \"chunk_rank\", \"shape\", \"rank_conj\"]\n",
    "vars_remove = None\n",
    "var_subspace = variables_cat\n",
    "npcs_keep = 10\n",
    "\n",
    "pa_subspace, subspace_axes_orig, subspace_axes_normed, dfcoeff, pa_test, PAresid, original_feature_mapping = PAscal.dataextract_subspace_targeted_pca_subtract_confounds(variables_cont, variables_cat, vars_remove,\n",
    "                                                             var_subspace, npcs_keep, \n",
    "                                                             PLOT_COEFF_HEATMAP=True, \n",
    "                                                             savedir_coeff_heatmap=savedir, demean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute syntax effect, do maximal control of motor effect:\n",
    "\n",
    "# Regress out motor stuff\n",
    "variables_cont = [\"motor_onsetx\", \"motor_onsety\", \"gap_from_prev_x\", \"gap_from_prev_y\", \"velmean_x\", \"velmean_y\"]\n",
    "variables_cat = [\"epoch\", \"gridloc\", \"DIFF_gridloc\", \"chunk_rank\", \"shape\", \"rank_conj\"]\n",
    "vars_remove = [\"motor_onsetx\", \"motor_onsety\", \"gap_from_prev_x\", \"gap_from_prev_y\", \"velmean_x\", \"velmean_y\", \"gridloc\", \"DIFF_gridloc\", \"chunk_rank\", \"shape\"]\n",
    "# var_subspace = None # Don't project\n",
    "_, _, _, _, _, pa_subspace_resid, _ = pa_subspace.dataextract_subspace_targeted_pca_subtract_confounds(variables_cont, variables_cat, vars_remove,\n",
    "                                                             None, None, \n",
    "                                                             PLOT_COEFF_HEATMAP=True, \n",
    "                                                             savedir_coeff_heatmap=savedir, demean=False)\n",
    "\n",
    "# Euclidean distance\n",
    "# Compute euclidean stuff\n",
    "# _npcs_keep_euclidean = min([euclidean_npcs_keep, pa_subspace.X.shape[0]])\n",
    "do_plot_rsa = False\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import targeted_pca_clean_plots_and_dfdist_params\n",
    "map_question_to_euclideanvars = targeted_pca_clean_plots_and_dfdist_params()[\"map_question_to_euclideanvars\"]\n",
    "\n",
    "_npcs_keep_euclidean = npcs_keep\n",
    "pa_subspace_this = pa_subspace.slice_by_dim_indices_wrapper(\"chans\", list(range(_npcs_keep_euclidean)))\n",
    "\n",
    "list_dfdist = []\n",
    "for question, euclidean_label_vars in map_question_to_euclideanvars.items():\n",
    "    if do_plot_rsa:\n",
    "        rsa_heatmap_savedir = savedir\n",
    "    else:\n",
    "        rsa_heatmap_savedir = None\n",
    "    dfdist, _ = timevarying_compute_fast_to_scalar(pa_subspace_this, label_vars=euclidean_label_vars, \n",
    "                                            rsa_heatmap_savedir=rsa_heatmap_savedir, plot_conjunctions_savedir=savedir)\n",
    "\n",
    "    # save it\n",
    "    # dfdist[\"i_proj\"] = i_proj\n",
    "    dfdist[\"var_subspace\"] = [var_subspace for _ in range(len(dfdist))]\n",
    "    dfdist[\"question\"] = question\n",
    "    dfdist[\"npcs_euclidean\"] = _npcs_keep_euclidean\n",
    "    list_dfdist.append(dfdist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac720b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist[\"dist_yue_diff\"] * dfdist[\"DIST_98\"] + 1.929697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0df7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist[\"dist_norm\"] * dfdist[\"DIST_98\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also compute euclidean distances without subtracting\n",
    "dfdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92986920",
   "metadata": {},
   "source": [
    "# [Good] Targeted PCA, for Shape vs. supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_concatbregion_preprocess_wrapper, dfpa_concat_bregion_to_combined_bregion\n",
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_concat_bregion_to_combined_bregion\n",
    "SAVEDIR = f\"/lemur2/lucas/analyses/recordings/main/syntax_good_superv\"\n",
    "\n",
    "\n",
    "animal = \"Diego\"\n",
    "# date = 230922\n",
    "date = 230924\n",
    "version = \"stroke\"\n",
    "combine = False\n",
    "\n",
    "### (1) load Grammar Dfallpa\n",
    "question = \"RULESW_ANY_SEQSUP_STROKE\"\n",
    "DFallpa = load_handsaved_wrapper(animal, date, version=version, combine_areas=combine, \n",
    "                                    question=question)\n",
    "DFallpa = dfpa_concat_bregion_to_combined_bregion(DFallpa)\n",
    "\n",
    "# Make a copy of all PA before normalization\n",
    "dfpa_concatbregion_preprocess_wrapper(DFallpa, animal, date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a73ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63333767",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = DFallpa[\"pa\"].values[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = \"/tmp\"\n",
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state import preprocess_pa, preprocess_pa_syntax\n",
    "preprocess_pa_syntax(PA)\n",
    "prune_min_n_trials = 3\n",
    "filtdict = {}\n",
    "prune_min_n_levs = 2\n",
    "# use these regardless of what subspace, as they are good for pruning\n",
    "_var_effect = \"chunk_within_rank_semantic_v2\"\n",
    "_vars_others = [\"epoch\", \"chunk_shape\", \"syntax_concrete\", \"task_kind\"]\n",
    "\n",
    "PA = preprocess_pa(PA, _var_effect, _vars_others, prune_min_n_trials, prune_min_n_levs, filtdict,\n",
    "            SAVEDIR, \n",
    "            None, None, None, None, None, \n",
    "            skip_dimredu=True, prune_by_conj_var=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebcd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_euclidian_dist_pop_script_MULT import load_preprocess_get_dates\n",
    "dates, question, _, _ = load_preprocess_get_dates(\"Pancho\", \"sh_vs_seqsup\")\n",
    "dates, question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab = PA.Xlabels[\"trials\"]\n",
    "\n",
    "\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "grouping_print_n_samples(dflab, [\"superv_COLOR_METHOD\", \"epoch_rand\", \"epoch\", \"epoch_is_DIR\", \"epoch_is_AnBmCk\", \"superv_is_seq_sup\", \"supervision_stage_concise\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab[\"sup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15133709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only data that has identical (shape, loc) sequence, but with and without supervision\n",
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars_helper\n",
    "plot_counts_heatmap_savepath = \"/tmp/counts.pdf\"\n",
    "dflabthis, _ = extract_with_levels_of_conjunction_vars_helper(dflab, \"epoch_rand\", [\"behseq_shapes\", \"behseq_locs_clust\"], 1, plot_counts_heatmap_savepath, 2, levels_var=[\"llCV3\", \"llCV3|S\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9502a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only data that has identical (shape, loc) sequence, but with and without supervision\n",
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars_helper\n",
    "plot_counts_heatmap_savepath = \"/tmp/counts.pdf\"\n",
    "dflabthis, _ = extract_with_levels_of_conjunction_vars_helper(dflab, \"epoch_rand\", [\"behseq_shapes\", \"behseq_locs_clust\"], 1, plot_counts_heatmap_savepath, 2, levels_var=[\"llCV3\", \"llCV3|S\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d66439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "\n",
    "grouping_print_n_samples(dflab, [\"epochset_shape\", \"syntax_concrete\", \"behseq_shapes\", \"behseq_locs_clust\", \"epoch_rand\", \"epoch_is_AnBmCk\", \"superv_is_seq_sup\", \"stroke_index\"])\n",
    "\n",
    "# This shows that I need to do the following contrasts\n",
    "\n",
    "# \"11_twoshapes\":[\"epochset_shape\", \"syntax_concrete\", \"behseq_shapes\", \"behseq_locs_clust\", \"epoch_rand\", \"superv_is_seq_sup\", \"stroke_index\"],\n",
    "\n",
    "\n",
    "# ------- Match the entire trial sequence (and then use stroke index)\n",
    "# --- weaker superv\n",
    "# \"11_twoshapes\":[\"epochset_shape\", \"syntax_concrete\", \"epoch_rand\", \"superv_is_seq_sup\", \"stroke_index\"],\n",
    "\n",
    "# epochset_shape = llv...\n",
    "# epoch_rand is in [llv|s and llv]\n",
    "# superv_is_seq_sup = False\n",
    "# effect_extract_helper_this_wrapper(DFDIST, question, subspaces, [\"stroke_index\"], [], only_within_pig, \"syntax_effect\", list_dfeffect)\n",
    "\n",
    "# epochset_shape = llv...\n",
    "# epoch_rand is in [llv|s and llv]\n",
    "# effect_extract_helper_this_wrapper(DFDIST, question, subspaces, [\"epoch_rand\", \"superv_is_seq_sup\"], [], only_within_pig, \"superv_effect\", list_dfeffect)\n",
    "\n",
    "# --- stronger superv\n",
    "# \"11_twoshapes\":[\"epochset_shape\", \"syntax_concrete\", \"epoch_rand\", \"superv_is_seq_sup\", \"stroke_index\", \"behseq_locs_clust\"], # not enough data\n",
    "\n",
    "# (contrasts are same as above)\n",
    "\n",
    "# ------ And then do the same for direction \n",
    "\n",
    "### subspace:\n",
    "# [\"epoch\", \"gridloc\", \"DIFF_gridloc\", \"stroke_index_is_first\", \"chunk_rank\", \"shape\", \"rank_conj\", \"superv_is_seq_sup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2601eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # # Compute eucl distance within each shape\n",
    "        # LIST_VAR = [\n",
    "        #     \"chunk_within_rank_semantic_v2\", \n",
    "        #     \"stroke_index\",\n",
    "        #     \"chunk_within_rank_semantic_v2\", \n",
    "        #     \"stroke_index\",\n",
    "        #     \"syntax_role\", # ------------- Using syntax_role instead of stroke_index\n",
    "        #     \"syntax_role\",\n",
    "        #     ]\n",
    "        # LIST_VARS_OTHERS = [\n",
    "        #     [\"epochset_shape\", \"epoch_rand\", \"chunk_rank\", \"shape\", \"superv_is_seq_sup\"], \n",
    "        #     [\"epochset_shape\", \"epoch_rand\", \"superv_is_seq_sup\"],\n",
    "        #     [\"epochset_dir\", \"epoch_rand\", \"chunk_rank\", \"shape\", \"superv_is_seq_sup\"],\n",
    "        #     [\"epochset_dir\", \"epoch_rand\", \"superv_is_seq_sup\"],\n",
    "        #     [\"epochset_shape\", \"epoch_rand\", \"superv_is_seq_sup\"], # ------------- Using syntax_role instead of stroke_index\n",
    "        #     [\"epochset_dir\", \"epoch_rand\", \"superv_is_seq_sup\"],\n",
    "        #     ]\n",
    "        # LIST_CONTEXT = [\n",
    "        #     {\"same\":[\"epochset_shape\", \"epoch_rand\", \"chunk_rank\", \"shape\", \"superv_is_seq_sup\"], \"diff\":None},\n",
    "        #     {\"same\":[\"epochset_shape\", \"epoch_rand\", \"superv_is_seq_sup\"], \"diff\":None},\n",
    "        #     {\"same\":[\"epochset_dir\", \"epoch_rand\", \"chunk_rank\", \"shape\", \"superv_is_seq_sup\"], \"diff\":None},\n",
    "        #     {\"same\":[\"epochset_dir\", \"epoch_rand\", \"superv_is_seq_sup\"], \"diff\":None},\n",
    "        #     {\"same\":[\"epochset_shape\", \"epoch_rand\", \"superv_is_seq_sup\"], \"diff\":None}, # ------------- Using syntax_role instead of stroke_index\n",
    "        #     {\"same\":[\"epochset_dir\", \"epoch_rand\", \"superv_is_seq_sup\"], \"diff\":None},\n",
    "        #     ]\n",
    "        \n",
    "        # if HACK:\n",
    "        #     # very hacky, just keep specific vars that are already extracted\n",
    "        #     LIST_VAR = LIST_VAR[:2]\n",
    "        #     LIST_VARS_OTHERS = LIST_VARS_OTHERS[:2]\n",
    "        #     LIST_CONTEXT = LIST_CONTEXT[:2]\n",
    "\n",
    "        # LIST_PRUNE_MIN_N_LEVS = [2 for _ in range(len(LIST_VAR))]\n",
    "        # # filtdict = {\"stroke_index\": list(range(1, 10, 1))}\n",
    "        # # filtdict = {\"epochset_shape\":[(\"llCV3\",)]}\n",
    "        # LIST_FILTDICT = [None for _ in range(len(LIST_VAR))]\n",
    "        # use_strings_for_vars_others = False\n",
    "        # list_subspace_projection = [\"stxsuperv\"]\n",
    "        # is_seqsup_version = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e961e6",
   "metadata": {},
   "source": [
    "##### [Devo] Load single day results and make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534298b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_syntax_good_eucl_state_MULT import targeted_pca_MULT_2_plot_single_load\n",
    "animal = \"Diego\"\n",
    "date = 230922\n",
    "run = 13\n",
    "DFDIST, map_question_to_euclideanvars, map_question_to_varsame = targeted_pca_MULT_2_plot_single_load(animal, date, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacky, just to devo code\n",
    "DFDIST[\"FEAT_num_strokes_beh\"] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDIST[\"question\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55facba",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"25_sh_vs_superv\"\n",
    "dfdist = DFDIST[DFDIST[\"question\"] == question].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62aac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep pairs that do not include the first or last stroke\n",
    "a = (dfdist[\"stroke_index_1\"] > 0) & (dfdist[\"stroke_index_1\"] < dfdist[\"FEAT_num_strokes_beh\"] - 1)\n",
    "b = (dfdist[\"stroke_index_2\"] > 0) & (dfdist[\"stroke_index_2\"] < dfdist[\"FEAT_num_strokes_beh\"] - 1)\n",
    "dfdist[a & b]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist[\"stroke_index_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "varsame = map_question_to_varsame[question]\n",
    "grouping_print_n_samples(dfdist, [varsame, \"labels_1\", \"labels_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_print_n_samples(dfdist, [varsame, \"stroke_index_1\", \"stroke_index_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar = \"dist_yue_diff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = sns.catplot(dfdist, x=\"bregion\", y=yvar, hue=varsame, col=\"superv_is_seq_sup_12\", kind=\"bar\")\n",
    "fig = sns.catplot(dfdist, x=\"bregion\", y=yvar, hue=\"superv_is_seq_sup_12\", col=varsame, col_wrap=6, kind=\"bar\")\n",
    "fig.set_titles(size=5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b06ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDIST[\"subspace\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37831c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/lemur2/lucas/analyses/recordings/main/syntax_good/targeted_dim_redu_v2/run15/MULT/DFDIST-Pancho-250322.pkl\"\n",
    "dfdist = pd.read_pickle(path)\n",
    "\n",
    "path = \"/lemur2/lucas/analyses/recordings/main/syntax_good/targeted_dim_redu_v2/run15/MULT/summary_each_date-yvar=dist_yue_diff/Pancho-250322/DFEFFECT.pkl\"\n",
    "dfeffect = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist[\"bregion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedd448",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfeffect[\"bregion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015fd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdist[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeee74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "\n",
    "grouping_print_n_samples(dfdist, [\"subspace\", \"question\", \"labels_1\", \"labels_2\", \"bregion\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drag2_matlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
