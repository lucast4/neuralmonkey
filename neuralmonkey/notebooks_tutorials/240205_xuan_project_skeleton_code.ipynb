{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting a DFallpa [for Lucas. Xuan can ignore]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b19797efdaef85a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper\n",
    "animal = \"Diego\"\n",
    "date = 230615\n",
    "question = \"SP_shape_loc\"\n",
    "list_time_windows = [(-0.4, 0.6)]\n",
    "events_keep = [\"03_samp\"]\n",
    "combine_into_larger_areas = False\n",
    "DFallpa = dfallpa_extraction_load_wrapper(animal, date, question, list_time_windows,\n",
    "                                events_keep = events_keep,\n",
    "                                HACK_RENAME_SHAPES=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "703578e54f80fbe2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a question\n",
    "from neuralmonkey.analyses.rsa import rsagood_questions_dict\n",
    "DictParamsEachQuestion = rsagood_questions_dict(animal, date)\n",
    "q_params = DictParamsEachQuestion[question]\n",
    "print(q_params)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f16c766a83258bf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalize, etc\n",
    "# Clean up DFallpa\n",
    "from neuralmonkey.analyses.rsa import preprocess_rsa_prepare_popanal_wrapper, popanal_preprocess_scalar_normalization\n",
    "\n",
    "subtract_mean_each_level_of_var = None\n",
    "plot_example_chan = None\n",
    "\n",
    "list_pa =[]\n",
    "list_panorm = []\n",
    "for pa in DFallpa[\"pa\"].tolist():\n",
    "    print(pa.X.shape)\n",
    "    pa, res_check_tasksets, res_check_effectvars = preprocess_rsa_prepare_popanal_wrapper(pa, **q_params)\n",
    "    print(pa.X.shape)\n",
    "\n",
    "    panorm, _, _, _, _, _ = popanal_preprocess_scalar_normalization(pa, q_params[\"effect_vars\"],\n",
    "                                                                                  subtract_mean_each_level_of_var)\n",
    "    \n",
    "    list_pa.append(pa)\n",
    "    list_panorm.append(panorm)\n",
    "    \n",
    "DFallpa[\"pa\"] = list_pa\n",
    "DFallpa[\"pa_norm\"] = list_panorm\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24b237f105e939e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save it\n",
    "import pickle\n",
    "path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa.pkl\"\n",
    "with open(path, \"wb\") as f:\n",
    "    pickle.dump(DFallpa, f)\n",
    "print(\"Saved to:\", path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7f94451b0831398"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load a dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f471c575413735b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To load and plot a dataset of neural activity across population, in a PopAnal class object.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "401a9851a443292c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:04:56.862833255Z",
     "start_time": "2024-02-16T17:04:56.838082067Z"
    }
   },
   "id": "6d72addf5c1494c2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "# this is the path to the dataset\n",
    "# path = '/gorilla1/analyses/recordings/main/RSA/Diego-230615/agg_True-subtr_None-dist_euclidian_unbiased/SP_shape_loc/DFallpa.pkl'\n",
    "path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa.pkl\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:04:57.257666703Z",
     "start_time": "2024-02-16T17:04:57.181928486Z"
    }
   },
   "id": "320be7d5ecbddf5f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DFallpa = pd.read_pickle(path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:04:57.743360529Z",
     "start_time": "2024-02-16T17:04:57.661902988Z"
    }
   },
   "id": "335e4da034da5b2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EXAMPLE CODE for preprocessing of data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c611342e89ddcfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get a PA, just for example\n",
    "pa = DFallpa[\"pa\"].values[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1efac77afface65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. First slice to time winodw, then take mean over time, i.e. a single time average\n",
    "twind = (0.1, 0.5)\n",
    "pa_sliced = pa.slice_by_dim_values_wrapper(\"times\", twind)\n",
    "pa_mean = pa_sliced.agg_wrapper(\"times\")\n",
    "\n",
    "print(\"Compare and see that times are binned\")\n",
    "print(\"-- original:\", pa.Times, \"... data shape: \", pa.X.shape)\n",
    "print(\"-- sliced:\", pa_sliced.Times, \"... data shape: \", pa_sliced.X.shape)\n",
    "print(\"-- mean:\", pa_mean.Times, \"... data shape: \", pa_mean.X.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e9cf7dd29b888af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. binning time windows\n",
    "binsize = 0.1\n",
    "binslide = 0.02\n",
    "pa_binned = pa.agg_by_time_windows_binned(binsize, binslide)\n",
    "    \n",
    "print(\"Compare and see that times are binned\")\n",
    "print(\"-- original:\", pa.Times, \"... data shape: \", pa.X.shape)\n",
    "print(\"-- sliced:\", pa_binned.Times, \"... data shape: \", pa_binned.X.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0878cda38dbc99b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Code example for benchmarking: decoding shapes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93edebd6e38ce91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This step takes in a representation of neural data and outputs a scalar score for how well you can decode \"shape\" from that data\n",
    "\n",
    "Here, this example is using the raw data (dimensionality = number of channels). The goal is to use methods to reduce the dimensionality of this data, each time running through this decoding benchmark, to compare the different methods"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "488ff1ca66a8098f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### First, pull out a specific PA. (just an example)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32c025e2bfc54ebe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE: tjhis is just for demonstration. Eventually you will want to loop thru all PA, scoring them all"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bb74aab4a961bd2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def extract_single_pa(DFallpa, bregion, twind):\n",
    "    which_level = \"trial\"\n",
    "    event = \"03_samp\"\n",
    "\n",
    "    a = DFallpa[\"which_level\"]==which_level\n",
    "    b = DFallpa[\"event\"]==event\n",
    "    c = DFallpa[\"bregion\"]==bregion\n",
    "    d = DFallpa[\"twind\"]==twind\n",
    "    \n",
    "    tmp = DFallpa[a & b & c & d]\n",
    "    assert len(tmp)==1\n",
    "    pa = tmp[\"pa\"].values[0]\n",
    "    \n",
    "    return pa\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:05:20.213719519Z",
     "start_time": "2024-02-16T17:05:20.137603368Z"
    }
   },
   "id": "10bc2b4059ed05b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### PARAMS\n",
    "bregion = \"PMv_m\"\n",
    "twind = (0.3, 0.5)\n",
    "\n",
    "### RUN\n",
    "pa = extract_single_pa(DFallpa, bregion, twind)\n",
    "\n",
    "nchans = pa.X.shape[0]\n",
    "ntrials = pa.X.shape[1]\n",
    "ntimes = pa.X.shape[2]\n",
    "\n",
    "print(\"Shape of this dataset (chans, trials, times):\", nchans, ntrials, ntimes)\n",
    "print(\"Data is stored in pa.X: \", pa.X.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "133efbcda306a086"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Finally, extract the data that goes into the decoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e0f1f1c709a0350"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract activity wthin a specific time bin. Eventualy, you would want to test all time bins."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a940c9919dde1ab9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tbin = 0\n",
    "X = pa.X[:, :, tbin].T # (ntrials, nchans)\n",
    "print(X.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f47393c036460dde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The variable you are trying to decode/predict is the shape on each trial."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d45248c173e29412"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "var = \"seqc_0_shape\"\n",
    "shapes = pa.Xlabels[\"trials\"][var].tolist()\n",
    "\n",
    "print(shapes[:5])\n",
    "print(len(shapes))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d410d731dc1c4a76"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Train and test decoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d41098effe97315a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is using a helper function I wrote (_model_fit) but you should go into the code to know how it works"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f841de3e24cf66a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.population.classify import _model_fit\n",
    "\n",
    "model_params_optimal = {\"C\":0.01} # optimized regularization params\n",
    "pipe, score = _model_fit(X, shapes, model_params=model_params_optimal, do_center=True, do_std=False)\n",
    "\n",
    "print(\"Model score (prediction accuracy on held-out test data):\", score)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0f130fe013e7376"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Expected score if guessing = \", 1/len(set(shapes)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfbccd7ffd9efbc1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PAnorm.plotNeurHeat(0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "546b8760158c0839"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pa.plotNeurHeat(0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1c442be99e39285"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LT added 2/15/24"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "859a87e32641a98e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Make sure to normalize PA before running any modeling on it:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "583a1e729ac08b30"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pa_norm'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'pa_norm'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m     list_panorm\u001B[38;5;241m.\u001B[39mappend(PAnorm)\n\u001B[1;32m      6\u001B[0m DFallpa[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpa\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m list_panorm\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m DFallpa[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpa_norm\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/core/generic.py:4048\u001B[0m, in \u001B[0;36mNDFrame.__delitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4043\u001B[0m             deleted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   4044\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m deleted:\n\u001B[1;32m   4045\u001B[0m     \u001B[38;5;66;03m# If the above loop ran and didn't delete anything because\u001B[39;00m\n\u001B[1;32m   4046\u001B[0m     \u001B[38;5;66;03m# there was no match, this call should raise the appropriate\u001B[39;00m\n\u001B[1;32m   4047\u001B[0m     \u001B[38;5;66;03m# exception:\u001B[39;00m\n\u001B[0;32m-> 4048\u001B[0m     loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maxes\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4049\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39midelete(loc)\n\u001B[1;32m   4051\u001B[0m \u001B[38;5;66;03m# delete from the caches\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3623\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3624\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3625\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3626\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3627\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'pa_norm'"
     ]
    }
   ],
   "source": [
    "list_panorm = []\n",
    "for pa in DFallpa[\"pa\"].tolist():\n",
    "    from neuralmonkey.analyses.state_space_good import popanal_preprocess_scalar_normalization\n",
    "    PAnorm, PAscal, PAscalagg, fig, axes, groupdict = popanal_preprocess_scalar_normalization(pa, None, DO_AGG_TRIALS=False)\n",
    "    list_panorm.append(PAnorm)\n",
    "DFallpa[\"pa\"] = list_panorm\n",
    "del DFallpa[\"pa_norm\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:07:32.527624109Z",
     "start_time": "2024-02-16T17:07:31.305348143Z"
    }
   },
   "id": "854db14b65f6c377"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Code to plot neural trajectories in lower dimensions, colored and split by variables of interest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee2fcd8653de5fba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.state_space_good import trajgood_construct_df_from_raw, trajgood_plot_colorby_splotby\n",
    "\n",
    "# Plot an example brain region's data.\n",
    "bregion = \"PMv\"\n",
    "twind = (-0.4, 0.6)\n",
    "pa = extract_single_pa(DFallpa, bregion, twind)\n",
    "\n",
    "# INPUT PARAMS\n",
    "var_color_by = \"seqc_0_shape\"\n",
    "var_subplots = \"seqc_0_loc\"\n",
    "\n",
    "# Runs\n",
    "\n",
    "# 1) Construct dataframe\n",
    "# df = pa.dataextract_split_by_label_grp_for_statespace(grpvars)\n",
    "grpvars = [var_color_by, var_subplots]\n",
    "X = pa.X # (chans, trials, times)\n",
    "labels = pa.Xlabels[\"trials\"].loc[:, grpvars] \n",
    "labelvars = grpvars\n",
    "df = trajgood_construct_df_from_raw(X, pa.Times, labels, labelvars)\n",
    "\n",
    "# 2) Plot\n",
    "dims = (2,3) # pairs of dimensions to plot\n",
    "times_to_mark = [0.] # you can mark specific times on the plot. here marks the 0. sec mark.\n",
    "times_to_mark_markers = [\"d\"] # mark with a diamond (\"d\")\n",
    "time_bin_size = 0.05 # to make plot easier to visaulize, you can bin in time.\n",
    "trajgood_plot_colorby_splotby(df, var_color_by, var_subplots, dims, \"traj\", mean_over_trials=True,\n",
    "                              times_to_mark = times_to_mark, times_to_mark_markers = times_to_mark_markers,\n",
    "                              time_bin_size=time_bin_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.527494868Z"
    }
   },
   "id": "96ec6f937ed0a2e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Same, but coloring by location\n",
    "\n",
    "var_color_by = \"seqc_0_loc\"\n",
    "var_subplots = \"seqc_0_shape\"\n",
    "\n",
    "# 1) Construct dataframe\n",
    "# df = pa.dataextract_split_by_label_grp_for_statespace(grpvars)\n",
    "grpvars = [var_color_by, var_subplots]\n",
    "X = pa.X # (chans, trials, times)\n",
    "labels = pa.Xlabels[\"trials\"].loc[:, grpvars] \n",
    "labelvars = grpvars\n",
    "df = trajgood_construct_df_from_raw(X, pa.Times, labels, labelvars)\n",
    "\n",
    "# 2) Plot\n",
    "dims = (0,1) # pairs of dimensions to plot\n",
    "times_to_mark = [0.] # you can mark specific times on the plot. here marks the 0. sec mark.\n",
    "times_to_mark_markers = [\"d\"] # mark with a diamond (\"d\")\n",
    "time_bin_size = 0.1 # to make plot easier to visaulize, you can bin in time.\n",
    "trajgood_plot_colorby_splotby(df, var_color_by, var_subplots, dims, \"traj\", mean_over_trials=True,\n",
    "                              times_to_mark = times_to_mark, times_to_mark_markers = times_to_mark_markers,\n",
    "                              time_bin_size=time_bin_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:07:32.530850042Z",
     "start_time": "2024-02-16T17:07:32.529134960Z"
    }
   },
   "id": "94ca5a794289beed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Plot single trials (this plots one example trial per condition)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2741b51ea37b7d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# INPUT PARAMS\n",
    "var_color_by = \"seqc_0_shape\"\n",
    "var_subplots = \"seqc_0_loc\"\n",
    "\n",
    "# Runs\n",
    "\n",
    "# 1) Construct dataframe\n",
    "# df = pa.dataextract_split_by_label_grp_for_statespace(grpvars)\n",
    "grpvars = [var_color_by, var_subplots]\n",
    "X = pa.X # (chans, trials, times)\n",
    "labels = pa.Xlabels[\"trials\"].loc[:, grpvars] \n",
    "labelvars = grpvars\n",
    "df = trajgood_construct_df_from_raw(X, pa.Times, labels, labelvars)\n",
    "\n",
    "# 2) Plot\n",
    "dims = (0,1) # pairs of dimensions to plot\n",
    "times_to_mark = None # you can mark specific times on the plot. here marks the 0. sec mark.\n",
    "times_to_mark_markers = None # mark with a diamond (\"d\")\n",
    "time_bin_size = 0.05 # to make plot easier to visaulize, you can bin in time.\n",
    "\n",
    "# plot a few times, each picking a random trial\n",
    "niter = 3\n",
    "mean_over_trials = False\n",
    "ntrials = 1\n",
    "for _ in range(niter):\n",
    "    trajgood_plot_colorby_splotby(df, var_color_by, var_subplots, dims, \"traj\", mean_over_trials=mean_over_trials,\n",
    "                                  times_to_mark = times_to_mark, times_to_mark_markers = times_to_mark_markers,\n",
    "                                  time_bin_size=time_bin_size, ntrials = ntrials)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.530826064Z"
    }
   },
   "id": "f2b1ddfc91a21a4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Score and plot decoding accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36745f908f0c7fd6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Try different methods for dim reduction of X. In all cases, if X is shape (nchans, ntrials, ntimes), dim reduction should return Xreduced of shape (ndim, ntrials, ntimes) where ndim < nchans\n",
    "2. For the benchmark decoder, you want to score looping through each bregion, twind, and tbin. i.e, see below"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b474a9d2c5bdd543"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_dim_reduction_methods = [\"pca\", \"CEBRA\"] # FILL THIS IN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:07:32.533634278Z",
     "start_time": "2024-02-16T17:07:32.532276488Z"
    }
   },
   "id": "f100be2757cd7241"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HACK = True # quickly run to see what it's like, without any dim reduction methods\n",
    "\n",
    "if HACK:\n",
    "    list_dim_reduction_methods = [\"IGNORE\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T17:07:32.552383087Z",
     "start_time": "2024-02-16T17:07:32.533963245Z"
    }
   },
   "id": "55368324b366ebf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_decode_score(x, labels, max_nsplits=5):\n",
    "    \"\"\"\n",
    "    Score decoding accuracy\n",
    "    \"\"\"\n",
    "    from neuralmonkey.analyses.decode_good import decode_categorical_wrapper\n",
    "    from neuralmonkey.population.classify import _model_fit\n",
    "    import numpy as np\n",
    "    \n",
    "    assert x.shape[0]==len(labels)\n",
    "    assert len(x.shape)==2\n",
    "    \n",
    "    res = decode_categorical_wrapper(Xreduced_this_time_bin, labels, 3, max_nsplits=max_nsplits)\n",
    "    # get mean score across splits\n",
    "    return np.mean([r[\"score_xval\"] for r in res])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.535485965Z"
    }
   },
   "id": "b20567b062de7ebe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.utils.frmat import bin_frmat_in_time\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.537092345Z"
    }
   },
   "id": "e9af95e288e0b3cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_br = DFallpa[\"bregion\"].unique().tolist()\n",
    "list_tw = DFallpa[\"twind\"].unique().tolist()\n",
    "\n",
    "res = []\n",
    "\n",
    "list_vars_decode = [\"seqc_0_shape\", \"seqc_0_loc\"]\n",
    "\n",
    "for br in list_br:\n",
    "    for tw in list_tw:\n",
    "        # 1. Extract the specific pa for this (br, tw)\n",
    "        pa = extract_single_pa(DFallpa, br, tw)\n",
    "        \n",
    "        # 2. Extract X from pa\n",
    "        X = pa.X # (nchans, ntrials, ntimes)\n",
    "        times = pa.Times\n",
    "        \n",
    "        # Optionally, bin X in time, to have fewer time bins to decode\n",
    "        X, times = bin_frmat_in_time(X, times, time_bin_size=0.1, slide=0.02)\n",
    "\n",
    "        list_tbin = range(X.shape[2])\n",
    "        for method in list_dim_reduction_methods:\n",
    "            print(br, tw, method)\n",
    "            # 2. Apply this method to pa\n",
    "            if HACK:\n",
    "                Xreduced = X\n",
    "            else:\n",
    "                Xreduced = dim_reduce(X, method) # FILL THIS IN\n",
    "            \n",
    "            for tbin in list_tbin:\n",
    "                # 3a. Extract data for this time bin\n",
    "                Xreduced_this_time_bin = Xreduced[:, :, tbin].T # (ntrials, nchans)                    \n",
    "    \n",
    "                # 3. Run decoder\n",
    "                for var_decode in list_vars_decode:\n",
    "                    # labels = pa.Xlabels[\"trials\"][var_decode].tolist()\n",
    "                    labels = pd.factorize(pa.Xlabels[\"trials\"][var_decode])[0]\n",
    "                    score = compute_decode_score(Xreduced_this_time_bin, labels) # FILL THIS IN\n",
    "                    \n",
    "                    # 3. Collect data\n",
    "                    res.append({\n",
    "                        \"method\":method,\n",
    "                        \"bregion\":br,\n",
    "                        \"twind\":tw,\n",
    "                        \"tbin\":tbin,\n",
    "                        \"time\":times[tbin],\n",
    "                        \"var_decode\":var_decode,\n",
    "                        \"score\":score\n",
    "                    })\n",
    "\n",
    "dfres = pd.DataFrame(res)\n",
    "     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.538518973Z"
    }
   },
   "id": "843192c847a11dc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfres[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.539452562Z"
    }
   },
   "id": "3369eb81dbf45778"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "##### Plot the results, comparing score across methods!!\n",
    "import seaborn as sns\n",
    "fig = sns.relplot(data=dfres, x=\"time\", y=\"score\", hue=\"bregion\", col=\"var_decode\", row=\"method\", kind=\"line\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.540317788Z"
    }
   },
   "id": "b85e7da96e759fd0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4) Cross-condition decoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98ec3d6e76bf4ebb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import decode_train, decode_categorical_cross_condition_wrapper\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.541325287Z"
    }
   },
   "id": "e78860e2ab19f58f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "subtract_mean_vars_conj = True # WHether to normalize by sutbracting mean within each level of othervar...\n",
    "list_var_decode = [\"seqc_0_shape\", \"seqc_0_loc\"][::-1]\n",
    "list_vars_conj = [\n",
    "    [\"seqc_0_loc\"],\n",
    "    [\"seqc_0_shape\"]][::-1]\n",
    "\n",
    "# RUns\n",
    "list_br = DFallpa[\"bregion\"].unique().tolist()\n",
    "list_tw = DFallpa[\"twind\"].unique().tolist()\n",
    "    \n",
    "res = []\n",
    "for br in list_br:\n",
    "    for tw in list_tw:\n",
    "        for var_decode, vars_conj_condition in zip(list_var_decode, list_vars_conj):\n",
    "            \n",
    "            # 1. Extract the specific pa for this (br, tw)\n",
    "            pa = extract_single_pa(DFallpa, br, tw).copy()\n",
    "            \n",
    "            if subtract_mean_vars_conj:\n",
    "                pa = pa.norm_by_label_subtract_mean(\"trials\", vars_conj_condition)\n",
    "    \n",
    "            # 2. Extract X from pa\n",
    "            X = pa.X # (nchans, ntrials, ntimes)\n",
    "            times = pa.Times\n",
    "            \n",
    "            # Optionally, bin X in time, to have fewer time bins to decode\n",
    "            X, times = bin_frmat_in_time(X, times, time_bin_size=0.1, slide=0.02)\n",
    "    \n",
    "            list_tbin = range(X.shape[2])\n",
    "            for method in list_dim_reduction_methods:\n",
    "                print(br, tw, method)\n",
    "                # 2. Apply this method to pa\n",
    "                if HACK:\n",
    "                    Xreduced = X\n",
    "                else:\n",
    "                    Xreduced = dim_reduce(X, method) # FILL THIS IN\n",
    "                \n",
    "                for tbin in list_tbin:\n",
    "                    \n",
    "                    Xscal = Xreduced[:, :, tbin].T # (ntrials, nchans)\n",
    "                    dflab = pa.Xlabels[\"trials\"]\n",
    "                    \n",
    "                    \n",
    "                    dfresthis, dfres_agg = decode_categorical_cross_condition_wrapper(Xscal, dflab, var_decode, vars_conj_condition, do_std=False)\n",
    "                    assert len(dfres_agg)==1\n",
    "                    \n",
    "                    # 3. Collect data\n",
    "                    res.append({\n",
    "                        \"method\":method,\n",
    "                        \"bregion\":br,\n",
    "                        \"twind\":tw,\n",
    "                        \"tbin\":tbin,\n",
    "                        \"time\":times[tbin],\n",
    "                        \"var_decode\":var_decode,\n",
    "                        \"vars_conj_condition\":tuple(vars_conj_condition),\n",
    "                        \"score\":dfres_agg[\"score\"].values[0],\n",
    "                        \"score_adjusted\":dfres_agg[\"score_adjusted\"].values[0],\n",
    "                    })\n",
    "\n",
    "DFRES = pd.DataFrame(res)\n",
    "     \n",
    "     "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.542324700Z"
    }
   },
   "id": "ea62377c46cf112b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFRES[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.543201585Z"
    }
   },
   "id": "85a8f0096d6d8954"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### Plot the results, comparing score across methods!!\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "fig = sns.relplot(data=DFRES, x=\"time\", y=\"score\", hue=\"bregion\", col=\"var_decode\", row=\"method\", kind=\"line\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T17:07:32.544213381Z"
    }
   },
   "id": "7b224d0e6754d9fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
