{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7125966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlot heatmaps of SP shape encoding, split by location.\\nFor paper figure\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plot heatmaps of SP shape encoding, split by location.\n",
    "For paper figure\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b248d33aff307a2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d20c8",
   "metadata": {},
   "source": [
    "# Load DFallPa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14525eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Method: loading functrion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5608555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_concatbregion_preprocess_wrapper,dfpa_match_chans_across_pa_each_bregion\n",
    "from neuralmonkey.classes.population_mult import extract_single_pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010699ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 - load a single DFallPA\n",
    "\n",
    "\n",
    "# animal = \"Diego\"\n",
    "# # date = 230615\n",
    "# date = 240510\n",
    "# combine = True\n",
    "# question = \"SP_BASE_trial\"\n",
    "# version = \"trial\"\n",
    "\n",
    "animal = \"Diego\"\n",
    "date = 230615\n",
    "# date = 230618\n",
    "combine = True\n",
    "question = \"SP_BASE_trial\"\n",
    "version = \"trial\"\n",
    "\n",
    "# animal = \"Diego\"\n",
    "# date = 231218\n",
    "# combine = True\n",
    "# question = \"CHAR_BASE_stroke\"\n",
    "# version = \"stroke\"\n",
    "\n",
    "\n",
    "# animal = \"Pancho\"\n",
    "# date = 220606\n",
    "# combine = True\n",
    "# question = \"SP_BASE_trial\"\n",
    "# version = \"trial\"\n",
    "\n",
    "DFallpa = load_handsaved_wrapper(animal, date, version=version, combine_areas=combine, question=question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2016033",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpa_concatbregion_preprocess_wrapper(DFallpa, animal, date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = DFallpa[\"pa\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d84ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import preprocess_pa\n",
    "\n",
    "var_other = \"gridsize\"\n",
    "var_context_same = \"seqc_0_loc\"\n",
    "\n",
    "remove_drift=True\n",
    "subspace_projection = \"shape\"\n",
    "subspace_projection_fitting_twind = (0.05, 0.9)\n",
    "twind_analy = (-0.5, 1.0)\n",
    "tbin_dur = 0.2\n",
    "tbin_slide = 0.05\n",
    "savedir = \"/tmp\"\n",
    "PAthis = preprocess_pa(PA, animal, date, var_other, savedir, remove_drift, subspace_projection, subspace_projection_fitting_twind, \n",
    "                twind_analy, tbin_dur, tbin_slide, var_context_same=var_context_same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12240623",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_grp_vars = [\"seqc_0_shape\", \"seqc_0_loc\", \"gridsize\"]\n",
    "fraction_constrained_set=0.75\n",
    "n_constrained=2\n",
    "list_labels_need_n=None\n",
    "min_frac_datapts_unconstrained=None\n",
    "min_n_datapts_unconstrained=1\n",
    "plot_train_test_counts=True\n",
    "plot_indices=True\n",
    "nsplits=2\n",
    "folds, fig_unc, fig_con = PAthis.split_stratified_constrained_grp_var(nsplits, label_grp_vars, fraction_constrained_set, n_constrained, \n",
    "                                             list_labels_need_n, min_frac_datapts_unconstrained,  \n",
    "                                             min_n_datapts_unconstrained, plot_train_test_counts, plot_indices);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca70b9",
   "metadata": {},
   "source": [
    "##### Quick, testing heatmap code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a995b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.neuralplots.population import heatmapwrapper_many_useful_plots\n",
    "import os\n",
    "savedir = \"/tmp/TESTTEST\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "diverge = True\n",
    "heatmapwrapper_many_useful_plots(PAthis, savedir, var_is_blocks=False, mean_over_trials=True, flip_rowcol=True, plot_fancy=True,\n",
    "    diverge=diverge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a303c9",
   "metadata": {},
   "source": [
    "##### Compute euclidian (for shape, controlling for size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune to scalar window\n",
    "twind_scal = (0.05, 1.0)\n",
    "pa = PAthis.slice_by_dim_values_wrapper(\"times\", twind_scal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf773c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflab = pa.Xlabels[\"trials\"]\n",
    "from pythonlib.tools.pandastools import grouping_plot_n_samples_conjunction_heatmap\n",
    "grouping_plot_n_samples_conjunction_heatmap(dflab, \"seqc_0_shape\", \"seqc_0_loc\", [\"gridsize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ef8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.euclidian_distance import timevarying_compute_fast_to_scalar\n",
    "var_effect = \"seqc_0_shape\"\n",
    "\n",
    "# var_other = \"seqc_0_loc\"\n",
    "# var_context_same = \"gridsize\"\n",
    "\n",
    "var_other = \"gridsize\"\n",
    "var_context_same = \"seqc_0_loc\"\n",
    "\n",
    "label_vars =  (var_effect, var_other)\n",
    "dfdist, Cldist = timevarying_compute_fast_to_scalar(pa, label_vars, \"/tmp\", var_context_same=var_context_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bac8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18e10c49",
   "metadata": {},
   "source": [
    "### Plot RSA heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.euclidian_distance import timevarying_compute_fast_to_scalar\n",
    "label_vars =  (\"seqc_0_shape\", \"seqc_0_loc\")\n",
    "timevarying_compute_fast_to_scalar(pa, label_vars, \"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78cb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dims = [(0,1), (1,2), (2,3)]\n",
    "PAthis.plot_state_space_good_wrapper(\"/tmp\", [\"seqc_0_shape\"], [[\"seqc_0_loc\"]], PLOT_CLEAN_VERSION=True,\n",
    "                                     list_dims=list_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cc055",
   "metadata": {},
   "source": [
    "# Plot heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62872931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SAVEDIR = \"/tmp/TEST3\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fea082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOD PLOTS\n",
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import heatmaps_plot_wrapper\n",
    "heatmaps_plot_wrapper(DFallpa, animal, date, SAVEDIR, \"seqc_0_loc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a728ff",
   "metadata": {},
   "source": [
    "##### Devo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338219d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each PC, convert to zscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af339b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this a grid of (dims, locs)\n",
    "vars_subplots = [\"seqc_0_loc\"]\n",
    "var = \"seqc_0_shape\"\n",
    "dims = [0,1,2]\n",
    "panorm.plotwrappergrid_smoothed_fr_splot_neuron(var, vars_subplots, dims);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edceb736",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_col = \"seqc_0_shape\"\n",
    "var_row = \"seqc_0_loc\"\n",
    "chans = [1]\n",
    "\n",
    "\n",
    "panorm.plotwrappergrid_smoothed_fr_splot_var(var_row, var_col, chans, plot_indiv=True)\n",
    "# pathis.plotwrappergrid_smoothed_fr_splot_var(var_row, var_col, chans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58273fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE --- this is using old code, which is now replaced by the new PA code above.\n",
    "from neuralmonkey.analyses.state_space_good import trajgood_construct_df_from_raw, trajgood_plot_colorby_splotby_timeseries\n",
    "PA_traj = panorm\n",
    "var = \"seqc_0_shape\"\n",
    "var_others = \"seqc_0_loc\"\n",
    "_vars = [\"seqc_0_shape\", \"seqc_0_loc\"]\n",
    "list_dim_timecourse = [1,2,3]\n",
    "plot_trials_n = 2\n",
    "df = trajgood_construct_df_from_raw(PA_traj.X, PA_traj.Times, PA_traj.Xlabels[\"trials\"], _vars)\n",
    "\n",
    "for dim in list_dim_timecourse:\n",
    "\n",
    "    # - (i) combined, plotting means.\n",
    "    fig, _ = trajgood_plot_colorby_splotby_timeseries(df, var, var_others, dim=dim,\n",
    "                                                    plot_trials_n=plot_trials_n, \n",
    "                                                    SUBPLOT_OPTION=\"split_levs\")\n",
    "    # path = f\"{sdir}/TIMECOURSEsplit-color={var}-sub={var_others}-dim={dim}-suff={i_var}.pdf\"\n",
    "    # print(\"Saving ... \", path)\n",
    "    # savefig(fig, path)\n",
    "\n",
    "    # - (2) split\n",
    "    fig, _ = trajgood_plot_colorby_splotby_timeseries(df, var, var_others, dim=dim, plot_trials_n=plot_trials_n,\n",
    "                                            plot_trials=False, SUBPLOT_OPTION=\"combine_levs\")\n",
    "    # path = f\"{sdir}/TIMECOURSEcomb-color={var}-sub={var_others}-dim={dim}-suff={i_var}.pdf\"\n",
    "    # print(\"Saving ... \", path)\n",
    "    # savefig(fig, path)\n",
    "    \n",
    "    # plt.close(\"all\")\n",
    "\n",
    "    assert False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8a0cc",
   "metadata": {},
   "source": [
    "### Running euclidian plots (and extraction/computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = DFallpa[\"pa\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b461494",
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = 0.2\n",
    "slide = 0.01\n",
    "PA = PA.agg_by_time_windows_binned(dur, slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf59125",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_effect = \"seqc_0_shape\"\n",
    "var_other = \"seqc_0_loc\"\n",
    "vars_group = [var_effect, var_other]\n",
    "version = \"traj\"\n",
    "DFDIST = PA.dataextractwrap_distance_between_groups(vars_group, version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b980029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "for var in [var_effect, var_other]:\n",
    "    DFDIST[f\"{var}_same\"] = DFDIST[f\"{var}_1\"] == DFDIST[f\"{var}_2\"]\n",
    "    DFDIST = append_col_with_grp_index(DFDIST, [f\"{var}_1\", f\"{var}_2\"], f\"{var}_12\")\n",
    "DFDIST = append_col_with_grp_index(DFDIST, [f\"{var_other}_same\", f\"{var_effect}_same\"], f\"same-{var_other}|{var_effect}\")\n",
    "# DFDIST = append_col_with_grp_index(DFDIST, [f\"{var_effect}_same\", f\"{var_other}_same\"], f\"same-{var_effect}|{var_other}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "for y in [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\"]:\n",
    "    # sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"same_shape|task_kind_12\", kind=\"line\", errorbar=(\"ci\", 68))\n",
    "    fig = sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"same-seqc_0_loc|seqc_0_shape\", kind=\"line\", errorbar=(\"ci\", 68))\n",
    "    # savefig(fig, f\"{SAVEDIR}/relplot-{y}-1.pdf\")\n",
    "\n",
    "    if False: # slow, and I don't use\n",
    "        fig = sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"same_shape|task_kind_12\", kind=\"line\", errorbar=(\"ci\", 68))\n",
    "        savefig(fig, f\"{SAVEDIR}/relplot-{y}-2.pdf\")\n",
    "\n",
    "        fig = sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"task_kind_12\", kind=\"line\", col=\"same-task|shape\", errorbar=(\"ci\", 68))\n",
    "        savefig(fig, f\"{SAVEDIR}/relplot-{y}-3.pdf\")\n",
    "\n",
    "        fig = sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=f\"{shape_var}_12\", kind=\"line\", col=\"same-task|shape\", \n",
    "                    errorbar=(\"ci\", 68), legend=False, alpha=0.5)\n",
    "        savefig(fig, f\"{SAVEDIR}/relplot-{y}-4.pdf\")\n",
    "\n",
    "    # plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "for y in [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\"]:\n",
    "    # sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"same_shape|task_kind_12\", kind=\"line\", errorbar=(\"ci\", 68))\n",
    "    fig = sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"same-seqc_0_loc|seqc_0_shape\", kind=\"line\", errorbar=(\"ci\", 68))\n",
    "    # savefig(fig, f\"{SAVEDIR}/relplot-{y}-1.pdf\")\n",
    "\n",
    "    if False: # slow, and I don't use\n",
    "        fig = sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"same_shape|task_kind_12\", kind=\"line\", errorbar=(\"ci\", 68))\n",
    "        savefig(fig, f\"{SAVEDIR}/relplot-{y}-2.pdf\")\n",
    "\n",
    "        fig = sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"task_kind_12\", kind=\"line\", col=\"same-task|shape\", errorbar=(\"ci\", 68))\n",
    "        savefig(fig, f\"{SAVEDIR}/relplot-{y}-3.pdf\")\n",
    "\n",
    "        fig = sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=f\"{shape_var}_12\", kind=\"line\", col=\"same-task|shape\", \n",
    "                    errorbar=(\"ci\", 68), legend=False, alpha=0.5)\n",
    "        savefig(fig, f\"{SAVEDIR}/relplot-{y}-4.pdf\")\n",
    "\n",
    "    # plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar values\n",
    "from neuralmonkey.analyses.euclidian_distance import compute_scalar_from_time_varying, timevarying_compute\n",
    "compute_scalar_from_time_varying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDIST = timevarying_compute(PA, vars_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\"]:\n",
    "    # sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"same_shape|task_kind_12\", kind=\"line\", errorbar=(\"ci\", 68))\n",
    "    fig = sns.relplot(data=DFDIST, x=\"time_bin\", y=y, hue=\"same-seqc_0_shape|seqc_0_loc\", kind=\"line\", errorbar=(\"ci\", 68))\n",
    "    # savefig(fig, f\"{SAVEDIR}/relplot-{y}-1.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67336941",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed4a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscal =timevarying_convert_to_scalar(DFDIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import plot_45scatter_means_flexible_grouping\n",
    "\n",
    "plot_45scatter_means_flexible_grouping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidian_time_resolved, preprocess_pa, _preprocess_pa_dim_reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c62c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAVEDIR_ANALYSIS = \"/tmp/EUCLD\"\n",
    "euclidian_time_resolved(DFallpa, animal, date, var_other, SAVEDIR_ANALYSIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f057d",
   "metadata": {},
   "source": [
    "# [#4] Euclidian, doing stats (and faster way to compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eaf2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR_ANALYSIS = \"/tmp/EUCL2\"\n",
    "os.makedirs(SAVEDIR_ANALYSIS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e73e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidian_time_resolved_fast_shuffled\n",
    "var_other = \"gridsize\"\n",
    "var_context_same = \"seqc_0_loc\"\n",
    "euclidian_time_resolved_fast_shuffled(DFallpa, animal, date, var_other, SAVEDIR_ANALYSIS, var_context_same=var_context_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08ba1f",
   "metadata": {},
   "source": [
    "##### [Devo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f906db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a8c53d6",
   "metadata": {},
   "source": [
    "# [#4.3] [Load for shuffle, each run's cached data --> STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccdfb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from pythonlib.tools.plottools import savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidian_time_resolved_fast_shuffled_mult_reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = \"Diego\"\n",
    "date = 230615\n",
    "var_other = \"seqc_0_loc\"\n",
    "\n",
    "list_dfdist, list_dfdist_shuff, SAVEDIR_PLOTS = euclidian_time_resolved_fast_shuffled_mult_reload(animal, date, var_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb367e6",
   "metadata": {},
   "source": [
    "### [Stats method #1] -- Trial-by-trial shuffles from euclidian_time_resolved_fast_shuffled()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4445cfa",
   "metadata": {},
   "source": [
    "This is from the really slow shuffling of all trials, and then using that distribution (each shuff gives one value) to compute empirical p value.\n",
    "\n",
    "This is the only one of the methods that uses the shuffled data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.neuralplots.brainschematic import datamod_reorder_by_bregion\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "from pythonlib.tools.pandastools import aggregGeneral\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Run separately for each bregion\n",
    "# bregion = \"PMv\"\n",
    "list_bregion = sorted(set([dfdist[\"bregion\"].unique()[0] for dfdist in list_dfdist]))\n",
    "for bregion in list_bregion:\n",
    "    print(bregion)\n",
    "\n",
    "    savedir = f\"{SAVEDIR_PLOTS}/bregion={bregion}\"\n",
    "    os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "    list_dfdist_this = [dfdist for dfdist in list_dfdist if dfdist[\"bregion\"].unique()[0]==bregion]\n",
    "    list_dfdist_shuff_this = [dfdist for dfdist in list_dfdist_shuff if dfdist[\"bregion\"].unique()[0]==bregion]\n",
    "\n",
    "    # First, generate all df\n",
    "    print(\"concatting...\")\n",
    "    DFDISTS = pd.concat(list_dfdist_this).reset_index(drop=True)\n",
    "    DFDISTS_SHUFF = pd.concat(list_dfdist_shuff_this).reset_index(drop=True)\n",
    "    DFDISTS = datamod_reorder_by_bregion(DFDISTS)\n",
    "    DFDISTS_SHUFF = datamod_reorder_by_bregion(DFDISTS_SHUFF)\n",
    "\n",
    "    print(\"appending...\")\n",
    "    DFDISTS = append_col_with_grp_index(DFDISTS, [\"subspace_projection\", \"subspace_projection_fitting_twind\"], \"subspace|twind\")\n",
    "    DFDISTS_SHUFF = append_col_with_grp_index(DFDISTS_SHUFF, [\"subspace_projection\", \"subspace_projection_fitting_twind\"], \"subspace|twind\")\n",
    "    DFDISTS_SHUFF = append_col_with_grp_index(DFDISTS_SHUFF, [\"dim_redu_fold\", \"shuffle_iter\"], \"drfold|shuffiter\")\n",
    "\n",
    "    DFDISTS = append_col_with_grp_index(DFDISTS, [\"shuffled\", \"shuffle_ver\"], \"shuffled|ver\")\n",
    "    DFDISTS_SHUFF = append_col_with_grp_index(DFDISTS_SHUFF, [\"shuffled\", \"shuffle_ver\"], \"shuffled|ver\")\n",
    "\n",
    "    print(\"agging...\")\n",
    "    # Agg over all dim redu splits\n",
    "    DFDISTS = aggregGeneral(DFDISTS, [\"bregion\", \"which_level\", \"event\", \"subspace|twind\", \"labels_1\", \"labels_2\"], \n",
    "                            [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\", \"DIST_50\", \"DIST_98\"], nonnumercols=\"all\")\n",
    "\n",
    "\n",
    "    # Agg over all conditions (e.g. label pairs)\n",
    "    DFDISTS_AGG = aggregGeneral(DFDISTS, [\"bregion\", \"which_level\", \"event\", \"subspace|twind\", \"same-seqc_0_shape|seqc_0_loc\"],\n",
    "                                [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\", \"DIST_50\", \"DIST_98\"], nonnumercols=\"all\")\n",
    "\n",
    "\n",
    "    # Get distribition over shuffs\n",
    "    # - go straight to agg, this is correct for shuff\n",
    "    DFDISTS_SHUFF_AGG = aggregGeneral(DFDISTS_SHUFF, [\"same-seqc_0_shape|seqc_0_loc\", \"bregion\", \"which_level\", \"event\", \n",
    "                                        \"subspace_projection\", \"subspace_projection_fitting_twind\", \"subspace|twind\", \n",
    "                                        \"shuffle_ver\", \"shuffled\", \"drfold|shuffiter\", \"shuffled|ver\"], \n",
    "                                        [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\", \"DIST_50\", \"DIST_98\"])\n",
    "\n",
    "    # Combine shuff and data into single dataframe\n",
    "    DFDISTS_ALL_AGG = pd.concat([DFDISTS_AGG, DFDISTS_SHUFF_AGG]).reset_index(drop=True)\n",
    "\n",
    "    for event in DFDISTS_ALL_AGG[\"event\"].unique():\n",
    "        dfthis = DFDISTS_ALL_AGG[(DFDISTS_ALL_AGG[\"event\"]==event)]\n",
    "        for y in [\"dist_yue_diff\", \"dist_mean\", \"DIST_50\"]:\n",
    "            fig = sns.catplot(data=dfthis, x=\"bregion\", y =y, col=\"same-seqc_0_shape|seqc_0_loc\", row=\"subspace|twind\", hue=\"shuffled|ver\", alpha=0.2, height=6)\n",
    "            savefig(fig, f\"{savedir}/COMBINED-catplot-event={event}-y={y}.pdf\")\n",
    "    plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e736af4",
   "metadata": {},
   "source": [
    "### (Stats method #2) Use sign-rank without shuffling, consider each \"label condition\" as independnet datapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a03d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17484682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.neuralplots.brainschematic import datamod_reorder_by_bregion\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "from pythonlib.tools.pandastools import aggregGeneral\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da80c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = f\"{SAVEDIR_PLOTS}/stats_using_signrank\"\n",
    "os.makedirs(savedir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735cdc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, generate all df\n",
    "print(\"concatting...\")\n",
    "DFDISTS = pd.concat(list_dfdist).reset_index(drop=True)\n",
    "DFDISTS = datamod_reorder_by_bregion(DFDISTS)\n",
    "\n",
    "print(\"appending...\")\n",
    "DFDISTS = append_col_with_grp_index(DFDISTS, [\"subspace_projection\", \"subspace_projection_fitting_twind\"], \"subspace|twind\")\n",
    "DFDISTS = append_col_with_grp_index(DFDISTS, [\"shuffled\", \"shuffle_ver\"], \"shuffled|ver\")\n",
    "\n",
    "print(\"agging...\")\n",
    "\n",
    "# Agg over all dim redu splits\n",
    "DFDISTS = aggregGeneral(DFDISTS, [\"bregion\", \"which_level\", \"event\", \"subspace|twind\", \"labels_1\", \"labels_2\"], \n",
    "                        [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\", \"DIST_50\", \"DIST_98\"], nonnumercols=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DFDISTS = stringify_values(DFDISTS)\n",
    "\n",
    "## FINAL AGGS\n",
    "# (1) each datapt is a unique label (multiple datapts per 0|1)\n",
    "tmp = DFDISTS.copy()\n",
    "tmp[\"labels_2\"] = DFDISTS[\"labels_1\"]\n",
    "tmp[\"labels_1\"] = DFDISTS[\"labels_2\"]\n",
    "tmp = pd.concat([tmp, DFDISTS]).reset_index(drop=True)\n",
    "if False: # Sanity check that got diagonals\n",
    "    from pythonlib.tools.pandastools import grouping_plot_n_samples_conjunction_heatmap\n",
    "    grouping_plot_n_samples_conjunction_heatmap(tmp, \"labels_1\", \"labels_2\")\n",
    "DFDISTS_DATPT_LABEL1 = aggregGeneral(tmp, [\"bregion\", \"which_level\", \"event\", \"subspace|twind\", \"labels_1\", \"same-seqc_0_shape|seqc_0_loc\"],\n",
    "            [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\", \"DIST_50\", \"DIST_98\"], nonnumercols=\"all\")\n",
    "if False:\n",
    "    # Check output\n",
    "    grouping_plot_n_samples_conjunction_heatmap(DFDISTS_DATPT_LABEL1, \"labels_1\", \"same-seqc_0_shape|seqc_0_loc\")\n",
    "\n",
    "\n",
    "# (2) each datapt is 0|1, 1|0, 1|1, 0|0 (i.e., 4 datapts per bregion/metaparams)\n",
    "# Agg over all conditions (e.g. label pairs)\n",
    "DFDISTS_AGG = aggregGeneral(DFDISTS_DATPT_LABEL1, [\"bregion\", \"which_level\", \"event\", \"subspace|twind\", \"same-seqc_0_shape|seqc_0_loc\"],\n",
    "                            [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\", \"DIST_50\", \"DIST_98\"], nonnumercols=\"all\")\n",
    "if False:\n",
    "    # check output\n",
    "    grouping_plot_n_samples_conjunction_heatmap(DFDISTS_DATPT_LABEL1, \"bregion\", \"same-seqc_0_shape|seqc_0_loc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef35886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBSOLETE -- below is better and does same thing.\n",
    "if False:\n",
    "    from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good, stringify_values\n",
    "\n",
    "    grp_vars = [\"bregion\", \"which_level\", \"event\", \"subspace|twind\", \"shuffled|ver\"]\n",
    "    # datapt_vars = [labels_1\tlabels_2]\n",
    "    datapt_vars = [\"labels_1\"]\n",
    "    # value_var = \"dist_yue_diff\"\n",
    "    value_var = \"dist_mean\"\n",
    "\n",
    "    contrast_var = \"same-seqc_0_shape|seqc_0_loc\"\n",
    "\n",
    "    res = []\n",
    "    for contrast_lev_2 in [\"0|1\", \"1|0\", \"0|0\"]:\n",
    "        contrast_levels = [\"1|1\", contrast_lev_2]\n",
    "\n",
    "        grpdict = grouping_append_and_return_inner_items_good(DFDISTS_DATPT_LABEL1, grp_vars)\n",
    "        \n",
    "        for grp, inds in grpdict.items():\n",
    "            dfthis = DFDISTS_DATPT_LABEL1.iloc[inds]\n",
    "            from pythonlib.tools.statstools import signrank_wilcoxon_from_df\n",
    "\n",
    "            # out, fig = signrank_wilcoxon_from_df(dfthis, datapt_vars, contrast_var, contrast_levels, value_var, True, \"/tmp/test.txt\")\n",
    "            out, fig = signrank_wilcoxon_from_df(dfthis, datapt_vars, contrast_var, contrast_levels, \n",
    "                                                value_var, True, f\"{savedir}/{grp}-{contrast_var}={contrast_lev_2}.txt\",\n",
    "                                                assert_no_na_rows=True)\n",
    "\n",
    "            res.append({\n",
    "                \"p\":out[\"p\"],\n",
    "                contrast_var:contrast_lev_2,\n",
    "            })\n",
    "            for var, val in zip(grp_vars, grp):\n",
    "                res[-1][var] = val\n",
    "\n",
    "            plt.close(\"all\")\n",
    "\n",
    "            savefig(fig, f\"{savedir}/{grp}-{contrast_var}={contrast_lev_2}.pdf\")\n",
    "            \n",
    "    dfstats = pd.DataFrame(res)\n",
    "    import numpy as np\n",
    "    dfstats[\"p_log\"] = np.log10(dfstats[\"p\"])\n",
    "\n",
    "    n_br = len(DFDISTS_DATPT_LABEL1[\"bregion\"].unique())\n",
    "    n_contrast = 2\n",
    "    n_test = n_br * n_contrast\n",
    "    alpha=0.05\n",
    "    alpha_bonf = alpha/n_test\n",
    "\n",
    "    print(\"N tests: \", n_test, \", new alpha=\", alpha_bonf)\n",
    "    # sns.catplot(data=dfstats, x=\"bregion\", y=\"p\", row=\"event\", col=\"subspace|twind\", kind=\"bar\")\n",
    "    # fig = sns.catplot(data=dfstats, x=\"bregion\", y=\"p_log\", row=\"event\", hue=\"same-seqc_0_shape|seqc_0_loc\", col=\"subspace|twind\")\n",
    "    # for ax in fig.axes.flatten():\n",
    "    #     ax.axhline(0)\n",
    "    fig = sns.catplot(data=dfstats, x=\"bregion\", y=\"p_log\", row=\"event\", hue=\"same-seqc_0_shape|seqc_0_loc\", col=\"subspace|twind\", kind=\"bar\")\n",
    "    for ax in fig.axes.flatten():\n",
    "        ax.axhline(np.log10(0.05))\n",
    "        ax.axhline(np.log10(0.005))\n",
    "        ax.axhline(np.log10(alpha_bonf), color=\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22405f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram plots, colored by significance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23921ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0609f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.session import _REGIONS_IN_ORDER_COMBINED\n",
    "order_bregion = _REGIONS_IN_ORDER_COMBINED\n",
    "list_bregion = order_bregion\n",
    "\n",
    "from neuralmonkey.neuralplots.brainschematic import datamod_reorder_by_bregion\n",
    "\n",
    "from pythonlib.tools.statstools import signrank_wilcoxon_from_df\n",
    "\n",
    "\n",
    "grp_vars = [\"which_level\", \"event\", \"subspace|twind\"]\n",
    "# value_var = \"dist_yue_diff\"\n",
    "value_var = \"dist_mean\"\n",
    "\n",
    "# For p-values\n",
    "# datapt_vars = [labels_1\tlabels_2]\n",
    "datapt_vars = [\"labels_1\"]\n",
    "# value_var = \"dist_yue_diff\"\n",
    "contrast_var = \"same-seqc_0_shape|seqc_0_loc\"\n",
    "\n",
    "grpdict = grouping_append_and_return_inner_items_good(DFDISTS_DATPT_LABEL1, grp_vars)\n",
    "\n",
    "res = []\n",
    "for grp, inds in grpdict.items():\n",
    "\n",
    "    DFTHIS = DFDISTS_DATPT_LABEL1.iloc[inds].reset_index(drop=True)\n",
    "    \n",
    "    # (1) Collect stats for each (bregion, contrast_lev)\n",
    "    map_bregioncontrast_to_stats ={}\n",
    "    for bregion in list_bregion:\n",
    "        for contrast_lev in [\"0|1\", \"1|0\"]:\n",
    "            contrast_levels = [\"1|1\", contrast_lev]\n",
    "\n",
    "            df_for_stats = DFTHIS[(DFTHIS[\"bregion\"] == bregion) & (DFTHIS[contrast_var].isin(contrast_levels))]\n",
    "            \n",
    "            savesuff = f\"{grp}-{bregion}-{contrast_var}={contrast_lev}\"\n",
    "\n",
    "            out, fig = signrank_wilcoxon_from_df(df_for_stats, datapt_vars, contrast_var, contrast_levels, \n",
    "                                                 value_var, True, f\"{savedir}/SIGNRANK-{savesuff}.txt\")\n",
    "            res.append({\n",
    "                \"p\":out[\"p\"],\n",
    "                \"bregion\":bregion,\n",
    "                contrast_var:contrast_lev,\n",
    "            })\n",
    "            for var, val in zip(grp_vars, grp):\n",
    "                res[-1][var] = val\n",
    "\n",
    "            savefig(fig, f\"{savedir}/SIGNRANK-{savesuff}.pdf\")\n",
    "\n",
    "            map_bregioncontrast_to_stats[(bregion, contrast_lev)] = out[\"p\"]\n",
    "\n",
    "    ### (2) Plota and overlay stats\n",
    "    dfthis = DFTHIS[DFTHIS[contrast_var].isin([\"0|1\", \"1|0\"])]\n",
    "    fig = sns.catplot(data=dfthis, x=\"bregion\", y=value_var, hue=contrast_var, kind=\"violin\", aspect=1.25,\n",
    "                    order=order_bregion)\n",
    "\n",
    "    from pythonlib.tools.statstools import plotmod_pvalues\n",
    "    for ax in fig.axes.flatten():\n",
    "        xs = ax.get_xticks()\n",
    "        assert len(xs)==len(order_bregion)\n",
    "        for y_loc_frac, contrast_lev in zip([0.75, 0.9], [\"0|1\", \"1|0\"]):\n",
    "            ps = [map_bregioncontrast_to_stats[(bregion, contrast_lev)] for bregion in order_bregion]\n",
    "            # plotmod_pvalues(ax, xs, ps, y_loc_frac=y_loc_frac, prefix=contrast_lev)\n",
    "            plotmod_pvalues(ax, xs, ps)\n",
    "\n",
    "        for x, bregion in zip(xs, order_bregion):\n",
    "                p = map_bregioncontrast_to_stats[(bregion, contrast_lev)]\n",
    "        ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "\n",
    "    # assert False\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstats = pd.DataFrame(res)\n",
    "import numpy as np\n",
    "dfstats[\"p_log\"] = np.log10(dfstats[\"p\"])\n",
    "\n",
    "n_br = len(DFDISTS_DATPT_LABEL1[\"bregion\"].unique())\n",
    "n_contrast = 2\n",
    "n_test = n_br * n_contrast\n",
    "alpha=0.05\n",
    "alpha_bonf = alpha/n_test\n",
    "\n",
    "print(\"N tests: \", n_test, \", new alpha=\", alpha_bonf)\n",
    "# sns.catplot(data=dfstats, x=\"bregion\", y=\"p\", row=\"event\", col=\"subspace|twind\", kind=\"bar\")\n",
    "# fig = sns.catplot(data=dfstats, x=\"bregion\", y=\"p_log\", row=\"event\", hue=\"same-seqc_0_shape|seqc_0_loc\", col=\"subspace|twind\")\n",
    "# for ax in fig.axes.flatten():\n",
    "#     ax.axhline(0)\n",
    "fig = sns.catplot(data=dfstats, x=\"bregion\", y=\"p_log\", row=\"event\", hue=\"same-seqc_0_shape|seqc_0_loc\", col=\"subspace|twind\", kind=\"bar\")\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(np.log10(0.05))\n",
    "    ax.axhline(np.log10(0.005))\n",
    "    ax.axhline(np.log10(alpha_bonf), color=\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also overlay p values\n",
    "dfstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.catplot(data=dfthis, x=\"bregion\", y=value_var, row=contrast_var, kind=\"boxen\")\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axhline(0, color=\"k\", alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b41016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (2) Each subplot = bregion\n",
    "fig = sns.displot(data=dfthis, x=value_var, hue=contrast_var, row=\"bregion\", \n",
    "                  element=\"step\", fill=True, bins=40, height=1.5, aspect=3)\n",
    "# map_function_tofacet(fig, lambda ax: ax.axvline(0, color=\"k\", alpha=0.5))\n",
    "# rotateLabel(fig)\n",
    "# savefig(fig, f\"{savedir}/all_regions-subplot=region.pdf\")\n",
    "for ax in fig.axes.flatten():\n",
    "    ax.axvline(0, color=\"k\", alpha=0.5)\n",
    "    # from pythonlib.tools.plottools import naked_erase_axes\n",
    "    # naked_erase_axes(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee95a9",
   "metadata": {},
   "source": [
    "##### sign rank - final stats and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did not finalize! I decided it was better to use linear model (pairwie )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17864f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidian_time_resolved_fast_shuffled_mult_reload\n",
    "\n",
    "animal = \"Diego\"\n",
    "date = 230615\n",
    "var_other = \"seqc_0_loc\"\n",
    "DFDISTS, DFDISTS_AGG, SAVEDIR_PLOTS = euclidian_time_resolved_fast_shuffled_mult_reload(animal, date, var_other, convert_to_df_with_postprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FINAL AGGS\n",
    "# (1) each datapt is a unique label (multiple datapts per 0|1)\n",
    "tmp = DFDISTS.copy()\n",
    "tmp[\"labels_2\"] = DFDISTS[\"labels_1\"]\n",
    "tmp[\"labels_1\"] = DFDISTS[\"labels_2\"]\n",
    "tmp = pd.concat([tmp, DFDISTS]).reset_index(drop=True)\n",
    "if False: # Sanity check that got diagonals\n",
    "    from pythonlib.tools.pandastools import grouping_plot_n_samples_conjunction_heatmap\n",
    "    grouping_plot_n_samples_conjunction_heatmap(tmp, \"labels_1\", \"labels_2\")\n",
    "DFDISTS_DATPT_LABEL1 = aggregGeneral(tmp, [\"bregion\", \"which_level\", \"event\", \"subspace|twind\", \"labels_1\", \"same-seqc_0_shape|seqc_0_loc\"],\n",
    "            [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\", \"DIST_50\", \"DIST_98\"], nonnumercols=\"all\")\n",
    "if False:\n",
    "    # Check output\n",
    "    grouping_plot_n_samples_conjunction_heatmap(DFDISTS_DATPT_LABEL1, \"labels_1\", \"same-seqc_0_shape|seqc_0_loc\")\n",
    "\n",
    "# (2) each datapt is 0|1, 1|0, 1|1, 0|0 (i.e., 4 datapts per bregion/metaparams)\n",
    "# Agg over all conditions (e.g. label pairs)\n",
    "DFDISTS_LABEL_AGG = aggregGeneral(DFDISTS_DATPT_LABEL1, [\"bregion\", \"which_level\", \"event\", \"subspace|twind\", \"same-seqc_0_shape|seqc_0_loc\"],\n",
    "                            [\"dist_mean\", \"dist_norm\", \"dist_yue_diff\", \"DIST_50\", \"DIST_98\"], nonnumercols=\"all\")\n",
    "if False:\n",
    "    # check output\n",
    "    grouping_plot_n_samples_conjunction_heatmap(DFDISTS_LABEL_AGG, \"bregion\", \"same-seqc_0_shape|seqc_0_loc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = \"03_samp|(0.05, 0.6)\"\n",
    "subspace_twind = \"shape|(0.05, 0.9)\"\n",
    "dfdists_labels = DFDISTS_DATPT_LABEL1[(DFDISTS_DATPT_LABEL1[\"event\"]==event) & (DFDISTS_DATPT_LABEL1[\"subspace|twind\"]==subspace_twind)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9582e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdists_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2de348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should have <n bregions> per cell.\n",
    "grouping_plot_n_samples_conjunction_heatmap(dfdists_labels, \"labels_1\", \"same-seqc_0_shape|seqc_0_loc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot, showing distributions of datapts\n",
    "from pythonlib.tools.pandastools import plot_45scatter_means_flexible_grouping\n",
    "plot_45scatter_means_flexible_grouping(dfdists_labels, \"same-seqc_0_shape|seqc_0_loc\", \"1|0\", \"0|1\", \"bregion\", \"dist_yue_diff\", \"labels_1\", shareaxes=True, plot_text=False, SIZE=3.5, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9494d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. collect the final days\n",
    "# 2. Plot avg and scatter as above.\n",
    "# 3. Final panels: (1) avg (each monkey). (2) show distribution for one monkey\n",
    "# 4. Final stats: (1) each region vs. 0 (LME?) (2) compare regions (shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3f306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ca43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LME\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe48f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each bregion, score effect of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdists_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.session import _REGIONS_IN_ORDER_COMBINED\n",
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good\n",
    "\n",
    "# order_bregion = _REGIONS_IN_ORDER_COMBINED\n",
    "# list_bregion = order_bregion\n",
    "# from neuralmonkey.neuralplots.brainschematic import datamod_reorder_by_bregion\n",
    "from pythonlib.tools.statstools import signrank_wilcoxon_from_df\n",
    "\n",
    "yvar = \"dist_norm\"\n",
    "# grp_vars = [\"bregion\", \"same-seqc_0_shape|seqc_0_loc\"]\n",
    "grp_vars = [\"bregion\"]\n",
    "grpdict = grouping_append_and_return_inner_items_good(dfdists_labels, grp_vars)\n",
    "\n",
    "for grp, inds in grpdict.items():\n",
    "    dfdists_labels_sub = dfdists_labels.iloc[inds]\n",
    "    for contrast_lev in [\"0|1\", \"1|0\"]:\n",
    "        contrast_levels = [\"1|1\", contrast_lev]\n",
    "\n",
    "        df_for_stats = dfdists_labels_sub[(dfdists_labels_sub[contrast_var].isin(contrast_levels))].reset_index(drop=True)\n",
    "\n",
    "        labels = df_for_stats[\"labels_1\"].tolist()\n",
    "        shapes = [lab[0] for lab in labels]\n",
    "        locs = [lab[1] for lab in labels]\n",
    "        vals_same_same = df_for_stats[contrast_var].tolist()\n",
    "        values = df_for_stats[yvar].tolist()\n",
    "\n",
    "        if grp[0]==\"M1\" and contrast_lev==\"0|1\":\n",
    "            assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b39e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_stats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e24709",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"/tmp\"\n",
    "savesuff = grp\n",
    "datapt_vars = [\"labels_1\"]\n",
    "contrast_var = \"same-seqc_0_shape|seqc_0_loc\"\n",
    "out, fig = signrank_wilcoxon_from_df(df_for_stats, datapt_vars, contrast_var, contrast_levels, \n",
    "                                        yvar, True, f\"{savedir}/SIGNRANK-{savesuff}.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f58229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_stats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grp)\n",
    "dflm = pd.DataFrame({\n",
    "    yvar:values,\n",
    "    \"shape\":shapes,\n",
    "    \"loc\":locs,\n",
    "    \"contrast\":vals_same_same\n",
    "})\n",
    "dflm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import convert_var_to_categorical\n",
    "convert_var_to_categorical(dflm, \"shape\", \"shape_cat\")\n",
    "convert_var_to_categorical(dflm, \"loc\", \"loc_cat\")\n",
    "convert_var_to_categorical(dflm, \"contrast\", \"contrast_cat\")\n",
    "dflm[\"shape_loc\"] = dflm[\"shape_cat\"].astype(str) + \":\" + dflm[\"loc_cat\"].astype(str)\n",
    "\n",
    "dflm[\"dist_norm_std\"] = (dflm[\"dist_norm\"] - dflm[\"dist_norm\"].mean()) / dflm[\"dist_norm\"].std()\n",
    "\n",
    "dflm[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = f\"{yvar}_std ~ C(contrast_cat, Treatment(1))\"\n",
    "\n",
    "if False:\n",
    "    md = smf.ols(formula, dflm)\n",
    "    mdf = md.fit()\n",
    "else:\n",
    "    # formula = f\"{yvar} ~ C(shapesame, Treatment(True)) + C(locsame, Treatment(True)) + C(shape12, Treatment((0,0))) + C(loc12, Treatment((0,0)))\"\n",
    "\n",
    "    # formula = f\"{yvar} ~ C(shape12, Treatment((0,0))) + C(loc12, Treatment((0,0)))\"\n",
    "    # formula = f\"{yvar} ~ C(shape12, Treatment((0,0)))\"\n",
    "    # formula = f\"{yvar} ~ C(loc12, Treatment((0,0)))\"\n",
    "\n",
    "    # str_treat = f\"C({fixed_treat}, Treatment('{lev_treat_default}'))\"\n",
    "    # formula = f\"{yvar} ~ {str_treat}\"\n",
    "    md = smf.mixedlm(formula, dflm, groups=dflm[\"shape_loc\"], re_formula=\"~1\")\n",
    "    # md = smf.mixedlm(formula, dflm, groups=dflm[\"loc_cat\"], re_formula=\"~1\")\n",
    "    # md = smf.ols(formula, dflm)\n",
    "    mdf = md.fit(method=\"lbfgs\")\n",
    "\n",
    "mdf.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa4b09b",
   "metadata": {},
   "source": [
    "### Stats Method #3 -- # Get p-value by shuffling conditions [GOOD]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neuralmonkey.neuralplots.brainschematic import datamod_reorder_by_bregion\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index, grouping_append_and_return_inner_items_good\n",
    "from pythonlib.tools.pandastools import aggregGeneral, stringify_values\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a161028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidian_time_resolved_fast_shuffled_mult_stats_v3\n",
    "euclidian_time_resolved_fast_shuffled_mult_stats_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b574a2",
   "metadata": {},
   "source": [
    "## [#4.4] [GOOD] Load all results from euclidian_time_resolved_fast_shuffled and plot, across all animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98197f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidian_time_resolved_fast_shuffled_mult_scatter_plots\n",
    "# analysis_kind = \"shape_invar\"\n",
    "# analysis_kind = \"shape_invar_context\"\n",
    "# analysis_kind = \"shape_invar_clean_loc\"\n",
    "# analysis_kind = \"shape_invar_clean_size\"\n",
    "\n",
    "# for analysis_kind in [\"shape_invar_clean_loc\", \"shape_invar_clean_size\"]:\n",
    "# for analysis_kind in [\"shape_invar_clean_loc\"]:\n",
    "for analysis_kind in [\"shape_invar_clean_size\"]:\n",
    "    euclidian_time_resolved_fast_shuffled_mult_scatter_plots(analysis_kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26d4051",
   "metadata": {},
   "source": [
    "### [Make RSA heatmaps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neuralmonkey.neuralplots.brainschematic import datamod_reorder_by_bregion\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index, grouping_append_and_return_inner_items_good\n",
    "from pythonlib.tools.pandastools import aggregGeneral, stringify_values\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35227763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidian_time_resolved_fast_shuffled_mult_reload\n",
    "animal = \"Diego\"\n",
    "date = 230615\n",
    "var_other = \"seqc_0_loc\"\n",
    "list_dfdist, list_dfdist_shuff, SAVEDIR_PLOTS = euclidian_time_resolved_fast_shuffled_mult_reload(animal, date, var_other, also_load_shuffled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bfa9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfdist[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0140a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "list(permutations(range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c675980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b24719ca",
   "metadata": {},
   "source": [
    "##### Entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8bef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'B': ['a', 'a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c'],\n",
    "    'A': [1, 1, 1, 1, 2, 2, 2, 3, 3, 3]\n",
    "})\n",
    "\n",
    "display(df)\n",
    "# Column names as variables\n",
    "column_to_remap = 'B'\n",
    "grouping_column = 'A'\n",
    "\n",
    "shuffle_dataset_hierarchical_remap(df, column_to_remap, grouping_column, use_same_mapping_across_groups=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "z_score = 3\n",
    "p_value = 1 - norm.cdf(z_score)  # For one-tailed (right-tailed) test\n",
    "\n",
    "print(p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidian_time_resolved_fast_shuffled_mult_stats_v3\n",
    "animal = \"Pancho\"\n",
    "date = 220715\n",
    "var_other = \"seqc_0_loc\"\n",
    "\n",
    "# var_shuffle = \"seqc_0_loc\"\n",
    "# var_stable = \"seqc_0_shape\"\n",
    "\n",
    "# var_shuffle = \"seqc_0_shape\"\n",
    "# var_stable = \"seqc_0_loc\"\n",
    "\n",
    "events_keep = [\"03_samp\"]\n",
    "n_shuff = 11\n",
    "for var_stable, var_shuffle in [\n",
    "    (\"seqc_0_shape\", \"seqc_0_loc\"), \n",
    "    (\"seqc_0_loc\", \"seqc_0_shape\")]:\n",
    "    euclidian_time_resolved_fast_shuffled_mult_stats_v3(animal, date, var_other, \n",
    "                                                        var_shuffle, var_stable, \n",
    "                                                        n_shuff = n_shuff, \n",
    "                                                        shuffle_method=2, events_keep=events_keep,\n",
    "                                                        PLOT_SHUFFLE_HEATMAP=False, HACK=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f86918",
   "metadata": {},
   "source": [
    "### Stats method # 4 -- linear model, at level of trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78772746",
   "metadata": {},
   "source": [
    "Idea -- model the distance matrix (each label1-label2 gives mean value) as B1*(same vs diff shape)[n=2 levels] + B2*(same vs. diff location)[2 lev] + B3*(shape pair) + B4*(loc pair) + B5*(shape-loc pair).\n",
    "\n",
    "Use this to get a p-value for shape and for location.\n",
    "\n",
    "Problem: Not sure if I can rely on this p-value. Also, the effect for \"same shape\" is an underestimate, becuase it is looking for a pure shape effect.\n",
    "\n",
    "I realized that for this I would still want to do a permutation test to test significance, which led me to go back to method 3.\n",
    "\n",
    "Future: No need to continue..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee44c84",
   "metadata": {},
   "source": [
    "Updated -- This is good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidian_time_resolved_fast_shuffled_mult_reload, _euclidian_time_resolved_fast_shuffled_mult_scatter_plots_params\n",
    "from pythonlib.tools.pandastools import convert_var_to_categorical\n",
    "from pythonlib.tools.plottools import savefig\n",
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidianshuff_stats_linear_load, euclidianshuff_stats_linear_plot_wrapper, euclidian_time_resolved_fast_shuffled_mult_reload, euclidian_time_resolved_fast_shuffled_mult_scatter_plots\n",
    "from pythonlib.tools.pandastools import convert_var_to_categorical\n",
    "from pythonlib.tools.plottools import savefig\n",
    "from neuralmonkey.neuralplots.brainschematic import datamod_reorder_by_bregion\n",
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good\n",
    "from pythonlib.tools.statstools import signrank_wilcoxon_from_df\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import _euclidianshuff_stats_linear_load_mult_dates_postprocess, euclidianshuff_stats_linear_load, euclidianshuff_stats_linear_plot_wrapper, euclidian_time_resolved_fast_shuffled_mult_reload, euclidian_time_resolved_fast_shuffled_mult_scatter_plots\n",
    "import os\n",
    "\n",
    "SAVE_TO_TMP = False\n",
    "merge_pancho_ss_twinds=True\n",
    "plot_coeff = False\n",
    "analysis_kind = \"shape_invar_clean_loc\"\n",
    "do_each_date = False\n",
    "for animal in [\"Diego\", \"Pancho\"]:\n",
    "# for animal in [\"Pancho\"]:\n",
    "    # for var_other in [\"gridsize\", \"seqc_0_loc\"]:\n",
    "    for var_other in [\"gridsize\"]:\n",
    "    # for var_other in [\"seqc_0_loc\"]:\n",
    "        \n",
    "        list_date = _euclidian_time_resolved_fast_shuffled_mult_scatter_plots_params(analysis_kind, animal, var_other)\n",
    "        var_same_same = f\"same-seqc_0_shape|{var_other}\"\n",
    "\n",
    "        if do_each_date:\n",
    "            for date in list_date:\n",
    "                DFDISTS, SAVEDIR_PLOTS = euclidianshuff_stats_linear_load(animal, date, var_other, merge_pancho_ss_twinds=merge_pancho_ss_twinds)\n",
    "\n",
    "                ### ALL PLOTS\n",
    "                euclidianshuff_stats_linear_plot_wrapper(DFDISTS, SAVEDIR_PLOTS, var_other)\n",
    "\n",
    "        from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import euclidianshuff_stats_linear_load_mult_dates\n",
    "        DFDISTS = euclidianshuff_stats_linear_load_mult_dates(animal, list_date, var_other, analysis_kind,\n",
    "                                                              merge_pancho_ss_twinds=merge_pancho_ss_twinds)\n",
    "        \n",
    "        if SAVE_TO_TMP:\n",
    "            SAVEDIR_PLOTS = f\"/tmp/stats_linear_model/{animal}-{'|'.join([str(d) for d in list_date])}-var_other={var_other}\"\n",
    "            os.makedirs(SAVEDIR_PLOTS, exist_ok=True)\n",
    "        else:\n",
    "            SAVEDIR_PLOTS = f\"/lemur2/lucas/analyses/recordings/main/shape_invariance/EUCLIDIAN_SHUFF/MULT/stats_linear_model/{animal}-{'|'.join([str(d) for d in list_date])}-var_other={var_other}\"\n",
    "            os.makedirs(SAVEDIR_PLOTS, exist_ok=True)\n",
    "\n",
    "        if False:\n",
    "            # Remove animal and date, so that anything that uses animal, date will fail. This is to ensure that is conisdering agged datapts.\n",
    "            # This is mainly sanity check for myself.\n",
    "            DFDISTS.drop(\"animal\", axis=1, inplace=True)\n",
    "            DFDISTS.drop(\"date\", axis=1, inplace=True)\n",
    "            DFDISTS.drop(\"animal_cat\", axis=1, inplace=True)\n",
    "            DFDISTS.drop(\"date_cat\", axis=1, inplace=True)\n",
    "\n",
    "        # Condition\n",
    "        DFDISTS = _euclidianshuff_stats_linear_load_mult_dates_postprocess(DFDISTS)\n",
    "\n",
    "        # Savedir\n",
    "        from pythonlib.tools.expttools import writeDictToTxt\n",
    "        writeDictToTxt({\"list_date\":list_date}, f\"{SAVEDIR_PLOTS}/list_date.txt\")\n",
    "        _, _, _, _ = euclidianshuff_stats_linear_plot_wrapper(DFDISTS, SAVEDIR_PLOTS, var_other)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e32cb",
   "metadata": {},
   "source": [
    "##### Debug, getting sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a38617",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_vars = [\"subspace|twind\", \"event\"]\n",
    "grpdict = grouping_append_and_return_inner_items_good(DFDISTS, grp_vars)\n",
    "for grp, inds in grpdict.items():\n",
    "    print(grp)\n",
    "    dfthis = DFDISTS.iloc[inds].reset_index(drop=True)\n",
    "    \n",
    "    savepath = f\"{savedir}/COUNTS-grp={grp}-counts.txt\"\n",
    "    grouping_print_n_samples(dfthis, [var_same_same, \"bregion\", \"labels_1\"], savepath=savepath)\n",
    "\n",
    "    if False:\n",
    "        # Should have <n bregions> per cell.\n",
    "        grouping_plot_n_samples_conjunction_heatmap(dfdists_labels, \"labels_1\", var_same_same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11645cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdsa\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples, grouping_plot_n_samples_conjunction_heatmap\n",
    "grouping_print_n_samples(dfthis, [\"bregion\", \"same-seqc_0_shape|gridsize\", \"shape1\", \"loc1\", \"shape2\", \"loc2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205cdd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir\n",
    "grouping_print_n_samples(dfthis, [\"bregion\", \"same-seqc_0_shape|gridsize\", \"labels_1\", \"labels_2\", \"date\"])\n",
    "grouping_plot_n_samples_conjunction_heatmap(dfthis, \"labels_1\", \"labels_2\", [\"same-seqc_0_shape|gridsize\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee299a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping_print_n_samples(dfthis, [\"bregion\", \"same-seqc_0_shape|gridsize\", \"labels_1\", \"labels_2\", \"date\"])\n",
    "adsa\n",
    "grouping_plot_n_samples_conjunction_heatmap(dfthis, \"labels_1\", \"labels_2\", [\"same-seqc_0_shape|gridsize\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfthis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6107588",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDISTS[\"animal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import _euclidianshuff_stats_linear_2br_compute\n",
    "DFSTATS_2BR = _euclidianshuff_stats_linear_2br_compute(DFDISTS, var_same_same)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380ecf7",
   "metadata": {},
   "source": [
    "# Make associated plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec87b27",
   "metadata": {},
   "source": [
    "### State space plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5491888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import statespace_scalar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = \"/tmp\"\n",
    "var_other = \"seqc_0_loc\"\n",
    "statespace_scalar_plot(DFallpa, animal, date, SAVEDIR, var_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a019409",
   "metadata": {},
   "source": [
    "### State space trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR_ANALYSIS = \"/tmp/traj\"\n",
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import preprocess_pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import statespace_traj_plot\n",
    "var_other = \"seqc_0_loc\"\n",
    "statespace_traj_plot(DFallpa, animal, date, SAVEDIR_ANALYSIS, var_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b5655",
   "metadata": {},
   "source": [
    "### Decoder (generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca12bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import decodercross_plot\n",
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_timeresolved_cross_condition, decodewrapouterloop_categorical_timeresolved_within_condition, decodewrapouterloop_categorical_timeresolved_cross_condition\n",
    "\n",
    "SAVEDIR = \"/tmp/DCODE\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodercross_plot(DFallpa, SAVEDIR_ANALYSIS=\"/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5284ab",
   "metadata": {},
   "source": [
    "# [LOAD MULT DATA] Euclidian (time-varying, here summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See analy_shape_invariance_all_plots_SP_MULT\n",
    "# Code copied below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8baf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_ANIMAL_DATE_COMB_VAROTHER = [\n",
    "    (\"Diego\", 230615, True, \"seqc_0_loc\"), \n",
    "]\n",
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import mult_load_euclidian_time_resolved\n",
    "DFDIST = mult_load_euclidian_time_resolved(LIST_ANIMAL_DATE_COMB_VAROTHER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a76e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR_MULT = f\"/lemur2/lucas/analyses/recordings/main/shape_invariance/EUCLIDIAN/MULT\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b873a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make save directory\n",
    "a = \"_\".join(set([x[0] for x in LIST_ANIMAL_DATE_COMB_VAROTHER]))\n",
    "b = min([x[1] for x in LIST_ANIMAL_DATE_COMB_VAROTHER])\n",
    "c = max([x[1] for x in LIST_ANIMAL_DATE_COMB_VAROTHER])\n",
    "var_other = [str(x[3]) for x in LIST_ANIMAL_DATE_COMB_VAROTHER][0]\n",
    "\n",
    "### Summarize extracted cases\n",
    "savesuff = \"test\"\n",
    "SAVEDIR = f\"{SAVEDIR_MULT}/{a}-{b}-to-{c}-varother={var_other}-suff={savesuff}\"\n",
    "print(SAVEDIR)\n",
    "import os\n",
    "os.makedirs(SAVEDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_euclidian_chars_sp_MULT import plot_scalar_all, plot_timecourse_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timecourse_all(DFDIST, SAVEDIR, var1=\"seqc_0_shape\", var2=var_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dbe903",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFDIST[\"event\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff99a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "savedir = f\"{SAVEDIR}/SCALAR\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "map_event_to_twind = {\n",
    "        \"03_samp\":[0.1, 0.8],\n",
    "        \"05_first_raise\":[-0.5,  0.2],\n",
    "        \"06_on_strokeidx_0\":(-0.5, 0.),\n",
    "    }\n",
    "\n",
    "\n",
    "map_event_to_listtwind = {\n",
    "        \"03_samp\":[(0.05, 0.3), (0.3, 0.6), (0.05, 0.6), (0.5, 1.0)],\n",
    "        \"05_first_raise\":[(-0.5,  -0.1), (-0.1, 0.5)],\n",
    "        \"06_on_strokeidx_0\":[(-0.5, -0.1), (0, 0.5)],\n",
    "    }\n",
    "\n",
    "\n",
    "var_other = \"seqc_0_loc\"\n",
    "plot_scalar_all(DFDIST, SAVEDIR, map_event_to_listtwind, var1=\"seqc_0_shape\", var2=var_other, reverse_axis_order=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e466b",
   "metadata": {},
   "source": [
    "# [SIZE] time-warping during strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA = DFallpa[\"pa\"].values[0]\n",
    "\n",
    "# Extract stroke durations\n",
    "dflab = PA.Xlabels[\"trials\"]\n",
    "durations = []\n",
    "for tk in dflab[\"Tkbeh_stkbeh\"]:\n",
    "    assert len(tk.Tokens)==1\n",
    "    tk.Tokens[0]\n",
    "    strok = tk.Tokens[0][\"Prim\"].Stroke()\n",
    "    durations.append(strok[-1, 2] - strok[0, 2])\n",
    "\n",
    "dflab[\"strok_duration\"] = durations\n",
    "\n",
    "import seaborn as sns\n",
    "from pythonlib.tools.snstools import rotateLabel\n",
    "fig = sns.catplot(data=dflab, x=\"seqc_0_shape\", y=\"strok_duration\", hue=\"gridsize\", jitter=True, alpha=0.3)\n",
    "rotateLabel(fig)\n",
    "\n",
    "fig = sns.catplot(data=dflab, x=\"seqc_0_shape\", y=\"strok_duration\", hue=\"gridsize\", kind=\"point\")\n",
    "rotateLabel(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed31b9a",
   "metadata": {},
   "source": [
    "### Version using trialpop (timewarped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-extracted trialpop data that has been time-warped. \n",
    "# Then do standard analyses here, including heatmaps, state space, and euclidean distance plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ab39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import timewarped_all_wrapper\n",
    "timewarped_all_wrapper() # Run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load precomputed\n",
    "# Here, doing so simply beucase it failed in the inital run. This should normally plot automaticalyl.\n",
    "import pandas as pd\n",
    "from neuralmonkey.analyses.euclidian_distance import dfdist_postprocess_wrapper, dfdist_summary_plots_wrapper\n",
    "import os\n",
    "\n",
    "for animal, date in [\n",
    "    (\"Diego\", 230619),\n",
    "    (\"Pancho\", 220716),\n",
    "    (\"Pancho\", 220717),\n",
    "    (\"Pancho\", 240530),\n",
    "    (\"Diego\", 230618),\n",
    "    ]:\n",
    "\n",
    "    SAVEDIR_ANALYSIS = f\"/lemur2/lucas/analyses/recordings/main/shape_invariance/TIMEWARPED/{animal}-{date}\"\n",
    "    path = f\"{SAVEDIR_ANALYSIS}/DFDIST.pkl\"\n",
    "    DFDIST = pd.read_pickle(path)\n",
    "\n",
    "    ### PLOTS  \n",
    "    var_effect = \"seqc_0_shape\"\n",
    "    var_other = \"gridsize\"\n",
    "    n_min_per_lev = 4\n",
    "\n",
    "    SAVEDIR = f\"{SAVEDIR_ANALYSIS}/PLOTS\"\n",
    "    os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "    # Preprocess\n",
    "    DFDIST, DFDIST_AGG = dfdist_postprocess_wrapper(DFDIST, var_effect, var_other, SAVEDIR, prune_min_n_trials=n_min_per_lev)\n",
    "\n",
    "    # Plot\n",
    "    PLOT_EACH_PAIR = False\n",
    "    dfdist_summary_plots_wrapper(DFDIST, DFDIST_AGG, var_effect, var_other, SAVEDIR,\n",
    "                                    PLOT_EACH_PAIR=PLOT_EACH_PAIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d459f1",
   "metadata": {},
   "source": [
    "# [Revision] Decode, getting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977fe0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import preprocess_pa, decode_scalar_confusion\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88923a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFallpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9117dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = \"/tmp/SCAL_DECODE\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "decode_scalar_confusion(DFallpa, animal, date, SAVEDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92974acc",
   "metadata": {},
   "source": [
    "### [Load mult decode] and do combined plots across dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46226735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import _euclidian_time_resolved_fast_shuffled_mult_scatter_plots_params\n",
    "from neuralmonkey.classes.session import _REGIONS_IN_ORDER_COMBINED\n",
    "import pickle\n",
    "\n",
    "SAVEDIR_MULT = \"/lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion\"\n",
    "event = \"03_samp\"\n",
    "twind = (0.05, 0.6)\n",
    "do_std = False\n",
    "res = []\n",
    "for analysis_kind in [\"shape_invar_clean\"]:\n",
    "    for animal in [\"Diego\", \"Pancho\"]:\n",
    "        for var_other in [\"seqc_0_loc\", \"gridsize\"]:\n",
    "            list_date = _euclidian_time_resolved_fast_shuffled_mult_scatter_plots_params(analysis_kind, animal, var_other)\n",
    "            for date in list_date:\n",
    "                for bregion in _REGIONS_IN_ORDER_COMBINED:\n",
    "                    path = f\"{SAVEDIR_MULT}/{animal}-{date}/{bregion}-event={event}-twind={twind}/decode-do_std={do_std}/RES.pkl\"\n",
    "                    with open(path, \"rb\") as f:\n",
    "                        RES = pickle.load(f)\n",
    "\n",
    "                    # Get labels\n",
    "                    from neuralmonkey.analyses.decode_good import decode_categorical, decode_categorical_plot_confusion_score_quick\n",
    "                    score, score_adjusted, dfclasses = decode_categorical_plot_confusion_score_quick(RES, savedir=None)\n",
    "                    # print(score, score_adjusted)\n",
    "                    \n",
    "                    dfclasses[\"analysis_kind\"] = analysis_kind\n",
    "                    dfclasses[\"animal\"] = animal\n",
    "                    dfclasses[\"var_other\"] = var_other\n",
    "                    dfclasses[\"date\"] = date\n",
    "                    dfclasses[\"bregion\"] = bregion\n",
    "\n",
    "                    res.append(dfclasses)\n",
    "\n",
    "DFRES = pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95585df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SAVEDIR_PLOTS = f\"{SAVEDIR_MULT}/PLOTS\"\n",
    "os.makedirs(SAVEDIR_PLOTS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5151b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good\n",
    "from pythonlib.tools.pandastools import grouping_plot_n_samples_conjunction_heatmap\n",
    "from pythonlib.tools.plottools import savefig\n",
    "\n",
    "savedir = f\"{SAVEDIR_PLOTS}/confusion_matrices\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "grpdict = grouping_append_and_return_inner_items_good(DFRES, [\"animal\", \"date\"])\n",
    "\n",
    "norm_method = \"row_div\"\n",
    "annotate_heatmap = False\n",
    "zlims=[0, 1]\n",
    "diverge=False\n",
    "n_columns = len(DFRES[\"bregion\"].unique())\n",
    "for grp, inds in grpdict.items():\n",
    "    dfres = DFRES.iloc[inds].reset_index(drop=True)\n",
    "    fig = grouping_plot_n_samples_conjunction_heatmap(dfres, \"label_actual\", \n",
    "                                                        \"label_predicted\", [\"bregion\"], \n",
    "                                                        norm_method=norm_method, \n",
    "                                                        annotate_heatmap=annotate_heatmap,\n",
    "                                                        n_columns=n_columns,\n",
    "                                                        zlims=zlims, diverge=diverge)\n",
    "    # assert False\n",
    "    savefig(fig, f\"{savedir}/accuracy_heatmap-grp={grp}-norm={norm_method}-annotate={annotate_heatmap}.pdf\")\n",
    "\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8113f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine across dates. And block out cases without enough data\n",
    "\n",
    "grpdict = grouping_append_and_return_inner_items_good(DFRES, [\"animal\"])\n",
    "\n",
    "norm_method = \"row_div\"\n",
    "annotate_heatmap = False\n",
    "zlims=[0, 1]\n",
    "diverge=False\n",
    "n_columns = len(DFRES[\"bregion\"].unique())\n",
    "for grp, inds in grpdict.items():\n",
    "    dfres = DFRES.iloc[inds].reset_index(drop=True)\n",
    "\n",
    "    fig = grouping_plot_n_samples_conjunction_heatmap(dfres, \"label_actual\", \n",
    "                                                        \"label_predicted\", [\"bregion\"], \n",
    "                                                        norm_method=norm_method, \n",
    "                                                        annotate_heatmap=annotate_heatmap,\n",
    "                                                        n_columns=n_columns,\n",
    "                                                        zlims=zlims, diverge=diverge)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ed13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres[\"labels_actual\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87bea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = sorted(set(dfres[\"label_actual\"].unique().tolist() + dfres[\"label_predicted\"].unique().tolist()))\n",
    "\n",
    "# ma = np.zeros((len(labels_all), len(labels_all))).astype(bool)\n",
    "counts = np.zeros((len(labels_all), len(labels_all))) - np.inf\n",
    "for i, lab1 in enumerate(labels_all):\n",
    "    for j, lab2 in enumerate(labels_all):\n",
    "        n = sum((dfres[\"label_actual\"] == lab1) & (dfres[\"label_predicted\"] == lab2))\n",
    "        counts[i, j] = n\n",
    "assert np.all(counts>=0)\n",
    "\n",
    "counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72597b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = counts>0\n",
    "plt.figure()\n",
    "plt.imshow(ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7599bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize in scatter, showing that all shapes are decodable vs. every other shape.\n",
    "\n",
    "dfres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129542f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60df552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each label_actual, get its \n",
    "from pythonlib.tools.pandastools import convert_to_2d_dataframe\n",
    "dfthis, fig, ax, rgba_values = convert_to_2d_dataframe(dfres, \"label_actual\", \"label_predicted\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Each row is a pair (labactual, labpred) and value is counts (or fraction, normalized to num cases of labactual).\n",
    "# # Then make scatterplot, where each dot is a (laba, labp), xaxis is \n",
    "# # [ACTUALLY NO -- each datapt should be like a single analysis including just a pair of labels. and then for that you have\n",
    "# # one number for frac_correct. Then plot as a 1D histogram. where the total n is the total number of pairwise comparisons.\n",
    "\n",
    "# And in addition can plot the heatmap to show what the comparisons are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bfa08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63900a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.pandastools import plot_45scatter_means_flexible_grouping\n",
    "plot_45scatter_means_flexible_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245219f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebcccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(RES, savedir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52930070",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ce115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9911bc40",
   "metadata": {},
   "source": [
    "# [Revision decode] new method, decoding for each pair of shapes, and doing cross-decoding across location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5545594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SAVEDIR = \"/tmp/DECODE\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b94c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonlib.tools.plottools import savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963471e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_euclidian_chars_sp import params_subspace_projection\n",
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import preprocess_pa\n",
    "from neuralmonkey.analyses.state_space_good import trajgood_plot_colorby_splotby_scalar_2dgrid_bregion\n",
    "from neuralmonkey.analyses.state_space_good import trajgood_plot_colorby_splotby_scalar_WRAPPER, dimredgood_nonlinear_embed_data\n",
    "from neuralmonkey.analyses.decode_good import decode_categorical, decode_categorical_plot_confusion_score_quick\n",
    "\n",
    "### PARAMS\n",
    "# Decode\n",
    "var_decode = \"seqc_0_shape\"\n",
    "var_other = \"seqc_0_loc\"\n",
    "NPCS_KEEP = 50 # high, since decoder will find axis in this space.\n",
    "map_event_to_listtwind = {\n",
    "        \"03_samp\":[(0.05, 0.3), (0.3, 0.6), (0.05, 0.6), (0.5, 1.0)],\n",
    "        \"05_first_raise\":[(-0.5,  -0.1), (-0.1, 0.5)],\n",
    "        \"06_on_strokeidx_0\":[(-0.5, -0.1), (0, 0.5)],\n",
    "    }\n",
    "\n",
    "# PCA\n",
    "subspace_projection = \"pca\"\n",
    "tbin_dur = \"default\"\n",
    "tbin_slide = None\n",
    "\n",
    "### First, preprocess all pa\n",
    "list_pa =[]\n",
    "for PA in DFallpa[\"pa\"]:\n",
    "    pa = preprocess_pa(PA, animal, date, var_other, \"/tmp\", True, \n",
    "                    None, None, None, None, None, False, skip_dim_reduction=True)    \n",
    "    plt.close(\"all\")\n",
    "    list_pa.append(pa)    \n",
    "DFallpa[\"pa\"] = list_pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[list(range(len(PA.Chans)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685930a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Equalize sample size across brain regions.\n",
    "\n",
    "# Do this with reference to PMv\n",
    "nchans_min = min([len(pa.Chans) for pa in DFallpa[\"pa\"]])\n",
    "\n",
    "# subsample num chans randomly\n",
    "from pythonlib.tools.statstools import balanced_subsamples\n",
    "nchans = len(pa.Chans)\n",
    "nchans_min = nchans+1\n",
    "nsplits = 2\n",
    "subsamples, counts = balanced_subsamples(nchans, nsplits, nchans_min, PRINT=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# plt.plot(range(len(counts)), counts, \"ok\")\n",
    "ax.hist(counts, bins=20)\n",
    "ax.set_xlim([0, 5])\n",
    "\n",
    "for inds in subsamples:\n",
    "    print(inds)\n",
    "    pa_sub = pa.slice_by_dim_indices_wrapper(\"chans\", inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130462e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See updated code in decode_scalar_confusion()\n",
    "\n",
    "map_event_to_listtwind = {\n",
    "        \"03_samp\":[(0.05, 0.6)],\n",
    "        \"05_first_raise\":[(-0.1, 0.5)],\n",
    "        \"06_on_strokeidx_0\":[(0, 0.5)],\n",
    "    }\n",
    "\n",
    "\n",
    "### Collect each PA (doing dim reduction)\n",
    "# (Project onto shape subspace)\n",
    "for _, row in DFallpa.iterrows():\n",
    "    event = row[\"event\"]\n",
    "    bregion = row[\"bregion\"]\n",
    "    PA = row[\"pa\"]\n",
    "\n",
    "    list_twind = map_event_to_listtwind[event]\n",
    "    for twind_scal in list_twind:\n",
    "\n",
    "        savedir = f\"{SAVEDIR}/{bregion}-event={event}-twind={twind_scal}\"\n",
    "        os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "        ### Dim reductions\n",
    "        dim_red_method, superv_dpca_params = params_subspace_projection(subspace_projection)\n",
    "        superv_dpca_var = superv_dpca_params['superv_dpca_var']\n",
    "        superv_dpca_vars_group = superv_dpca_params['superv_dpca_vars_group']\n",
    "        superv_dpca_filtdict = superv_dpca_params['superv_dpca_filtdict']\n",
    "        _, PAredu = PA.dataextract_dimred_wrapper(\"scal\", dim_red_method, savedir, twind_scal, \n",
    "                                    tbin_dur=tbin_dur, tbin_slide = tbin_slide, \n",
    "                                    NPCS_KEEP=NPCS_KEEP, \n",
    "                                    dpca_var=superv_dpca_var, dpca_vars_group=superv_dpca_vars_group, \n",
    "                                    dpca_filtdict=superv_dpca_filtdict,\n",
    "                                    raw_subtract_mean_each_timepoint=False)    \n",
    "\n",
    "        assert False\n",
    "        ###\n",
    "        X = PAredu.X.squeeze().T # (ntrials, ndims)\n",
    "        dflab = PAredu.Xlabels[\"trials\"]\n",
    "\n",
    "\n",
    "\n",
    "        ### For each pair of shapes, do decoding\n",
    "        from neuralmonkey.analyses.decode_good import decode_categorical_pairwise\n",
    "        do_across_condition = True\n",
    "        DFRES, DFRES_COUNTS, dfres_scores = decode_categorical_pairwise(X, dflab, var_decode, 4, savedir,\n",
    "                                do_across_condition, vars_conj_condition=vars_conj_condition,\n",
    "                                do_std=False)\n",
    "        \n",
    "        sadsad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83beca10",
   "metadata": {},
   "source": [
    "##### [Quick Devo] scalar umap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuralmonkey.analyses.state_space_good import _trajgood_plot_colorby_scalar_BASE_GOOD\n",
    "from pythonlib.tools.plottools import share_axes_row_or_col_of_subplots\n",
    "\n",
    "# var_col = var_other\n",
    "var_effect = \"seqc_0_shape\"\n",
    "var_other = \"seqc_0_loc\"\n",
    "savedir = \"/tmp\"\n",
    "N_MIN_TRIALS_PER_SHAPE = 5\n",
    "# Extract event to plot\n",
    "for event in DFallpa[\"event\"].unique().tolist():\n",
    "    # event = \"03_samp\"\n",
    "    dfallpa = DFallpa[DFallpa[\"event\"]==event].reset_index(drop=True)\n",
    "\n",
    "    trajgood_plot_colorby_splotby_scalar_2dgrid_bregion(dfallpa, var_effect, var_other, savedir, \n",
    "                                                        pa_var = \"pa\", prune_min_n_trials=N_MIN_TRIALS_PER_SHAPE,\n",
    "                                                        pretty_plot=True, alpha=0.7)\n",
    "    assert False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59018eec",
   "metadata": {},
   "source": [
    "### [MULT] Collect \"pairwise decode\" across all saved, and summary plots here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3daeafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load(savedir, analysis_kind, animal, date, bregion):\n",
    "    import pickle\n",
    "    path = f\"{savedir}/DFRES_COUNTS.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        DFRES_COUNTS = pickle.load(f)\n",
    "\n",
    "    path = f\"{savedir}/DFRES.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        DFRES = pickle.load(f)\n",
    "\n",
    "    path = f\"{savedir}/dfres_scores.pkl\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        dfres_scores = pickle.load(f)\n",
    "\n",
    "    # # Get labels\n",
    "    # from neuralmonkey.analyses.decode_good import decode_categorical, decode_categorical_plot_confusion_score_quick\n",
    "    # score, score_adjusted, dfclasses = decode_categorical_plot_confusion_score_quick(RES, savedir=None)\n",
    "    # # print(score, score_adjusted)\n",
    "\n",
    "    for df in [DFRES_COUNTS, DFRES, dfres_scores]:\n",
    "        df[\"analysis_kind\"] = analysis_kind\n",
    "        df[\"animal\"] = animal\n",
    "        # df[\"var_other\"] = var_other\n",
    "        df[\"date\"] = date\n",
    "        df[\"bregion\"] = bregion\n",
    "\n",
    "    return DFRES_COUNTS, DFRES, dfres_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc10bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230614/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230615/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-240508/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230618/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Diego-230619/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220715/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220724/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220716/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-220717/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/M1-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/PMv-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/PMd-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/dlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/vlPFC-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/FP-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=6/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/SMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=7/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=0/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=1/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=2/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=3/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=4/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n",
      "Loading a single subset of chans:  /lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion/Pancho-240530/preSMA-event=03_samp-twind=(0.05, 0.6)-subchaniterv2=5/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\n"
     ]
    }
   ],
   "source": [
    "from neuralmonkey.scripts.analy_shape_invariance_all_plots_SP import _euclidian_time_resolved_fast_shuffled_mult_scatter_plots_params\n",
    "from neuralmonkey.classes.session import _REGIONS_IN_ORDER_COMBINED\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pythonlib.tools.stringtools import decompose_string\n",
    "\n",
    "# version_subset_chans = 0 # no subsetting\n",
    "# version_subset_chans = 1 # determine nmin using nmin chans across ALL bregion\n",
    "version_subset_chans = 2 # determine nmin using nmin chans just across the bregions of interest \n",
    "\n",
    "SAVEDIR_MULT = \"/lemur2/lucas/analyses/recordings/main/shape_invariance/decode_confusion\"\n",
    "event = \"03_samp\"\n",
    "twind = (0.05, 0.6)\n",
    "do_std = False\n",
    "res_1 = []\n",
    "res_2 = []\n",
    "res_3 = []\n",
    "for analysis_kind in [\"shape_invar_clean\"]:\n",
    "    for animal in [\"Diego\", \"Pancho\"]:\n",
    "        for var_other in [\"seqc_0_loc\", \"gridsize\"]:\n",
    "            list_date = _euclidian_time_resolved_fast_shuffled_mult_scatter_plots_params(analysis_kind, animal, var_other)\n",
    "            for date in list_date:\n",
    "                for bregion in _REGIONS_IN_ORDER_COMBINED:\n",
    "\n",
    "                    if version_subset_chans==0:\n",
    "                        savedir = f\"{SAVEDIR_MULT}/{animal}-{date}/{bregion}-event={event}-twind={twind}/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\"\n",
    "                        DFRES_COUNTS, DFRES, dfres_scores = _load(savedir, analysis_kind, animal, date, bregion)                    \n",
    "                        \n",
    "                    elif version_subset_chans in [1, 2]:\n",
    "                        \n",
    "                        if version_subset_chans==1:\n",
    "                            pathstring = \"subchaniter\"\n",
    "                        elif version_subset_chans==2:\n",
    "                            pathstring = \"subchaniterv2\"\n",
    "                        else:\n",
    "                            assert False\n",
    "\n",
    "                        tmp = f\"{SAVEDIR_MULT}/{animal}-{date}/{bregion}-event={event}-twind={twind}-{pathstring}=*\"\n",
    "                        list_iter_dir = glob(tmp)\n",
    "\n",
    "                        # Load each iternum, and average over them\n",
    "                        res_scores = []\n",
    "                        for iter_dir in sorted(list_iter_dir):\n",
    "                            iter_num = int(decompose_string(iter_dir, \"=\")[-1])\n",
    "                            savedir = f\"{SAVEDIR_MULT}/{animal}-{date}/{bregion}-event={event}-twind={twind}-{pathstring}={iter_num}/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\"\n",
    "                            _, _, dfres_scores = _load(savedir, analysis_kind, animal, date, bregion)        \n",
    "                            print(\"Loading a single subset of chans: \", savedir)\n",
    "                            dfres_scores[\"subchans_iter_num\"] = iter_num    \n",
    "                            res_scores.append(dfres_scores)\n",
    "                            # display(dfres_scores)\n",
    "                        dfres_scores = pd.concat(res_scores).reset_index(drop=True)\n",
    "\n",
    "                        # Agg over all iter nums\n",
    "                        from pythonlib.tools.pandastools import aggregGeneral\n",
    "                        dfres_scores = aggregGeneral(dfres_scores, [\"shape_pair\", \"shape_1\", \"shape_2\", \"analysis_kind\", \"animal\", \"date\", \"bregion\"], \n",
    "                                    [\"score\", \"score_adjusted\", \"score_minus_50\"])\n",
    "                                            \n",
    "                    else:\n",
    "                        assert False\n",
    "\n",
    "                    # elif version_subset_chans==2:\n",
    "                    #     savedir = f\"{SAVEDIR_MULT}/{animal}-{date}/{bregion}-event={event}-twind={twind}-subchaniterv2={}/decodepairwise-varsother=['seqc_0_loc', 'gridsize']-do_std=False\"\n",
    "\n",
    "                    # path = f\"{savedir}/DFRES_COUNTS.pkl\"\n",
    "                    # with open(path, \"rb\") as f:\n",
    "                    #     DFRES_COUNTS = pickle.load(f)\n",
    "\n",
    "                    # path = f\"{savedir}/DFRES.pkl\"\n",
    "                    # with open(path, \"rb\") as f:\n",
    "                    #     DFRES = pickle.load(f)\n",
    "\n",
    "                    # path = f\"{savedir}/dfres_scores.pkl\"\n",
    "                    # with open(path, \"rb\") as f:\n",
    "                    #     dfres_scores = pickle.load(f)\n",
    "\n",
    "                    # # # Get labels\n",
    "                    # # from neuralmonkey.analyses.decode_good import decode_categorical, decode_categorical_plot_confusion_score_quick\n",
    "                    # # score, score_adjusted, dfclasses = decode_categorical_plot_confusion_score_quick(RES, savedir=None)\n",
    "                    # # # print(score, score_adjusted)\n",
    "\n",
    "                    # for df in [DFRES_COUNTS, DFRES, dfres_scores]:\n",
    "                    #     df[\"analysis_kind\"] = analysis_kind\n",
    "                    #     df[\"animal\"] = animal\n",
    "                    #     # df[\"var_other\"] = var_other\n",
    "                    #     df[\"date\"] = date\n",
    "                    #     df[\"bregion\"] = bregion\n",
    "\n",
    "                    if False: # not using these\n",
    "                        res_1.append(DFRES_COUNTS)\n",
    "                        res_2.append(DFRES)\n",
    "                    res_3.append(dfres_scores)\n",
    "\n",
    "# DFRES = pd.concat(res).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4cb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n",
      "/home/lucas/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n",
      "/home/lucas/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n",
      "/home/lucas/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n",
      "/home/lucas/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n",
      "/home/lucas/miniconda3/envs/drag2_matlab/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to:  /tmp/DECODE/PLOTS/PAIRWISE_DECODE-version_subset_chans=2/catplot_datapt=shape_pair-COUNTS_before_agg.txt\n",
      "Saved to:  /tmp/DECODE/PLOTS/PAIRWISE_DECODE-version_subset_chans=2/catplot_datapt=shape_pair-COUNTS.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if True:\n",
    "    SAVEDIR_PLOTS = f\"{SAVEDIR_MULT}/PLOTS/PAIRWISE_DECODE-version_subset_chans={version_subset_chans}\"\n",
    "else:\n",
    "    # Just for debugging\n",
    "    SAVEDIR_PLOTS = f\"/tmp/DECODE/PLOTS/PAIRWISE_DECODE-version_subset_chans={version_subset_chans}\"\n",
    "os.makedirs(SAVEDIR_PLOTS, exist_ok=True)\n",
    "\n",
    "### Plots\n",
    "\n",
    "# (1) Pairwise, across all expts.\n",
    "\n",
    "# (2) Scatterplot --> show that every shape is separated from every other shape.\n",
    "DFSCORES = pd.concat(res_3).reset_index(drop=True)\n",
    "# Rename shapes for Diego\n",
    "from pythonlib.drawmodel.tokens import map_sh_to_new_sh\n",
    "DFSCORES[\"shape_1\"] = [map_sh_to_new_sh[sh] if sh in map_sh_to_new_sh else sh for sh in DFSCORES[\"shape_1\"]]\n",
    "DFSCORES[\"shape_2\"] = [map_sh_to_new_sh[sh] if sh in map_sh_to_new_sh else sh for sh in DFSCORES[\"shape_2\"]]\n",
    "DFSCORES[\"shape_pair\"] = [(row[\"shape_1\"], row[\"shape_2\"]) for _, row in DFSCORES.iterrows()]\n",
    "\n",
    "from neuralmonkey.analyses.decode_good import decode_categorical_pairwise_plots\n",
    "decode_categorical_pairwise_plots(DFSCORES, SAVEDIR_PLOTS)\n",
    "\n",
    "# # Append a copy with shape 1 and 2 flipped (as this is symmetric)\n",
    "# dftmp = DFSCORES.copy()\n",
    "# dftmp[\"shape_1\"] = DFSCORES[\"shape_2\"]\n",
    "# dftmp[\"shape_2\"] = DFSCORES[\"shape_1\"]\n",
    "# dftmp[\"shape_pair\"] = [(row[\"shape_1\"], row[\"shape_2\"]) for _, row in dftmp.iterrows()]\n",
    "\n",
    "# DFSCORES_FULL = pd.concat([DFSCORES, dftmp]).reset_index(drop=True)\n",
    "# from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good, plot_subplots_heatmap\n",
    "# from pythonlib.tools.plottools import savefig\n",
    "\n",
    "# annotate_heatmap = False\n",
    "# grpdict = grouping_append_and_return_inner_items_good(DFSCORES_FULL, [\"animal\"])\n",
    "# for grp, inds in grpdict.items():\n",
    "#     dfscores = DFSCORES_FULL.iloc[inds].reset_index(drop=True)\n",
    "#     shapes = sorted(dfscores[\"shape_1\"].unique())\n",
    "    \n",
    "#     fig, axes = plot_subplots_heatmap(dfscores, \"shape_1\", \"shape_2\", \"score_minus_50\", \"bregion\", diverge=True, \n",
    "#                           annotate_heatmap=annotate_heatmap, ZLIMS=[-0.5, 0.5], \n",
    "#                           row_values=shapes, col_values=shapes, diverge_center_dark=True)\n",
    "#     # plot_subplots_heatmap(dfscores, \"shape_1\", \"shape_2\", \"score\", \"bregion\", False, True, ZLIMS=[0,1], \n",
    "#     #                       row_values=shapes, col_values=shapes)    \n",
    "\n",
    "#     # Color background, those cases without data.\n",
    "#     for ax in axes.flatten():\n",
    "#         # ax.set_facecolor('g')\n",
    "#         ax.set_facecolor([0.85, 0.85, 0.85])\n",
    "#         # ax.set_facecolor([0.1, 0.1, 0.1])\n",
    "#         # ax.set_facecolor([0.2, 0.4, 0.2])\n",
    "    \n",
    "#     if False:\n",
    "#         # Keep just the upper triangle\n",
    "#         ma_ut = np.triu(np.ones_like(self.Xinput, dtype=bool), k=k)\n",
    "\n",
    "#     savefig(fig, f\"{SAVEDIR_PLOTS}/heatmap_pairwise_decode-animal={grp}.pdf\")\n",
    "#     plt.close(\"all\")\n",
    "\n",
    "\n",
    "# from pythonlib.tools.pandastools import grouping_append_and_return_inner_items_good, plot_subplots_heatmap\n",
    "# grpdict = grouping_append_and_return_inner_items_good(DFSCORES_FULL, [\"animal\", \"date\"])\n",
    "# for grp, inds in grpdict.items():\n",
    "#     dfscores = DFSCORES_FULL.iloc[inds].reset_index(drop=True)\n",
    "#     shapes = sorted(dfscores[\"shape_1\"].unique())\n",
    "#     fig, axes = plot_subplots_heatmap(dfscores, \"shape_1\", \"shape_2\", \"score_minus_50\", \"bregion\", diverge=True, \n",
    "#                           annotate_heatmap=annotate_heatmap, ZLIMS=[-0.5, 0.5], \n",
    "#                           row_values=shapes, col_values=shapes, diverge_center_dark=True)\n",
    "\n",
    "#     # Color background, those cases without data.\n",
    "#     for ax in axes.flatten():\n",
    "#         ax.set_facecolor([0.85, 0.85, 0.85])\n",
    "\n",
    "#     savefig(fig, f\"{SAVEDIR_PLOTS}/heatmap_pairwise_decode-animal_date={grp}.pdf\")\n",
    "#     plt.close(\"all\")\n",
    "# def _compute_mask_shapes_exist(df, shapes_in_order, rowname, colname):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "    \n",
    "#     counts = np.zeros((len(shapes_in_order), len(shapes_in_order))) - np.inf\n",
    "#     for i, lab1 in enumerate(shapes_in_order):\n",
    "#         for j, lab2 in enumerate(shapes_in_order):\n",
    "#             n = sum((df[rowname] == lab1) & (df[colname] == lab2))\n",
    "#             counts[i, j] = n\n",
    "#     assert np.all(counts>=0)\n",
    "\n",
    "#     ma_exist = counts>0\n",
    "#     plt.figure()\n",
    "#     plt.imshow(ma_exist)\n",
    "\n",
    "#     return counts, ma_exist\n",
    "# counts, ma_exist = _compute_mask_shapes_exist(DFSCORES_FULL, shapes, \"shape_1\", \"shape_2\");\n",
    "# ma_none = ~ma_exist\n",
    "# ### Plot 1D histogram of decoding (highlighting if significantly > 0.5)\n",
    "# from pythonlib.tools.pandastools import aggregGeneral, stringify_values\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Agg across dates, so each shape_pair has one datapt\n",
    "# DFSCORES_AGG = aggregGeneral(stringify_values(DFSCORES), [\"shape_pair\", \"analysis_kind\", \"animal\", \"bregion\"], [\"score\", \"score_adjusted\", \"score_minus_50\"])\n",
    "# fig = sns.catplot(data=DFSCORES_AGG, x=\"bregion\", y=\"score_minus_50\", col=\"animal\", jitter=True, alpha=0.3)\n",
    "# for ax in fig.axes.flatten():\n",
    "#     ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR_PLOTS}/catplot_datapt=shape_pair-1.pdf\")\n",
    "\n",
    "# fig = sns.catplot(data=DFSCORES_AGG, x=\"bregion\", y=\"score_minus_50\", col=\"animal\", kind=\"bar\")\n",
    "# for ax in fig.axes.flatten():\n",
    "#     ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR_PLOTS}/catplot_datapt=shape_pair-2.pdf\")\n",
    "\n",
    "# fig = sns.catplot(data=DFSCORES_AGG, x=\"bregion\", y=\"score_minus_50\", col=\"animal\", kind=\"violin\")\n",
    "# for ax in fig.axes.flatten():\n",
    "#     ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR_PLOTS}/catplot_datapt=shape_pair-3.pdf\")\n",
    "\n",
    "# fig = sns.catplot(data=DFSCORES_AGG, x=\"bregion\", y=\"score_minus_50\", col=\"animal\", kind=\"boxen\", color=\"k\")\n",
    "# for ax in fig.axes.flatten():\n",
    "#     ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR_PLOTS}/catplot_datapt=shape_pair-4.pdf\")\n",
    "\n",
    "# # Plot for each date\n",
    "# fig = sns.catplot(data=DFSCORES, x=\"bregion\", y=\"score_minus_50\", row=\"animal\", col=\"date\", jitter=True, alpha=0.3)\n",
    "# # fig = sns.catplot(data=DFSCORES, x=\"bregion\", y=\"score_minus_50\", row=\"animal\", col=\"date\", kind=\"swarm\", size=3)\n",
    "# for ax in fig.axes.flatten():\n",
    "#     ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR_PLOTS}/catplot_datapt=shape_pair-5.pdf\")\n",
    "\n",
    "# fig = sns.catplot(data=DFSCORES, x=\"bregion\", y=\"score_minus_50\", row=\"animal\", hue=\"date\", kind=\"point\")\n",
    "# # fig = sns.catplot(data=DFSCORES, x=\"bregion\", y=\"score_minus_50\", row=\"animal\", col=\"date\", kind=\"swarm\", size=3)\n",
    "# for ax in fig.axes.flatten():\n",
    "#     ax.axhline(0, color=\"k\", alpha=0.5)\n",
    "# savefig(fig, f\"{SAVEDIR_PLOTS}/catplot_datapt=shape_pair-6.pdf\")\n",
    "\n",
    "# plt.close(\"all\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drag2_matlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
