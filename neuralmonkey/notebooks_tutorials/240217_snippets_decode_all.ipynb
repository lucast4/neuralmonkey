{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\"\"\"\"\n",
    "Devo code for all kinds of decoding analyses, inclduing:\n",
    "[NOTE: all are time-resolved]\n",
    "- default\n",
    "- cross-generalization (at each time point)\n",
    "- generalization over time\n",
    "--- variation: single-trial covert.\n",
    "- shared subspace (single decoder over time)\n",
    "\n",
    "Inspired to do this mainly re: quyestion of evidence for single trial shape decoding during palnning, espeically for chars.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e3fd17c4f13ba43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load a pre-computed Snippets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e64d1e318d5757d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper\n",
    "animal = \"Diego\"\n",
    "date = 230817\n",
    "question = \"RULE_BASE_stroke\"\n",
    "which_level = \"stroke\"\n",
    "list_time_windows = [(-0.6, 0.6)]\n",
    "events_keep = [\"00_stroke\"]\n",
    "\n",
    "combine_into_larger_areas = False\n",
    "exclude_bad_areas = True\n",
    "SPIKES_VERSION = \"kilosort_if_exists\"\n",
    "HACK_RENAME_SHAPES = False\n",
    "# fr_normalization_method = \"across_time_bins\"\n",
    "fr_normalization_method = None\n",
    "DFallpa = dfallpa_extraction_load_wrapper(animal, date, question, list_time_windows,\n",
    "                                          which_level=which_level, events_keep=events_keep,\n",
    "                                          combine_into_larger_areas = combine_into_larger_areas,\n",
    "                                          exclude_bad_areas = exclude_bad_areas,\n",
    "                                          SPIKES_VERSION = SPIKES_VERSION,\n",
    "                                          HACK_RENAME_SHAPES = HACK_RENAME_SHAPES,\n",
    "                                          fr_normalization_method=fr_normalization_method)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b6e8425ba4d829d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load a dataset (saved for Xuan)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f471c575413735b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To load and plot a dataset of neural activity across population, in a PopAnal class object.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "401a9851a443292c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d72addf5c1494c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# this is the path to the dataset\n",
    "# path = '/gorilla1/analyses/recordings/main/RSA/Diego-230615/agg_True-subtr_None-dist_euclidian_unbiased/SP_shape_loc/DFallpa.pkl'\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa.pkl\"\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_samp_and_stroke.pkl\"\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_pig_planning.pkl\"\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_pig_concat_trial_and_stroke_which_levels.pkl\"\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_char_concat_trial_and_stroke_Pancho_230126.pkl\"\n",
    "path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_char_trial_Pancho_230126.pkl\"\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "320be7d5ecbddf5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFallpa = pd.read_pickle(path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "335e4da034da5b2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### To save"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7eb640a16cc1bc17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save it\n",
    "import pickle\n",
    "path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_char_trial_Pancho_230126.pkl\"\n",
    "with open(path, \"wb\") as f:\n",
    "    pickle.dump(DFallpa, f)\n",
    "print(\"Saved to:\", path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c796042c0d19d1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load a DFallpa"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "122e1e23ec6b587"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Char, \n",
    "# animal = \"Pancho\"\n",
    "# date = 230126\n",
    "# do_combine = True\n",
    "\n",
    "# Single prim, novels\n",
    "# animal = \"Pancho\"\n",
    "# date = 230126\n",
    "animal = \"Diego\"\n",
    "date = 230817\n",
    "# date = 230817\n",
    "do_combine = False\n",
    "\n",
    "if do_combine:\n",
    "    # COMBINE trial and stroke\n",
    "    dir_suffix = \"test\"\n",
    "    question = None\n",
    "    # q_params = None\n",
    "    which_level = None\n",
    "    q_params = {\n",
    "        \"effect_vars\": [\"seqc_0_shape\", \"seqc_0_loc\"]\n",
    "    }\n",
    "    \n",
    "    combine_trial_and_stroke = True\n",
    "    \n",
    "    # PIG\n",
    "    # question_trial = \"PIG_BASE_trial\"\n",
    "    # question_stroke = \"PIG_BASE_stroke\"\n",
    "    # check_that_locs_match = True\n",
    "    \n",
    "    # CHAR\n",
    "    question_trial = \"CHAR_BASE_trial\"\n",
    "    question_stroke = \"CHAR_BASE_stroke\"\n",
    "    check_that_locs_match = True\n",
    "    check_that_shapes_match = True\n",
    "else:\n",
    "    # DONT COMBINE, use questions.\n",
    "    # question = \"CHAR_BASE_stroke\"\n",
    "    # question = \"CHAR_BASE_trial\"\n",
    "    # question = \"SP_shape_loc\"\n",
    "    question = \"PIG_BASE_stroke\"\n",
    "    # question = \"PIG_BASE_trial\"\n",
    "    combine_trial_and_stroke = False\n",
    "    # which_level = \"stroke\" # Doesnt matter\n",
    "    which_level = \"stroke\" # Doesnt matter\n",
    "    dir_suffix = question\n",
    "\n",
    "    # Load q_params\n",
    "    from neuralmonkey.analyses.rsa import rsagood_questions_dict, rsagood_questions_params\n",
    "    q_params = rsagood_questions_dict(animal, date, question)[question]\n",
    "\n",
    "############### PARAMS\n",
    "exclude_bad_areas = True\n",
    "SPIKES_VERSION = \"tdt\" # since Snippets not yet extracted for ks\n",
    "combine_into_larger_areas = False\n",
    "HACK_RENAME_SHAPES = False\n",
    "list_time_windows = [(-0.6, 0.6)]\n",
    "events_keep = None\n",
    "fr_normalization_method = \"across_time_bins\"\n",
    "########################################## RUN\n",
    "\n",
    "if combine_trial_and_stroke:\n",
    "    from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper_combine_trial_strokes\n",
    "    DFallpa = dfallpa_extraction_load_wrapper_combine_trial_strokes(animal, date, question_trial,\n",
    "                                                                       question_stroke,\n",
    "                                                list_time_windows, events_keep=events_keep,\n",
    "                                               combine_into_larger_areas = combine_into_larger_areas,\n",
    "                                               exclude_bad_areas=exclude_bad_areas,\n",
    "                                                SPIKES_VERSION=\"tdt\",\n",
    "                                                HACK_RENAME_SHAPES = HACK_RENAME_SHAPES,\n",
    "                                               fr_normalization_method=fr_normalization_method,\n",
    "                                                    check_that_shapes_match=check_that_shapes_match,\n",
    "                                                check_that_locs_match=check_that_locs_match)\n",
    "else:\n",
    "    from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper\n",
    "    DFallpa = dfallpa_extraction_load_wrapper(animal, date, question, list_time_windows,\n",
    "                                              which_level=which_level, events_keep=events_keep,\n",
    "                                              combine_into_larger_areas = combine_into_larger_areas,\n",
    "                                              exclude_bad_areas = exclude_bad_areas,\n",
    "                                              SPIKES_VERSION = SPIKES_VERSION,\n",
    "                                              HACK_RENAME_SHAPES = HACK_RENAME_SHAPES,\n",
    "                                              fr_normalization_method=fr_normalization_method)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58ea6f5073b3909f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Code example for benchmarking: decoding shapes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93edebd6e38ce91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This step takes in a representation of neural data and outputs a scalar score for how well you can decode \"shape\" from that data\n",
    "\n",
    "Here, this example is using the raw data (dimensionality = number of channels). The goal is to use methods to reduce the dimensionality of this data, each time running through this decoding benchmark, to compare the different methods"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "488ff1ca66a8098f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pa = DFallpa[\"pa\"].values[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d9464a47ba11ed8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pa.Xlabels[\"trials\"][:2].columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "389e5f898d84b074"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### First, pull out a specific PA. (just an example)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32c025e2bfc54ebe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE: tjhis is just for demonstration. Eventually you will want to loop thru all PA, scoring them all"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bb74aab4a961bd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import extract_single_pa\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10bc2b4059ed05b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make sure to normalize PA before running any modeling on it:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "583a1e729ac08b30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pa.norm_subtract_mean_each_chan"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84d07e7375dc049e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pa.norm_subtract_mean_each_chan()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "561c113813341660"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFallpa"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1a559c00690b540"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "True in pa.Chans"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e8232dc218ec46b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pa.Chans.index(True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4941bf500680c61d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.state_space_good import popanal_preprocess_scalar_normalization\n",
    "list_panorm = []\n",
    "plot_example_chan_number = None\n",
    "plot_example_split_var_string = None\n",
    "subtract_mean_at_each_timepoint=False\n",
    "subtract_mean_across_time_and_trial=True\n",
    "grouping_vars = None\n",
    "for pa in DFallpa[\"pa\"].tolist():\n",
    "    PAnorm, PAscal, PAscalagg, fig, axes, groupdict = popanal_preprocess_scalar_normalization(pa, grouping_vars, subtract_mean_each_level_of_var =\"IGNORE\",\n",
    "                                            plot_example_chan_number=plot_example_chan_number,\n",
    "                                            plot_example_split_var_string=plot_example_split_var_string,\n",
    "                                            DO_AGG_TRIALS=False,\n",
    "                                            subtract_mean_at_each_timepoint=subtract_mean_at_each_timepoint,\n",
    "                                            subtract_mean_across_time_and_trial=subtract_mean_across_time_and_trial)\n",
    "    list_panorm.append(PAnorm)\n",
    "DFallpa[\"pa\"] = list_panorm\n",
    "\n",
    "# del DFallpa[\"pa_norm\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "854db14b65f6c377"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pythonlib.globals import PATH_ANALYSIS_OUTCOMES\n",
    "import os\n",
    "SAVEDIR_ANALYSIS = f\"{PATH_ANALYSIS_OUTCOMES}/recordings/main/DECODE\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cab933058cb251a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Figure out how long is seuqence\n",
    "n_strokes_max = -1\n",
    "for i in range(2):\n",
    "    n_ignore = sum(PAnorm.Xlabels[\"trials\"][f\"seqc_{i}_shape\"]==\"IGNORE\")\n",
    "    n_total = len(PAnorm.Xlabels[\"trials\"][f\"seqc_{i}_shape\"])\n",
    "    print(n_ignore, n_total)\n",
    "    if n_ignore<n_total:\n",
    "        n_strokes_max=i+1\n",
    "assert n_strokes_max>0\n",
    "print(n_strokes_max)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a2fa80f4fc611b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Keep specific events"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9228636d0e758329"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFallpa[\"event\"].unique()\n",
    "events_keep = [\"03_samp\", \"04_go_cue\"]\n",
    "DFallpa = DFallpa[DFallpa[\"event\"].isin(events_keep)].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49f56c2188b45159"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PREPROCESS - factorize all relevant labels FIRST here.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8634a855e2b24c5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DFallpa"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1718534d31e4e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfallpa_preprocess_vars_conjunctions_extract\n",
    "dfallpa_preprocess_vars_conjunctions_extract(DFallpa, which_level=which_level)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "441abc9cc89c86b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dflab = pa.Xlabels[\"trials\"]\n",
    "sorted([col for col in dflab.columns if \"seqc_\" in col])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99c1d21c5e23270e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract all "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdabd18c2d872166"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import preprocess_factorize_class_labels_ints\n",
    "MAP_LABELS_TO_INT = preprocess_factorize_class_labels_ints(DFallpa)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87e0da3ce5099d79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sandbox -- distribution of variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f0c53a7cd8b4115"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Context\n",
    "\n",
    "var = \"CTXT_shapeloc_next\"\n",
    "vars_others = (\"CTXT_shapeloc_prev\", \"shape\", \"gridloc\", \"stroke_index_semantic\", \"task_kind\") # important to have SIS, to separate (shapeloc) from END.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20356c2de41fb50c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # var_loc_next = \"CTXT_loc_next\"\n",
    "    var_loc_next = \"CTXT_locclust_next\"\n",
    "    var_loc_prev = \"CTXT_locclust_prev\"\n",
    "    var_loc = \"loc_on_clust\"\n",
    "\n",
    "    LIST_VAR = [\n",
    "        \"CTXT_loc_next\",\n",
    "        \"CTXT_loc_next\",\n",
    "        \"CTXT_loc_next\",\n",
    "        \"CTXT_shape_next\",\n",
    "        \"CTXT_shape_next\",\n",
    "        \"CTXT_shape_next\",\n",
    "\n",
    "        \"task_kind\",\n",
    "        \"stroke_index\",\n",
    "        \"stroke_index_fromlast_tskstks\",\n",
    "        \"stroke_index_fromlast_tskstks\",\n",
    "        \"FEAT_num_strokes_task\",\n",
    "\n",
    "        \"shape\",\n",
    "        \"shape\",\n",
    "        # \"shape\",\n",
    "        var_loc,\n",
    "        var_loc,\n",
    "        var_loc,\n",
    "    ]\n",
    "    # More restrictive\n",
    "    LIST_VARS_OTHERS = [\n",
    "        [\"stroke_index_is_first\", \"task_kind\", var_loc_prev, \"shape\", var_loc],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", var_loc_prev, \"shape\", var_loc, \"CTXT_shape_next\"],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", \"CTXT_shape_prev\", var_loc_prev, \"shape\", var_loc, \"CTXT_shape_next\"],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", var_loc_prev, \"shape\", var_loc],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", var_loc_prev, \"shape\", var_loc, var_loc_next],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", \"CTXT_shape_prev\", var_loc_prev, \"shape\", var_loc, var_loc_next],\n",
    "\n",
    "        [\"stroke_index_is_first\", \"shape\", var_loc, \"CTXT_shape_prev\", var_loc_prev],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", \"CTXT_shape_prev\", var_loc_prev, \"shape\", var_loc],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", \"CTXT_shape_prev\", var_loc_prev, \"shape\", var_loc],\n",
    "        [\"stroke_index_is_first\", \"FEAT_num_strokes_task\", \"task_kind\", \"CTXT_shape_prev\", var_loc_prev, \"shape\", var_loc],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", var_loc_prev, \"shape\", var_loc, \"stroke_index\"],\n",
    "\n",
    "        # [\"stroke_index_is_first\", \"task_kind\", var_loc, var_loc_prev, var_loc_next],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", var_loc, \"CTXT_shape_prev\", var_loc_prev],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", var_loc, var_loc_prev],\n",
    "        # [\"stroke_index_is_first\", \"task_kind\", var_loc, \"gridloc_within\", \"CTXT_shape_prev\", var_loc_prev],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", \"shape\", \"CTXT_shape_prev\", var_loc_prev, var_loc_next],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", \"shape\", \"CTXT_shape_prev\", var_loc_prev],\n",
    "        [\"stroke_index_is_first\", \"task_kind\", \"shape\", var_loc_prev],\n",
    "        ]\n",
    "\n",
    "    assert len(LIST_VAR)==len(LIST_VARS_OTHERS)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35965fa2677a03f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1) Default: Time-resolved decoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36745f908f0c7fd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVEDIR_ANALYSIS = \"/tmp\"\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94465b7df045064f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List of task kinds\n",
    "pa = DFallpa[\"pa\"].values[0]\n",
    "pa.Xlabels[\"trials\"][\"task_kind\"].value_counts()\n",
    "\n",
    "LIST_TASK_KIND = pa.Xlabels[\"trials\"][\"task_kind\"].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa62eee84c10ed1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVEDIR = f\"{SAVEDIR_ANALYSIS}/1_time_resolved\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "print(SAVEDIR)\n",
    "\n",
    "n_min_trials = 6\n",
    "\n",
    "from neuralmonkey.utils.frmat import bin_frmat_in_time\n",
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_timeresolved_singlevar, decodewrapouterloop_categorical_timeresolved\n",
    "from pythonlib.tools.plottools import savefig\n",
    "import pandas as pd\n",
    "RES = []\n",
    "\n",
    "# list_vars_decode = [\"seqc_0_shape\", \"seqc_0_loc\"]\n",
    "# list_vars_decode = [\"seqc_0_shape\"]\n",
    "list_vars_decode = [\"shape_this_event\"]\n",
    "# list_vars_decode = [\"seqc_2_shape\"]\n",
    "\n",
    "# list_vars_decode = [\"shape_is_novel_all\"]\n",
    "\n",
    "time_bin_size = 0.2\n",
    "slide = 0.2\n",
    "max_nsplits = 2\n",
    "\n",
    "DFRES = decodewrapouterloop_categorical_timeresolved(DFallpa, list_vars_decode, SAVEDIR, time_bin_size, slide, n_min_trials,\n",
    "                                                     max_nsplits=max_nsplits)\n",
    "# \n",
    "# for i, row in DFallpa.iterrows():\n",
    "#     br = row[\"bregion\"]\n",
    "#     tw = row[\"twind\"]\n",
    "#     ev = row[\"event\"]\n",
    "#     PA = row[\"pa\"]\n",
    "#     \n",
    "#     for task_kind in LIST_TASK_KIND:\n",
    "#         pa = PA.slice_by_labels(\"trials\", \"task_kind\", [task_kind])\n",
    "#     \n",
    "#         # 2. Extract X from pa\n",
    "#         X = pa.X # (nchans, ntrials, ntimes)\n",
    "#         times = pa.Times\n",
    "#         dflab = pa.Xlabels[\"trials\"]\n",
    "#     \n",
    "#         \n",
    "#         for var_decode in list_vars_decode:\n",
    "#             print(br, ev, var_decode)\n",
    "#             \n",
    "#             # Prune dflab\n",
    "#             from pythonlib.tools.pandastools import filter_by_min_n\n",
    "#             dftmp = filter_by_min_n(dflab, var_decode, n_min_trials)\n",
    "#             \n",
    "#             if len(dftmp)>0:\n",
    "#                 indskeep = dftmp[\"_index\"].tolist()\n",
    "#                 Xthis = X[:, indskeep, :]\n",
    "#                 dflab_this = dflab.iloc[indskeep]\n",
    "#                 \n",
    "#                 if len(dflab_this[var_decode].unique())==1:\n",
    "#                     print(\"SKIPPING, becuase only one label:\")\n",
    "#                     print(dflab_this[var_decode].unique())\n",
    "#                     continue\n",
    "#         \n",
    "#                 if len(Xthis)>0:\n",
    "#                     res = decodewrap_categorical_timeresolved_singlevar(Xthis, times, dflab_this, [var_decode],\n",
    "#                                                   time_bin_size=time_bin_size, slide=slide, max_nsplits=max_nsplits)\n",
    "#                     for r in res:\n",
    "#                         r[\"event\"]=ev\n",
    "#                         r[\"bregion\"]=br\n",
    "#                         r[\"twind\"]=tw\n",
    "#                         r[\"var_decode\"]=var_decode\n",
    "#                         r[\"task_kind\"] = task_kind\n",
    "#                     RES.extend(res)\n",
    "#                 \n",
    "# DFRES = pd.DataFrame(RES)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8a276f76dd803cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4) Cross-condition decoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98ec3d6e76bf4ebb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For each time bin, decode shape genearlizing across location"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4237c1dd8d95bce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import decode_train_model, decode_categorical_cross_condition,decodewrap_categorical_timeresolved_cross_condition\n",
    "\n",
    "list_br = DFallpa[\"bregion\"].unique().tolist()\n",
    "list_tw = DFallpa[\"twind\"].unique().tolist()\n",
    "list_ev = DFallpa[\"event\"].unique().tolist()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f752951c3d6f1846"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAP_LABELS_TO_INT[\"shape\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3991acb980a7948e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVEDIR = \"/tmp\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78e6a7b2d10704a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAP_LABELS_TO_INT[\"loc\"][\"map_int_to_class\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8872524005a2f929"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_timeresolved_cross_condition, decodewrapouterloop_categorical_timeresolved_cross_condition\n",
    "\n",
    "filtdict = None\n",
    "separate_by_task_kind = True\n",
    "\n",
    "# PARAMS\n",
    "# subtract_mean_vars_conj = True # WHether to normalize by sutbracting mean within each level of othervar...\n",
    "\n",
    "\n",
    "# Context\n",
    "list_var_decode = [\n",
    "    \"taskconfig_shp_SHSEM\",\n",
    "    \"taskconfig_shp_SHSEM\",\n",
    "    \"taskconfig_shp_SHSEM\",\n",
    "    \"taskconfig_shploc_SHSEM\",\n",
    "    \"taskconfig_shploc_SHSEM\",\n",
    "    \"taskconfig_shploc_SHSEM\",\n",
    "]\n",
    "list_vars_conj = [\n",
    "    [\"task_kind\"], # minimal control\n",
    "    [\"seqc_0_shape\", \"seqc_0_center_binned\", \"task_kind\"], # control for first action.\n",
    "    [\"character\", \"task_kind\"], # control for image.\n",
    "    [\"task_kind\"], # minimal control\n",
    "    [\"seqc_0_shape\", \"seqc_0_center_binned\", \"task_kind\"], # control for first action.\n",
    "    [\"character\", \"task_kind\"], # control for image.\n",
    "    ]\n",
    "\n",
    "time_bin_size = 0.2\n",
    "slide = 0.2\n",
    "subtract_mean_vars_conj = False\n",
    "DFRES = decodewrapouterloop_categorical_timeresolved_cross_condition(DFallpa, list_var_decode,\n",
    "                                                     list_vars_conj,\n",
    "                                                     SAVEDIR, time_bin_size=time_bin_size, slide=slide,\n",
    "                                                     subtract_mean_vars_conj=subtract_mean_vars_conj,\n",
    "                                                                     filtdict=filtdict,\n",
    "                                                                     separate_by_task_kind=separate_by_task_kind)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea62377c46cf112b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2b) Separate decoder for each level of other var (then take average over decoders). Useful to controlling for variables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14744ec7fa463a16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfallpa_preprocess_vars_conjunctions_extract\n",
    "dfallpa_preprocess_vars_conjunctions_extract(DFallpa, which_level)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e6958e15184de87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess for sequence context\n",
    "SEQ_CONTEXT_MODE = \"seq_pred\"\n",
    "            from neuralmonkey.analyses.rsa import rsagood_questions_dict, rsagood_questions_params\n",
    "            from neuralmonkey.analyses.rsa import preprocess_prune_pa_enough_data, preprocess_rsa_prepare_popanal_wrapper\n",
    "            \n",
    "            q_params = rsagood_questions_dict(animal, date, SEQ_CONTEXT_MODE)[SEQ_CONTEXT_MODE]\n",
    "            # q_params[\"effect_vars\"] = [\"shape_this_event\", \"loc_this_event\", \"stroke_index_fromlast_tskstks\"]         \n",
    "            # q_params[\"effect_vars\"] = [\"shape_this_event\", \"loc_this_event\", \"stroke_index\"]         \n",
    "            q_params[\"effect_vars\"] = [var_decode] + vars_conj_condition         \n",
    "            \n",
    "            # q_params[\"exclude_first_stroke\"] = False\n",
    "            pa, res_check_tasksets, res_check_effectvars = preprocess_rsa_prepare_popanal_wrapper(pa, **q_params)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8105d779dd26c63c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import decodewrapouterloop_categorical_timeresolved_within_condition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46879615721504a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVEDIR = \"/tmp\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5692844afa5b51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Variable --> shape config\n",
    "pa = DFallpa[\"pa\"].values[0]\n",
    "dflab = pa.Xlabels[\"trials\"]\n",
    "dflab[:10]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59fc914abdb214aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "\n",
    "separate_by_task_kind = True\n",
    "\n",
    "# Context\n",
    "# Context\n",
    "list_var_decode = [\n",
    "    \"seqc_0_shape\",\n",
    "    \"seqc_0_shape\",\n",
    "    \"seqc_0_shapesemcat\",\n",
    "    \"seqc_0_locon_binned\",\n",
    "]\n",
    "list_vars_conj = [\n",
    "    [\"seqc_0_center_binned\", \"gridsize\", \"task_kind\"],\n",
    "    [\"taskconfig_shp_SHSEM\", \"seqc_0_center_binned\", \"task_kind\"], # control for parse\n",
    "    [\"seqc_0_center_binned\", \"gridsize\", \"task_kind\"],\n",
    "    [\"seqc_0_shape\", \"gridsize\", \"task_kind\"],\n",
    "    ]\n",
    "# filtdict = {\n",
    "#     \"stroke_index\":[0,3,4,5,6,7,8],\n",
    "# }\n",
    "# TRy with and without this.\n",
    "filtdict = None\n",
    "\n",
    "\n",
    "# RUns\n",
    "max_nsplits = 2\n",
    "time_bin_size = 0.2\n",
    "slide = 0.2\n",
    "\n",
    "# filtdict = {\n",
    "#     \"stroke_index\":[0,1, 23,4,5,6,7,8],\n",
    "# }\n",
    "# filtdict = None\n",
    "\n",
    "# PARAMS\n",
    "DFRES = decodewrapouterloop_categorical_timeresolved_within_condition(DFallpa, list_var_decode,\n",
    "                                                     list_vars_conj,\n",
    "                                                    SAVEDIR, time_bin_size=time_bin_size, slide=slide, filtdict=filtdict,\n",
    "                                                                      separate_by_task_kind=separate_by_task_kind)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "659c92a799c90cf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pa = DFallpa[\"pa\"].values[0]\n",
    "dflab = pa.Xlabels[\"trials\"]\n",
    "from pythonlib.tools.pandastools import extract_with_levels_of_conjunction_vars\n",
    "prune_min_n_trials = 5\n",
    "prune_min_n_levs = 2\n",
    "plot_counts_heatmap_savepath = \"/tmp/tmp.png\"\n",
    "balance_no_missed_conjunctions = False\n",
    "extract_with_levels_of_conjunction_vars(dflab, list_var_decode[0], list_vars_conj[0],\n",
    "                                                                 n_min_across_all_levs_var=prune_min_n_trials,\n",
    "                                                                 lenient_allow_data_if_has_n_levels=prune_min_n_levs,\n",
    "                                                                 prune_levels_with_low_n=True,\n",
    "                                                                 ignore_values_called_ignore=True,\n",
    "                                                                 plot_counts_heatmap_savepath=plot_counts_heatmap_savepath,\n",
    "                                                                 balance_no_missed_conjunctions=balance_no_missed_conjunctions)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11427ae70eb5cc2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) Train a single decoder on specific dataset, then test across all time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3691223d7c46942"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# HACK - combine all bregions into single pa\n",
    "if False:\n",
    "    from neuralmonkey.classes.population import concatenate_popanals_flexible\n",
    "    list_wl = DFallpa[\"which_level\"].unique().tolist()\n",
    "    resthis = []\n",
    "    for wl in list_wl:\n",
    "        for ev in list_ev:\n",
    "            for tw in list_tw:\n",
    "                a = DFallpa[\"event\"] == ev\n",
    "                b = DFallpa[\"twind\"] == tw\n",
    "                c = DFallpa[\"which_level\"] == wl\n",
    "                dfthis = DFallpa[a & b]\n",
    "                pa = concatenate_popanals_flexible(dfthis[\"pa\"].tolist(), \"chans\")[0]\n",
    "                resthis.append({\n",
    "                    \"which_level\":wl,\n",
    "                    \"event\":ev,\n",
    "                    \"bregion\":\"ALL\",\n",
    "                    \"twind\":tw,\n",
    "                    \"pa\":pa\n",
    "                })\n",
    "    DFallpa_ALL = pd.DataFrame(resthis)\n",
    "    DFallpa_ALL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0c16b1af399872b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trials_train = pa.Xlabels[\"trials\"][pa.Xlabels[\"trials\"][\"task_kind\"]==\"prims_single\"].index.tolist()\n",
    "trials_test = pa.Xlabels[\"trials\"][pa.Xlabels[\"trials\"][\"task_kind\"]==\"prims_on_grid\"].index.tolist()\n",
    "ntrials_expected_assert = len(pa.Xlabels[\"trials\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71d93407c75be66d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HACK = False\n",
    "if HACK:\n",
    "    # Use all brain regions\n",
    "    DFallpaTHIS = DFallpa_ALL\n",
    "else:\n",
    "    DFallpaTHIS = DFallpa\n",
    "\n",
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_single_decoder_across_time\n",
    "list_br = DFallpaTHIS[\"bregion\"].unique().tolist()\n",
    "list_tw = DFallpaTHIS[\"twind\"].unique().tolist()\n",
    "# list_var_decode = [\"seqc_0_shape\", \"seqc_0_loc\"]\n",
    "list_var_decode = [\"seqc_0_shape\"]\n",
    "# ev_train = \"03_samp\"\n",
    "# twind_train = [0.4, 0.6]\n",
    "ev_train = \"06_on_strokeidx_0\"\n",
    "twind_train = [0.05, 0.35]\n",
    "\n",
    "ev_test = \"03_samp\"\n",
    "# ev_test = \"06_on_strokeidx_0\"\n",
    "time_bin_size=0.05\n",
    "slide=0.025\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e57ef9aec8741621"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RES = []\n",
    "for br in list_br:\n",
    "    for tw in list_tw:\n",
    "        # 1. Extract the specific pa for this (br, tw)\n",
    "        \n",
    "        # Prep train and test PA\n",
    "        PA_train = extract_single_pa(DFallpaTHIS, br, tw, event=ev_train)\n",
    "        PA_train = PA_train.slice_by_dim_values_wrapper(\"trials\", trials_train)\n",
    "        PA_train = PA_train.slice_by_dim_values_wrapper(\"times\", twind_train)\n",
    "        PA_train = PA_train.agg_wrapper(\"times\")\n",
    "        x_train = PA_train.X.squeeze(axis=2).T # (ntrials, nchans)\n",
    "        \n",
    "        PA_test = extract_single_pa(DFallpaTHIS, br, tw, event=ev_test)\n",
    "        PA_test = PA_test.slice_by_dim_values_wrapper(\"trials\", trials_test)\n",
    "        if time_bin_size is not None:\n",
    "            PA_test = PA_test.agg_by_time_windows_binned(time_bin_size, slide)\n",
    "        X_test = PA_test.X # (chans, trials, times)\n",
    "        times_test = PA_test.Times\n",
    "        \n",
    "        for var_decode in list_var_decode:\n",
    "\n",
    "            # Train model\n",
    "            labels_train = PA_train.Xlabels[\"trials\"][var_decode].tolist()\n",
    "            \n",
    "            # Get test data\n",
    "            labels_test = PA_test.Xlabels[\"trials\"][var_decode].tolist()\n",
    "            \n",
    "            res = decodewrap_categorical_single_decoder_across_time(x_train, labels_train, X_test, labels_test,\n",
    "                                                                  times_test, do_std=False)\n",
    "        \n",
    "            for r in res:\n",
    "                r[\"var_decode\"]=var_decode\n",
    "                r[\"bregion\"]=br\n",
    "                r[\"twind\"]=tw   \n",
    "                r[\"event\"] = ev_test\n",
    "\n",
    "            RES.extend(res)\n",
    "\n",
    "DFRES = pd.DataFrame(RES)\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6abaf4b5797db13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract single trial results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3a21d2839843b42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# PARAMS\n",
    "var_decode = \"seqc_0_shape\"\n",
    "bregion = \"PMv\"\n",
    "twind = (-0.4, 0.6)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f98b66754dbece70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "a = DFRES[\"var_decode\"]==var_decode\n",
    "b = DFRES[\"bregion\"]==bregion\n",
    "c = DFRES[\"twind\"]==twind\n",
    "dfthis = DFRES[a & b & c]\n",
    "\n",
    "times = dfthis[\"time\"]\n",
    "import numpy as np\n",
    "labels_predicted = np.stack(dfthis[\"labels_predicted\"]).T # (ntrials, ntimes)\n",
    "labels_test = np.stack(dfthis[\"labels_test\"]).T\n",
    "conf_scores = np.transpose(np.stack(dfthis[\"conf_scores\"]), [1,0,2]) # (ntrials, ntimes, nclasses)\n",
    "\n",
    "# score each time bin as correct or incorrect\n",
    "labels_correct = (labels_predicted == labels_test).astype(int)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8296d5b9f2e7ea8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For each trial, what was its label\n",
    "assert np.all(np.diff(labels_test, axis=1))==0, \"otherwise cant do next step.\"\n",
    "labels_each_trial = labels_test[:,0]\n",
    "labels_orig = PA_test.Xlabels[\"trials\"][var_decode].tolist()\n",
    "assert len(labels_orig)==len(labels_each_trial)\n",
    "\n",
    "map_labint_to_trials = {}\n",
    "map_labint_to_laborig = {}\n",
    "labels_unique = np.unique(labels_each_trial)\n",
    "for lab in labels_unique:\n",
    "    inds_this_label = np.argwhere(labels_each_trial == lab).squeeze() # the indices which ahve this label as the CORRECT\n",
    "    map_labint_to_trials[lab] = inds_this_label\n",
    "\n",
    "    # Map it back to original label\n",
    "    lab_orig = PA_test.Xlabels[\"trials\"][var_decode][inds_this_label].unique()\n",
    "    assert len(lab_orig)==1\n",
    "    map_labint_to_laborig[lab] = lab_orig[0]\n",
    "\n",
    "map_trial_to_labint = {i:labint for i, labint in enumerate(labels_each_trial)}\n",
    "print(map_labint_to_laborig)    \n",
    "map_laborig_to_labint = {}\n",
    "for labint, laborig in map_labint_to_laborig.items():\n",
    "    assert laborig not in map_laborig_to_labint\n",
    "    map_laborig_to_labint[laborig] = labint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pythonlib.tools.plottools import makeColors\n",
    "pcols = makeColors(len(map_labint_to_laborig))\n",
    "map_trial_to_seq = {}\n",
    "map_trial_to_seq_ints = {}\n",
    "for i, seq in enumerate(PA_test.Xlabels[\"trials\"].loc[:, [\"seqc_0_shape\", \"seqc_1_shape\"]].values.tolist()):\n",
    "    map_trial_to_seq[i] = (tuple(seq))\n",
    "    map_trial_to_seq_ints[i] = [map_laborig_to_labint[s] if s in map_laborig_to_labint else s for s in seq]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3025b97e2c823fa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pick n random trials\n",
    "import random\n",
    "n=  9\n",
    "trials_all = list(range(len(map_trial_to_labint)))\n",
    "trials = random.sample(trials_all, n)\n",
    "ncols = 3\n",
    "nrows = int(np.ceil(len(trials)/ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*4, nrows*3), sharex=True, sharey=True)\n",
    "\n",
    "for tr, ax in zip(trials, axes.flatten()):\n",
    "    \n",
    "    # ax = axes.flatten()[0]\n",
    "    lab_pred = labels_predicted[tr,:]\n",
    "    # lab_corr = labels_correct[trial,:]\n",
    "    # lab_test = labels_test[trial,:]\n",
    "    # ax.plot(times, lab_pred, \"-ok\"),\n",
    "    # ax.plot(times, lab_test, \"-r\")\n",
    "    \n",
    "    # for each class, plot its time series\n",
    "    for labint in map_labint_to_laborig:\n",
    "        cs_this_lab = conf_scores[tr, :, labint].squeeze()\n",
    "        \n",
    "        ax.plot(times, cs_this_lab, label=labint, color=pcols[labint])\n",
    "        # ax.plot(times[lab_pred==labint], cs_this_lab[lab_pred==labint], \"-\", color=pcols[labint], linewidth=4)\n",
    "        ax.plot(times[lab_pred==labint], cs_this_lab[lab_pred==labint], \"s\", color=pcols[labint])\n",
    "    \n",
    "    ax.axvline(0, color=\"k\", alpha=0.5)\n",
    "    ax.set_title(f\"{var_decode}={map_trial_to_labint[tr]}\", color=pcols[map_trial_to_labint[tr]])\n",
    "    ax.set_xlabel(f\"seq: {map_trial_to_seq_ints[tr]}\")\n",
    "    ax.legend()\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eeac8f2e7321bfd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For each class label, collect all trials for which that is the correct label, and overlap\n",
    "\n",
    "labels_unique = np.unique(labels_each_trial)\n",
    "ncols = 3\n",
    "nrows = int(np.ceil(len(labels_unique)/ncols))\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*4, nrows*4))\n",
    "\n",
    "for lab, ax in zip(labels_unique, axes.flatten()):\n",
    "    inds_this_label = np.argwhere(labels_each_trial == lab).squeeze() # the indices which ahve this label as the CORRECT \n",
    "    ax.plot(times, labels_predicted[inds_this_label, :].T, \"-ok\", alpha=0.05)\n",
    "    ax.set_title(lab)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8efa1735ce6376c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "ax = axes.flatten()[0]\n",
    "ax.plot(times, labels_correct.T, \"xk\", alpha=0.003);"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c7a8e07c6d583ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### Plot the results, comparing score across methods!!\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "fig = sns.relplot(data=DFRES, x=\"time\", y=\"score\", hue=\"bregion\", col=\"var_decode\",  kind=\"line\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ddae94bd60f728e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### Plot the results, comparing score across methods!!\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "fig = sns.relplot(data=DFRES, x=\"time\", y=\"score\", hue=\"bregion\", col=\"var_decode\",  kind=\"line\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ef8b1c64ea5cadd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 4) Cross-decoding across time bins"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3e89d8c3064a967"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import decodewrapouterloop_categorical_cross_time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5483ffe2c1ea629f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVEDIR_ANALYSIS = \"/tmp\"\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af81acf8ae6cd5d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_cross_time\n",
    "\n",
    "SAVEDIR = f\"{SAVEDIR_ANALYSIS}/3_cross_temporal\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "print(SAVEDIR)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3813e5625d5647dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### A variation, where instead of first concatting PAs, just compute decode separately (and across PA) and then concatenate to plot\n",
    "Advantage: dont have to have identical trials, which is needed if you want to concat breigons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3658025bc4117336"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "assert False, \"add methdo to subtract mean in other window...\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28003a0e2a0f59f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFallpa"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb762d8394e495c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFallpa_TEST = DFallpa[:20]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8cd08d2eabd4017"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_var_decode"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "277450d6e1171809"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from neuralmonkey.analyses.decode_good import preprocess_extract_X_and_labels\n",
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_cross_time, decodewrapouterloop_categorical_cross_time_plot\n",
    "\n",
    "SAVEDIR = f\"{SAVEDIR_ANALYSIS}/3_cross_temporal\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "print(SAVEDIR)\n",
    "\n",
    "# Make sure all pa use the same variables to refer to shapes.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "# warnings.filterwarnings(\"error\")\n",
    "time_bin_size = 0.3\n",
    "slide=0.3\n",
    "\n",
    "list_vars_decode = [\"seqc_0_shape\"]\n",
    "list_ev = ['04_go_cue', '06_on_STK_1']\n",
    "\n",
    "assert len(DFallpa[\"twind\"].unique())==1, \"not big deal. just change code below to iter over all (ev, tw).\"\n",
    "\n",
    "from neuralmonkey.analyses.decode_good import decodewrapouterloop_categorical_cross_time\n",
    "DFRES = decodewrapouterloop_categorical_cross_time(DFallpa_TEST, list_var_decode, time_bin_size, slide)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18e78f93ad0a24c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_cross_time, decodewrapouterloop_categorical_cross_time_plot\n",
    "decodewrapouterloop_categorical_cross_time_plot(DFRES, SAVEDIR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb93cb1ae6dee162"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Variation, focusing on \"shape_this_event\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9266dbf14fa3a06d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_var_decode = [\"shape_this_event\"]\n",
    "time_bin_size = 0.2\n",
    "slide = 0.2\n",
    "DFRES = decodewrapouterloop_categorical_cross_time(DFallpa, list_var_decode, time_bin_size, slide, savedir_ndata=\"/tmp\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f256b68bd8e88050"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFRES[:2]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40e8fbfe3e9fb2f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for var in [\"event_train\", \"event_test\", \"task_kind_train\", \"task_kind_test\"]:\n",
    "    print(DFRES[var].unique())\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e137d821cf73cebb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "inds = list(range(100000))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b04d9cab20007a67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.all(np.diff(inds)==1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b0e131f5af23123"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "(list(sorted(set(inds)))==inds) and (inds[-1] == len(inds)-1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b568bc83ee56db9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "(list(sorted(set(inds)))==inds) and (inds[-1] == len(inds)-1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4af0d8c987c2465"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2ebc0a166e61379b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "all([i2-i1==1 for i1, i2 in zip(inds[:-1], inds[1:])])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6b9549a0b1e970b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### New plots, which compare decoding across-context vs. within-context, etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a08e6fd791aa04c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFRESTHIS = DFRES[DFRES[\"bregion\"].isin([\"M1_m\", \"PM_v\"])].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "802badf0ea8691fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import decodewrapouterloop_categorical_cross_time_plot_compare_contexts\n",
    "\n",
    "var_decode = \"shape_this_event\"\n",
    "SAVEDIR = \"/tmp\"\n",
    "decodewrapouterloop_categorical_cross_time_plot_compare_contexts(DFRESTHIS, var_decode,\n",
    "                                                                     SAVEDIR)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63a3476c431b9115"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### For a given decoder, plot its predictions during a given event [OBSOLETE< see #5 below)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69deb18aa11e2266"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bregion = \"PMv\"\n",
    "\n",
    "var_decode = \"seqc_0_shape\"\n",
    "event_train = \"04_go_cue\"\n",
    "tbin_train = 1\n",
    "event_test = \"06_on_STK_1\"\n",
    "tbin_test = 1\n",
    "\n",
    "# var_decode = \"seqc_0_shape\"\n",
    "# event_train = \"04_go_cue\"\n",
    "# tbin_train = 1\n",
    "# event_test = \"06_on_STK_0\"\n",
    "# tbin_test = 1\n",
    "# \n",
    "# var_decode = \"seqc_0_shape\"\n",
    "# event_train = \"06_on_STK_0\"\n",
    "# tbin_train = 2\n",
    "# event_test = \"04_go_cue\"\n",
    "# tbin_test = 1\n",
    "\n",
    "a = DFRES[\"bregion\"] == bregion\n",
    "b = DFRES[\"var_decode\"] == var_decode\n",
    "c = DFRES[\"event_train\"] == event_train\n",
    "d = DFRES[\"tbin_train\"] == tbin_train\n",
    "e = DFRES[\"event_test\"] == event_test\n",
    "f = DFRES[\"tbin_test\"] == tbin_test\n",
    "\n",
    "tmp = DFRES[a & b & c & d & e & f]\n",
    "assert len(tmp)==1\n",
    "\n",
    "# Labels (convert label ints to actual value)\n",
    "labels_pred = tmp[\"labels_predicted\"].values[0]\n",
    "map_int_to_lab = tmp[\"map_int_to_lab\"].values[0]\n",
    "labels_pred = [map_int_to_lab[i] for i in labels_pred]\n",
    "\n",
    "score = tmp[\"score\"].values[0]\n",
    "\n",
    "# For each trial, compare to its sequence context\n",
    "inds_keep_test = tmp[\"inds_keep_test\"].values[0]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "106c2e0e46abc6a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3daaef98ed34201b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pa_test = extract_single_pa(DFallpa, bregion, twind, \"trial\", event=event_test)\n",
    "dflab_test = pa_test.Xlabels[\"trials\"].iloc[inds_keep_test].copy()\n",
    "\n",
    "\n",
    "list_seq = dflab_test.loc[:, [\"seqc_0_shape\", \"seqc_1_shape\"]].values.tolist() # list of n-tuples (len of seq)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c1824d8f13b0e8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dflab_test[\"labels_pred\"] = labels_pred\n",
    "dflab_test[:5]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f1c808932d0a3a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.displot(data=dflab_test, x=\"labels_pred\", row=\"seqc_0_shape\", col=\"seqc_1_shape\", height=5)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb004a290865470e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sumamraize:\n",
    "\n",
    "# frequency of prediction matching first shape\n",
    "# same, for second shape.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccde37f8286c734a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5) Cross-temporal decoder, but with decoder trained using one variable (e.g., seqc_0_shape) and testing prediction of another variable (e.g., seqc_1_shape).\n",
    "Useful if, for example, want to see if decoder trained during visual presentation can decode 2nd stroke DURING 1st stroke."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1487d1d771d3490"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(range(1,3))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89a147e241b53ce2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVEDIR = f\"{SAVEDIR_ANALYSIS}/4_cross_temporal_diff_var_train_test\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "print(SAVEDIR)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d443eeb181b33520"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFallpa[\"event\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ab9fc36dea9c6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_cross_time, decodewrapouterloop_categorical_cross_time_cross_var"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df788b7c1c64483d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = sorted(set(DFRES[\"var_decode_train\"].tolist()))\n",
    "B = sorted(set(DFRES[\"var_decode_test\"].tolist()))\n",
    "list_var_decode_train_test = [(a, b) for a in A for b in B]\n",
    "list_var_decode_train_test\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43d0bb9d59044017"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make sure all pa use the same variables to refer to shapes.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"default\")\n",
    "# warnings.filterwarnings(\"error\")\n",
    "\n",
    "# list_var_decode_train_test = [\n",
    "#     [\"seqc_0_shape\", \"seqc_1_shape\"], # (variable to construct decoder, variable that you will try to predict).\n",
    "#     [\"seqc_0_shape\", \"seqc_2_shape\"], # (variable to construct decoder, variable that you will try to predict).\n",
    "#     [\"seqc_1_shape\", \"seqc_2_shape\"] # (variable to construct decoder, variable that you will try to predict).\n",
    "# ]\n",
    "list_var_decode_train_test = [\n",
    "    [\"seqc_0_shape\", \"seqc_1_shape\"], # (variable to construct decoder, variable that you will try to predict).\n",
    "]\n",
    "\n",
    "labels_ignore = [\"IGNORE\", (\"IGNORE\",)]\n",
    "# list_ev = ['04_go_cue', '06_on_STK_0', '06_on_STK_1', '06_on_STK_2']\n",
    "list_ev = ['04_go_cue', '06_on_STK_0']\n",
    "\n",
    "assert len(DFallpa[\"twind\"].unique())==1, \"not big deal. just change code below to iter over all (ev, tw).\"\n",
    "\n",
    "SAVEDIR = f\"{SAVEDIR_ANALYSIS}/4_cross_temporal_diff_var_train_test\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "print(SAVEDIR)\n",
    "\n",
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_cross_time\n",
    "\n",
    "# Make sure all pa use the same variables to refer to shapes.\n",
    "time_bin_size = 0.3\n",
    "slide=0.3\n",
    "\n",
    "\n",
    "DFRES = decodewrapouterloop_categorical_cross_time_cross_var(DFallpa,\n",
    "                                                     list_var_decode_train_test,\n",
    "                                                         time_bin_size, slide)\n",
    "from neuralmonkey.analyses.decode_good import decodewrap_categorical_cross_time, decodewrapouterloop_categorical_cross_time_plot\n",
    "decodewrapouterloop_categorical_cross_time_plot(DFRES, SAVEDIR)\n",
    "\n",
    "# \n",
    "# assert len(DFallpa[\"twind\"].unique())==1, \"not big deal. just change code below to iter over all (ev, tw).\"\n",
    "# \n",
    "# RES = []\n",
    "# for br in list_br:\n",
    "#     for tw in list_tw:\n",
    "#         for ev_train in list_ev:\n",
    "#             for ev_test in list_ev:\n",
    "# \n",
    "#                 print(br, tw, ev_train, ev_test)\n",
    "# \n",
    "#                 # TRAIN\n",
    "#                 PA_train = extract_single_pa(DFallpa, br, tw, event=ev_train)\n",
    "#                 if time_bin_size is not None:\n",
    "#                     PA_train = PA_train.agg_by_time_windows_binned(time_bin_size, slide)\n",
    "# \n",
    "#                 # TEST\n",
    "#                 PA_test = extract_single_pa(DFallpa, br, tw, event=ev_test)\n",
    "#                 if time_bin_size is not None:\n",
    "#                     PA_test = PA_test.agg_by_time_windows_binned(time_bin_size, slide)\n",
    "# \n",
    "#                 for var_decode_train, var_decode_test in list_var_decode_train_test:\n",
    "# \n",
    "#                     X_train, labels_train, times_train = preprocess_extract_X_and_labels(PA_train, var_decode_train)\n",
    "#                     X_test, labels_test, times_test = preprocess_extract_X_and_labels(PA_test, var_decode_test)\n",
    "# \n",
    "#                     if len(set(labels_train))==1 or len(set(labels_test))==1:\n",
    "#                         print(\"SKIPPING, becuase only one label:\")\n",
    "#                         print(\"Train:\", set(labels_train))\n",
    "#                         print(\"Test:\", set(labels_test))\n",
    "#                         continue\n",
    "# \n",
    "#                     # Only do splits if these are same trials\n",
    "#                     do_train_test_kfold_splits = labels_train==labels_test\n",
    "# \n",
    "#                     res = decodewrap_categorical_cross_time(X_train, labels_train, times_train,\n",
    "#                                                       X_test, labels_test, times_test,\n",
    "#                                                       do_std=False, labels_ignore=labels_ignore,\n",
    "#                                                             do_train_test_kfold_splits=do_train_test_kfold_splits)\n",
    "# \n",
    "#                     for r in res:\n",
    "#                         r[\"var_decode_train\"]=var_decode_train\n",
    "#                         r[\"var_decode_test\"]=var_decode_test\n",
    "#                         r[\"bregion\"]=br\n",
    "#                         r[\"event_train\"]=ev_train\n",
    "#                         r[\"event_test\"]=ev_test\n",
    "# \n",
    "#                     RES.extend(res)\n",
    "# DFRES = pd.DataFrame(RES)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "572ae792311d1a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LOAD a pre-saved results from decoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ce7eb19a2692bed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pythonlib.tools.pandastools import grouping_print_n_samples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pythonlib.tools.pandastools import applyFunctionToAllRows\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "import os\n",
    "from pythonlib.tools.pandastools import plot_45scatter_means_flexible_grouping\n",
    "from pythonlib.tools.plottools import savefig\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3824ff7b34b8b0fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pancho\n",
    "# TIME_TRAIN_REL_TEST = 0.075\n",
    "# TIME_WIND_TEST_REL_EVENT = [-0.3, 0.3]\n",
    "\n",
    "# TIME_TRAIN_REL_TEST = 0.175\n",
    "# TIME_WIND_TEST_REL_EVENT = [-0.3, 0.4]\n",
    "\n",
    "# TIME_TRAIN_REL_TEST = 0.225\n",
    "# TIME_WIND_TEST_REL_EVENT = [-0.6, 0.6]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "615dd90ea3b9ec89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# animal = \"Pancho\"\n",
    "# date = 230126\n",
    "\n",
    "N_STROKES_MAX = 4\n",
    "for animal, date, question in [\n",
    "    (\"Pancho\", 230623, \"PIG\"),\n",
    "    (\"Diego\", 230628, \"PIG\"),\n",
    "    (\"Pancho\", 230626, \"PIG\"),\n",
    "    (\"Diego\", 230630, \"PIG\"),\n",
    "    (\"Pancho\", 230126, \"CHAR\"),\n",
    "    (\"Diego\", 231201, \"CHAR\"),\n",
    "    (\"Diego\", 231204, \"CHAR\"),\n",
    "    (\"Diego\", 231219, \"CHAR\"),\n",
    "]:\n",
    "    # animal = \"Diego\"\n",
    "    # date = 231219\n",
    "    # question = \"CHAR\"\n",
    "    combined_trial_stroke = 1\n",
    "    combine_areas = False\n",
    "    which_decode = \"3_cross_temporal\"\n",
    "    \n",
    "    ############################## LOAD DATA\n",
    "    SAVEDIR_LOAD = f\"/gorilla1/analyses/recordings/main/DECODE/{animal}-{date}/{question}-combined_{combined_trial_stroke}-combine_areas_{combine_areas}\" \n",
    "    # SAVEDIR = f\"/gorilla1/analyses/recordings/main/DECODE/{animal}-{date}/{question}-combined_{combined_trial_stroke}-combine_areas_{combine_areas}/{which_decode}\"\n",
    "    path = f\"{SAVEDIR_LOAD}/{which_decode}/DFRES.pkl\"\n",
    "    print(SAVEDIR_LOAD)\n",
    "    \n",
    "    DFRES = pd.read_pickle(path)    \n",
    "    \n",
    "    ############################# PREP DATAFRAME\n",
    "    ##### Context (same, diff) plots, binning tbins --> scalar\n",
    "    # Give new column that classifies the \"context\" \n",
    "    def F(x):\n",
    "        # If is not strokes, then ignore it (throw out)\n",
    "        if \"06_on_\" not in x[\"event_train\"]:\n",
    "            return \"IGNORE\"\n",
    "            \n",
    "        # Classify context\n",
    "        tktrain, tktest, evtrain, evtest = x[\"task_kind_train\"], x[\"task_kind_test\"], x[\"event_train\"], x[\"event_test\"]\n",
    "        if tktrain==tktest and evtrain==evtest:\n",
    "            return \"same\"\n",
    "        elif (tktrain==tktest) and (not evtrain==evtest):\n",
    "            return \"same_tk_diff_ev\"\n",
    "        elif (not tktrain==tktest) and (evtrain==evtest):\n",
    "            return \"diff_tk_same_ev\"\n",
    "        else:\n",
    "            return \"diff_tk_diff_ev\"    \n",
    "    DFRES = applyFunctionToAllRows(DFRES, F, \"context_tk_ev\")\n",
    "    \n",
    "    # Also group all \"diff\" into a single \"diff\"\n",
    "    inds = DFRES[\"context_tk_ev\"].isin([\"same_tk_diff_ev\", \"diff_tk_same_ev\", \"diff_tk_diff_ev\"])\n",
    "    DFRES[\"context_tk_ev_simple\"] = DFRES[\"context_tk_ev\"]\n",
    "    DFRES.loc[inds, \"context_tk_ev_simple\"] = \"diff\"\n",
    "        \n",
    "    # Only call \"diff\" those cases that are diff task kind... (avoid confounds in correlations across stroke indices, for same task kind).\n",
    "    inds = DFRES[\"context_tk_ev\"].isin([\"diff_tk_same_ev\", \"diff_tk_diff_ev\"])\n",
    "    DFRES[\"context_tk_ev_simple_diff_tk\"] = DFRES[\"context_tk_ev\"]\n",
    "    DFRES.loc[inds, \"context_tk_ev_simple_diff_tk\"] = \"diff\"\n",
    "    \n",
    "    # Append column with the test \"event x \"task kind\". \n",
    "    DFRES = append_col_with_grp_index(DFRES, [\"task_kind_test\", \"event_test\"], \"tk_ev_test\", strings_compact=True)\n",
    "    DFRES = append_col_with_grp_index(DFRES, [\"task_kind_train\", \"event_train\"], \"tk_ev_train\", strings_compact=True)\n",
    "    \n",
    "    grouping_print_n_samples(DFRES, [\"context_tk_ev_simple\", \"context_tk_ev\", \"task_kind_train\", \"task_kind_test\", \"event_train\", \"event_test\"]);\n",
    "    \n",
    "    # for TIME_TRAIN_REL_TEST in [0.125, 0.175, 0.225]:\n",
    "    for TIME_TRAIN_REL_TEST in [0.175]:\n",
    "        for TIME_WIND_TEST_REL_EVENT in [\n",
    "                                    # [-0.5, 0.5],\n",
    "                                    # [-0.3, 0.4],\n",
    "                                    [-0.4, -0.025],\n",
    "                                    [0.025, 0.4],\n",
    "                                ]:\n",
    "            #             TIME_TRAIN_REL_TEST = 0.175\n",
    "            # TIME_WIND_TEST_REL_EVENT = [-0.3, 0.4]\n",
    "    \n",
    "            ##### Convert to scalar by taking mean over time bins\n",
    "            # criterion for time bins\n",
    "            def F(x):\n",
    "                # relative time\n",
    "                a = np.abs(x[\"time_train\"] - x[\"time_test\"]) < TIME_TRAIN_REL_TEST\n",
    "                # absolute time\n",
    "                b = (x[\"time_test\"] >= TIME_WIND_TEST_REL_EVENT[0]) & (x[\"time_test\"] <= TIME_WIND_TEST_REL_EVENT[1])\n",
    "                return a & b\n",
    "            DFRES = applyFunctionToAllRows(DFRES, F, \"keep_tbin\")\n",
    "        \n",
    "            # Print results\n",
    "            if False:\n",
    "                grouping_print_n_samples(DFRES, [\"keep_tbin\", \"time_train\", \"time_test\"])\n",
    "            \n",
    "            for INCLUDE_PIG in [True, False]:\n",
    "                for EXCLUDE_FIRST_STROKE in [True, False]:\n",
    "                    \n",
    "                    ####################### PRUNE DATA TO JUST TIME BINS OF INTEREST\n",
    "                    DFRES_THIS = DFRES.copy()\n",
    "                    \n",
    "                    print(len(DFRES))\n",
    "                    # Prune to just those with tbins to keep\n",
    "                    DFRES_THIS = DFRES_THIS[DFRES_THIS[\"keep_tbin\"]==True]\n",
    "                    print(len(DFRES_THIS))\n",
    "                    \n",
    "                    # Remove those with CONTEXT ignore.\n",
    "                    DFRES_THIS = DFRES_THIS[DFRES_THIS[\"context_tk_ev\"] != \"IGNORE\"]\n",
    "                    print(len(DFRES_THIS))\n",
    "                    \n",
    "                    if INCLUDE_PIG==False:\n",
    "                        # Only include data that is single prims or character (since PIG is low N).\n",
    "                        DFRES_THIS = DFRES_THIS[(DFRES_THIS[\"task_kind_train\"].isin([\"prims_single\", \"character\"])) & (DFRES_THIS[\"task_kind_test\"].isin([\"prims_single\", \"character\"]))]\n",
    "                    \n",
    "                    # Remove cases that are the high N stroke nums, they are usualyl noise\n",
    "                    events_keep = [f\"06_on_STK_{i}\" for i in range(N_STROKES_MAX)]\n",
    "                    print(len(DFRES_THIS))\n",
    "                    DFRES_THIS = DFRES_THIS[(DFRES_THIS[\"event_train\"].isin(events_keep)) & (DFRES_THIS[\"event_test\"].isin(events_keep))]\n",
    "                    print(len(DFRES_THIS))\n",
    "                    \n",
    "                    if EXCLUDE_FIRST_STROKE:\n",
    "                        DFRES_THIS = DFRES_THIS[~(DFRES_THIS[\"event_train\"]==\"06_on_STK_0\") & ~(DFRES_THIS[\"event_test\"]==\"06_on_STK_0\")]\n",
    "                    \n",
    "                    #################################### Aggregate to average over time bins\n",
    "                    from pythonlib.tools.pandastools import aggregGeneral\n",
    "                    DFRES_THIS = aggregGeneral(DFRES_THIS, [\"var_decode\", \"bregion\", \"event_train\", \"event_test\", \"task_kind_train\", \"task_kind_test\", \n",
    "                                                            \"context_tk_ev\", \"context_tk_ev_simple\", \"context_tk_ev_simple_diff_tk\",\n",
    "                                                            \"keep_tbin\", \"tk_ev_test\", \"tk_ev_train\"], values=[\"score\", \"score_adjusted\"])\n",
    "                    \n",
    "                    DFRES_THIS = DFRES_THIS.reset_index(drop=True)\n",
    "                    \n",
    "                    #################################### PLOTS\n",
    "                    a = TIME_TRAIN_REL_TEST\n",
    "                    b = \"_\".join([str(x) for x in TIME_WIND_TEST_REL_EVENT])\n",
    "                    savedir = f\"{SAVEDIR_LOAD}/3_cross_temporal_split_by_contexts_scalar/inclPIG={INCLUDE_PIG}-excldFrstStk={EXCLUDE_FIRST_STROKE}-TRelTest={a}-TWindRelEv={b}\"\n",
    "            \n",
    "                    os.makedirs(savedir, exist_ok=True)\n",
    "                    \n",
    "                    if \"diff\" in DFRES_THIS[\"context_tk_ev_simple\"].tolist():\n",
    "                        # Sometimes pruning leads to loss of all data...\n",
    "                        \n",
    "                        dfthis = DFRES[DFRES[\"bregion\"]==DFRES[\"bregion\"].values[0]] # pick out a subsample --> smaler plots.\n",
    "                        fig = sns.relplot(data=dfthis, x=\"time_train\", y=\"time_test\", col=\"keep_tbin\")\n",
    "                        savefig(fig, f\"{savedir}/time_bins.pdf\")\n",
    "                        \n",
    "                        for ctxt_diff in [\"same_tk_diff_ev\", \"diff_tk_same_ev\", \"diff_tk_diff_ev\"]:\n",
    "                            if ctxt_diff in DFRES_THIS[\"context_tk_ev\"].tolist():\n",
    "                                _, fig = plot_45scatter_means_flexible_grouping(DFRES_THIS, var_manip=\"context_tk_ev\", x_lev_manip=\"same\", y_lev_manip=ctxt_diff, var_subplot=\"var_decode\", var_value=\"score_adjusted\", var_datapt=\"bregion\")\n",
    "                                savefig(fig, f\"{savedir}/scatter-same-vs-{ctxt_diff}.pdf\")\n",
    "                                plt.close(\"all\")\n",
    "                        \n",
    "                        # just \"same\" vs \"diff\" (combining all diff).\n",
    "                        _, fig = plot_45scatter_means_flexible_grouping(DFRES_THIS, var_manip=\"context_tk_ev_simple\", x_lev_manip=\"same\", y_lev_manip=\"diff\", var_subplot=\"var_decode\", var_value=\"score_adjusted\", var_datapt=\"bregion\")\n",
    "                        savefig(fig, f\"{savedir}/scatter-same-vs-diff.pdf\")\n",
    "                        plt.close(\"all\")\n",
    "                        \n",
    "                        if \"diff\" in DFRES_THIS[\"context_tk_ev_simple_diff_tk\"].tolist():\n",
    "                            _, fig = plot_45scatter_means_flexible_grouping(DFRES_THIS, var_manip=\"context_tk_ev_simple_diff_tk\", x_lev_manip=\"same\", y_lev_manip=\"diff\", var_subplot=\"var_decode\", var_value=\"score_adjusted\", var_datapt=\"bregion\")\n",
    "                            savefig(fig, f\"{savedir}/scatter-same-vs-diff_task_kind.pdf\")\n",
    "                            plt.close(\"all\")\n",
    "                        \n",
    "                        # Separate subplot for each bregion.\n",
    "                        for var_datapt in [\"tk_ev_train\", \"tk_ev_test\"]:\n",
    "                            _, fig = plot_45scatter_means_flexible_grouping(DFRES_THIS, var_manip=\"context_tk_ev_simple\", x_lev_manip=\"same\", y_lev_manip=\"diff\",    var_subplot=\"bregion\", var_value=\"score_adjusted\", var_datapt=var_datapt, plot_error_bars = False, shareaxes=True)\n",
    "                            savefig(fig, f\"{savedir}/scatter_by_bregion-same-vs-diff-datapt={var_datapt}.pdf\")\n",
    "                                                \n",
    "                            plt.close(\"all\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33c97d6655d46653"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
