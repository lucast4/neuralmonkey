{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\"\"\"\"\n",
    "Devo code for all kinds of state space plotting, especially things like dPCA and tsne.\n",
    "\n",
    "NOTE: previously dPCA plots:\n",
    "- 240128_snippets_demixed_PCA\n",
    "- analy_dpca_plot_script.py [More general purpose]\n",
    "- analyquick_dpca_script_substrokes [Focusing on substrokes]\n",
    "(Here, try to consolidate all of these things)\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9e3fd17c4f13ba43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load a prviously saved DFallPA\n",
    "(This saving is only done by hand)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f471c575413735b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d72addf5c1494c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "1"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ecf74e7e4d033fe7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# this is the path to the dataset\n",
    "# path = '/gorilla1/analyses/recordings/main/RSA/Diego-230615/agg_True-subtr_None-dist_euclidian_unbiased/SP_shape_loc/DFallpa.pkl'\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa.pkl\"\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_samp_and_stroke.pkl\"\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_pig_planning.pkl\"\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_pig_concat_trial_and_stroke_which_levels.pkl\"\n",
    "# path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_char_concat_trial_and_stroke_Pancho_230126.pkl\"\n",
    "path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_shape_loc_Pancho_220715.pkl\"\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "320be7d5ecbddf5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFallpa = pd.read_pickle(path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "335e4da034da5b2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make sure to normalize PA before running any modeling on it:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5ba36bb2b0d2e09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_panorm = []\n",
    "for pa in DFallpa[\"pa\"].tolist():\n",
    "    from neuralmonkey.analyses.state_space_good import popanal_preprocess_scalar_normalization\n",
    "    PAnorm, PAscal, PAscalagg, fig, axes, groupdict = popanal_preprocess_scalar_normalization(pa, None, DO_AGG_TRIALS=False)\n",
    "    list_panorm.append(PAnorm)\n",
    "DFallpa[\"pa\"] = list_panorm\n",
    "\n",
    "# del DFallpa[\"pa_norm\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "689c9ae42f06ba72"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate a DFallpa (from Snippets)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "122e1e23ec6b587"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Char, \n",
    "# animal = \"Pancho\"\n",
    "# date = 230126\n",
    "# do_combine = True\n",
    "\n",
    "# Single prim, novels\n",
    "animal = \"Diego\"\n",
    "# date = 221220\n",
    "date = 230630\n",
    "do_combine = False\n",
    "\n",
    "if do_combine:\n",
    "    # COMBINE trial and stroke\n",
    "    dir_suffix = \"test\"\n",
    "    question = None\n",
    "    # q_params = None\n",
    "    which_level = None\n",
    "    q_params = {\n",
    "        \"effect_vars\": [\"seqc_0_shape\", \"seqc_0_loc\"]\n",
    "    }\n",
    "    \n",
    "    combine_trial_and_stroke = True\n",
    "    \n",
    "    # PIG\n",
    "    # question_trial = \"PIG_BASE_trial\"\n",
    "    # question_stroke = \"PIG_BASE_stroke\"\n",
    "    # check_that_locs_match = True\n",
    "    \n",
    "    # CHAR\n",
    "    question_trial = \"CHAR_BASE_trial\"\n",
    "    question_stroke = \"CHAR_BASE_stroke\"\n",
    "    check_that_locs_match = True\n",
    "    check_that_shapes_match = True\n",
    "else:\n",
    "    # DONT COMBINE, use questions.\n",
    "    # question = \"CHAR_BASE_trial\"\n",
    "    question = \"PIG_BASE_trial\"\n",
    "    # question = \"SP_novel_shape\"\n",
    "    # question = \"SP_shape_loc\"\n",
    "    # question = \"SP_shape_size\"\n",
    "    combine_trial_and_stroke = False\n",
    "    which_level = \"trial\" # Doesnt matter\n",
    "    dir_suffix = question\n",
    "\n",
    "    # Load q_params\n",
    "    from neuralmonkey.analyses.rsa import rsagood_questions_dict, rsagood_questions_params\n",
    "    q_params = rsagood_questions_dict(animal, date, question)[question]\n",
    "\n",
    "############### PARAMS\n",
    "exclude_bad_areas = True\n",
    "SPIKES_VERSION = \"tdt\" # since Snippets not yet extracted for ks\n",
    "combine_into_larger_areas = False\n",
    "HACK_RENAME_SHAPES = False\n",
    "list_time_windows = [(-0.6, 0.6)]\n",
    "\n",
    "########################################## RUN\n",
    "\n",
    "if combine_trial_and_stroke:\n",
    "    from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper_combine_trial_strokes\n",
    "    DFallpa = dfallpa_extraction_load_wrapper_combine_trial_strokes(animal, date, question_trial,\n",
    "                                                                       question_stroke,\n",
    "                                                list_time_windows,\n",
    "                                               combine_into_larger_areas = combine_into_larger_areas,\n",
    "                                               exclude_bad_areas=exclude_bad_areas,\n",
    "                                                SPIKES_VERSION=\"tdt\",\n",
    "                                                HACK_RENAME_SHAPES = HACK_RENAME_SHAPES,\n",
    "                                               do_fr_normalization=True,\n",
    "                                                    check_that_shapes_match=check_that_shapes_match,\n",
    "                                                check_that_locs_match=check_that_locs_match)\n",
    "else:\n",
    "    from neuralmonkey.classes.population_mult import dfallpa_extraction_load_wrapper\n",
    "    DFallpa = dfallpa_extraction_load_wrapper(animal, date, question, list_time_windows,\n",
    "                                              which_level=which_level,\n",
    "                                              combine_into_larger_areas = combine_into_larger_areas,\n",
    "                                              exclude_bad_areas = exclude_bad_areas,\n",
    "                                              SPIKES_VERSION = SPIKES_VERSION,\n",
    "                                              HACK_RENAME_SHAPES = HACK_RENAME_SHAPES,\n",
    "                                              do_fr_normalization=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58ea6f5073b3909f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### To save DFallPA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b2b88d538f5c517"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save it\n",
    "import pickle\n",
    "path = \"/gorilla4/Dropbox/SCIENCE/FREIWALD_LAB/DATA/for_xuan/DFallpa_shape_loc_Pancho_220715.pkl\"\n",
    "with open(path, \"wb\") as f:\n",
    "    pickle.dump(DFallpa, f)\n",
    "print(\"Saved to:\", path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee1acb5baa6a83b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pythonlib.globals import PATH_ANALYSIS_OUTCOMES\n",
    "import os\n",
    "SAVEDIR_ANALYSIS = f\"{PATH_ANALYSIS_OUTCOMES}/recordings/main/statespacegood\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cab933058cb251a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PREPROCESS - factorize all relevant labels FIRST here.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8634a855e2b24c5a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_good import preprocess_factorize_class_labels_ints\n",
    "MAP_LABELS_TO_INT = preprocess_factorize_class_labels_ints(DFallpa)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87e0da3ce5099d79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [TESTING] State space plots (tsne)\n",
    "NOTE: previously have dPCA plots..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71caf94b369f4732"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocess PA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7cbf24855fd542"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Extract information about the first stroke (semantic labels)\n",
    "locations_allpa =[]\n",
    "angles_allpa =[]\n",
    "list_i_j = []\n",
    "for i, pa in enumerate(DFallpa[\"pa\"]):\n",
    "    dflab = pa.Xlabels[\"trials\"]\n",
    "    \n",
    "    list_seqc_0_shsem = []\n",
    "    list_seqc_0_locon = []\n",
    "    for j, row in dflab.iterrows():\n",
    "        \n",
    "        # To get semantic label for shape, use task token\n",
    "        Tk = row[\"Tkbeh_stktask\"]\n",
    "        Tk.features_extract_wrapper(features_get=[\"shape_semantic\"])\n",
    "        list_seqc_0_shsem.append(Tk.Tokens[0][\"shape_semantic\"])\n",
    "        \n",
    "        # To get motoro stuff\n",
    "        Tk = row[\"Tkbeh_stkbeh\"]\n",
    "        Tk.features_extract_wrapper(features_get=[\"loc_on\", \"angle_on\"])\n",
    "        list_seqc_0_locon.append(Tk.Tokens[0][\"loc_on\"])\n",
    "\n",
    "        # Collect acorss pa\n",
    "        locations_allpa.append(Tk.Tokens[0][\"loc_on\"])\n",
    "        angles_allpa.append(Tk.Tokens[0][\"angle_on\"])\n",
    "        list_i_j.append((i,j))\n",
    "        \n",
    "    dflab[\"seqc_0_shsem\"] = list_seqc_0_shsem\n",
    "    dflab[\"seqc_0_locon\"] = list_seqc_0_locon\n",
    "    dflab[\"seqc_0_locx\"] = np.array(list_seqc_0_locon)[:,0]\n",
    "    dflab[\"seqc_0_locy\"] = np.array(list_seqc_0_locon)[:,1]\n",
    "    \n",
    "    \n",
    "# BIN LOCATIONS\n",
    "from pythonlib.tools.nptools import bin_values_by_rank\n",
    "# Given list of locations, bin them in x and y\n",
    "import numpy as np\n",
    "tmp = np.stack(locations_allpa)\n",
    "xs = tmp[:,0]\n",
    "ys = tmp[:,1]\n",
    "\n",
    "xs_binned = bin_values_by_rank(xs, nbins=2)\n",
    "ys_binned = bin_values_by_rank(ys, nbins=2)\n",
    "locations_allpa_binned = np.stack([xs_binned, ys_binned], axis=1)\n",
    "# map from (i,j) to locations_binned\n",
    "map_ij_to_locbinned ={}\n",
    "assert len(list_i_j)==len(locations_allpa_binned)\n",
    "for (i,j), loc_binned in zip(list_i_j, locations_allpa_binned):\n",
    "    map_ij_to_locbinned[(i,j)] = loc_binned\n",
    "# Place back into pa\n",
    "colname = \"seqc_0_loconbinned\"\n",
    "for i, pa in enumerate(DFallpa[\"pa\"]):\n",
    "    dflab = pa.Xlabels[\"trials\"]\n",
    "    vals = []\n",
    "    for j, row in dflab.iterrows():\n",
    "        vals.append(tuple(map_ij_to_locbinned[(i,j)].tolist()))\n",
    "    dflab[colname] = vals \n",
    "\n",
    "# BIN ANGLES\n",
    "from pythonlib.tools.vectools import bin_angle_by_direction\n",
    "angles_binned = bin_angle_by_direction(angles_allpa, num_angle_bins=4)\n",
    "\n",
    "map_ij_to_anglebinned ={}\n",
    "map_ij_to_angle ={}\n",
    "assert len(list_i_j)==len(angles_binned)\n",
    "for (i,j), ab, a in zip(list_i_j, angles_binned, angles_allpa):\n",
    "    map_ij_to_anglebinned[(i,j)] = ab\n",
    "    map_ij_to_angle[(i,j)] = a\n",
    "    \n",
    "# Place back into pa\n",
    "colname = \"seqc_0_anglebinned\"\n",
    "for i, pa in enumerate(DFallpa[\"pa\"]):\n",
    "    dflab = pa.Xlabels[\"trials\"]\n",
    "    vals = []\n",
    "    for j, row in dflab.iterrows():\n",
    "        vals.append(map_ij_to_anglebinned[(i,j)])\n",
    "    dflab[colname] = vals \n",
    "\n",
    "colname = \"seqc_0_angle\"\n",
    "for i, pa in enumerate(DFallpa[\"pa\"]):\n",
    "    dflab = pa.Xlabels[\"trials\"]\n",
    "    vals = []\n",
    "    for j, row in dflab.iterrows():\n",
    "        vals.append(map_ij_to_angle[(i,j)])\n",
    "    dflab[colname] = vals \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "482a8ae56d0dbd6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get angle as continuous variable, not just binned\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9457ed55d8194bb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dflab.loc[:, [\"seqc_0_locon\", \"seqc_0_loconbinned\", \"seqc_0_anglebinned\"]]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b18c8fb9fd5c19a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dflab[\"seqc_0_loconbinned\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38f4e1924ff45daf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper functions for tsne"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b180e7e080543da4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.state_space_good import dimredgood_nonlinear_embed_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ee0493aa271f88d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import umap.plot\n",
    "umap.plot.points(mapper, labels=dflab[\"seqc_0_shape\"], theme=\"fire\")\n",
    "import umap.plot\n",
    "umap.plot.points(mapper, labels=dflab[\"seqc_0_shape\"], theme=\"fire\")\n",
    "umap.plot.connectivity(mapper, show_points=True, edge_bundling='hammer')\n",
    "umap.plot.diagnostic(mapper, diagnostic_type='pca')\n",
    "\n",
    "# p = umap.plot.interactive(mapper, labels=dflab[\"seqc_0_shape\"], hover_data=hover_data, point_size=2)\n",
    "p = umap.plot.interactive(mapper, labels=dflab[\"seqc_0_shape\"], point_size=2)\n",
    "umap.plot.show(p)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65b7b12ab549d969"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb229d71872cc976"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.state_space_good import trajgood_construct_df_from_raw, trajgood_plot_colorby_splotby, trajgood_plot_colorby_splotby_scalar\n",
    "from pythonlib.tools.pandastools import append_col_with_grp_index\n",
    "from pythonlib.tools.plottools import savefig\n",
    "from pythonlib.globals import PATH_ANALYSIS_OUTCOMES\n",
    "import os\n",
    "\n",
    "### PARAMS\n",
    "tbin_dur = 0.1\n",
    "tbin_slide = 0.1\n",
    "reshape_method = \"ntrials_x_nchans_ntimes\"\n",
    "animal = \"Pancho\"\n",
    "date = 220715\n",
    "SAVEDIR_ANALYSIS = f\"{PATH_ANALYSIS_OUTCOMES}/recordings/main/STATE_SPACE_GENERAL/{animal}-{date}\"\n",
    "RES = []\n",
    "\n",
    "for i, row in DFallpa.iterrows():\n",
    "    pa = row[\"pa\"]\n",
    "    br = row[\"bregion\"]\n",
    "    wl = row[\"which_level\"]\n",
    "    ev = row[\"event\"]\n",
    "    tw = row[\"twind\"]\n",
    "\n",
    "    # print(br, wl, ev, tw)\n",
    "    # # if br==\"vlPFC_p\" and ev==\"03_samp\":\n",
    "    # # if br==\"PMd_a\" and ev==\"03_samp\":\n",
    "    # # if br==\"M1_m\" and ev==\"06_on_strokeidx_0\":\n",
    "    # if br==\"PMv_m\" and ev==\"03_samp\":\n",
    "    # # if br==\"PMv_m\" and ev==\"06_on_strokeidx_0\":\n",
    "    #     print(\"GOOD\")\n",
    "    #     break\n",
    "    \n",
    "    if ev==\"03_samp\":\n",
    "        list_twind_overall = [\n",
    "            [0.2, 0.6]\n",
    "        ]\n",
    "    elif ev==\"06_on_strokeidx_0\":\n",
    "        list_twind_overall = [\n",
    "            [-0.4, 0],\n",
    "            [0, 0.4]\n",
    "        ]\n",
    "    else:\n",
    "        print(ev)\n",
    "        assert False\n",
    "        \n",
    "    # if br==\"PMv_m\" and ev==\"06_on_strokeidx_0\":\n",
    "    for twind_overall in list_twind_overall:\n",
    "                \n",
    "        # Extract data\n",
    "        X, pathis = pa.dataextract_state_space_decode_flex(twind_overall, tbin_dur, tbin_slide, reshape_method)\n",
    "        dflab = pathis.Xlabels[\"trials\"]\n",
    "        dflab = append_col_with_grp_index(dflab, [\"seqc_0_shape\", \"seqc_0_loc\"], \"seqc_0_shapeloc\")\n",
    "\n",
    "        STROKES_BEH = [tk.Tokens[0][\"Prim\"].Stroke() for tk in dflab[\"Tkbeh_stkbeh\"]]\n",
    "        STROKES_TASK = [tk.Tokens[0][\"Prim\"].Stroke() for tk in dflab[\"Tkbeh_stktask\"]] \n",
    "        \n",
    "        # Embed data\n",
    "        for METHOD in [\"umap\", \"tsne\"]:\n",
    "            Xredu = dimredgood_nonlinear_embed_data(X, METHOD=METHOD, n_components=2, tsne_perp=\"auto\", umap_n_neighbors=\"auto\")\n",
    "                \n",
    "            ##### Plot scalars\n",
    "            savedir = f\"{SAVEDIR_ANALYSIS}/{br}-{ev}-twind={'_'.join([str(t) for t in twind_overall])}-METHOD={METHOD}\"\n",
    "            print(savedir)\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "            \n",
    "            # List of plots to make\n",
    "            list_var_color_var_subplot = [\n",
    "                [\"seqc_0_shape\", \"seqc_0_loc\"],\n",
    "                [\"seqc_0_loc\", \"seqc_0_shape\"],\n",
    "                [\"seqc_0_locx\", \"seqc_0_shape\"],\n",
    "                [\"seqc_0_locy\", \"seqc_0_shape\"],\n",
    "                [\"seqc_0_angle\", \"seqc_0_shape\"],\n",
    "                [\"seqc_0_angle\", \"seqc_0_loc\"],\n",
    "                [\"seqc_0_shape\", \"seqc_0_anglebinned\"],\n",
    "                [\"seqc_0_shape\", \"shape_is_novel_all\"]]\n",
    "            \n",
    "            if False:\n",
    "                ##### Create meaned data to plot\n",
    "                effect_vars = [\"seqc_0_shape\", \"seqc_0_loc\", \"shape_is_novel_all\", \"seqc_0_shsem\", \"seqc_0_loconbinned\", \"seqc_0_anglebinned\"]\n",
    "                pathis_meaned = pathis.slice_and_agg_wrapper(\"trials\", effect_vars)\n",
    "            \n",
    "\n",
    "            for var_color, var_subplot in list_var_color_var_subplot:\n",
    "                xs = Xredu[:,0]\n",
    "                ys = Xredu[:,1]\n",
    "                labels_color = dflab[var_color].tolist()\n",
    "                # text_to_plot = labels_color\n",
    "                text_to_plot = None\n",
    "                labels_subplot = dflab[var_subplot].tolist()\n",
    "                fig, axes, map_levo_to_ax, map_levo_to_inds = trajgood_plot_colorby_splotby_scalar(xs, ys, labels_color, labels_subplot, var_color, \n",
    "                                                                       var_subplot, SIZE=7,\n",
    "                                                                       overlay_mean=True, text_to_plot=text_to_plot,\n",
    "                                                                       STROKES_BEH=STROKES_BEH, STROKES_TASK=STROKES_TASK)\n",
    "                savefig(fig, f\"{savedir}/color={var_color}-sub={var_subplot}.pdf\")\n",
    "                plt.close(\"all\")\n",
    "            assert False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5661157fd6b4d14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - collect all --> 1 figure for each bregion, etc.\n",
    "# - Other datasets:\n",
    "# - novel prims\n",
    "# ---- sim structure\n",
    "# ---- novel cluster together?\n",
    "# - shape vs. size\n",
    "# - PIG\n",
    "# - char"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63e28aa3a1d46b95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Plot overlaying stroke drawing associated with each shape [DONE, moved above]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "100e7ad223a94768"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract strokes\n",
    "# from pythonlib.tools.stroketools import strokes_alignonset, strokes_centerize\n",
    "import matplotlib.pyplot as plt\n",
    "# strokes_ver = \"beh\"\n",
    "STROKES_BEH = [tk.Tokens[0][\"Prim\"].Stroke() for tk in dflab[\"Tkbeh_stkbeh\"]]\n",
    "STROKES_TASK = [tk.Tokens[0][\"Prim\"].Stroke() for tk in dflab[\"Tkbeh_stktask\"]] \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "394e050a583bf261"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b36ed80d214f45a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xs = Xredu[:,0]\n",
    "ys = Xredu[:,1]\n",
    "labels_color = dflab[var_color].tolist()\n",
    "labels_color = np.random.rand(len(xs))\n",
    "# text_to_plot = labels_color\n",
    "text_to_plot = None\n",
    "labels_subplot = dflab[var_subplot].tolist()\n",
    "\n",
    "fig, axes, map_levo_to_ax, map_levo_to_inds = trajgood_plot_colorby_splotby_scalar(xs, ys, labels_color, labels_subplot, var_color, var_subplot, SIZE=7,\n",
    "                                                       overlay_mean=True, text_to_plot=text_to_plot,\n",
    "                                                                                          STROKES_BEH=STROKES_BEH, STROKES_TASK=STROKES_TASK)\n",
    "\n",
    "# from pythonlib.tools.pandastools import grouping_append_and_return_inner_items\n",
    "# grpdict = grouping_append_and_return_inner_items(dflab, [var_color, var_subplot])\n",
    "# levels_var_color = dflab[var_color].unique().tolist()\n",
    "# \n",
    "# for strokes, align_to, pcol in [\n",
    "#     [STROKES_BEH, \"onset\", \"k\"],\n",
    "#     [STROKES_TASK, \"center\", \"m\"]\n",
    "# ]:\n",
    "#     if False:\n",
    "#         # Overlay nplot random strokes\n",
    "#         ax = axes.flatten()[0]\n",
    "#         nplot = 40\n",
    "#         overlay_stroke_on_plot_mult_rand(strokes, xs, ys, nplot, align_to)\n",
    "#     \n",
    "#     # Overlay random strokes, sampling within each level of labels_color\n",
    "#     nplot = 4\n",
    "#     for levo, ax in map_levo_to_ax.items():\n",
    "#         for lev in levels_var_color:\n",
    "#             inds = grpdict[lev, levo]\n",
    "#             overlay_stroke_on_plot_mult_rand([strokes[i] for i in inds], xs[inds], ys[inds], nplot, align_to, color=pcol)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c6f38ad8d9df3e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def overlay_stroke_on_plot_mult_rand(strokes, xs, ys, nrand=10, align_to=\"onset\", color=None):\n",
    "    import random\n",
    "\n",
    "    inds = range(len(strokes))\n",
    "\n",
    "    if len(inds)>nrand:\n",
    "        inds = random.sample(inds, nrand)\n",
    "\n",
    "    for i in inds:\n",
    "        strok = strokes[i][:, :2]\n",
    "        # times = strokes[i][:, 2]\n",
    "        x = xs[i]\n",
    "        y = ys[i]\n",
    "        overlay_stroke_on_plot(strok, x, y, ax, align_to=align_to, color=color)\n",
    "        \n",
    "\n",
    "def overlay_stroke_on_plot(strok, x, y, ax, SIZE = 0.05, align_to=\"onset\", color=None):\n",
    "    \"\"\"\n",
    "    PARAMS:\n",
    "    - SIZE, frac of screen to make the size of the strok.\n",
    "    \"\"\"\n",
    "    \n",
    "    if color is None:\n",
    "        color=\"k\"\n",
    "    from pythonlib.tools.stroketools import strokes_bounding_box_dimensions\n",
    "    # Get dimensions of figure, so can correctly scale stroke\n",
    "    XLIM = ax.get_xlim()\n",
    "    YLIM = ax.get_ylim()\n",
    "    xdiff = XLIM[1] - XLIM[0]\n",
    "    ydiff = YLIM[1] - YLIM[0]\n",
    "    d_ax = (xdiff**2 + ydiff**2)**0.5 \n",
    "        \n",
    "    # Decide if align at onset (beh) or center (task)\n",
    "    from pythonlib.tools.stroketools import strokes_alignonset, strokes_centerize\n",
    "    import matplotlib.pyplot as plt\n",
    "    if align_to == \"onset\":\n",
    "        strok = strokes_alignonset([strok])[0]\n",
    "    elif align_to == \"center\":\n",
    "        strok = strokes_centerize([strok])[0]\n",
    "    elif align_to is None:\n",
    "        pass\n",
    "    else:\n",
    "        print(align_to)\n",
    "        assert False\n",
    "            \n",
    "    # Rescale stroke\n",
    "    w, h, d = strokes_bounding_box_dimensions([strok])\n",
    "    rescale = SIZE * d_ax/d \n",
    "    aspect = [1, ydiff/xdiff] \n",
    "    strok = strok * rescale # rescale to page\n",
    "    strok = strok * aspect # to make sure strok aspect is visually accurate\n",
    "    strok = strok + [x,y] # move to location\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(strok[:,0], strok[:,1], '-', alpha=0.7, color=color)\n",
    "    # ax.scatter(strok[:,0], strok[:,1], c=times)\n",
    "    # if align_to==\"onset\":\n",
    "    ax.plot(x, y, 'o', mfc=\"none\", alpha=0.4, color=color)\n",
    "        \n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dc99c242dd6ba70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1f6af75370067d4b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ced8070283eb5fc3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dflab[\"Tkbeh_stktask\"].values[0].Tokens[0][\"Prim\"].Stroke()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d63c1f3da705578"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ed70cb45100dbf31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load DS for this animal on this day\n",
    " # Load a daily dataset\n",
    "from pythonlib.dataset.dataset import load_dataset_notdaily_helper, load_dataset_daily_helper\n",
    "\n",
    "D = load_dataset_daily_helper(animal, date)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5be507e9b0b0cf95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pythonlib.dataset.dataset_strokes import preprocess_dataset_to_datstrokes, DatStrokes\n",
    "# DS = DatStrokes(D)\n",
    "DS = preprocess_dataset_to_datstrokes(D, \"all_no_abort_superv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31f4f5eec6b85dd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_n_by_dist = 15\n",
    "DS.distgood_compute_beh_task_strok_distances()\n",
    "dfdat = DS.features_generate_dataset_mean_primshape(\"shape\", best_n_by_dist=best_n_by_dist)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b16bbec61e35e241"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shape = \"novelprim--6288514134535433462-90-3.4-0.9\"\n",
    "inds = DS.find_indices_this_shape(shape)\n",
    "titles = [DS.stroke_shape_align_flip_vs_task(i) for i in inds] \n",
    "DS.plot_multiple_overlay_entire_trial(inds, overlay_beh_or_task=\"task\", titles=titles);\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e7de60142adb3d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Given a shape, extract strokes and task\n",
    "shape = \"circle-67-6.0-0.4\"\n",
    "n = 5\n",
    "inds = DS.find_indices_this_shape(shape)\n",
    "# pick n random inds\n",
    "import random\n",
    "inds = random.sample(inds, n)\n",
    "\n",
    "strokes_beh = DS.extract_strokes(inds=inds, ver_behtask=\"beh\")\n",
    "strokes_task = DS.extract_strokes(inds=inds, ver_behtask=\"task_aligned_single_strok\")\n",
    "\n",
    "# for all beh, align to stroke onset\n",
    "from pythonlib.tools.stroketools import strokes_alignonset\n",
    "import matplotlib.pyplot as plt\n",
    "strokes_beh = strokes_alignonset(strokes_beh)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "XLIM = ax.get_xlim()\n",
    "YLIM = ax.get_ylim()\n",
    "xdiff = XLIM[1] - XLIM[0]\n",
    "ydiff = YLIM[1] - YLIM[0]\n",
    "strokes_beh = [[x, y] + strok[:,:2] * xdiff/ydiff for strok in strokes_beh]\n",
    "# strok[:,0] =  strok[:,0] * xdiff/ydiff # so it looks correct even if aspect is not 1\n",
    "# strok = strok + loc # move to new locatin\n",
    "\n",
    "# plot at that location, starting from strok onset\n",
    "for strok in strokes_beh:\n",
    "    ax.plot(strok[:,0], strok[:,1], '-')\n",
    "    ax.plot(strok[0,0], strok[0,1], 'ok')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4826712bec638f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pythonlib.drawmodel.strokePlots import plotDatStrokes\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "plotDatStrokes([strok], ax)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4ec64262926ccf4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# var_color = \"seqc_0_shape\"\n",
    "var_color = \"seqc_0_anglebinned\"\n",
    "# var_color = \"seqc_0_loconbinned\"\n",
    "var_subplot = \"shape_is_novel_all\"\n",
    "\n",
    "xs = Xtsne[:,0]\n",
    "ys = Xtsne[:,1]\n",
    "labels_color = dflab[var_color].tolist()\n",
    "labels_subplot = dflab[var_subplot].tolist()\n",
    "fig, axes= trajgood_plot_colorby_splotby_scalar(xs, ys, labels_color, labels_subplot, var_color, var_subplot, SIZE=7,\n",
    "                                                       overlay_mean=False, text_to_plot=labels_color,\n",
    "                                                       strokes_to_overlay=strokes_to_overlay)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10ed1d2a2e66b80b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dflab[\"seqc_0_shape\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18f18620d2778e7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shapes = dflab[\"shap\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4026ae8a1a3f9ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DS.Version"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f87b2de3749e4a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pa.Xlabels[\"trials\"].keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb93a5b4cacbf6fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4a6cfb6c4293c652"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4b511e1910e3b9ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xs = Xtsne[:,0]\n",
    "ys = Xtsne[:,1]\n",
    "labels_color = dflab[var_color].tolist()\n",
    "labels_subplot = dflab[var_subplot].tolist()\n",
    "fig, axes= trajgood_plot_colorby_splotby_scalar(xs, ys, labels_color, labels_subplot, var_color, var_subplot, SIZE=4);"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d7075693910d547"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot, subsampling to N trials for each level"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad312bb52aa3aa66"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Plot trajectories"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ba29a09ec74405b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# INPUT PARAMS\n",
    "var_color_by = \"seqc_0_shape\"\n",
    "var_subplots = \"seqc_0_loc\"\n",
    "\n",
    "# Runs\n",
    "# 1) Construct dataframe\n",
    "# df = pa.dataextract_split_by_label_grp_for_statespace(grpvars)\n",
    "grpvars = [var_color_by, var_subplots]\n",
    "labels = pa.Xlabels[\"trials\"].loc[:, grpvars] \n",
    "labelvars = grpvars\n",
    "df = trajgood_construct_df_from_raw(X, pa.Times, labels, labelvars)\n",
    "\n",
    "# 2) Plot\n",
    "dims = (2,3) # pairs of dimensions to plot\n",
    "times_to_mark = [0.] # you can mark specific times on the plot. here marks the 0. sec mark.\n",
    "times_to_mark_markers = [\"d\"] # mark with a diamond (\"d\")\n",
    "time_bin_size = 0.05 # to make plot easier to visaulize, you can bin in time.\n",
    "trajgood_plot_colorby_splotby(df, var_color_by, var_subplots, dims, \"traj\", mean_over_trials=True,\n",
    "                              times_to_mark = times_to_mark, times_to_mark_markers = times_to_mark_markers,\n",
    "                              time_bin_size=time_bin_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51328ddb4886799d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bregion = \"PMv_m\"\n",
    "twind = (-0.6, 0.6)\n",
    "event = \"03_samp\"\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24898f5ac3d1da42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DFallpa"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a904a066922e8a09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
