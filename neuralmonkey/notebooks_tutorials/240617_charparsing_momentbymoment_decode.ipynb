{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d5b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\"\"\n",
    "Devo code for moment by moment decoding --> i.e., for each time bin, find strength of representation of\n",
    "each class of a variable (e.g., shape), as opposed to decoding average accuracy across trials.\n",
    "\n",
    "\n",
    "Here collecting methods and quick analyses\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833bb0a",
   "metadata": {},
   "source": [
    "### A note on how shapes are represented in chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7000ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY:\n",
    "# seqc_{i}_shapesem and seqc_{i}_shapesemgrp are same between char and SP/PIG.\n",
    "# seqc_{i}_shape is NOT the same between SP/PIG (it uses ground-truth shape labels) and char (it uses charclust labels).\n",
    "\n",
    "# SP/PIG (it uses ground-truth shape labels) and char (it uses charclust labels), therefore matches on semantic\n",
    "\n",
    "# EXAMPLES:\n",
    "# (1) PIG/SP tasks during char day\n",
    "# ---> \n",
    "\n",
    "# A SP trial where the charclust label (top) differs from the ground-truth label (bottom)\n",
    "# ============== beh_using_beh_data\n",
    "# shape  --  ['Lcentered-4-1-0']\n",
    "# shape_semantic  --  ['Lcentered-UL-UL']\n",
    "# gridloc  --  [(1, 1)]\n",
    "# seqc_{i}_shape: ['zigzagSq-92-3.5-0.5']\n",
    "# seqc_{i}_shapesem: ['zigzagSq-UU-0.0']\n",
    "# seqc_{i}_shapesemgrp: ['ZZ-UU-0.0']\n",
    "# ============== beh_using_task_data\n",
    "# shape  --  ['zigzagSq-92-3.5-0.5']\n",
    "# shape_semantic  --  ['zigzagSq-UU-0.0']\n",
    "# gridloc  --  [(1, 1)]\n",
    "# seqc_{i}_shape: ['zigzagSq-92-3.5-0.5']\n",
    "# seqc_{i}_shapesem: ['zigzagSq-UU-0.0']\n",
    "# seqc_{i}_shapesemgrp: ['ZZ-UU-0.0']\n",
    "\n",
    "# A CHAR trial\n",
    "# ============== beh_using_beh_data\n",
    "# shape  --  ['line-8-2-0', 'squiggle3-3-1-1', 'arcdeep-4-3-0', 'line-8-1-0']\n",
    "# shape_semantic  --  ['line-UU-UU', 'squiggle3-UU-0.0', 'arcdeep-RR-RR', 'line-LL-LL']\n",
    "# gridloc  --  [('IGN', 'IGN'), ('IGN', 'IGN'), ('IGN', 'IGN'), ('IGN', 'IGN')]\n",
    "# seqc_{i}_shape: ['line-8-2-0', 'squiggle3-3-1-1', 'arcdeep-4-3-0', 'line-8-1-0']\n",
    "# seqc_{i}_shapesem: ['line-UU-UU', 'squiggle3-UU-0.0', 'arcdeep-RR-RR', 'line-LL-LL']\n",
    "# seqc_{i}_shapesemgrp: ['line-UU-UU', 'ZZ-UU-0.0', 'ARC-RR', 'line-LL-LL']\n",
    "# ============== beh_using_task_data\n",
    "# shape  --  ['line-8-2-0', 'squiggle3-3-1-1', 'arcdeep-4-3-0', 'line-8-1-0']\n",
    "# shape_semantic  --  ['line-UU-UU', 'squiggle3-UU-0.0', 'arcdeep-RR-RR', 'line-LL-LL']\n",
    "# gridloc  --  [('IGN', 'IGN'), ('IGN', 'IGN'), ('IGN', 'IGN'), ('IGN', 'IGN')]\n",
    "# seqc_{i}_shape: ['line-8-2-0', 'squiggle3-3-1-1', 'arcdeep-4-3-0', 'line-8-1-0']\n",
    "# seqc_{i}_shapesem: ['line-UU-UU', 'squiggle3-UU-0.0', 'arcdeep-RR-RR', 'line-LL-LL']\n",
    "# seqc_{i}_shapesemgrp: ['line-UU-UU', 'ZZ-UU-0.0', 'ARC-RR', 'line-LL-LL']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50813ff4",
   "metadata": {},
   "source": [
    "# Load a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf10d0",
   "metadata": {},
   "source": [
    "To load and plot a dataset of neural activity across population, in a PopAnal class object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_match_chans_across_pa_each_bregion\n",
    "from neuralmonkey.classes.population_mult import extract_single_pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6345314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 - load a single DFallPA\n",
    "DFallpa = load_handsaved_wrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c98009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 - load a single DFallPA\n",
    "DFallpa = load_handsaved_wrapper(animal=\"Pancho\", date=230623, version=\"trial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 - Combine two dfallpa\n",
    "animal = \"Diego\"\n",
    "date = 231130\n",
    "COMBINE_AREAS = True\n",
    "\n",
    "DFallpa1 = load_handsaved_wrapper(animal=animal, date=date, version=\"trial\", combine_areas=COMBINE_AREAS, use_time=True)\n",
    "DFallpa2 = load_handsaved_wrapper(animal=animal, date=date, version=\"stroke\", combine_areas=COMBINE_AREAS, use_time=True)\n",
    "DFallpa = pd.concat([DFallpa1, DFallpa2]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = DFallpa[\"pa\"].values[0]\n",
    "dflab = pa.Xlabels[\"trials\"]\n",
    "dflab[\"seqc_0_shapesemgrp\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c05c1",
   "metadata": {},
   "source": [
    "# Sanity checks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b672bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cdccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_pig_decode_moment_syntaxTI import dfallpa_preprocess_condition\n",
    "dfallpa_preprocess_condition(DFallpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ab1b9",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f373551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import load_handsaved_wrapper, dfpa_match_chans_across_pa_each_bregion\n",
    "from neuralmonkey.classes.population_mult import extract_single_pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ba91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prune to chans that are common across pa for each bregion (intersection of chans)|\n",
    "dfpa_match_chans_across_pa_each_bregion(DFallpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34978a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = f\"/lemur2/lucas/analyses/recordings/main/decode_moment/CHAR/{animal}-{date}\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359b451",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e793d5",
   "metadata": {},
   "source": [
    "##### Devo -- removing noisy channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daefb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfpa_concatbregion_preprocess_clean_bad_channels\n",
    "dfpa_concatbregion_preprocess_clean_bad_channels(DFallpa, PLOT=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15877d2",
   "metadata": {},
   "source": [
    "# Sqrt normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pa in DFallpa[\"pa\"]:\n",
    "    pa.X = pa.X**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94d963",
   "metadata": {},
   "source": [
    "### FR Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54ffdc",
   "metadata": {},
   "source": [
    "##### Method 1 - each PA normalize independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfallpa_preprocess_fr_normalization\n",
    "# fr_normalization_method = \"each_time_bin\"\n",
    "fr_normalization_method = \"across_time_bins\"\n",
    "plot_savedir = \"/tmp\"\n",
    "dfallpa_preprocess_fr_normalization(DFallpa, fr_normalization_method, plot_savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282ffe4",
   "metadata": {},
   "source": [
    "##### Method 2 - Concat events (for each bregion) and normalize all same way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91505d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfpa_concat_normalize_fr_split_multbregion\n",
    "# fr_normalization_method = \"each_time_bin\"\n",
    "fr_normalization_method = \"across_time_bins\"\n",
    "dfpa_concat_normalize_fr_split_multbregion(DFallpa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad140e2f",
   "metadata": {},
   "source": [
    "##### Method 3 - concat events (flexible version, only constrianed to have same n chans across PA) [works if have both trial and stroke!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.classes.population_mult import dfpa_concat_normalize_fr_split_multbregion_flex\n",
    "fr_mean_subtract_method = \"across_time_bins\"\n",
    "# fr_mean_subtract_method = \"each_time_bin\"\n",
    "PLOT=False\n",
    "\n",
    "pa = DFallpa[\"pa\"].values[10]\n",
    "pa.plotNeurHeat(0)\n",
    "\n",
    "dfpa_concat_normalize_fr_split_multbregion_flex(DFallpa, fr_mean_subtract_method, PLOT)\n",
    "\n",
    "pa = DFallpa[\"pa\"].values[10]\n",
    "pa.plotNeurHeat(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba2ed2",
   "metadata": {},
   "source": [
    "### Factorize all relevant labels FIRST here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d396bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Ingore this for now\n",
    "    from neuralmonkey.analyses.decode_good import preprocess_factorize_class_labels_ints\n",
    "    MAP_LABELS_TO_INT = preprocess_factorize_class_labels_ints(DFallpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c9cf9",
   "metadata": {},
   "source": [
    "# Extract relevant variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd76772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.scripts.analy_pig_decode_moment_syntaxTI import dfallpa_preprocess_condition\n",
    "shape_var_suff = \"shapesemgrp\"\n",
    "loc_var_suff = \"loc_on_clust\"\n",
    "dfallpa_preprocess_condition(DFallpa, shape_var_suff, loc_var_suff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257fa5de",
   "metadata": {},
   "source": [
    "# Train - test of decoder (on char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ee422",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = f\"/lemur2/lucas/analyses/recordings/main/decode_moment/CHAR/{animal}-{date}/v2\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f93319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for pa in DFallpa[\"pa\"]:\n",
    "    print(\"her\")\n",
    "    assert not np.any(np.isnan(pa.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f800cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_moment import analy_chars_score_postsamp, analy_chars_dfscores_condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b255c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analy_chars_score_postsamp(DFallpa, SAVEDIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab389576",
   "metadata": {},
   "source": [
    "# DEVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: all of these are in analy_chars_score_postsamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078863e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_moment import train_decoder_helper, pipeline_train_test_scalar_score, pipeline_train_test_scalar_score_mult_train_dataset, test_decoder_helper, train_decoder_helper_extract_train_dataset\n",
    "from neuralmonkey.scripts.analy_pig_decode_moment_syntaxTI import get_dataset_params\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "bregion = \"vlPFC\"\n",
    "SAVEDIR = \"/tmp\"\n",
    "classifier_version = \"logistic\"\n",
    "# classifier_version = \"ensemble\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard coded params:\n",
    "include_null_data = False\n",
    "n_min_per_var = 3\n",
    "subtract_baseline=False\n",
    "subtract_baseline_twind=(-0.45, -0.05)\n",
    "PLOT = True\n",
    "\n",
    "### Test params\n",
    "# - post-samp\n",
    "# test_dataset = \"char_samp_post\"\n",
    "# var_test = \"seqc_1_shapesemgrp\"\n",
    "\n",
    "test_dataset = \"char_samp_post\"\n",
    "var_test = \"seqc_0_shapesemgrp\"\n",
    "\n",
    "######### TRAINING PARAMS\n",
    "list_train_dataset = [\"sp_samp\", \"pig_samp\", \"sp_pig_pre_stroke_all\"]\n",
    "list_var_train = [\"seqc_0_shapesemgrp\", \"seqc_0_shapesemgrp\", \"shape_semantic_grp\"]\n",
    "save_suff = \"|\".join(list_train_dataset)\n",
    "\n",
    "# list_train_dataset = [\"sp_samp\", \"pig_samp\"]\n",
    "# list_var_train = [\"seqc_0_shapesemgrp\", \"seqc_0_shapesemgrp\"]\n",
    "# save_suff = \"|\".join(list_train_dataset)\n",
    "\n",
    "# Extract some params\n",
    "list_bregion = DFallpa[\"bregion\"].unique().tolist()\n",
    "event_test, _, filterdict_test, list_twind_test, which_level_test = get_dataset_params(test_dataset)\n",
    "\n",
    "# Other params\n",
    "savedir = f\"{SAVEDIR}/traindata={save_suff}-testdata={test_dataset}/{bregion}/decoder_training_mult\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "print(savedir)\n",
    "\n",
    "dfscores, Dc, PAtrain, PAtest = pipeline_train_test_scalar_score_mult_train_dataset(DFallpa, bregion, \n",
    "                                    list_train_dataset, list_var_train, \n",
    "                                    var_test, event_test, list_twind_test, filterdict_test, \n",
    "                                    which_level_test, savedir, include_null_data, \n",
    "                                    prune_labels_exist_in_train_and_test=True, PLOT=PLOT, n_min_per_var=n_min_per_var,\n",
    "                                    subtract_baseline=subtract_baseline, subtract_baseline_twind=subtract_baseline_twind,\n",
    "                                    classifier_version=classifier_version)\n",
    "\n",
    "# APPEND info related to trials.\n",
    "dflab = PAtest.Xlabels[\"trials\"]\n",
    "dfscores = analy_chars_dfscores_condition(dfscores, dflab)\n",
    "\n",
    "# list_decoder_class_idx_in_shapes_drawn = []\n",
    "# list_decoder_class_was_drawn = []\n",
    "# list_decoder_class_was_seen = []\n",
    "# list_decoder_class_was_first_drawn = []\n",
    "\n",
    "# for _i, row in dfscores.iterrows():\n",
    "\n",
    "#     decoder_class = row[\"decoder_class\"]\n",
    "#     pa_idx = row[\"pa_idx\"]\n",
    "#     trialcode = row[\"trialcode\"]\n",
    "#     epoch = row[\"epoch\"]\n",
    "\n",
    "#     shapes_drawn = dflab.iloc[pa_idx][\"shapes_drawn\"]\n",
    "#     FEAT_num_strokes_beh = dflab.iloc[pa_idx][\"FEAT_num_strokes_beh\"]\n",
    "#     # shapes_visible = dflab.iloc[pa_idx][\"taskconfig_shp\"]\n",
    "#     if decoder_class in shapes_drawn:\n",
    "#         decoder_class_idx_in_shapes_drawn = shapes_drawn.index(decoder_class)\n",
    "#     else:\n",
    "#         decoder_class_idx_in_shapes_drawn = -1\n",
    "    \n",
    "#     assert FEAT_num_strokes_beh==len(shapes_drawn)\n",
    "#     assert decoder_class_idx_in_shapes_drawn<FEAT_num_strokes_beh\n",
    "    \n",
    "#     list_decoder_class_idx_in_shapes_drawn.append(decoder_class_idx_in_shapes_drawn)\n",
    "#     list_decoder_class_was_drawn.append(decoder_class in shapes_drawn)\n",
    "#     # list_decoder_class_was_seen.append(decoder_class in shapes_visible)\n",
    "#     list_decoder_class_was_first_drawn.append(decoder_class == shapes_drawn[0])\n",
    "    \n",
    "# dfscores[\"decoder_class_idx_in_shapes_drawn\"] = list_decoder_class_idx_in_shapes_drawn\n",
    "# dfscores[\"decoder_class_was_drawn\"] = list_decoder_class_was_drawn\n",
    "# # dfscores[\"decoder_class_was_seen\"] = list_decoder_class_was_seen\n",
    "# dfscores[\"decoder_class_was_first_drawn\"] = list_decoder_class_was_first_drawn\n",
    "\n",
    "# dfscores[\"FEAT_num_strokes_beh\"] = [dflab.iloc[pa_idx][\"FEAT_num_strokes_beh\"] for pa_idx in dfscores[\"pa_idx\"]]\n",
    "# dfscores[\"bregion\"] = bregion\n",
    "\n",
    "\n",
    "# # Normalize decode by subtracting mean within each decoder class\n",
    "# from pythonlib.tools.pandastools import datamod_normalize_row_after_grouping_return_same_len_df\n",
    "# dfscores, _, _ = datamod_normalize_row_after_grouping_return_same_len_df(dfscores, \"decoder_class_was_drawn\", \n",
    "#                                                                         [\"decoder_class\"], \"score\", False, True, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c6c28",
   "metadata": {},
   "source": [
    "##### [Good] pull out chars that have multiple parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_moment import _analy_chars_score_postsamp_same_image_diff_parse\n",
    "_analy_chars_score_postsamp_same_image_diff_parse(dfscores, \"/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bbebe7",
   "metadata": {},
   "source": [
    "### Plot timecourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep shapes that have decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af397dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b33e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_moment import _analy_chars_score_postsamp_plot_timecourse\n",
    "_analy_chars_score_postsamp_plot_timecourse(Dc, PAtest, savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ad914",
   "metadata": {},
   "source": [
    "# Trial by trial correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481da64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86579a",
   "metadata": {},
   "source": [
    "### Quantify --> entropy over shapes at start and end of planning period [TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c34fe7",
   "metadata": {},
   "source": [
    "# Split trials by similar or different image distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e975486",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"/tmp/image_distances\"\n",
    "os.makedirs(savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49919c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_moment import _analy_chars_score_postsamp_timecourse_splitby_image_distance\n",
    "_analy_chars_score_postsamp_timecourse_splitby_image_distance(Dc, PAtest, animal, date, savedir, twind_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d757823b",
   "metadata": {},
   "source": [
    "# Euclidian distances between pairs of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d35ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmonkey.analyses.decode_moment import _analy_chars_score_postsamp_image_distance_neural_distance\n",
    "savedir = \"/tmp/eucl\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "_analy_chars_score_postsamp_image_distance_neural_distance(PAtest, var_test, animal, date, savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ad231",
   "metadata": {},
   "source": [
    "##### Method 2 -- datapt = char. [OBSOLETE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM -- need to compare cases matching first shape drawn -- or else PMv effects are dominated by that.\n",
    "# Instead, just use pairs of trials, above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558778d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Datapt = char\n",
    "res = []\n",
    "for i, char1 in enumerate(list_char):\n",
    "    for j, char2 in enumerate(list_char):\n",
    "        if j>i:\n",
    "\n",
    "            # Get neural distance\n",
    "            dist_neural = Cl.index_find_dat_by_label((char1,), (char2,))\n",
    "\n",
    "            # Get shape distance\n",
    "            dist_shape = shape_distance_compute(dflab, char1, char2)\n",
    "\n",
    "            # Get image distance\n",
    "            dist_image = distance_mat[i, j]\n",
    "\n",
    "            res.append({\n",
    "                \"dist_neural\":dist_neural,\n",
    "                \"dist_shape\":dist_shape,\n",
    "                \"dist_image\":dist_image,\n",
    "                \"char1\":char1,\n",
    "                \"char2\":char2,\n",
    "                \"i_char\":i,\n",
    "                \"j_char\":j,\n",
    "                \"n_strokes_char1\":map_char_to_n_drawn_strokes[char1],\n",
    "                \"n_strokes_char2\":map_char_to_n_drawn_strokes[char2]\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1938a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = pd.DataFrame(res)\n",
    "dfres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66270b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres[\"n_strokes_char1_binned\"] = pd.cut(dfres[\"n_strokes_char1\"], 4)\n",
    "dfres[\"n_strokes_char2_binned\"] = pd.cut(dfres[\"n_strokes_char2\"], 4)\n",
    "\n",
    "dfres[\"dist_shape_binned\"] = pd.cut(dfres[\"dist_shape\"], 6)\n",
    "dfres[\"dist_image_binned\"] = pd.cut(dfres[\"dist_image\"], 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08460750",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=dfres, x=\"dist_image_binned\", y=\"dist_neural\", hue=\"dist_shape_binned\", kind=\"point\", \n",
    "            col=\"n_strokes_char1_binned\", row=\"n_strokes_char2_binned\")\n",
    "\n",
    "sns.catplot(data=dfres, x=\"dist_shape_binned\", y=\"dist_neural\", hue=\"dist_image_binned\", kind=\"point\", \n",
    "            col=\"n_strokes_char1_binned\", row=\"n_strokes_char2_binned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres[\"dist_shape\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59732b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.relplot(data=dfres, x=\"dist_shape\", y=\"dist_neural\", alpha=0.1, col=\"n_strokes_char1_binned\", row=\"n_strokes_char2_binned\", height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ae8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=dfres, x=\"dist_shape\", y=\"dist_neural\", col=\"n_strokes_char1_binned\", row=\"n_strokes_char2_binned\", \n",
    "            height=5, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract slices of data with high and low image and shape distance\n",
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de19ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.relplot(data=dfres, x=\"dist_image\", y=\"dist_neural\", alpha=0.1, col=\"n_strokes_char1_binned\", row=\"n_strokes_char2_binned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a0db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32e155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a56d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cl.rsa_dataextract_with_labels_as_flattened_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0925a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5994de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(Cl.Xinput.flatten(), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd83b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAtest.dataextract_as_distance_matrix_clusters_flex()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
